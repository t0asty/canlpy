<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 12.0.2"/>
    <title>canlpy.core.models.ernie.model API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../ernie.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;canlpy.core.models.ernie</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



        <h2>API Documentation</h2>
            <ul class="memberlist">
            <li>
                    <a class="class" href="#ErnieConfig">ErnieConfig</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieConfig.__init__">ErnieConfig</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieConfig.load_from_json">load_from_json</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieConfig.to_json_string">to_json_string</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieConfig.to_dict">to_dict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PreTrainedErnieModel">PreTrainedErnieModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PreTrainedErnieModel.__init__">PreTrainedErnieModel</a>
                        </li>
                        <li>
                                <a class="function" href="#PreTrainedErnieModel.init_weights">init_weights</a>
                        </li>
                        <li>
                                <a class="function" href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieModel">ErnieModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieModel.__init__">ErnieModel</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieModel.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForMaskedLM">ErnieForMaskedLM</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForMaskedLM.__init__">ErnieForMaskedLM</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForMaskedLM.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForPreTraining">ErnieForPreTraining</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForPreTraining.__init__">ErnieForPreTraining</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForPreTraining.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForNextSentencePrediction.__init__">ErnieForNextSentencePrediction</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForNextSentencePrediction.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForEntityTyping">ErnieForEntityTyping</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForEntityTyping.__init__">ErnieForEntityTyping</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForEntityTyping.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForSTSB">ErnieForSTSB</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForSTSB.__init__">ErnieForSTSB</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForSTSB.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForSequenceClassification">ErnieForSequenceClassification</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForSequenceClassification.__init__">ErnieForSequenceClassification</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForSequenceClassification.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForNQ">ErnieForNQ</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForNQ.__init__">ErnieForNQ</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForNQ.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ErnieForQuestionAnswering">ErnieForQuestionAnswering</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ErnieForQuestionAnswering.__init__">ErnieForQuestionAnswering</a>
                        </li>
                        <li>
                                <a class="function" href="#ErnieForQuestionAnswering.forward">forward</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../../../canlpy.html">canlpy</a><wbr>.<a href="./../../../core.html">core</a><wbr>.<a href="./../../models.html">models</a><wbr>.<a href="./../ernie.html">ernie</a><wbr>.model    </h1>

                
                        <input id="model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="model-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="kn">import</span> <span class="nn">typing</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span><span class="n">Dict</span><span class="p">,</span><span class="n">Tuple</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="kn">import</span> <span class="nn">json</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="kn">import</span> <span class="nn">math</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="n">BCEWithLogitsLoss</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a><span class="kn">import</span> <span class="nn">logging</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a><span class="kn">import</span> <span class="nn">canlpy.core.models.bert.model</span> <span class="k">as</span> <span class="nn">bert</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a><span class="kn">from</span> <span class="nn">canlpy.core.models.bert.model</span> <span class="kn">import</span> <span class="n">BertEmbeddings</span><span class="p">,</span> <span class="n">BertPooler</span><span class="p">,</span> <span class="n">LayerNorm</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="kn">from</span> <span class="nn">canlpy.core.models.ernie.components</span> <span class="kn">import</span> <span class="n">ErnieLayer</span><span class="p">,</span> <span class="n">ErnieLayerMix</span><span class="p">,</span><span class="n">ErnieEncoder</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a><span class="kn">from</span> <span class="nn">canlpy.core.components.heads</span> <span class="kn">import</span> <span class="n">BertOnlyMLMHead</span><span class="p">,</span><span class="n">BertOnlyNSPHead</span><span class="p">,</span><span class="n">ErniePreTrainingHeads</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a><span class="n">CONFIG_NAME</span> <span class="o">=</span> <span class="s1">&#39;ernie_config.json&#39;</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a><span class="n">WEIGHTS_NAME</span> <span class="o">=</span> <span class="s1">&#39;pytorch_model.bin&#39;</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a><span class="n">MAPPING_FILE</span> <span class="o">=</span> <span class="s1">&#39;mapping.json&#39;</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a><span class="k">class</span> <span class="nc">ErnieConfig</span><span class="p">():</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a><span class="sd">    Configuration class to store the configuration of an `ErnieModel`.</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a>                 <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a>                 <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a>                 <span class="n">entity_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a>                 <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a>                 <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>                 <span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a>                 <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a>                 <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a>                 <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>                 <span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a>                 <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a>                 <span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>                 <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a>                 <span class="n">layer_types</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a><span class="sd">        Constructs ErnieConfig.</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a><span class="sd">        Args:</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a><span class="sd">            vocab_size: Vocabulary size of `inputs_ids` in `ErnieModel`.</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a><span class="sd">            hidden_size: Size of the encoder layers and the pooler layer.</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a><span class="sd">            entity_size: Size of the entity embeddings,</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a><span class="sd">            num_hidden_layers: Number of hidden layers in the Transformer encoder.</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a><span class="sd">            num_attention_heads: Number of attention heads for each attention layer in</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a><span class="sd">                the Transformer encoder for the tokens.</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a><span class="sd">            num_attention_heads_ent: Number of attention heads for each attention layer in</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a><span class="sd">                the Transformer encoder for the entities.</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a><span class="sd">            intermediate_size: The size of the &quot;intermediate&quot; (i.e., feed-forward)</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a><span class="sd">                layer in the Transformer encoder.</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a><span class="sd">            hidden_act: The non-linear activation function (function or string) in the</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a><span class="sd">                encoder and pooler. If string, &quot;gelu&quot;, &quot;relu&quot; and &quot;swish&quot; are supported.</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a><span class="sd">            hidden_dropout_prob: The dropout probabilitiy for all fully connected</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a><span class="sd">                layers in the embeddings, encoder, and pooler.</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a><span class="sd">            attention_probs_dropout_prob: The dropout ratio for the attention</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a><span class="sd">                probabilities.</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a><span class="sd">            max_position_embeddings: The maximum sequence length that this model might</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a><span class="sd">                ever be used with. Typically set this to something large just in case</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a><span class="sd">                (e.g., 512 or 1024 or 2048).</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a><span class="sd">            type_vocab_size: The vocabulary size of the `token_type_ids` passed into</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a><span class="sd">                `ErnieModel`.</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a><span class="sd">            initializer_range: The sttdev of the truncated_normal_initializer for</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a><span class="sd">                initializing all weight matrices.</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a><span class="sd">            layer_types: list() of ErnieEncoders which can be &#39;sim&#39; (Bert encoder), </span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a><span class="sd">            &#39;mix&#39; (Ernie encoder but no multihead attention for entities) or &#39;norm&#39; (standard Ernie encoder)</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">entity_size</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads_ent</span> <span class="o">=</span> <span class="n">num_attention_heads_ent</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span> <span class="c1">#Stores a string</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dropout_prob</span> <span class="o">=</span> <span class="n">hidden_dropout_prob</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span> <span class="o">=</span> <span class="n">attention_probs_dropout_prob</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_vocab_size</span> <span class="o">=</span> <span class="n">type_vocab_size</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="n">layer_types</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a>       
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>    <span class="k">def</span> <span class="nf">load_from_json</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span><span class="n">path</span><span class="p">):</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>        <span class="sd">&quot;&quot;&quot;Loads and returns a config class from a json file located at path&quot;&quot;&quot;</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="c1">#Create default config</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a>            <span class="n">json_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">json_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a>                <span class="n">config</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>        <span class="k">return</span> <span class="n">config</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_json_string</span><span class="p">())</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a>    <span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a JSON string.&quot;&quot;&quot;</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a>        
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a Python dictionary.&quot;&quot;&quot;</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a>    
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a><span class="k">class</span> <span class="nc">PreTrainedErnieModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>    <span class="sd">&quot;&quot;&quot; </span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a><span class="sd">    An abstract class to handle weights initialization and</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a><span class="sd">        a simple interface for downloading and loading pretrained models.</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">ErnieConfig</span><span class="p">):</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a>                <span class="s2">&quot;Parameter config in `</span><span class="si">{}</span><span class="s2">(config)` should be an instance of class `ErnieConfig`. &quot;</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a>                <span class="s2">&quot;To create a model from a Google pretrained model use &quot;</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a>                <span class="s2">&quot;`model = </span><span class="si">{}</span><span class="s2">.from_pretrained(PRETRAINED_MODEL_NAME)`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a>                <span class="p">))</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>        <span class="sd">&quot;&quot;&quot; </span>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a><span class="sd">        Initialize the weights.</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a>        <span class="n">bert</span><span class="o">.</span><span class="n">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dir_path</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a><span class="sd">        Instantiate a PreTrainedErnieModel from a pre-trained model file or a pytorch state dict.</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a><span class="sd">        Args:</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a><span class="sd">            dir_path:</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a><span class="sd">                - a path to a pretrained model archive containing:</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a><span class="sd">                    . `ernie_config.json`: a configuration file for the model</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a><span class="sd">                    . `pytorch_model.bin`: a PyTorch dump of a ErnieForPreTraining instance</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a><span class="sd">                    .  `mapping.json`: an Optional file to remap the weights from the pre-trained weights to this implementation </span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a><span class="sd">            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of the PyTorch dump</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a><span class="sd">            *inputs, **kwargs: additional input for the specific Ernie class</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a><span class="sd">                (ex: num_labels for ErnieForSequenceClassification)</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a><span class="sd">        Returns:</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a><span class="sd">            The loaded pretrained model</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a>        
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a>        <span class="c1"># Load config</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a>        <span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">CONFIG_NAME</span><span class="p">)</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">ErnieConfig</span><span class="o">.</span><span class="n">load_from_json</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">state_dict</span><span class="o">==</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a>            <span class="n">weights_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a>            <span class="k">if</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span><span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>        <span class="n">missing_keys</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a>        <span class="c1"># copy state_dict so _load_from_state_dict can modify it</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>        <span class="n">metadata</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="s1">&#39;_metadata&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>        
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a>        <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>            <span class="n">state_dict</span><span class="o">.</span><span class="n">_metadata</span> <span class="o">=</span> <span class="n">metadata</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>        <span class="n">mapping_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">MAPPING_FILE</span><span class="p">)</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">)):</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>                <span class="n">mapping</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a>            <span class="k">for</span> <span class="n">old_key</span><span class="p">,</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>                <span class="k">if</span><span class="p">(</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()):</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a>                    <span class="n">model_shape</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">new_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>                    <span class="k">if</span><span class="p">(</span><span class="n">model_shape</span><span class="o">!=</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;model.state_dict() </span><span class="si">{</span><span class="n">new_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">model_shape</span><span class="si">}</span><span class="s1"> != state_dict </span><span class="si">{</span><span class="n">old_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>                        
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>                <span class="n">state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>        <span class="n">missing_keys</span><span class="p">,</span><span class="n">unexpected_keys</span> <span class="o">=</span>  <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Missing keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">missing_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">missing_keys</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a><span class="k">class</span> <span class="nc">ErnieModel</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a><span class="sd">    Ernie model</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a><span class="sd">    Params:</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a><span class="sd">        config: an ErnieConfig class instance with the configuration to build a new model</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a><span class="sd">    Args:</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a><span class="sd">        `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a><span class="sd">    Returns: Tuple of (encoded_layers, pooled_output)</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a><span class="sd">        `encoded_layers`: controled by `output_all_encoded_layers` argument:</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a><span class="sd">            - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a><span class="sd">                of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a><span class="sd">                encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a><span class="sd">            - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a><span class="sd">                to the last attention block of shape [batch_size, sequence_length, hidden_size],</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a><span class="sd">        `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a><span class="sd">             classifier pretrained on top of the hidden state associated to the first character of the</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a><span class="sd">             input (`CLS`) to train on the Next-Sentence task (see BERT&#39;s paper).</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a><span class="sd">    Example usage:</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a><span class="sd">    ```python</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a><span class="sd">    # Already been converted into WordPiece token ids</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a><span class="sd">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a><span class="sd">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a><span class="sd">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a><span class="sd">    input_ent: shape(1,6,100)</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a><span class="sd">    ent_mask: torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a><span class="sd">    config = modeling.ErnieConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a><span class="sd">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a><span class="sd">    model = modeling.ErnieModel(config=config)</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a><span class="sd">    all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask, input_ent, ent_mask)</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a><span class="sd">    ```</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">type_vocab_size</span><span class="p">)</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="o">=</span> <span class="n">BertPooler</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>        <span class="k">if</span> <span class="n">token_type_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>            <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a>        <span class="c1"># We create a 3D attention mask from a 2D tensor mask.</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>        <span class="c1"># Sizes are [batch_size, 1, 1, to_seq_length]</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a>        <span class="c1"># So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a>        <span class="c1"># this attention mask is more simple than the triangular masking of causal attention</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a>        <span class="c1"># used in OpenAI GPT, we just need to prepare the broadcast dimension here.</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a>        <span class="c1"># Since attention_mask is 1.0 for positions we want to attend and 0.0 for</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a>        <span class="c1"># masked positions, this operation will create a tensor which is 0.0 for</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a>        <span class="c1"># positions we want to attend and -10000.0 for masked positions.</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a>        <span class="c1"># Since we are adding it to the raw scores before the softmax, this is</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>        <span class="c1"># effectively the same as removing these entirely.</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">extended_ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_ent_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a>        <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>        <span class="n">encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">,</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>                                      <span class="n">extended_attention_mask</span><span class="p">,</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>                                      <span class="n">input_ent</span><span class="p">,</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>                                      <span class="n">extended_ent_mask</span><span class="p">,</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a>                                      <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a>                                      <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a>            <span class="n">encoded_layers</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a>        <span class="k">return</span> <span class="n">encoded_layers</span><span class="p">,</span> <span class="n">pooled_output</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a><span class="c1">#Specific ERNIE models</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a><span class="k">class</span> <span class="nc">ErnieForMaskedLM</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a><span class="sd">    Ernie model with the masked language modeling head.</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a><span class="sd">    This module comprises the Ernie model followed by the masked language modeling head.</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a><span class="sd">    Params:</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a><span class="sd">    Args:</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos">305</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos">306</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos">307</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos">308</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos">309</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos">310</span></a><span class="sd">        `masked_lm_labels`: masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos">311</span></a><span class="sd">            with indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos">312</span></a><span class="sd">            is only computed for the labels set in [0, ..., vocab_size]</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos">313</span></a>
</span><span id="L-314"><a href="#L-314"><span class="linenos">314</span></a><span class="sd">    Returns:</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos">315</span></a><span class="sd">        if `masked_lm_labels` is `None`:</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos">316</span></a><span class="sd">            Outputs the masked language modeling loss.</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos">317</span></a><span class="sd">        if `masked_lm_labels` is `None`:</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos">318</span></a><span class="sd">            Outputs the masked language modeling logits of shape [batch_size, sequence_length, vocab_size].</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos">319</span></a>
</span><span id="L-320"><a href="#L-320"><span class="linenos">320</span></a><span class="sd">    Example usage:</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos">321</span></a><span class="sd">    ```python</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos">322</span></a><span class="sd">    # Already been converted into WordPiece token ids</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos">323</span></a><span class="sd">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos">324</span></a><span class="sd">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos">325</span></a><span class="sd">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos">326</span></a><span class="sd">    input_ent: shape(1,6,100)</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos">327</span></a><span class="sd">    ent_mask: torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos">328</span></a>
</span><span id="L-329"><a href="#L-329"><span class="linenos">329</span></a><span class="sd">    config = ErnieConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos">330</span></a><span class="sd">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos">331</span></a>
</span><span id="L-332"><a href="#L-332"><span class="linenos">332</span></a><span class="sd">    model = ErnieForMaskedLM(config)</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos">333</span></a><span class="sd">    masked_lm_logits_scores = model(input_ids, token_type_ids, input_mask,input_ent,ent_mask)</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos">334</span></a><span class="sd">    ```</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos">335</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos">336</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos">337</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos">338</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos">339</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="L-340"><a href="#L-340"><span class="linenos">340</span></a>        <span class="c1">#Recursively initalize all the weights</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos">341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos">342</span></a>
</span><span id="L-343"><a href="#L-343"><span class="linenos">343</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos">344</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="L-345"><a href="#L-345"><span class="linenos">345</span></a>                                       <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos">346</span></a>        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos">347</span></a>
</span><span id="L-348"><a href="#L-348"><span class="linenos">348</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos">349</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos">350</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos">351</span></a>            <span class="k">return</span> <span class="n">masked_lm_loss</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos">352</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos">353</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos">354</span></a>
</span><span id="L-355"><a href="#L-355"><span class="linenos">355</span></a><span class="k">class</span> <span class="nc">ErnieForPreTraining</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos">356</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos">357</span></a><span class="sd">    Ernie model with pre-training heads.</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos">358</span></a><span class="sd">    This module comprises the Ernie model followed by the two pre-training heads:</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos">359</span></a><span class="sd">        - the masked language modeling head, and</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos">360</span></a><span class="sd">        - the next sentence classification head.</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos">361</span></a>
</span><span id="L-362"><a href="#L-362"><span class="linenos">362</span></a><span class="sd">    Params:</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos">363</span></a><span class="sd">        config: an ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos">364</span></a>
</span><span id="L-365"><a href="#L-365"><span class="linenos">365</span></a><span class="sd">    Args:</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos">366</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos">367</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos">368</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos">369</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos">370</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos">371</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos">372</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos">373</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos">374</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos">375</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos">376</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-377"><a href="#L-377"><span class="linenos">377</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos">378</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-379"><a href="#L-379"><span class="linenos">379</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos">380</span></a><span class="sd">        `masked_lm_labels`: masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos">381</span></a><span class="sd">            with indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos">382</span></a><span class="sd">            is only computed for the labels set in [0, ..., vocab_size]</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos">383</span></a><span class="sd">        `next_sentence_label`: next sentence classification loss: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos">384</span></a><span class="sd">            with indices selected in [0, 1].</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos">385</span></a><span class="sd">            0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos">386</span></a>
</span><span id="L-387"><a href="#L-387"><span class="linenos">387</span></a><span class="sd">    Returns:</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos">388</span></a><span class="sd">        if `masked_lm_labels` and `next_sentence_label` are not `None`:</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos">389</span></a><span class="sd">            Outputs the total_loss which is the sum of the masked language modeling loss and the next</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos">390</span></a><span class="sd">            sentence classification loss.</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos">391</span></a><span class="sd">        if `masked_lm_labels` or `next_sentence_label` is `None`:</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos">392</span></a><span class="sd">            Outputs a tuple comprising</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos">393</span></a><span class="sd">            - the masked language modeling logits of shape [batch_size, sequence_length, vocab_size], and</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos">394</span></a><span class="sd">            - the next sentence classification logits of shape [batch_size, 2].</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos">395</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos">396</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos">397</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos">398</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos">399</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">ErniePreTrainingHeads</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos">400</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos">401</span></a>
</span><span id="L-402"><a href="#L-402"><span class="linenos">402</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
</span><span id="L-403"><a href="#L-403"><span class="linenos">403</span></a>        <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">candidate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos">404</span></a>        <span class="c1"># the id in ent_labels should be consistent with the order of candidate.</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos">405</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos">406</span></a>                                                   <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos">407</span></a>        <span class="n">prediction_scores</span><span class="p">,</span> <span class="n">seq_relationship_score</span><span class="p">,</span> <span class="n">prediction_scores_ent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span><span class="p">,</span> <span class="n">candidate</span><span class="p">)</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos">408</span></a>
</span><span id="L-409"><a href="#L-409"><span class="linenos">409</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">next_sentence_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos">410</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos">411</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos">412</span></a>            <span class="n">next_sentence_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">seq_relationship_score</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">next_sentence_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos">413</span></a>            <span class="n">ent_ae_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores_ent</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">candidate</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">ent_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos">414</span></a>            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">masked_lm_loss</span> <span class="o">+</span> <span class="n">next_sentence_loss</span> <span class="o">+</span> <span class="n">ent_ae_loss</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos">415</span></a>            <span class="n">original_loss</span> <span class="o">=</span> <span class="n">masked_lm_loss</span> <span class="o">+</span> <span class="n">next_sentence_loss</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos">416</span></a>            <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">original_loss</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos">417</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos">418</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span><span class="p">,</span> <span class="n">seq_relationship_score</span><span class="p">,</span> <span class="n">prediction_scores_ent</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos">419</span></a>
</span><span id="L-420"><a href="#L-420"><span class="linenos">420</span></a><span class="k">class</span> <span class="nc">ErnieForNextSentencePrediction</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos">421</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos">422</span></a><span class="sd">    Ernie model with next sentence prediction head.</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos">423</span></a><span class="sd">    This module comprises the Ernie model followed by the next sentence classification head.</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos">424</span></a>
</span><span id="L-425"><a href="#L-425"><span class="linenos">425</span></a><span class="sd">    Params:</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos">426</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos">427</span></a>
</span><span id="L-428"><a href="#L-428"><span class="linenos">428</span></a><span class="sd">    Args:</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos">429</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos">430</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos">431</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos">432</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos">433</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos">434</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos">435</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos">436</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos">437</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos">438</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-439"><a href="#L-439"><span class="linenos">439</span></a><span class="sd">        `next_sentence_label`: next sentence classification loss: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos">440</span></a><span class="sd">            with indices selected in [0, 1].</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos">441</span></a><span class="sd">            0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos">442</span></a>
</span><span id="L-443"><a href="#L-443"><span class="linenos">443</span></a><span class="sd">    Returns:</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos">444</span></a><span class="sd">        if `next_sentence_label` is not `None`:</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos">445</span></a><span class="sd">            Outputs the total_loss which is the sum of the masked language modeling loss and the next</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos">446</span></a><span class="sd">            sentence classification loss.</span>
</span><span id="L-447"><a href="#L-447"><span class="linenos">447</span></a><span class="sd">        if `next_sentence_label` is `None`:</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos">448</span></a><span class="sd">            Outputs the next sentence classification logits of shape [batch_size, 2].</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos">449</span></a>
</span><span id="L-450"><a href="#L-450"><span class="linenos">450</span></a><span class="sd">    Example usage:</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos">451</span></a><span class="sd">    ```python</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos">452</span></a><span class="sd">    # Already been converted into WordPiece token ids</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos">453</span></a><span class="sd">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos">454</span></a><span class="sd">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos">455</span></a><span class="sd">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos">456</span></a>
</span><span id="L-457"><a href="#L-457"><span class="linenos">457</span></a><span class="sd">    config = ErnieConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos">458</span></a><span class="sd">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos">459</span></a>
</span><span id="L-460"><a href="#L-460"><span class="linenos">460</span></a><span class="sd">    model = ErnieForNextSentencePrediction(config)</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos">461</span></a><span class="sd">    seq_relationship_logits = model(input_ids, token_type_ids, input_mask)</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos">462</span></a><span class="sd">    ```</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos">463</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos">464</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos">465</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos">466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos">467</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyNSPHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos">468</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos">469</span></a>
</span><span id="L-470"><a href="#L-470"><span class="linenos">470</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos">471</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos">472</span></a>                                     <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-473"><a href="#L-473"><span class="linenos">473</span></a>        <span class="n">seq_relationship_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span> <span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos">474</span></a>
</span><span id="L-475"><a href="#L-475"><span class="linenos">475</span></a>        <span class="k">if</span> <span class="n">next_sentence_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos">476</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos">477</span></a>            <span class="n">next_sentence_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">seq_relationship_score</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">next_sentence_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos">478</span></a>            <span class="k">return</span> <span class="n">next_sentence_loss</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos">479</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos">480</span></a>            <span class="k">return</span> <span class="n">seq_relationship_score</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos">481</span></a>
</span><span id="L-482"><a href="#L-482"><span class="linenos">482</span></a><span class="k">class</span> <span class="nc">ErnieForEntityTyping</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos">483</span></a>
</span><span id="L-484"><a href="#L-484"><span class="linenos">484</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos">485</span></a><span class="sd">    Ernie model with entity typing prediction head.</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos">486</span></a><span class="sd">    This module comprises the Ernie model followed by the entity typing head.</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos">487</span></a>
</span><span id="L-488"><a href="#L-488"><span class="linenos">488</span></a><span class="sd">    Params:</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos">489</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos">490</span></a><span class="sd">        `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos">491</span></a>
</span><span id="L-492"><a href="#L-492"><span class="linenos">492</span></a><span class="sd">    Args:</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos">493</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos">494</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos">495</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-496"><a href="#L-496"><span class="linenos">496</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos">497</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos">498</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-499"><a href="#L-499"><span class="linenos">499</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos">500</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos">501</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-502"><a href="#L-502"><span class="linenos">502</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos">503</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos">504</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos">505</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos">506</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos">507</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos">508</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos">509</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos">510</span></a>
</span><span id="L-511"><a href="#L-511"><span class="linenos">511</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos">512</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos">513</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos">514</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos">515</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="L-516"><a href="#L-516"><span class="linenos">516</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">typing</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos">517</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos">518</span></a>
</span><span id="L-519"><a href="#L-519"><span class="linenos">519</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos">520</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos">521</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos">522</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">typing</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos">523</span></a>
</span><span id="L-524"><a href="#L-524"><span class="linenos">524</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos">525</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos">526</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos">527</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos">528</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos">529</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos">530</span></a>
</span><span id="L-531"><a href="#L-531"><span class="linenos">531</span></a><span class="k">class</span> <span class="nc">ErnieForSTSB</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos">532</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos">533</span></a><span class="sd">    Ernie model with STSB prediction head (predict sentence similarity).</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos">534</span></a><span class="sd">    This module comprises the Ernie model followed by the STSB head.</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos">535</span></a>
</span><span id="L-536"><a href="#L-536"><span class="linenos">536</span></a><span class="sd">    Params:</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos">537</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos">538</span></a><span class="sd">        `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos">539</span></a>
</span><span id="L-540"><a href="#L-540"><span class="linenos">540</span></a><span class="sd">    Args:</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos">541</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos">542</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos">543</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos">544</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos">545</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos">546</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos">547</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos">548</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos">549</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos">550</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos">551</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos">552</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos">553</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos">554</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-555"><a href="#L-555"><span class="linenos">555</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos">556</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos">557</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos">558</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos">559</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos">560</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">2</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos">561</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos">562</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos">563</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos">564</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-565"><a href="#L-565"><span class="linenos">565</span></a>
</span><span id="L-566"><a href="#L-566"><span class="linenos">566</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos">567</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos">568</span></a>
</span><span id="L-569"><a href="#L-569"><span class="linenos">569</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos">570</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos">571</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos">572</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos">573</span></a>
</span><span id="L-574"><a href="#L-574"><span class="linenos">574</span></a>        <span class="n">probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos">575</span></a>
</span><span id="L-576"><a href="#L-576"><span class="linenos">576</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos">577</span></a>            <span class="n">per_example_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">*</span> <span class="n">probs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos">578</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">per_example_loss</span><span class="p">)</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos">579</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos">580</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos">581</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos">582</span></a>
</span><span id="L-583"><a href="#L-583"><span class="linenos">583</span></a><span class="k">class</span> <span class="nc">ErnieForSequenceClassification</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos">584</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos">585</span></a><span class="sd">    Ernie model for classification.</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos">586</span></a><span class="sd">    This module is composed of the Ernie model with a linear layer on top of</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos">587</span></a><span class="sd">    the pooled output.</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos">588</span></a>
</span><span id="L-589"><a href="#L-589"><span class="linenos">589</span></a><span class="sd">    Params:</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos">590</span></a><span class="sd">        `config`: an ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos">591</span></a><span class="sd">        `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos">592</span></a>
</span><span id="L-593"><a href="#L-593"><span class="linenos">593</span></a><span class="sd">    Args:</span>
</span><span id="L-594"><a href="#L-594"><span class="linenos">594</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos">595</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos">596</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos">597</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos">598</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos">599</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-600"><a href="#L-600"><span class="linenos">600</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos">601</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos">602</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-603"><a href="#L-603"><span class="linenos">603</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos">604</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos">605</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos">606</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos">607</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos">608</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos">609</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos">610</span></a>
</span><span id="L-611"><a href="#L-611"><span class="linenos">611</span></a><span class="sd">    Returns:</span>
</span><span id="L-612"><a href="#L-612"><span class="linenos">612</span></a><span class="sd">        if `labels` is not `None`:</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos">613</span></a><span class="sd">            Outputs the CrossEntropy classification loss of the output with the labels.</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos">614</span></a><span class="sd">        if `labels` is `None`:</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos">615</span></a><span class="sd">            Outputs the classification logits of shape [batch_size, num_labels].</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos">616</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos">617</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos">618</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos">619</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos">620</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos">621</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="L-622"><a href="#L-622"><span class="linenos">622</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos">623</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos">624</span></a>
</span><span id="L-625"><a href="#L-625"><span class="linenos">625</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos">626</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos">627</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos">628</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos">629</span></a>
</span><span id="L-630"><a href="#L-630"><span class="linenos">630</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-631"><a href="#L-631"><span class="linenos">631</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos">632</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-633"><a href="#L-633"><span class="linenos">633</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos">634</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos">635</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos">636</span></a>
</span><span id="L-637"><a href="#L-637"><span class="linenos">637</span></a><span class="k">class</span> <span class="nc">ErnieForNQ</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos">638</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos">639</span></a><span class="sd">    Ernie model for NQ.</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos">640</span></a><span class="sd">    This module is composed of the Ernie model with a linear layer on top of</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos">641</span></a><span class="sd">    the pooled output.</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos">642</span></a>
</span><span id="L-643"><a href="#L-643"><span class="linenos">643</span></a><span class="sd">    Params:</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos">644</span></a><span class="sd">        `config`: an ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos">645</span></a><span class="sd">        `num_choices`: the number of classes for the classifier. Default = 2.</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos">646</span></a>
</span><span id="L-647"><a href="#L-647"><span class="linenos">647</span></a><span class="sd">    Args:</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos">648</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos">649</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos">650</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-651"><a href="#L-651"><span class="linenos">651</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-652"><a href="#L-652"><span class="linenos">652</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-653"><a href="#L-653"><span class="linenos">653</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos">654</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-655"><a href="#L-655"><span class="linenos">655</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos">656</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos">657</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-658"><a href="#L-658"><span class="linenos">658</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-659"><a href="#L-659"><span class="linenos">659</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-660"><a href="#L-660"><span class="linenos">660</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos">661</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-662"><a href="#L-662"><span class="linenos">662</span></a><span class="sd">        `choice_mask`:</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos">663</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-664"><a href="#L-664"><span class="linenos">664</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos">665</span></a>
</span><span id="L-666"><a href="#L-666"><span class="linenos">666</span></a><span class="sd">    Returns:</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos">667</span></a><span class="sd">        if `labels` is not `None`:</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos">668</span></a><span class="sd">            Outputs the CrossEntropy classification loss of the output with the labels.</span>
</span><span id="L-669"><a href="#L-669"><span class="linenos">669</span></a><span class="sd">        if `labels` is `None`:</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos">670</span></a><span class="sd">            Outputs the classification logits of shape [batch_size, num_labels].</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos">671</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-672"><a href="#L-672"><span class="linenos">672</span></a>
</span><span id="L-673"><a href="#L-673"><span class="linenos">673</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_choices</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos">674</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos">675</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_choices</span> <span class="o">=</span> <span class="n">num_choices</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos">676</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-677"><a href="#L-677"><span class="linenos">677</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="L-678"><a href="#L-678"><span class="linenos">678</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos">679</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos">680</span></a>
</span><span id="L-681"><a href="#L-681"><span class="linenos">681</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">choice_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-682"><a href="#L-682"><span class="linenos">682</span></a>            
</span><span id="L-683"><a href="#L-683"><span class="linenos">683</span></a>        <span class="n">flat_input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos">684</span></a>        <span class="n">flat_token_type_ids</span> <span class="o">=</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-685"><a href="#L-685"><span class="linenos">685</span></a>        <span class="n">flat_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-686"><a href="#L-686"><span class="linenos">686</span></a>        <span class="n">flat_input_ent</span> <span class="o">=</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos">687</span></a>        <span class="n">flat_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos">688</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">flat_input_ids</span><span class="p">,</span> <span class="n">flat_token_type_ids</span><span class="p">,</span> <span class="n">flat_attention_mask</span><span class="p">,</span> <span class="n">flat_input_ent</span><span class="p">,</span> <span class="n">flat_ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-689"><a href="#L-689"><span class="linenos">689</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos">690</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-691"><a href="#L-691"><span class="linenos">691</span></a>        <span class="n">reshaped_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_choices</span><span class="p">)</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos">692</span></a>
</span><span id="L-693"><a href="#L-693"><span class="linenos">693</span></a>        <span class="n">null_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos">694</span></a>        <span class="n">reshaped_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">null_score</span><span class="p">,</span> <span class="n">reshaped_logits</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">choice_mask</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos">695</span></a>
</span><span id="L-696"><a href="#L-696"><span class="linenos">696</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-697"><a href="#L-697"><span class="linenos">697</span></a>            <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos">698</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos">699</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">reshaped_logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-700"><a href="#L-700"><span class="linenos">700</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos">701</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos">702</span></a>            <span class="k">return</span> <span class="n">reshaped_logits</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos">703</span></a>
</span><span id="L-704"><a href="#L-704"><span class="linenos">704</span></a><span class="k">class</span> <span class="nc">ErnieForQuestionAnswering</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos">705</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-706"><a href="#L-706"><span class="linenos">706</span></a><span class="sd">    Ernie model for Question Answering (span extraction).</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos">707</span></a><span class="sd">    This module is composed of the Ernie model with a linear layer on top of</span>
</span><span id="L-708"><a href="#L-708"><span class="linenos">708</span></a><span class="sd">    the sequence output that computes start_logits and end_logits</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos">709</span></a>
</span><span id="L-710"><a href="#L-710"><span class="linenos">710</span></a><span class="sd">    Params:</span>
</span><span id="L-711"><a href="#L-711"><span class="linenos">711</span></a><span class="sd">        `config`: either</span>
</span><span id="L-712"><a href="#L-712"><span class="linenos">712</span></a><span class="sd">            - a ErnieConfig class instance with the configuration to build a new model</span>
</span><span id="L-713"><a href="#L-713"><span class="linenos">713</span></a>
</span><span id="L-714"><a href="#L-714"><span class="linenos">714</span></a><span class="sd">    Inputs:</span>
</span><span id="L-715"><a href="#L-715"><span class="linenos">715</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos">716</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-717"><a href="#L-717"><span class="linenos">717</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-718"><a href="#L-718"><span class="linenos">718</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-719"><a href="#L-719"><span class="linenos">719</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-720"><a href="#L-720"><span class="linenos">720</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos">721</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos">722</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-723"><a href="#L-723"><span class="linenos">723</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-724"><a href="#L-724"><span class="linenos">724</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="L-725"><a href="#L-725"><span class="linenos">725</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-726"><a href="#L-726"><span class="linenos">726</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="L-727"><a href="#L-727"><span class="linenos">727</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos">728</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="L-729"><a href="#L-729"><span class="linenos">729</span></a><span class="sd">        `start_positions`: position of the first token for the labeled span: torch.LongTensor of shape [batch_size].</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos">730</span></a><span class="sd">            Positions are clamped to the length of the sequence and position outside of the sequence are not taken</span>
</span><span id="L-731"><a href="#L-731"><span class="linenos">731</span></a><span class="sd">            into account for computing the loss.</span>
</span><span id="L-732"><a href="#L-732"><span class="linenos">732</span></a><span class="sd">        `end_positions`: position of the last token for the labeled span: torch.LongTensor of shape [batch_size].</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos">733</span></a><span class="sd">            Positions are clamped to the length of the sequence and position outside of the sequence are not taken</span>
</span><span id="L-734"><a href="#L-734"><span class="linenos">734</span></a><span class="sd">            into account for computing the loss.</span>
</span><span id="L-735"><a href="#L-735"><span class="linenos">735</span></a>
</span><span id="L-736"><a href="#L-736"><span class="linenos">736</span></a><span class="sd">    Outputs:</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos">737</span></a><span class="sd">        if `start_positions` and `end_positions` are not `None`:</span>
</span><span id="L-738"><a href="#L-738"><span class="linenos">738</span></a><span class="sd">            Outputs the total_loss which is the sum of the CrossEntropy loss for the start and end token positions.</span>
</span><span id="L-739"><a href="#L-739"><span class="linenos">739</span></a><span class="sd">        if `start_positions` or `end_positions` is `None`:</span>
</span><span id="L-740"><a href="#L-740"><span class="linenos">740</span></a><span class="sd">            Outputs a tuple of start_logits, end_logits which are the logits respectively for the start and end</span>
</span><span id="L-741"><a href="#L-741"><span class="linenos">741</span></a><span class="sd">            position tokens of shape [batch_size, sequence_length].</span>
</span><span id="L-742"><a href="#L-742"><span class="linenos">742</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-743"><a href="#L-743"><span class="linenos">743</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-744"><a href="#L-744"><span class="linenos">744</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-745"><a href="#L-745"><span class="linenos">745</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-746"><a href="#L-746"><span class="linenos">746</span></a>        <span class="c1"># TODO check with Google if it&#39;s normal there is no dropout on the token classifier of SQuAD in the TF version</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos">747</span></a>        <span class="c1"># self.dropout = nn.Dropout(config.hidden_dropout_prob)</span>
</span><span id="L-748"><a href="#L-748"><span class="linenos">748</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">qa_outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="L-749"><a href="#L-749"><span class="linenos">749</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="L-750"><a href="#L-750"><span class="linenos">750</span></a>
</span><span id="L-751"><a href="#L-751"><span class="linenos">751</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end_positions</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-752"><a href="#L-752"><span class="linenos">752</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-753"><a href="#L-753"><span class="linenos">753</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qa_outputs</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="L-754"><a href="#L-754"><span class="linenos">754</span></a>        <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-755"><a href="#L-755"><span class="linenos">755</span></a>        <span class="n">start_logits</span> <span class="o">=</span> <span class="n">start_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-756"><a href="#L-756"><span class="linenos">756</span></a>        <span class="n">end_logits</span> <span class="o">=</span> <span class="n">end_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-757"><a href="#L-757"><span class="linenos">757</span></a>
</span><span id="L-758"><a href="#L-758"><span class="linenos">758</span></a>        <span class="k">if</span> <span class="n">start_positions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">end_positions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-759"><a href="#L-759"><span class="linenos">759</span></a>            <span class="c1"># If we are on multi-GPU, split add a dimension</span>
</span><span id="L-760"><a href="#L-760"><span class="linenos">760</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">start_positions</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-761"><a href="#L-761"><span class="linenos">761</span></a>                <span class="n">start_positions</span> <span class="o">=</span> <span class="n">start_positions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-762"><a href="#L-762"><span class="linenos">762</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_positions</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos">763</span></a>                <span class="n">end_positions</span> <span class="o">=</span> <span class="n">end_positions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-764"><a href="#L-764"><span class="linenos">764</span></a>            <span class="c1"># sometimes the start/end positions are outside our model inputs, we ignore these terms</span>
</span><span id="L-765"><a href="#L-765"><span class="linenos">765</span></a>            <span class="n">ignored_index</span> <span class="o">=</span> <span class="n">start_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos">766</span></a>            <span class="n">start_positions</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignored_index</span><span class="p">)</span>
</span><span id="L-767"><a href="#L-767"><span class="linenos">767</span></a>            <span class="n">end_positions</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignored_index</span><span class="p">)</span>
</span><span id="L-768"><a href="#L-768"><span class="linenos">768</span></a>
</span><span id="L-769"><a href="#L-769"><span class="linenos">769</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">ignored_index</span><span class="p">)</span>
</span><span id="L-770"><a href="#L-770"><span class="linenos">770</span></a>            <span class="n">start_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">start_positions</span><span class="p">)</span>
</span><span id="L-771"><a href="#L-771"><span class="linenos">771</span></a>            <span class="n">end_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">end_logits</span><span class="p">,</span> <span class="n">end_positions</span><span class="p">)</span>
</span><span id="L-772"><a href="#L-772"><span class="linenos">772</span></a>            <span class="n">total_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">start_loss</span> <span class="o">+</span> <span class="n">end_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos">773</span></a>            <span class="k">return</span> <span class="n">total_loss</span>
</span><span id="L-774"><a href="#L-774"><span class="linenos">774</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos">775</span></a>            <span class="k">return</span> <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span>
</span></pre></div>


            </section>
                <section id="ErnieConfig">
                            <input id="ErnieConfig-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieConfig</span>:

                <label class="view-source-button" for="ErnieConfig-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieConfig"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieConfig-23"><a href="#ErnieConfig-23"><span class="linenos"> 23</span></a><span class="k">class</span> <span class="nc">ErnieConfig</span><span class="p">():</span>
</span><span id="ErnieConfig-24"><a href="#ErnieConfig-24"><span class="linenos"> 24</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieConfig-25"><a href="#ErnieConfig-25"><span class="linenos"> 25</span></a><span class="sd">    Configuration class to store the configuration of an `ErnieModel`.</span>
</span><span id="ErnieConfig-26"><a href="#ErnieConfig-26"><span class="linenos"> 26</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieConfig-27"><a href="#ErnieConfig-27"><span class="linenos"> 27</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="ErnieConfig-28"><a href="#ErnieConfig-28"><span class="linenos"> 28</span></a>                 <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="ErnieConfig-29"><a href="#ErnieConfig-29"><span class="linenos"> 29</span></a>                 <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="ErnieConfig-30"><a href="#ErnieConfig-30"><span class="linenos"> 30</span></a>                 <span class="n">entity_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="ErnieConfig-31"><a href="#ErnieConfig-31"><span class="linenos"> 31</span></a>                 <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="ErnieConfig-32"><a href="#ErnieConfig-32"><span class="linenos"> 32</span></a>                 <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="ErnieConfig-33"><a href="#ErnieConfig-33"><span class="linenos"> 33</span></a>                 <span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="ErnieConfig-34"><a href="#ErnieConfig-34"><span class="linenos"> 34</span></a>                 <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
</span><span id="ErnieConfig-35"><a href="#ErnieConfig-35"><span class="linenos"> 35</span></a>                 <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
</span><span id="ErnieConfig-36"><a href="#ErnieConfig-36"><span class="linenos"> 36</span></a>                 <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="ErnieConfig-37"><a href="#ErnieConfig-37"><span class="linenos"> 37</span></a>                 <span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="ErnieConfig-38"><a href="#ErnieConfig-38"><span class="linenos"> 38</span></a>                 <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="ErnieConfig-39"><a href="#ErnieConfig-39"><span class="linenos"> 39</span></a>                 <span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="ErnieConfig-40"><a href="#ErnieConfig-40"><span class="linenos"> 40</span></a>                 <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
</span><span id="ErnieConfig-41"><a href="#ErnieConfig-41"><span class="linenos"> 41</span></a>                 <span class="n">layer_types</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieConfig-42"><a href="#ErnieConfig-42"><span class="linenos"> 42</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieConfig-43"><a href="#ErnieConfig-43"><span class="linenos"> 43</span></a><span class="sd">        Constructs ErnieConfig.</span>
</span><span id="ErnieConfig-44"><a href="#ErnieConfig-44"><span class="linenos"> 44</span></a>
</span><span id="ErnieConfig-45"><a href="#ErnieConfig-45"><span class="linenos"> 45</span></a><span class="sd">        Args:</span>
</span><span id="ErnieConfig-46"><a href="#ErnieConfig-46"><span class="linenos"> 46</span></a><span class="sd">            vocab_size: Vocabulary size of `inputs_ids` in `ErnieModel`.</span>
</span><span id="ErnieConfig-47"><a href="#ErnieConfig-47"><span class="linenos"> 47</span></a><span class="sd">            hidden_size: Size of the encoder layers and the pooler layer.</span>
</span><span id="ErnieConfig-48"><a href="#ErnieConfig-48"><span class="linenos"> 48</span></a><span class="sd">            entity_size: Size of the entity embeddings,</span>
</span><span id="ErnieConfig-49"><a href="#ErnieConfig-49"><span class="linenos"> 49</span></a><span class="sd">            num_hidden_layers: Number of hidden layers in the Transformer encoder.</span>
</span><span id="ErnieConfig-50"><a href="#ErnieConfig-50"><span class="linenos"> 50</span></a><span class="sd">            num_attention_heads: Number of attention heads for each attention layer in</span>
</span><span id="ErnieConfig-51"><a href="#ErnieConfig-51"><span class="linenos"> 51</span></a><span class="sd">                the Transformer encoder for the tokens.</span>
</span><span id="ErnieConfig-52"><a href="#ErnieConfig-52"><span class="linenos"> 52</span></a><span class="sd">            num_attention_heads_ent: Number of attention heads for each attention layer in</span>
</span><span id="ErnieConfig-53"><a href="#ErnieConfig-53"><span class="linenos"> 53</span></a><span class="sd">                the Transformer encoder for the entities.</span>
</span><span id="ErnieConfig-54"><a href="#ErnieConfig-54"><span class="linenos"> 54</span></a><span class="sd">            intermediate_size: The size of the &quot;intermediate&quot; (i.e., feed-forward)</span>
</span><span id="ErnieConfig-55"><a href="#ErnieConfig-55"><span class="linenos"> 55</span></a><span class="sd">                layer in the Transformer encoder.</span>
</span><span id="ErnieConfig-56"><a href="#ErnieConfig-56"><span class="linenos"> 56</span></a><span class="sd">            hidden_act: The non-linear activation function (function or string) in the</span>
</span><span id="ErnieConfig-57"><a href="#ErnieConfig-57"><span class="linenos"> 57</span></a><span class="sd">                encoder and pooler. If string, &quot;gelu&quot;, &quot;relu&quot; and &quot;swish&quot; are supported.</span>
</span><span id="ErnieConfig-58"><a href="#ErnieConfig-58"><span class="linenos"> 58</span></a><span class="sd">            hidden_dropout_prob: The dropout probabilitiy for all fully connected</span>
</span><span id="ErnieConfig-59"><a href="#ErnieConfig-59"><span class="linenos"> 59</span></a><span class="sd">                layers in the embeddings, encoder, and pooler.</span>
</span><span id="ErnieConfig-60"><a href="#ErnieConfig-60"><span class="linenos"> 60</span></a><span class="sd">            attention_probs_dropout_prob: The dropout ratio for the attention</span>
</span><span id="ErnieConfig-61"><a href="#ErnieConfig-61"><span class="linenos"> 61</span></a><span class="sd">                probabilities.</span>
</span><span id="ErnieConfig-62"><a href="#ErnieConfig-62"><span class="linenos"> 62</span></a><span class="sd">            max_position_embeddings: The maximum sequence length that this model might</span>
</span><span id="ErnieConfig-63"><a href="#ErnieConfig-63"><span class="linenos"> 63</span></a><span class="sd">                ever be used with. Typically set this to something large just in case</span>
</span><span id="ErnieConfig-64"><a href="#ErnieConfig-64"><span class="linenos"> 64</span></a><span class="sd">                (e.g., 512 or 1024 or 2048).</span>
</span><span id="ErnieConfig-65"><a href="#ErnieConfig-65"><span class="linenos"> 65</span></a><span class="sd">            type_vocab_size: The vocabulary size of the `token_type_ids` passed into</span>
</span><span id="ErnieConfig-66"><a href="#ErnieConfig-66"><span class="linenos"> 66</span></a><span class="sd">                `ErnieModel`.</span>
</span><span id="ErnieConfig-67"><a href="#ErnieConfig-67"><span class="linenos"> 67</span></a><span class="sd">            initializer_range: The sttdev of the truncated_normal_initializer for</span>
</span><span id="ErnieConfig-68"><a href="#ErnieConfig-68"><span class="linenos"> 68</span></a><span class="sd">                initializing all weight matrices.</span>
</span><span id="ErnieConfig-69"><a href="#ErnieConfig-69"><span class="linenos"> 69</span></a><span class="sd">            layer_types: list() of ErnieEncoders which can be &#39;sim&#39; (Bert encoder), </span>
</span><span id="ErnieConfig-70"><a href="#ErnieConfig-70"><span class="linenos"> 70</span></a><span class="sd">            &#39;mix&#39; (Ernie encoder but no multihead attention for entities) or &#39;norm&#39; (standard Ernie encoder)</span>
</span><span id="ErnieConfig-71"><a href="#ErnieConfig-71"><span class="linenos"> 71</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ErnieConfig-72"><a href="#ErnieConfig-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span><span id="ErnieConfig-73"><a href="#ErnieConfig-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
</span><span id="ErnieConfig-74"><a href="#ErnieConfig-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">entity_size</span>
</span><span id="ErnieConfig-75"><a href="#ErnieConfig-75"><span class="linenos"> 75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
</span><span id="ErnieConfig-76"><a href="#ErnieConfig-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
</span><span id="ErnieConfig-77"><a href="#ErnieConfig-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads_ent</span> <span class="o">=</span> <span class="n">num_attention_heads_ent</span>
</span><span id="ErnieConfig-78"><a href="#ErnieConfig-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span> <span class="c1">#Stores a string</span>
</span><span id="ErnieConfig-79"><a href="#ErnieConfig-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
</span><span id="ErnieConfig-80"><a href="#ErnieConfig-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dropout_prob</span> <span class="o">=</span> <span class="n">hidden_dropout_prob</span>
</span><span id="ErnieConfig-81"><a href="#ErnieConfig-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span> <span class="o">=</span> <span class="n">attention_probs_dropout_prob</span>
</span><span id="ErnieConfig-82"><a href="#ErnieConfig-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
</span><span id="ErnieConfig-83"><a href="#ErnieConfig-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_vocab_size</span> <span class="o">=</span> <span class="n">type_vocab_size</span>
</span><span id="ErnieConfig-84"><a href="#ErnieConfig-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</span><span id="ErnieConfig-85"><a href="#ErnieConfig-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="n">layer_types</span>
</span><span id="ErnieConfig-86"><a href="#ErnieConfig-86"><span class="linenos"> 86</span></a>       
</span><span id="ErnieConfig-87"><a href="#ErnieConfig-87"><span class="linenos"> 87</span></a>    <span class="nd">@classmethod</span>
</span><span id="ErnieConfig-88"><a href="#ErnieConfig-88"><span class="linenos"> 88</span></a>    <span class="k">def</span> <span class="nf">load_from_json</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span><span class="n">path</span><span class="p">):</span>
</span><span id="ErnieConfig-89"><a href="#ErnieConfig-89"><span class="linenos"> 89</span></a>        <span class="sd">&quot;&quot;&quot;Loads and returns a config class from a json file located at path&quot;&quot;&quot;</span>
</span><span id="ErnieConfig-90"><a href="#ErnieConfig-90"><span class="linenos"> 90</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="c1">#Create default config</span>
</span><span id="ErnieConfig-91"><a href="#ErnieConfig-91"><span class="linenos"> 91</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
</span><span id="ErnieConfig-92"><a href="#ErnieConfig-92"><span class="linenos"> 92</span></a>            <span class="n">json_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span id="ErnieConfig-93"><a href="#ErnieConfig-93"><span class="linenos"> 93</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">json_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="ErnieConfig-94"><a href="#ErnieConfig-94"><span class="linenos"> 94</span></a>                <span class="n">config</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="ErnieConfig-95"><a href="#ErnieConfig-95"><span class="linenos"> 95</span></a>        <span class="k">return</span> <span class="n">config</span>
</span><span id="ErnieConfig-96"><a href="#ErnieConfig-96"><span class="linenos"> 96</span></a>
</span><span id="ErnieConfig-97"><a href="#ErnieConfig-97"><span class="linenos"> 97</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ErnieConfig-98"><a href="#ErnieConfig-98"><span class="linenos"> 98</span></a>        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_json_string</span><span class="p">())</span>
</span><span id="ErnieConfig-99"><a href="#ErnieConfig-99"><span class="linenos"> 99</span></a>
</span><span id="ErnieConfig-100"><a href="#ErnieConfig-100"><span class="linenos">100</span></a>    <span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ErnieConfig-101"><a href="#ErnieConfig-101"><span class="linenos">101</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a JSON string.&quot;&quot;&quot;</span>
</span><span id="ErnieConfig-102"><a href="#ErnieConfig-102"><span class="linenos">102</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="ErnieConfig-103"><a href="#ErnieConfig-103"><span class="linenos">103</span></a>        
</span><span id="ErnieConfig-104"><a href="#ErnieConfig-104"><span class="linenos">104</span></a>    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ErnieConfig-105"><a href="#ErnieConfig-105"><span class="linenos">105</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a Python dictionary.&quot;&quot;&quot;</span>
</span><span id="ErnieConfig-106"><a href="#ErnieConfig-106"><span class="linenos">106</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</span><span id="ErnieConfig-107"><a href="#ErnieConfig-107"><span class="linenos">107</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


            <div class="docstring"><p>Configuration class to store the configuration of an <code><a href="#ErnieModel">ErnieModel</a></code>.</p>
</div>


                            <div id="ErnieConfig.__init__" class="classattr">
                                        <input id="ErnieConfig.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieConfig</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">vocab_size</span>,</span><span class="param">	<span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span>,</span><span class="param">	<span class="n">entity_size</span><span class="o">=</span><span class="mi">100</span>,</span><span class="param">	<span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span>,</span><span class="param">	<span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span>,</span><span class="param">	<span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span>,</span><span class="param">	<span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span>,</span><span class="param">	<span class="n">hidden_act</span><span class="o">=</span><span class="s1">&#39;gelu&#39;</span>,</span><span class="param">	<span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span>,</span><span class="param">	<span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span>,</span><span class="param">	<span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span>,</span><span class="param">	<span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span>,</span><span class="param">	<span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span>,</span><span class="param">	<span class="n">layer_types</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieConfig.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieConfig.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieConfig.__init__-27"><a href="#ErnieConfig.__init__-27"><span class="linenos">27</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-28"><a href="#ErnieConfig.__init__-28"><span class="linenos">28</span></a>                 <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-29"><a href="#ErnieConfig.__init__-29"><span class="linenos">29</span></a>                 <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-30"><a href="#ErnieConfig.__init__-30"><span class="linenos">30</span></a>                 <span class="n">entity_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-31"><a href="#ErnieConfig.__init__-31"><span class="linenos">31</span></a>                 <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-32"><a href="#ErnieConfig.__init__-32"><span class="linenos">32</span></a>                 <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-33"><a href="#ErnieConfig.__init__-33"><span class="linenos">33</span></a>                 <span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-34"><a href="#ErnieConfig.__init__-34"><span class="linenos">34</span></a>                 <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-35"><a href="#ErnieConfig.__init__-35"><span class="linenos">35</span></a>                 <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-36"><a href="#ErnieConfig.__init__-36"><span class="linenos">36</span></a>                 <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-37"><a href="#ErnieConfig.__init__-37"><span class="linenos">37</span></a>                 <span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-38"><a href="#ErnieConfig.__init__-38"><span class="linenos">38</span></a>                 <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-39"><a href="#ErnieConfig.__init__-39"><span class="linenos">39</span></a>                 <span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-40"><a href="#ErnieConfig.__init__-40"><span class="linenos">40</span></a>                 <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
</span><span id="ErnieConfig.__init__-41"><a href="#ErnieConfig.__init__-41"><span class="linenos">41</span></a>                 <span class="n">layer_types</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieConfig.__init__-42"><a href="#ErnieConfig.__init__-42"><span class="linenos">42</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieConfig.__init__-43"><a href="#ErnieConfig.__init__-43"><span class="linenos">43</span></a><span class="sd">        Constructs ErnieConfig.</span>
</span><span id="ErnieConfig.__init__-44"><a href="#ErnieConfig.__init__-44"><span class="linenos">44</span></a>
</span><span id="ErnieConfig.__init__-45"><a href="#ErnieConfig.__init__-45"><span class="linenos">45</span></a><span class="sd">        Args:</span>
</span><span id="ErnieConfig.__init__-46"><a href="#ErnieConfig.__init__-46"><span class="linenos">46</span></a><span class="sd">            vocab_size: Vocabulary size of `inputs_ids` in `ErnieModel`.</span>
</span><span id="ErnieConfig.__init__-47"><a href="#ErnieConfig.__init__-47"><span class="linenos">47</span></a><span class="sd">            hidden_size: Size of the encoder layers and the pooler layer.</span>
</span><span id="ErnieConfig.__init__-48"><a href="#ErnieConfig.__init__-48"><span class="linenos">48</span></a><span class="sd">            entity_size: Size of the entity embeddings,</span>
</span><span id="ErnieConfig.__init__-49"><a href="#ErnieConfig.__init__-49"><span class="linenos">49</span></a><span class="sd">            num_hidden_layers: Number of hidden layers in the Transformer encoder.</span>
</span><span id="ErnieConfig.__init__-50"><a href="#ErnieConfig.__init__-50"><span class="linenos">50</span></a><span class="sd">            num_attention_heads: Number of attention heads for each attention layer in</span>
</span><span id="ErnieConfig.__init__-51"><a href="#ErnieConfig.__init__-51"><span class="linenos">51</span></a><span class="sd">                the Transformer encoder for the tokens.</span>
</span><span id="ErnieConfig.__init__-52"><a href="#ErnieConfig.__init__-52"><span class="linenos">52</span></a><span class="sd">            num_attention_heads_ent: Number of attention heads for each attention layer in</span>
</span><span id="ErnieConfig.__init__-53"><a href="#ErnieConfig.__init__-53"><span class="linenos">53</span></a><span class="sd">                the Transformer encoder for the entities.</span>
</span><span id="ErnieConfig.__init__-54"><a href="#ErnieConfig.__init__-54"><span class="linenos">54</span></a><span class="sd">            intermediate_size: The size of the &quot;intermediate&quot; (i.e., feed-forward)</span>
</span><span id="ErnieConfig.__init__-55"><a href="#ErnieConfig.__init__-55"><span class="linenos">55</span></a><span class="sd">                layer in the Transformer encoder.</span>
</span><span id="ErnieConfig.__init__-56"><a href="#ErnieConfig.__init__-56"><span class="linenos">56</span></a><span class="sd">            hidden_act: The non-linear activation function (function or string) in the</span>
</span><span id="ErnieConfig.__init__-57"><a href="#ErnieConfig.__init__-57"><span class="linenos">57</span></a><span class="sd">                encoder and pooler. If string, &quot;gelu&quot;, &quot;relu&quot; and &quot;swish&quot; are supported.</span>
</span><span id="ErnieConfig.__init__-58"><a href="#ErnieConfig.__init__-58"><span class="linenos">58</span></a><span class="sd">            hidden_dropout_prob: The dropout probabilitiy for all fully connected</span>
</span><span id="ErnieConfig.__init__-59"><a href="#ErnieConfig.__init__-59"><span class="linenos">59</span></a><span class="sd">                layers in the embeddings, encoder, and pooler.</span>
</span><span id="ErnieConfig.__init__-60"><a href="#ErnieConfig.__init__-60"><span class="linenos">60</span></a><span class="sd">            attention_probs_dropout_prob: The dropout ratio for the attention</span>
</span><span id="ErnieConfig.__init__-61"><a href="#ErnieConfig.__init__-61"><span class="linenos">61</span></a><span class="sd">                probabilities.</span>
</span><span id="ErnieConfig.__init__-62"><a href="#ErnieConfig.__init__-62"><span class="linenos">62</span></a><span class="sd">            max_position_embeddings: The maximum sequence length that this model might</span>
</span><span id="ErnieConfig.__init__-63"><a href="#ErnieConfig.__init__-63"><span class="linenos">63</span></a><span class="sd">                ever be used with. Typically set this to something large just in case</span>
</span><span id="ErnieConfig.__init__-64"><a href="#ErnieConfig.__init__-64"><span class="linenos">64</span></a><span class="sd">                (e.g., 512 or 1024 or 2048).</span>
</span><span id="ErnieConfig.__init__-65"><a href="#ErnieConfig.__init__-65"><span class="linenos">65</span></a><span class="sd">            type_vocab_size: The vocabulary size of the `token_type_ids` passed into</span>
</span><span id="ErnieConfig.__init__-66"><a href="#ErnieConfig.__init__-66"><span class="linenos">66</span></a><span class="sd">                `ErnieModel`.</span>
</span><span id="ErnieConfig.__init__-67"><a href="#ErnieConfig.__init__-67"><span class="linenos">67</span></a><span class="sd">            initializer_range: The sttdev of the truncated_normal_initializer for</span>
</span><span id="ErnieConfig.__init__-68"><a href="#ErnieConfig.__init__-68"><span class="linenos">68</span></a><span class="sd">                initializing all weight matrices.</span>
</span><span id="ErnieConfig.__init__-69"><a href="#ErnieConfig.__init__-69"><span class="linenos">69</span></a><span class="sd">            layer_types: list() of ErnieEncoders which can be &#39;sim&#39; (Bert encoder), </span>
</span><span id="ErnieConfig.__init__-70"><a href="#ErnieConfig.__init__-70"><span class="linenos">70</span></a><span class="sd">            &#39;mix&#39; (Ernie encoder but no multihead attention for entities) or &#39;norm&#39; (standard Ernie encoder)</span>
</span><span id="ErnieConfig.__init__-71"><a href="#ErnieConfig.__init__-71"><span class="linenos">71</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ErnieConfig.__init__-72"><a href="#ErnieConfig.__init__-72"><span class="linenos">72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span><span id="ErnieConfig.__init__-73"><a href="#ErnieConfig.__init__-73"><span class="linenos">73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
</span><span id="ErnieConfig.__init__-74"><a href="#ErnieConfig.__init__-74"><span class="linenos">74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">entity_size</span>
</span><span id="ErnieConfig.__init__-75"><a href="#ErnieConfig.__init__-75"><span class="linenos">75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
</span><span id="ErnieConfig.__init__-76"><a href="#ErnieConfig.__init__-76"><span class="linenos">76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
</span><span id="ErnieConfig.__init__-77"><a href="#ErnieConfig.__init__-77"><span class="linenos">77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads_ent</span> <span class="o">=</span> <span class="n">num_attention_heads_ent</span>
</span><span id="ErnieConfig.__init__-78"><a href="#ErnieConfig.__init__-78"><span class="linenos">78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span> <span class="c1">#Stores a string</span>
</span><span id="ErnieConfig.__init__-79"><a href="#ErnieConfig.__init__-79"><span class="linenos">79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
</span><span id="ErnieConfig.__init__-80"><a href="#ErnieConfig.__init__-80"><span class="linenos">80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dropout_prob</span> <span class="o">=</span> <span class="n">hidden_dropout_prob</span>
</span><span id="ErnieConfig.__init__-81"><a href="#ErnieConfig.__init__-81"><span class="linenos">81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span> <span class="o">=</span> <span class="n">attention_probs_dropout_prob</span>
</span><span id="ErnieConfig.__init__-82"><a href="#ErnieConfig.__init__-82"><span class="linenos">82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
</span><span id="ErnieConfig.__init__-83"><a href="#ErnieConfig.__init__-83"><span class="linenos">83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_vocab_size</span> <span class="o">=</span> <span class="n">type_vocab_size</span>
</span><span id="ErnieConfig.__init__-84"><a href="#ErnieConfig.__init__-84"><span class="linenos">84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</span><span id="ErnieConfig.__init__-85"><a href="#ErnieConfig.__init__-85"><span class="linenos">85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="n">layer_types</span>
</span></pre></div>


            <div class="docstring"><p>Constructs ErnieConfig.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>vocab_size:</strong>  Vocabulary size of <code>inputs_ids</code> in <code><a href="#ErnieModel">ErnieModel</a></code>.</li>
<li><strong>hidden_size:</strong>  Size of the encoder layers and the pooler layer.</li>
<li><strong>entity_size:</strong>  Size of the entity embeddings,</li>
<li><strong>num_hidden_layers:</strong>  Number of hidden layers in the Transformer encoder.</li>
<li><strong>num_attention_heads:</strong>  Number of attention heads for each attention layer in
the Transformer encoder for the tokens.</li>
<li><strong>num_attention_heads_ent:</strong>  Number of attention heads for each attention layer in
the Transformer encoder for the entities.</li>
<li><strong>intermediate_size:</strong>  The size of the "intermediate" (i.e., feed-forward)
layer in the Transformer encoder.</li>
<li><strong>hidden_act:</strong>  The non-linear activation function (function or string) in the
encoder and pooler. If string, "gelu", "relu" and "swish" are supported.</li>
<li><strong>hidden_dropout_prob:</strong>  The dropout probabilitiy for all fully connected
layers in the embeddings, encoder, and pooler.</li>
<li><strong>attention_probs_dropout_prob:</strong>  The dropout ratio for the attention
probabilities.</li>
<li><strong>max_position_embeddings:</strong>  The maximum sequence length that this model might
ever be used with. Typically set this to something large just in case
(e.g., 512 or 1024 or 2048).</li>
<li><strong>type_vocab_size:</strong>  The vocabulary size of the <code>token_type_ids</code> passed into
<code><a href="#ErnieModel">ErnieModel</a></code>.</li>
<li><strong>initializer_range:</strong>  The sttdev of the truncated_normal_initializer for
initializing all weight matrices.</li>
<li><strong>layer_types:</strong>  list() of ErnieEncoders which can be 'sim' (Bert encoder), </li>
<li>'mix' (Ernie encoder but no multihead attention for entities) or 'norm' (standard Ernie encoder)</li>
</ul>
</div>


                            </div>
                            <div id="ErnieConfig.load_from_json" class="classattr">
                                        <input id="ErnieConfig.load_from_json-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">load_from_json</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">path</span></span>)</span>

                <label class="view-source-button" for="ErnieConfig.load_from_json-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieConfig.load_from_json"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieConfig.load_from_json-87"><a href="#ErnieConfig.load_from_json-87"><span class="linenos">87</span></a>    <span class="nd">@classmethod</span>
</span><span id="ErnieConfig.load_from_json-88"><a href="#ErnieConfig.load_from_json-88"><span class="linenos">88</span></a>    <span class="k">def</span> <span class="nf">load_from_json</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span><span class="n">path</span><span class="p">):</span>
</span><span id="ErnieConfig.load_from_json-89"><a href="#ErnieConfig.load_from_json-89"><span class="linenos">89</span></a>        <span class="sd">&quot;&quot;&quot;Loads and returns a config class from a json file located at path&quot;&quot;&quot;</span>
</span><span id="ErnieConfig.load_from_json-90"><a href="#ErnieConfig.load_from_json-90"><span class="linenos">90</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="c1">#Create default config</span>
</span><span id="ErnieConfig.load_from_json-91"><a href="#ErnieConfig.load_from_json-91"><span class="linenos">91</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
</span><span id="ErnieConfig.load_from_json-92"><a href="#ErnieConfig.load_from_json-92"><span class="linenos">92</span></a>            <span class="n">json_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span id="ErnieConfig.load_from_json-93"><a href="#ErnieConfig.load_from_json-93"><span class="linenos">93</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">json_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="ErnieConfig.load_from_json-94"><a href="#ErnieConfig.load_from_json-94"><span class="linenos">94</span></a>                <span class="n">config</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="ErnieConfig.load_from_json-95"><a href="#ErnieConfig.load_from_json-95"><span class="linenos">95</span></a>        <span class="k">return</span> <span class="n">config</span>
</span></pre></div>


            <div class="docstring"><p>Loads and returns a config class from a json file located at path</p>
</div>


                            </div>
                            <div id="ErnieConfig.to_json_string" class="classattr">
                                        <input id="ErnieConfig.to_json_string-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_json_string</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span>)</span>

                <label class="view-source-button" for="ErnieConfig.to_json_string-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieConfig.to_json_string"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieConfig.to_json_string-100"><a href="#ErnieConfig.to_json_string-100"><span class="linenos">100</span></a>    <span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ErnieConfig.to_json_string-101"><a href="#ErnieConfig.to_json_string-101"><span class="linenos">101</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a JSON string.&quot;&quot;&quot;</span>
</span><span id="ErnieConfig.to_json_string-102"><a href="#ErnieConfig.to_json_string-102"><span class="linenos">102</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Serializes this instance to a JSON string.</p>
</div>


                            </div>
                            <div id="ErnieConfig.to_dict" class="classattr">
                                        <input id="ErnieConfig.to_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_dict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span>)</span>

                <label class="view-source-button" for="ErnieConfig.to_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieConfig.to_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieConfig.to_dict-104"><a href="#ErnieConfig.to_dict-104"><span class="linenos">104</span></a>    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ErnieConfig.to_dict-105"><a href="#ErnieConfig.to_dict-105"><span class="linenos">105</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a Python dictionary.&quot;&quot;&quot;</span>
</span><span id="ErnieConfig.to_dict-106"><a href="#ErnieConfig.to_dict-106"><span class="linenos">106</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</span><span id="ErnieConfig.to_dict-107"><a href="#ErnieConfig.to_dict-107"><span class="linenos">107</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


            <div class="docstring"><p>Serializes this instance to a Python dictionary.</p>
</div>


                            </div>
                </section>
                <section id="PreTrainedErnieModel">
                            <input id="PreTrainedErnieModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PreTrainedErnieModel</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="PreTrainedErnieModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedErnieModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedErnieModel-109"><a href="#PreTrainedErnieModel-109"><span class="linenos">109</span></a><span class="k">class</span> <span class="nc">PreTrainedErnieModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel-110"><a href="#PreTrainedErnieModel-110"><span class="linenos">110</span></a>    <span class="sd">&quot;&quot;&quot; </span>
</span><span id="PreTrainedErnieModel-111"><a href="#PreTrainedErnieModel-111"><span class="linenos">111</span></a><span class="sd">    An abstract class to handle weights initialization and</span>
</span><span id="PreTrainedErnieModel-112"><a href="#PreTrainedErnieModel-112"><span class="linenos">112</span></a><span class="sd">        a simple interface for downloading and loading pretrained models.</span>
</span><span id="PreTrainedErnieModel-113"><a href="#PreTrainedErnieModel-113"><span class="linenos">113</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PreTrainedErnieModel-114"><a href="#PreTrainedErnieModel-114"><span class="linenos">114</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel-115"><a href="#PreTrainedErnieModel-115"><span class="linenos">115</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="PreTrainedErnieModel-116"><a href="#PreTrainedErnieModel-116"><span class="linenos">116</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">ErnieConfig</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel-117"><a href="#PreTrainedErnieModel-117"><span class="linenos">117</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="PreTrainedErnieModel-118"><a href="#PreTrainedErnieModel-118"><span class="linenos">118</span></a>                <span class="s2">&quot;Parameter config in `</span><span class="si">{}</span><span class="s2">(config)` should be an instance of class `ErnieConfig`. &quot;</span>
</span><span id="PreTrainedErnieModel-119"><a href="#PreTrainedErnieModel-119"><span class="linenos">119</span></a>                <span class="s2">&quot;To create a model from a Google pretrained model use &quot;</span>
</span><span id="PreTrainedErnieModel-120"><a href="#PreTrainedErnieModel-120"><span class="linenos">120</span></a>                <span class="s2">&quot;`model = </span><span class="si">{}</span><span class="s2">.from_pretrained(PRETRAINED_MODEL_NAME)`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="PreTrainedErnieModel-121"><a href="#PreTrainedErnieModel-121"><span class="linenos">121</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="PreTrainedErnieModel-122"><a href="#PreTrainedErnieModel-122"><span class="linenos">122</span></a>                <span class="p">))</span>
</span><span id="PreTrainedErnieModel-123"><a href="#PreTrainedErnieModel-123"><span class="linenos">123</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="PreTrainedErnieModel-124"><a href="#PreTrainedErnieModel-124"><span class="linenos">124</span></a>
</span><span id="PreTrainedErnieModel-125"><a href="#PreTrainedErnieModel-125"><span class="linenos">125</span></a>    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel-126"><a href="#PreTrainedErnieModel-126"><span class="linenos">126</span></a>        <span class="sd">&quot;&quot;&quot; </span>
</span><span id="PreTrainedErnieModel-127"><a href="#PreTrainedErnieModel-127"><span class="linenos">127</span></a><span class="sd">        Initialize the weights.</span>
</span><span id="PreTrainedErnieModel-128"><a href="#PreTrainedErnieModel-128"><span class="linenos">128</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedErnieModel-129"><a href="#PreTrainedErnieModel-129"><span class="linenos">129</span></a>        <span class="n">bert</span><span class="o">.</span><span class="n">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-130"><a href="#PreTrainedErnieModel-130"><span class="linenos">130</span></a>
</span><span id="PreTrainedErnieModel-131"><a href="#PreTrainedErnieModel-131"><span class="linenos">131</span></a>    <span class="nd">@classmethod</span>
</span><span id="PreTrainedErnieModel-132"><a href="#PreTrainedErnieModel-132"><span class="linenos">132</span></a>    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dir_path</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel-133"><a href="#PreTrainedErnieModel-133"><span class="linenos">133</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="PreTrainedErnieModel-134"><a href="#PreTrainedErnieModel-134"><span class="linenos">134</span></a><span class="sd">        Instantiate a PreTrainedErnieModel from a pre-trained model file or a pytorch state dict.</span>
</span><span id="PreTrainedErnieModel-135"><a href="#PreTrainedErnieModel-135"><span class="linenos">135</span></a>
</span><span id="PreTrainedErnieModel-136"><a href="#PreTrainedErnieModel-136"><span class="linenos">136</span></a><span class="sd">        Args:</span>
</span><span id="PreTrainedErnieModel-137"><a href="#PreTrainedErnieModel-137"><span class="linenos">137</span></a><span class="sd">            dir_path:</span>
</span><span id="PreTrainedErnieModel-138"><a href="#PreTrainedErnieModel-138"><span class="linenos">138</span></a><span class="sd">                - a path to a pretrained model archive containing:</span>
</span><span id="PreTrainedErnieModel-139"><a href="#PreTrainedErnieModel-139"><span class="linenos">139</span></a><span class="sd">                    . `ernie_config.json`: a configuration file for the model</span>
</span><span id="PreTrainedErnieModel-140"><a href="#PreTrainedErnieModel-140"><span class="linenos">140</span></a><span class="sd">                    . `pytorch_model.bin`: a PyTorch dump of a ErnieForPreTraining instance</span>
</span><span id="PreTrainedErnieModel-141"><a href="#PreTrainedErnieModel-141"><span class="linenos">141</span></a><span class="sd">                    .  `mapping.json`: an Optional file to remap the weights from the pre-trained weights to this implementation </span>
</span><span id="PreTrainedErnieModel-142"><a href="#PreTrainedErnieModel-142"><span class="linenos">142</span></a><span class="sd">            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of the PyTorch dump</span>
</span><span id="PreTrainedErnieModel-143"><a href="#PreTrainedErnieModel-143"><span class="linenos">143</span></a><span class="sd">            *inputs, **kwargs: additional input for the specific Ernie class</span>
</span><span id="PreTrainedErnieModel-144"><a href="#PreTrainedErnieModel-144"><span class="linenos">144</span></a><span class="sd">                (ex: num_labels for ErnieForSequenceClassification)</span>
</span><span id="PreTrainedErnieModel-145"><a href="#PreTrainedErnieModel-145"><span class="linenos">145</span></a><span class="sd">        Returns:</span>
</span><span id="PreTrainedErnieModel-146"><a href="#PreTrainedErnieModel-146"><span class="linenos">146</span></a><span class="sd">            The loaded pretrained model</span>
</span><span id="PreTrainedErnieModel-147"><a href="#PreTrainedErnieModel-147"><span class="linenos">147</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedErnieModel-148"><a href="#PreTrainedErnieModel-148"><span class="linenos">148</span></a>        
</span><span id="PreTrainedErnieModel-149"><a href="#PreTrainedErnieModel-149"><span class="linenos">149</span></a>        <span class="c1"># Load config</span>
</span><span id="PreTrainedErnieModel-150"><a href="#PreTrainedErnieModel-150"><span class="linenos">150</span></a>        <span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">CONFIG_NAME</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-151"><a href="#PreTrainedErnieModel-151"><span class="linenos">151</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">ErnieConfig</span><span class="o">.</span><span class="n">load_from_json</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-152"><a href="#PreTrainedErnieModel-152"><span class="linenos">152</span></a>
</span><span id="PreTrainedErnieModel-153"><a href="#PreTrainedErnieModel-153"><span class="linenos">153</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-154"><a href="#PreTrainedErnieModel-154"><span class="linenos">154</span></a>
</span><span id="PreTrainedErnieModel-155"><a href="#PreTrainedErnieModel-155"><span class="linenos">155</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">state_dict</span><span class="o">==</span><span class="kc">None</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel-156"><a href="#PreTrainedErnieModel-156"><span class="linenos">156</span></a>            <span class="n">weights_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-157"><a href="#PreTrainedErnieModel-157"><span class="linenos">157</span></a>            <span class="k">if</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="PreTrainedErnieModel-158"><a href="#PreTrainedErnieModel-158"><span class="linenos">158</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-159"><a href="#PreTrainedErnieModel-159"><span class="linenos">159</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PreTrainedErnieModel-160"><a href="#PreTrainedErnieModel-160"><span class="linenos">160</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span><span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-161"><a href="#PreTrainedErnieModel-161"><span class="linenos">161</span></a>
</span><span id="PreTrainedErnieModel-162"><a href="#PreTrainedErnieModel-162"><span class="linenos">162</span></a>        <span class="n">missing_keys</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PreTrainedErnieModel-163"><a href="#PreTrainedErnieModel-163"><span class="linenos">163</span></a>        <span class="c1"># copy state_dict so _load_from_state_dict can modify it</span>
</span><span id="PreTrainedErnieModel-164"><a href="#PreTrainedErnieModel-164"><span class="linenos">164</span></a>        <span class="n">metadata</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="s1">&#39;_metadata&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-165"><a href="#PreTrainedErnieModel-165"><span class="linenos">165</span></a>        
</span><span id="PreTrainedErnieModel-166"><a href="#PreTrainedErnieModel-166"><span class="linenos">166</span></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="PreTrainedErnieModel-167"><a href="#PreTrainedErnieModel-167"><span class="linenos">167</span></a>        <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PreTrainedErnieModel-168"><a href="#PreTrainedErnieModel-168"><span class="linenos">168</span></a>            <span class="n">state_dict</span><span class="o">.</span><span class="n">_metadata</span> <span class="o">=</span> <span class="n">metadata</span>
</span><span id="PreTrainedErnieModel-169"><a href="#PreTrainedErnieModel-169"><span class="linenos">169</span></a>
</span><span id="PreTrainedErnieModel-170"><a href="#PreTrainedErnieModel-170"><span class="linenos">170</span></a>        <span class="n">mapping_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">MAPPING_FILE</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-171"><a href="#PreTrainedErnieModel-171"><span class="linenos">171</span></a>
</span><span id="PreTrainedErnieModel-172"><a href="#PreTrainedErnieModel-172"><span class="linenos">172</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">)):</span>
</span><span id="PreTrainedErnieModel-173"><a href="#PreTrainedErnieModel-173"><span class="linenos">173</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
</span><span id="PreTrainedErnieModel-174"><a href="#PreTrainedErnieModel-174"><span class="linenos">174</span></a>                <span class="n">mapping</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-175"><a href="#PreTrainedErnieModel-175"><span class="linenos">175</span></a>
</span><span id="PreTrainedErnieModel-176"><a href="#PreTrainedErnieModel-176"><span class="linenos">176</span></a>            <span class="k">for</span> <span class="n">old_key</span><span class="p">,</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="PreTrainedErnieModel-177"><a href="#PreTrainedErnieModel-177"><span class="linenos">177</span></a>                <span class="k">if</span><span class="p">(</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()):</span>
</span><span id="PreTrainedErnieModel-178"><a href="#PreTrainedErnieModel-178"><span class="linenos">178</span></a>                    <span class="n">model_shape</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">new_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</span><span id="PreTrainedErnieModel-179"><a href="#PreTrainedErnieModel-179"><span class="linenos">179</span></a>                    <span class="k">if</span><span class="p">(</span><span class="n">model_shape</span><span class="o">!=</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel-180"><a href="#PreTrainedErnieModel-180"><span class="linenos">180</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;model.state_dict() </span><span class="si">{</span><span class="n">new_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">model_shape</span><span class="si">}</span><span class="s1"> != state_dict </span><span class="si">{</span><span class="n">old_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-181"><a href="#PreTrainedErnieModel-181"><span class="linenos">181</span></a>                        
</span><span id="PreTrainedErnieModel-182"><a href="#PreTrainedErnieModel-182"><span class="linenos">182</span></a>                <span class="n">state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-183"><a href="#PreTrainedErnieModel-183"><span class="linenos">183</span></a>
</span><span id="PreTrainedErnieModel-184"><a href="#PreTrainedErnieModel-184"><span class="linenos">184</span></a>        <span class="n">missing_keys</span><span class="p">,</span><span class="n">unexpected_keys</span> <span class="o">=</span>  <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-185"><a href="#PreTrainedErnieModel-185"><span class="linenos">185</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Missing keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">missing_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-186"><a href="#PreTrainedErnieModel-186"><span class="linenos">186</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel-187"><a href="#PreTrainedErnieModel-187"><span class="linenos">187</span></a>
</span><span id="PreTrainedErnieModel-188"><a href="#PreTrainedErnieModel-188"><span class="linenos">188</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">missing_keys</span>
</span></pre></div>


            <div class="docstring"><p>An abstract class to handle weights initialization and
    a simple interface for downloading and loading pretrained models.</p>
</div>


                            <div id="PreTrainedErnieModel.__init__" class="classattr">
                                        <input id="PreTrainedErnieModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PreTrainedErnieModel</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="o">*</span><span class="n">inputs</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="PreTrainedErnieModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedErnieModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedErnieModel.__init__-114"><a href="#PreTrainedErnieModel.__init__-114"><span class="linenos">114</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel.__init__-115"><a href="#PreTrainedErnieModel.__init__-115"><span class="linenos">115</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="PreTrainedErnieModel.__init__-116"><a href="#PreTrainedErnieModel.__init__-116"><span class="linenos">116</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">ErnieConfig</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel.__init__-117"><a href="#PreTrainedErnieModel.__init__-117"><span class="linenos">117</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="PreTrainedErnieModel.__init__-118"><a href="#PreTrainedErnieModel.__init__-118"><span class="linenos">118</span></a>                <span class="s2">&quot;Parameter config in `</span><span class="si">{}</span><span class="s2">(config)` should be an instance of class `ErnieConfig`. &quot;</span>
</span><span id="PreTrainedErnieModel.__init__-119"><a href="#PreTrainedErnieModel.__init__-119"><span class="linenos">119</span></a>                <span class="s2">&quot;To create a model from a Google pretrained model use &quot;</span>
</span><span id="PreTrainedErnieModel.__init__-120"><a href="#PreTrainedErnieModel.__init__-120"><span class="linenos">120</span></a>                <span class="s2">&quot;`model = </span><span class="si">{}</span><span class="s2">.from_pretrained(PRETRAINED_MODEL_NAME)`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="PreTrainedErnieModel.__init__-121"><a href="#PreTrainedErnieModel.__init__-121"><span class="linenos">121</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="PreTrainedErnieModel.__init__-122"><a href="#PreTrainedErnieModel.__init__-122"><span class="linenos">122</span></a>                <span class="p">))</span>
</span><span id="PreTrainedErnieModel.__init__-123"><a href="#PreTrainedErnieModel.__init__-123"><span class="linenos">123</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="PreTrainedErnieModel.init_weights" class="classattr">
                                        <input id="PreTrainedErnieModel.init_weights-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">init_weights</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span>)</span>

                <label class="view-source-button" for="PreTrainedErnieModel.init_weights-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedErnieModel.init_weights"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedErnieModel.init_weights-125"><a href="#PreTrainedErnieModel.init_weights-125"><span class="linenos">125</span></a>    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel.init_weights-126"><a href="#PreTrainedErnieModel.init_weights-126"><span class="linenos">126</span></a>        <span class="sd">&quot;&quot;&quot; </span>
</span><span id="PreTrainedErnieModel.init_weights-127"><a href="#PreTrainedErnieModel.init_weights-127"><span class="linenos">127</span></a><span class="sd">        Initialize the weights.</span>
</span><span id="PreTrainedErnieModel.init_weights-128"><a href="#PreTrainedErnieModel.init_weights-128"><span class="linenos">128</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedErnieModel.init_weights-129"><a href="#PreTrainedErnieModel.init_weights-129"><span class="linenos">129</span></a>        <span class="n">bert</span><span class="o">.</span><span class="n">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initialize the weights.</p>
</div>


                            </div>
                            <div id="PreTrainedErnieModel.from_pretrained" class="classattr">
                                        <input id="PreTrainedErnieModel.from_pretrained-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">from_pretrained</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">dir_path</span>, </span><span class="param"><span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="o">*</span><span class="n">inputs</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="PreTrainedErnieModel.from_pretrained-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedErnieModel.from_pretrained"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedErnieModel.from_pretrained-131"><a href="#PreTrainedErnieModel.from_pretrained-131"><span class="linenos">131</span></a>    <span class="nd">@classmethod</span>
</span><span id="PreTrainedErnieModel.from_pretrained-132"><a href="#PreTrainedErnieModel.from_pretrained-132"><span class="linenos">132</span></a>    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dir_path</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel.from_pretrained-133"><a href="#PreTrainedErnieModel.from_pretrained-133"><span class="linenos">133</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="PreTrainedErnieModel.from_pretrained-134"><a href="#PreTrainedErnieModel.from_pretrained-134"><span class="linenos">134</span></a><span class="sd">        Instantiate a PreTrainedErnieModel from a pre-trained model file or a pytorch state dict.</span>
</span><span id="PreTrainedErnieModel.from_pretrained-135"><a href="#PreTrainedErnieModel.from_pretrained-135"><span class="linenos">135</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-136"><a href="#PreTrainedErnieModel.from_pretrained-136"><span class="linenos">136</span></a><span class="sd">        Args:</span>
</span><span id="PreTrainedErnieModel.from_pretrained-137"><a href="#PreTrainedErnieModel.from_pretrained-137"><span class="linenos">137</span></a><span class="sd">            dir_path:</span>
</span><span id="PreTrainedErnieModel.from_pretrained-138"><a href="#PreTrainedErnieModel.from_pretrained-138"><span class="linenos">138</span></a><span class="sd">                - a path to a pretrained model archive containing:</span>
</span><span id="PreTrainedErnieModel.from_pretrained-139"><a href="#PreTrainedErnieModel.from_pretrained-139"><span class="linenos">139</span></a><span class="sd">                    . `ernie_config.json`: a configuration file for the model</span>
</span><span id="PreTrainedErnieModel.from_pretrained-140"><a href="#PreTrainedErnieModel.from_pretrained-140"><span class="linenos">140</span></a><span class="sd">                    . `pytorch_model.bin`: a PyTorch dump of a ErnieForPreTraining instance</span>
</span><span id="PreTrainedErnieModel.from_pretrained-141"><a href="#PreTrainedErnieModel.from_pretrained-141"><span class="linenos">141</span></a><span class="sd">                    .  `mapping.json`: an Optional file to remap the weights from the pre-trained weights to this implementation </span>
</span><span id="PreTrainedErnieModel.from_pretrained-142"><a href="#PreTrainedErnieModel.from_pretrained-142"><span class="linenos">142</span></a><span class="sd">            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of the PyTorch dump</span>
</span><span id="PreTrainedErnieModel.from_pretrained-143"><a href="#PreTrainedErnieModel.from_pretrained-143"><span class="linenos">143</span></a><span class="sd">            *inputs, **kwargs: additional input for the specific Ernie class</span>
</span><span id="PreTrainedErnieModel.from_pretrained-144"><a href="#PreTrainedErnieModel.from_pretrained-144"><span class="linenos">144</span></a><span class="sd">                (ex: num_labels for ErnieForSequenceClassification)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-145"><a href="#PreTrainedErnieModel.from_pretrained-145"><span class="linenos">145</span></a><span class="sd">        Returns:</span>
</span><span id="PreTrainedErnieModel.from_pretrained-146"><a href="#PreTrainedErnieModel.from_pretrained-146"><span class="linenos">146</span></a><span class="sd">            The loaded pretrained model</span>
</span><span id="PreTrainedErnieModel.from_pretrained-147"><a href="#PreTrainedErnieModel.from_pretrained-147"><span class="linenos">147</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedErnieModel.from_pretrained-148"><a href="#PreTrainedErnieModel.from_pretrained-148"><span class="linenos">148</span></a>        
</span><span id="PreTrainedErnieModel.from_pretrained-149"><a href="#PreTrainedErnieModel.from_pretrained-149"><span class="linenos">149</span></a>        <span class="c1"># Load config</span>
</span><span id="PreTrainedErnieModel.from_pretrained-150"><a href="#PreTrainedErnieModel.from_pretrained-150"><span class="linenos">150</span></a>        <span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">CONFIG_NAME</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-151"><a href="#PreTrainedErnieModel.from_pretrained-151"><span class="linenos">151</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">ErnieConfig</span><span class="o">.</span><span class="n">load_from_json</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-152"><a href="#PreTrainedErnieModel.from_pretrained-152"><span class="linenos">152</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-153"><a href="#PreTrainedErnieModel.from_pretrained-153"><span class="linenos">153</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-154"><a href="#PreTrainedErnieModel.from_pretrained-154"><span class="linenos">154</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-155"><a href="#PreTrainedErnieModel.from_pretrained-155"><span class="linenos">155</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">state_dict</span><span class="o">==</span><span class="kc">None</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel.from_pretrained-156"><a href="#PreTrainedErnieModel.from_pretrained-156"><span class="linenos">156</span></a>            <span class="n">weights_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-157"><a href="#PreTrainedErnieModel.from_pretrained-157"><span class="linenos">157</span></a>            <span class="k">if</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="PreTrainedErnieModel.from_pretrained-158"><a href="#PreTrainedErnieModel.from_pretrained-158"><span class="linenos">158</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-159"><a href="#PreTrainedErnieModel.from_pretrained-159"><span class="linenos">159</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PreTrainedErnieModel.from_pretrained-160"><a href="#PreTrainedErnieModel.from_pretrained-160"><span class="linenos">160</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span><span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-161"><a href="#PreTrainedErnieModel.from_pretrained-161"><span class="linenos">161</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-162"><a href="#PreTrainedErnieModel.from_pretrained-162"><span class="linenos">162</span></a>        <span class="n">missing_keys</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PreTrainedErnieModel.from_pretrained-163"><a href="#PreTrainedErnieModel.from_pretrained-163"><span class="linenos">163</span></a>        <span class="c1"># copy state_dict so _load_from_state_dict can modify it</span>
</span><span id="PreTrainedErnieModel.from_pretrained-164"><a href="#PreTrainedErnieModel.from_pretrained-164"><span class="linenos">164</span></a>        <span class="n">metadata</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="s1">&#39;_metadata&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-165"><a href="#PreTrainedErnieModel.from_pretrained-165"><span class="linenos">165</span></a>        
</span><span id="PreTrainedErnieModel.from_pretrained-166"><a href="#PreTrainedErnieModel.from_pretrained-166"><span class="linenos">166</span></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="PreTrainedErnieModel.from_pretrained-167"><a href="#PreTrainedErnieModel.from_pretrained-167"><span class="linenos">167</span></a>        <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PreTrainedErnieModel.from_pretrained-168"><a href="#PreTrainedErnieModel.from_pretrained-168"><span class="linenos">168</span></a>            <span class="n">state_dict</span><span class="o">.</span><span class="n">_metadata</span> <span class="o">=</span> <span class="n">metadata</span>
</span><span id="PreTrainedErnieModel.from_pretrained-169"><a href="#PreTrainedErnieModel.from_pretrained-169"><span class="linenos">169</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-170"><a href="#PreTrainedErnieModel.from_pretrained-170"><span class="linenos">170</span></a>        <span class="n">mapping_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">MAPPING_FILE</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-171"><a href="#PreTrainedErnieModel.from_pretrained-171"><span class="linenos">171</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-172"><a href="#PreTrainedErnieModel.from_pretrained-172"><span class="linenos">172</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">)):</span>
</span><span id="PreTrainedErnieModel.from_pretrained-173"><a href="#PreTrainedErnieModel.from_pretrained-173"><span class="linenos">173</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
</span><span id="PreTrainedErnieModel.from_pretrained-174"><a href="#PreTrainedErnieModel.from_pretrained-174"><span class="linenos">174</span></a>                <span class="n">mapping</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-175"><a href="#PreTrainedErnieModel.from_pretrained-175"><span class="linenos">175</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-176"><a href="#PreTrainedErnieModel.from_pretrained-176"><span class="linenos">176</span></a>            <span class="k">for</span> <span class="n">old_key</span><span class="p">,</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="PreTrainedErnieModel.from_pretrained-177"><a href="#PreTrainedErnieModel.from_pretrained-177"><span class="linenos">177</span></a>                <span class="k">if</span><span class="p">(</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()):</span>
</span><span id="PreTrainedErnieModel.from_pretrained-178"><a href="#PreTrainedErnieModel.from_pretrained-178"><span class="linenos">178</span></a>                    <span class="n">model_shape</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">new_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</span><span id="PreTrainedErnieModel.from_pretrained-179"><a href="#PreTrainedErnieModel.from_pretrained-179"><span class="linenos">179</span></a>                    <span class="k">if</span><span class="p">(</span><span class="n">model_shape</span><span class="o">!=</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
</span><span id="PreTrainedErnieModel.from_pretrained-180"><a href="#PreTrainedErnieModel.from_pretrained-180"><span class="linenos">180</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;model.state_dict() </span><span class="si">{</span><span class="n">new_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">model_shape</span><span class="si">}</span><span class="s1"> != state_dict </span><span class="si">{</span><span class="n">old_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-181"><a href="#PreTrainedErnieModel.from_pretrained-181"><span class="linenos">181</span></a>                        
</span><span id="PreTrainedErnieModel.from_pretrained-182"><a href="#PreTrainedErnieModel.from_pretrained-182"><span class="linenos">182</span></a>                <span class="n">state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-183"><a href="#PreTrainedErnieModel.from_pretrained-183"><span class="linenos">183</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-184"><a href="#PreTrainedErnieModel.from_pretrained-184"><span class="linenos">184</span></a>        <span class="n">missing_keys</span><span class="p">,</span><span class="n">unexpected_keys</span> <span class="o">=</span>  <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-185"><a href="#PreTrainedErnieModel.from_pretrained-185"><span class="linenos">185</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Missing keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">missing_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-186"><a href="#PreTrainedErnieModel.from_pretrained-186"><span class="linenos">186</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedErnieModel.from_pretrained-187"><a href="#PreTrainedErnieModel.from_pretrained-187"><span class="linenos">187</span></a>
</span><span id="PreTrainedErnieModel.from_pretrained-188"><a href="#PreTrainedErnieModel.from_pretrained-188"><span class="linenos">188</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">missing_keys</span>
</span></pre></div>


            <div class="docstring"><p>Instantiate a PreTrainedErnieModel from a pre-trained model file or a pytorch state dict.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>dir_path:</strong>  - a path to a pretrained model archive containing:
   . <code>ernie_config.json</code>: a configuration file for the model
   . <code>pytorch_model.bin</code>: a PyTorch dump of a ErnieForPreTraining instance
   .  <code>mapping.json</code>: an Optional file to remap the weights from the pre-trained weights to this implementation </li>
<li><strong>state_dict:</strong>  an optional state dictionnary (collections.OrderedDict object) to use instead of the PyTorch dump</li>
<li><strong><em>inputs, *</em>kwargs:</strong>  additional input for the specific Ernie class
(ex: num_labels for ErnieForSequenceClassification)</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>The loaded pretrained model</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="PreTrainedErnieModel.dump_patches" class="variable">dump_patches</dd>
                <dd id="PreTrainedErnieModel.forward" class="function">forward</dd>
                <dd id="PreTrainedErnieModel.register_buffer" class="function">register_buffer</dd>
                <dd id="PreTrainedErnieModel.register_parameter" class="function">register_parameter</dd>
                <dd id="PreTrainedErnieModel.add_module" class="function">add_module</dd>
                <dd id="PreTrainedErnieModel.apply" class="function">apply</dd>
                <dd id="PreTrainedErnieModel.cuda" class="function">cuda</dd>
                <dd id="PreTrainedErnieModel.cpu" class="function">cpu</dd>
                <dd id="PreTrainedErnieModel.type" class="function">type</dd>
                <dd id="PreTrainedErnieModel.float" class="function">float</dd>
                <dd id="PreTrainedErnieModel.double" class="function">double</dd>
                <dd id="PreTrainedErnieModel.half" class="function">half</dd>
                <dd id="PreTrainedErnieModel.bfloat16" class="function">bfloat16</dd>
                <dd id="PreTrainedErnieModel.to" class="function">to</dd>
                <dd id="PreTrainedErnieModel.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="PreTrainedErnieModel.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="PreTrainedErnieModel.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="PreTrainedErnieModel.T_destination" class="variable">T_destination</dd>
                <dd id="PreTrainedErnieModel.state_dict" class="function">state_dict</dd>
                <dd id="PreTrainedErnieModel.load_state_dict" class="function">load_state_dict</dd>
                <dd id="PreTrainedErnieModel.parameters" class="function">parameters</dd>
                <dd id="PreTrainedErnieModel.named_parameters" class="function">named_parameters</dd>
                <dd id="PreTrainedErnieModel.buffers" class="function">buffers</dd>
                <dd id="PreTrainedErnieModel.named_buffers" class="function">named_buffers</dd>
                <dd id="PreTrainedErnieModel.children" class="function">children</dd>
                <dd id="PreTrainedErnieModel.named_children" class="function">named_children</dd>
                <dd id="PreTrainedErnieModel.modules" class="function">modules</dd>
                <dd id="PreTrainedErnieModel.named_modules" class="function">named_modules</dd>
                <dd id="PreTrainedErnieModel.train" class="function">train</dd>
                <dd id="PreTrainedErnieModel.eval" class="function">eval</dd>
                <dd id="PreTrainedErnieModel.requires_grad_" class="function">requires_grad_</dd>
                <dd id="PreTrainedErnieModel.zero_grad" class="function">zero_grad</dd>
                <dd id="PreTrainedErnieModel.share_memory" class="function">share_memory</dd>
                <dd id="PreTrainedErnieModel.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieModel">
                            <input id="ErnieModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieModel</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieModel-190"><a href="#ErnieModel-190"><span class="linenos">190</span></a><span class="k">class</span> <span class="nc">ErnieModel</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieModel-191"><a href="#ErnieModel-191"><span class="linenos">191</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieModel-192"><a href="#ErnieModel-192"><span class="linenos">192</span></a><span class="sd">    Ernie model</span>
</span><span id="ErnieModel-193"><a href="#ErnieModel-193"><span class="linenos">193</span></a>
</span><span id="ErnieModel-194"><a href="#ErnieModel-194"><span class="linenos">194</span></a><span class="sd">    Params:</span>
</span><span id="ErnieModel-195"><a href="#ErnieModel-195"><span class="linenos">195</span></a><span class="sd">        config: an ErnieConfig class instance with the configuration to build a new model</span>
</span><span id="ErnieModel-196"><a href="#ErnieModel-196"><span class="linenos">196</span></a>
</span><span id="ErnieModel-197"><a href="#ErnieModel-197"><span class="linenos">197</span></a><span class="sd">    Args:</span>
</span><span id="ErnieModel-198"><a href="#ErnieModel-198"><span class="linenos">198</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieModel-199"><a href="#ErnieModel-199"><span class="linenos">199</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieModel-200"><a href="#ErnieModel-200"><span class="linenos">200</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieModel-201"><a href="#ErnieModel-201"><span class="linenos">201</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieModel-202"><a href="#ErnieModel-202"><span class="linenos">202</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieModel-203"><a href="#ErnieModel-203"><span class="linenos">203</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieModel-204"><a href="#ErnieModel-204"><span class="linenos">204</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieModel-205"><a href="#ErnieModel-205"><span class="linenos">205</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieModel-206"><a href="#ErnieModel-206"><span class="linenos">206</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieModel-207"><a href="#ErnieModel-207"><span class="linenos">207</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieModel-208"><a href="#ErnieModel-208"><span class="linenos">208</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieModel-209"><a href="#ErnieModel-209"><span class="linenos">209</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieModel-210"><a href="#ErnieModel-210"><span class="linenos">210</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieModel-211"><a href="#ErnieModel-211"><span class="linenos">211</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieModel-212"><a href="#ErnieModel-212"><span class="linenos">212</span></a><span class="sd">        `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.</span>
</span><span id="ErnieModel-213"><a href="#ErnieModel-213"><span class="linenos">213</span></a>
</span><span id="ErnieModel-214"><a href="#ErnieModel-214"><span class="linenos">214</span></a><span class="sd">    Returns: Tuple of (encoded_layers, pooled_output)</span>
</span><span id="ErnieModel-215"><a href="#ErnieModel-215"><span class="linenos">215</span></a><span class="sd">        `encoded_layers`: controled by `output_all_encoded_layers` argument:</span>
</span><span id="ErnieModel-216"><a href="#ErnieModel-216"><span class="linenos">216</span></a><span class="sd">            - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end</span>
</span><span id="ErnieModel-217"><a href="#ErnieModel-217"><span class="linenos">217</span></a><span class="sd">                of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each</span>
</span><span id="ErnieModel-218"><a href="#ErnieModel-218"><span class="linenos">218</span></a><span class="sd">                encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],</span>
</span><span id="ErnieModel-219"><a href="#ErnieModel-219"><span class="linenos">219</span></a><span class="sd">            - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding</span>
</span><span id="ErnieModel-220"><a href="#ErnieModel-220"><span class="linenos">220</span></a><span class="sd">                to the last attention block of shape [batch_size, sequence_length, hidden_size],</span>
</span><span id="ErnieModel-221"><a href="#ErnieModel-221"><span class="linenos">221</span></a><span class="sd">        `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a</span>
</span><span id="ErnieModel-222"><a href="#ErnieModel-222"><span class="linenos">222</span></a><span class="sd">             classifier pretrained on top of the hidden state associated to the first character of the</span>
</span><span id="ErnieModel-223"><a href="#ErnieModel-223"><span class="linenos">223</span></a><span class="sd">             input (`CLS`) to train on the Next-Sentence task (see BERT&#39;s paper).</span>
</span><span id="ErnieModel-224"><a href="#ErnieModel-224"><span class="linenos">224</span></a>
</span><span id="ErnieModel-225"><a href="#ErnieModel-225"><span class="linenos">225</span></a><span class="sd">    Example usage:</span>
</span><span id="ErnieModel-226"><a href="#ErnieModel-226"><span class="linenos">226</span></a><span class="sd">    ```python</span>
</span><span id="ErnieModel-227"><a href="#ErnieModel-227"><span class="linenos">227</span></a><span class="sd">    # Already been converted into WordPiece token ids</span>
</span><span id="ErnieModel-228"><a href="#ErnieModel-228"><span class="linenos">228</span></a><span class="sd">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span>
</span><span id="ErnieModel-229"><a href="#ErnieModel-229"><span class="linenos">229</span></a><span class="sd">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span>
</span><span id="ErnieModel-230"><a href="#ErnieModel-230"><span class="linenos">230</span></a><span class="sd">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="ErnieModel-231"><a href="#ErnieModel-231"><span class="linenos">231</span></a><span class="sd">    input_ent: shape(1,6,100)</span>
</span><span id="ErnieModel-232"><a href="#ErnieModel-232"><span class="linenos">232</span></a><span class="sd">    ent_mask: torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="ErnieModel-233"><a href="#ErnieModel-233"><span class="linenos">233</span></a>
</span><span id="ErnieModel-234"><a href="#ErnieModel-234"><span class="linenos">234</span></a><span class="sd">    config = modeling.ErnieConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span>
</span><span id="ErnieModel-235"><a href="#ErnieModel-235"><span class="linenos">235</span></a><span class="sd">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span>
</span><span id="ErnieModel-236"><a href="#ErnieModel-236"><span class="linenos">236</span></a>
</span><span id="ErnieModel-237"><a href="#ErnieModel-237"><span class="linenos">237</span></a><span class="sd">    model = modeling.ErnieModel(config=config)</span>
</span><span id="ErnieModel-238"><a href="#ErnieModel-238"><span class="linenos">238</span></a><span class="sd">    all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask, input_ent, ent_mask)</span>
</span><span id="ErnieModel-239"><a href="#ErnieModel-239"><span class="linenos">239</span></a><span class="sd">    ```</span>
</span><span id="ErnieModel-240"><a href="#ErnieModel-240"><span class="linenos">240</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieModel-241"><a href="#ErnieModel-241"><span class="linenos">241</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieModel-242"><a href="#ErnieModel-242"><span class="linenos">242</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieModel-243"><a href="#ErnieModel-243"><span class="linenos">243</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">type_vocab_size</span><span class="p">)</span>
</span><span id="ErnieModel-244"><a href="#ErnieModel-244"><span class="linenos">244</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieModel-245"><a href="#ErnieModel-245"><span class="linenos">245</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="o">=</span> <span class="n">BertPooler</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ErnieModel-246"><a href="#ErnieModel-246"><span class="linenos">246</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieModel-247"><a href="#ErnieModel-247"><span class="linenos">247</span></a>
</span><span id="ErnieModel-248"><a href="#ErnieModel-248"><span class="linenos">248</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="ErnieModel-249"><a href="#ErnieModel-249"><span class="linenos">249</span></a>        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieModel-250"><a href="#ErnieModel-250"><span class="linenos">250</span></a>            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="ErnieModel-251"><a href="#ErnieModel-251"><span class="linenos">251</span></a>        <span class="k">if</span> <span class="n">token_type_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieModel-252"><a href="#ErnieModel-252"><span class="linenos">252</span></a>            <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="ErnieModel-253"><a href="#ErnieModel-253"><span class="linenos">253</span></a>
</span><span id="ErnieModel-254"><a href="#ErnieModel-254"><span class="linenos">254</span></a>        <span class="c1"># We create a 3D attention mask from a 2D tensor mask.</span>
</span><span id="ErnieModel-255"><a href="#ErnieModel-255"><span class="linenos">255</span></a>        <span class="c1"># Sizes are [batch_size, 1, 1, to_seq_length]</span>
</span><span id="ErnieModel-256"><a href="#ErnieModel-256"><span class="linenos">256</span></a>        <span class="c1"># So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]</span>
</span><span id="ErnieModel-257"><a href="#ErnieModel-257"><span class="linenos">257</span></a>        <span class="c1"># this attention mask is more simple than the triangular masking of causal attention</span>
</span><span id="ErnieModel-258"><a href="#ErnieModel-258"><span class="linenos">258</span></a>        <span class="c1"># used in OpenAI GPT, we just need to prepare the broadcast dimension here.</span>
</span><span id="ErnieModel-259"><a href="#ErnieModel-259"><span class="linenos">259</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="ErnieModel-260"><a href="#ErnieModel-260"><span class="linenos">260</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="ErnieModel-261"><a href="#ErnieModel-261"><span class="linenos">261</span></a>
</span><span id="ErnieModel-262"><a href="#ErnieModel-262"><span class="linenos">262</span></a>        <span class="c1"># Since attention_mask is 1.0 for positions we want to attend and 0.0 for</span>
</span><span id="ErnieModel-263"><a href="#ErnieModel-263"><span class="linenos">263</span></a>        <span class="c1"># masked positions, this operation will create a tensor which is 0.0 for</span>
</span><span id="ErnieModel-264"><a href="#ErnieModel-264"><span class="linenos">264</span></a>        <span class="c1"># positions we want to attend and -10000.0 for masked positions.</span>
</span><span id="ErnieModel-265"><a href="#ErnieModel-265"><span class="linenos">265</span></a>        <span class="c1"># Since we are adding it to the raw scores before the softmax, this is</span>
</span><span id="ErnieModel-266"><a href="#ErnieModel-266"><span class="linenos">266</span></a>        <span class="c1"># effectively the same as removing these entirely.</span>
</span><span id="ErnieModel-267"><a href="#ErnieModel-267"><span class="linenos">267</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
</span><span id="ErnieModel-268"><a href="#ErnieModel-268"><span class="linenos">268</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="ErnieModel-269"><a href="#ErnieModel-269"><span class="linenos">269</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">extended_ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
</span><span id="ErnieModel-270"><a href="#ErnieModel-270"><span class="linenos">270</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_ent_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="ErnieModel-271"><a href="#ErnieModel-271"><span class="linenos">271</span></a>
</span><span id="ErnieModel-272"><a href="#ErnieModel-272"><span class="linenos">272</span></a>        <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
</span><span id="ErnieModel-273"><a href="#ErnieModel-273"><span class="linenos">273</span></a>        <span class="n">encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">,</span>
</span><span id="ErnieModel-274"><a href="#ErnieModel-274"><span class="linenos">274</span></a>                                      <span class="n">extended_attention_mask</span><span class="p">,</span>
</span><span id="ErnieModel-275"><a href="#ErnieModel-275"><span class="linenos">275</span></a>                                      <span class="n">input_ent</span><span class="p">,</span>
</span><span id="ErnieModel-276"><a href="#ErnieModel-276"><span class="linenos">276</span></a>                                      <span class="n">extended_ent_mask</span><span class="p">,</span>
</span><span id="ErnieModel-277"><a href="#ErnieModel-277"><span class="linenos">277</span></a>                                      <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="ErnieModel-278"><a href="#ErnieModel-278"><span class="linenos">278</span></a>                                      <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="ErnieModel-279"><a href="#ErnieModel-279"><span class="linenos">279</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ErnieModel-280"><a href="#ErnieModel-280"><span class="linenos">280</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="ErnieModel-281"><a href="#ErnieModel-281"><span class="linenos">281</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="ErnieModel-282"><a href="#ErnieModel-282"><span class="linenos">282</span></a>            <span class="n">encoded_layers</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ErnieModel-283"><a href="#ErnieModel-283"><span class="linenos">283</span></a>        <span class="k">return</span> <span class="n">encoded_layers</span><span class="p">,</span> <span class="n">pooled_output</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model</p>

<h6 id="params">Params</h6>

<blockquote>
  <p>config: an ErnieConfig class instance with the configuration to build a new model</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>output_all_encoded_layers</code>:</strong>  boolean which controls the content of the <code>encoded_layers</code> output as described below. Default: <code>True</code>.</li>
</ul>

<p>Returns: Tuple of (encoded_layers, pooled_output)
    <code>encoded_layers</code>: controled by <code>output_all_encoded_layers</code> argument:
        - <code>output_all_encoded_layers=True</code>: outputs a list of the full sequences of encoded-hidden-states at the end
            of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each
            encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],
        - <code>output_all_encoded_layers=False</code>: outputs only the full sequence of hidden-states corresponding
            to the last attention block of shape [batch_size, sequence_length, hidden_size],
    <code>pooled_output</code>: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a
         classifier pretrained on top of the hidden state associated to the first character of the
         input (<code>CLS</code>) to train on the Next-Sentence task (see BERT's paper).</p>

<p>Example usage:</p>

<div class="pdoc-code codehilite"><pre><span></span><code><span class="c1"># Already been converted into WordPiece token ids</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">31</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">99</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">input_ent</span><span class="p">:</span> <span class="n">shape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ent_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">modeling</span><span class="o">.</span><span class="n">ErnieConfig</span><span class="p">(</span><span class="n">vocab_size_or_config_json_file</span><span class="o">=</span><span class="mi">32000</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">modeling</span><span class="o">.</span><span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">all_encoder_layers</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">)</span>
</code></pre></div>
</div>


                            <div id="ErnieModel.__init__" class="classattr">
                                        <input id="ErnieModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieModel</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ErnieModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieModel.__init__-241"><a href="#ErnieModel.__init__-241"><span class="linenos">241</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieModel.__init__-242"><a href="#ErnieModel.__init__-242"><span class="linenos">242</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieModel.__init__-243"><a href="#ErnieModel.__init__-243"><span class="linenos">243</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">,</span><span class="n">config</span><span class="o">.</span><span class="n">type_vocab_size</span><span class="p">)</span>
</span><span id="ErnieModel.__init__-244"><a href="#ErnieModel.__init__-244"><span class="linenos">244</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieModel.__init__-245"><a href="#ErnieModel.__init__-245"><span class="linenos">245</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="o">=</span> <span class="n">BertPooler</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="ErnieModel.__init__-246"><a href="#ErnieModel.__init__-246"><span class="linenos">246</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieModel.forward" class="classattr">
                                        <input id="ErnieModel.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="ErnieModel.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieModel.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieModel.forward-248"><a href="#ErnieModel.forward-248"><span class="linenos">248</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="ErnieModel.forward-249"><a href="#ErnieModel.forward-249"><span class="linenos">249</span></a>        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieModel.forward-250"><a href="#ErnieModel.forward-250"><span class="linenos">250</span></a>            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="ErnieModel.forward-251"><a href="#ErnieModel.forward-251"><span class="linenos">251</span></a>        <span class="k">if</span> <span class="n">token_type_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieModel.forward-252"><a href="#ErnieModel.forward-252"><span class="linenos">252</span></a>            <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="ErnieModel.forward-253"><a href="#ErnieModel.forward-253"><span class="linenos">253</span></a>
</span><span id="ErnieModel.forward-254"><a href="#ErnieModel.forward-254"><span class="linenos">254</span></a>        <span class="c1"># We create a 3D attention mask from a 2D tensor mask.</span>
</span><span id="ErnieModel.forward-255"><a href="#ErnieModel.forward-255"><span class="linenos">255</span></a>        <span class="c1"># Sizes are [batch_size, 1, 1, to_seq_length]</span>
</span><span id="ErnieModel.forward-256"><a href="#ErnieModel.forward-256"><span class="linenos">256</span></a>        <span class="c1"># So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]</span>
</span><span id="ErnieModel.forward-257"><a href="#ErnieModel.forward-257"><span class="linenos">257</span></a>        <span class="c1"># this attention mask is more simple than the triangular masking of causal attention</span>
</span><span id="ErnieModel.forward-258"><a href="#ErnieModel.forward-258"><span class="linenos">258</span></a>        <span class="c1"># used in OpenAI GPT, we just need to prepare the broadcast dimension here.</span>
</span><span id="ErnieModel.forward-259"><a href="#ErnieModel.forward-259"><span class="linenos">259</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="ErnieModel.forward-260"><a href="#ErnieModel.forward-260"><span class="linenos">260</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="ErnieModel.forward-261"><a href="#ErnieModel.forward-261"><span class="linenos">261</span></a>
</span><span id="ErnieModel.forward-262"><a href="#ErnieModel.forward-262"><span class="linenos">262</span></a>        <span class="c1"># Since attention_mask is 1.0 for positions we want to attend and 0.0 for</span>
</span><span id="ErnieModel.forward-263"><a href="#ErnieModel.forward-263"><span class="linenos">263</span></a>        <span class="c1"># masked positions, this operation will create a tensor which is 0.0 for</span>
</span><span id="ErnieModel.forward-264"><a href="#ErnieModel.forward-264"><span class="linenos">264</span></a>        <span class="c1"># positions we want to attend and -10000.0 for masked positions.</span>
</span><span id="ErnieModel.forward-265"><a href="#ErnieModel.forward-265"><span class="linenos">265</span></a>        <span class="c1"># Since we are adding it to the raw scores before the softmax, this is</span>
</span><span id="ErnieModel.forward-266"><a href="#ErnieModel.forward-266"><span class="linenos">266</span></a>        <span class="c1"># effectively the same as removing these entirely.</span>
</span><span id="ErnieModel.forward-267"><a href="#ErnieModel.forward-267"><span class="linenos">267</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
</span><span id="ErnieModel.forward-268"><a href="#ErnieModel.forward-268"><span class="linenos">268</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="ErnieModel.forward-269"><a href="#ErnieModel.forward-269"><span class="linenos">269</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">extended_ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># fp16 compatibility</span>
</span><span id="ErnieModel.forward-270"><a href="#ErnieModel.forward-270"><span class="linenos">270</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_ent_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="ErnieModel.forward-271"><a href="#ErnieModel.forward-271"><span class="linenos">271</span></a>
</span><span id="ErnieModel.forward-272"><a href="#ErnieModel.forward-272"><span class="linenos">272</span></a>        <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
</span><span id="ErnieModel.forward-273"><a href="#ErnieModel.forward-273"><span class="linenos">273</span></a>        <span class="n">encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">,</span>
</span><span id="ErnieModel.forward-274"><a href="#ErnieModel.forward-274"><span class="linenos">274</span></a>                                      <span class="n">extended_attention_mask</span><span class="p">,</span>
</span><span id="ErnieModel.forward-275"><a href="#ErnieModel.forward-275"><span class="linenos">275</span></a>                                      <span class="n">input_ent</span><span class="p">,</span>
</span><span id="ErnieModel.forward-276"><a href="#ErnieModel.forward-276"><span class="linenos">276</span></a>                                      <span class="n">extended_ent_mask</span><span class="p">,</span>
</span><span id="ErnieModel.forward-277"><a href="#ErnieModel.forward-277"><span class="linenos">277</span></a>                                      <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="ErnieModel.forward-278"><a href="#ErnieModel.forward-278"><span class="linenos">278</span></a>                                      <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="ErnieModel.forward-279"><a href="#ErnieModel.forward-279"><span class="linenos">279</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ErnieModel.forward-280"><a href="#ErnieModel.forward-280"><span class="linenos">280</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="ErnieModel.forward-281"><a href="#ErnieModel.forward-281"><span class="linenos">281</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="ErnieModel.forward-282"><a href="#ErnieModel.forward-282"><span class="linenos">282</span></a>            <span class="n">encoded_layers</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ErnieModel.forward-283"><a href="#ErnieModel.forward-283"><span class="linenos">283</span></a>        <span class="k">return</span> <span class="n">encoded_layers</span><span class="p">,</span> <span class="n">pooled_output</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieModel.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieModel.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieModel.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieModel.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieModel.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieModel.add_module" class="function">add_module</dd>
                <dd id="ErnieModel.apply" class="function">apply</dd>
                <dd id="ErnieModel.cuda" class="function">cuda</dd>
                <dd id="ErnieModel.cpu" class="function">cpu</dd>
                <dd id="ErnieModel.type" class="function">type</dd>
                <dd id="ErnieModel.float" class="function">float</dd>
                <dd id="ErnieModel.double" class="function">double</dd>
                <dd id="ErnieModel.half" class="function">half</dd>
                <dd id="ErnieModel.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieModel.to" class="function">to</dd>
                <dd id="ErnieModel.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieModel.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieModel.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieModel.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieModel.state_dict" class="function">state_dict</dd>
                <dd id="ErnieModel.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieModel.parameters" class="function">parameters</dd>
                <dd id="ErnieModel.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieModel.buffers" class="function">buffers</dd>
                <dd id="ErnieModel.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieModel.children" class="function">children</dd>
                <dd id="ErnieModel.named_children" class="function">named_children</dd>
                <dd id="ErnieModel.modules" class="function">modules</dd>
                <dd id="ErnieModel.named_modules" class="function">named_modules</dd>
                <dd id="ErnieModel.train" class="function">train</dd>
                <dd id="ErnieModel.eval" class="function">eval</dd>
                <dd id="ErnieModel.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieModel.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieModel.share_memory" class="function">share_memory</dd>
                <dd id="ErnieModel.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForMaskedLM">
                            <input id="ErnieForMaskedLM-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForMaskedLM</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForMaskedLM-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForMaskedLM"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForMaskedLM-287"><a href="#ErnieForMaskedLM-287"><span class="linenos">287</span></a><span class="k">class</span> <span class="nc">ErnieForMaskedLM</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForMaskedLM-288"><a href="#ErnieForMaskedLM-288"><span class="linenos">288</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForMaskedLM-289"><a href="#ErnieForMaskedLM-289"><span class="linenos">289</span></a><span class="sd">    Ernie model with the masked language modeling head.</span>
</span><span id="ErnieForMaskedLM-290"><a href="#ErnieForMaskedLM-290"><span class="linenos">290</span></a>
</span><span id="ErnieForMaskedLM-291"><a href="#ErnieForMaskedLM-291"><span class="linenos">291</span></a><span class="sd">    This module comprises the Ernie model followed by the masked language modeling head.</span>
</span><span id="ErnieForMaskedLM-292"><a href="#ErnieForMaskedLM-292"><span class="linenos">292</span></a>
</span><span id="ErnieForMaskedLM-293"><a href="#ErnieForMaskedLM-293"><span class="linenos">293</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForMaskedLM-294"><a href="#ErnieForMaskedLM-294"><span class="linenos">294</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="ErnieForMaskedLM-295"><a href="#ErnieForMaskedLM-295"><span class="linenos">295</span></a>
</span><span id="ErnieForMaskedLM-296"><a href="#ErnieForMaskedLM-296"><span class="linenos">296</span></a><span class="sd">    Args:</span>
</span><span id="ErnieForMaskedLM-297"><a href="#ErnieForMaskedLM-297"><span class="linenos">297</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForMaskedLM-298"><a href="#ErnieForMaskedLM-298"><span class="linenos">298</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForMaskedLM-299"><a href="#ErnieForMaskedLM-299"><span class="linenos">299</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForMaskedLM-300"><a href="#ErnieForMaskedLM-300"><span class="linenos">300</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForMaskedLM-301"><a href="#ErnieForMaskedLM-301"><span class="linenos">301</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForMaskedLM-302"><a href="#ErnieForMaskedLM-302"><span class="linenos">302</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForMaskedLM-303"><a href="#ErnieForMaskedLM-303"><span class="linenos">303</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForMaskedLM-304"><a href="#ErnieForMaskedLM-304"><span class="linenos">304</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForMaskedLM-305"><a href="#ErnieForMaskedLM-305"><span class="linenos">305</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForMaskedLM-306"><a href="#ErnieForMaskedLM-306"><span class="linenos">306</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForMaskedLM-307"><a href="#ErnieForMaskedLM-307"><span class="linenos">307</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieForMaskedLM-308"><a href="#ErnieForMaskedLM-308"><span class="linenos">308</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieForMaskedLM-309"><a href="#ErnieForMaskedLM-309"><span class="linenos">309</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForMaskedLM-310"><a href="#ErnieForMaskedLM-310"><span class="linenos">310</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieForMaskedLM-311"><a href="#ErnieForMaskedLM-311"><span class="linenos">311</span></a><span class="sd">        `masked_lm_labels`: masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForMaskedLM-312"><a href="#ErnieForMaskedLM-312"><span class="linenos">312</span></a><span class="sd">            with indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss</span>
</span><span id="ErnieForMaskedLM-313"><a href="#ErnieForMaskedLM-313"><span class="linenos">313</span></a><span class="sd">            is only computed for the labels set in [0, ..., vocab_size]</span>
</span><span id="ErnieForMaskedLM-314"><a href="#ErnieForMaskedLM-314"><span class="linenos">314</span></a>
</span><span id="ErnieForMaskedLM-315"><a href="#ErnieForMaskedLM-315"><span class="linenos">315</span></a><span class="sd">    Returns:</span>
</span><span id="ErnieForMaskedLM-316"><a href="#ErnieForMaskedLM-316"><span class="linenos">316</span></a><span class="sd">        if `masked_lm_labels` is `None`:</span>
</span><span id="ErnieForMaskedLM-317"><a href="#ErnieForMaskedLM-317"><span class="linenos">317</span></a><span class="sd">            Outputs the masked language modeling loss.</span>
</span><span id="ErnieForMaskedLM-318"><a href="#ErnieForMaskedLM-318"><span class="linenos">318</span></a><span class="sd">        if `masked_lm_labels` is `None`:</span>
</span><span id="ErnieForMaskedLM-319"><a href="#ErnieForMaskedLM-319"><span class="linenos">319</span></a><span class="sd">            Outputs the masked language modeling logits of shape [batch_size, sequence_length, vocab_size].</span>
</span><span id="ErnieForMaskedLM-320"><a href="#ErnieForMaskedLM-320"><span class="linenos">320</span></a>
</span><span id="ErnieForMaskedLM-321"><a href="#ErnieForMaskedLM-321"><span class="linenos">321</span></a><span class="sd">    Example usage:</span>
</span><span id="ErnieForMaskedLM-322"><a href="#ErnieForMaskedLM-322"><span class="linenos">322</span></a><span class="sd">    ```python</span>
</span><span id="ErnieForMaskedLM-323"><a href="#ErnieForMaskedLM-323"><span class="linenos">323</span></a><span class="sd">    # Already been converted into WordPiece token ids</span>
</span><span id="ErnieForMaskedLM-324"><a href="#ErnieForMaskedLM-324"><span class="linenos">324</span></a><span class="sd">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span>
</span><span id="ErnieForMaskedLM-325"><a href="#ErnieForMaskedLM-325"><span class="linenos">325</span></a><span class="sd">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span>
</span><span id="ErnieForMaskedLM-326"><a href="#ErnieForMaskedLM-326"><span class="linenos">326</span></a><span class="sd">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="ErnieForMaskedLM-327"><a href="#ErnieForMaskedLM-327"><span class="linenos">327</span></a><span class="sd">    input_ent: shape(1,6,100)</span>
</span><span id="ErnieForMaskedLM-328"><a href="#ErnieForMaskedLM-328"><span class="linenos">328</span></a><span class="sd">    ent_mask: torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="ErnieForMaskedLM-329"><a href="#ErnieForMaskedLM-329"><span class="linenos">329</span></a>
</span><span id="ErnieForMaskedLM-330"><a href="#ErnieForMaskedLM-330"><span class="linenos">330</span></a><span class="sd">    config = ErnieConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span>
</span><span id="ErnieForMaskedLM-331"><a href="#ErnieForMaskedLM-331"><span class="linenos">331</span></a><span class="sd">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span>
</span><span id="ErnieForMaskedLM-332"><a href="#ErnieForMaskedLM-332"><span class="linenos">332</span></a>
</span><span id="ErnieForMaskedLM-333"><a href="#ErnieForMaskedLM-333"><span class="linenos">333</span></a><span class="sd">    model = ErnieForMaskedLM(config)</span>
</span><span id="ErnieForMaskedLM-334"><a href="#ErnieForMaskedLM-334"><span class="linenos">334</span></a><span class="sd">    masked_lm_logits_scores = model(input_ids, token_type_ids, input_mask,input_ent,ent_mask)</span>
</span><span id="ErnieForMaskedLM-335"><a href="#ErnieForMaskedLM-335"><span class="linenos">335</span></a><span class="sd">    ```</span>
</span><span id="ErnieForMaskedLM-336"><a href="#ErnieForMaskedLM-336"><span class="linenos">336</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForMaskedLM-337"><a href="#ErnieForMaskedLM-337"><span class="linenos">337</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForMaskedLM-338"><a href="#ErnieForMaskedLM-338"><span class="linenos">338</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM-339"><a href="#ErnieForMaskedLM-339"><span class="linenos">339</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM-340"><a href="#ErnieForMaskedLM-340"><span class="linenos">340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM-341"><a href="#ErnieForMaskedLM-341"><span class="linenos">341</span></a>        <span class="c1">#Recursively initalize all the weights</span>
</span><span id="ErnieForMaskedLM-342"><a href="#ErnieForMaskedLM-342"><span class="linenos">342</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForMaskedLM-343"><a href="#ErnieForMaskedLM-343"><span class="linenos">343</span></a>
</span><span id="ErnieForMaskedLM-344"><a href="#ErnieForMaskedLM-344"><span class="linenos">344</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForMaskedLM-345"><a href="#ErnieForMaskedLM-345"><span class="linenos">345</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="ErnieForMaskedLM-346"><a href="#ErnieForMaskedLM-346"><span class="linenos">346</span></a>                                       <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM-347"><a href="#ErnieForMaskedLM-347"><span class="linenos">347</span></a>        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM-348"><a href="#ErnieForMaskedLM-348"><span class="linenos">348</span></a>
</span><span id="ErnieForMaskedLM-349"><a href="#ErnieForMaskedLM-349"><span class="linenos">349</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForMaskedLM-350"><a href="#ErnieForMaskedLM-350"><span class="linenos">350</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM-351"><a href="#ErnieForMaskedLM-351"><span class="linenos">351</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForMaskedLM-352"><a href="#ErnieForMaskedLM-352"><span class="linenos">352</span></a>            <span class="k">return</span> <span class="n">masked_lm_loss</span>
</span><span id="ErnieForMaskedLM-353"><a href="#ErnieForMaskedLM-353"><span class="linenos">353</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForMaskedLM-354"><a href="#ErnieForMaskedLM-354"><span class="linenos">354</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model with the masked language modeling head.</p>

<p>This module comprises the Ernie model followed by the masked language modeling head.</p>

<h6 id="params">Params</h6>

<blockquote>
  <p>config: a ErnieConfig class instance with the configuration to build a new model.</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>masked_lm_labels</code>:</strong>  masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]
with indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss
is only computed for the labels set in [0, ..., vocab_size]</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>masked_lm_labels</code> is <code>None</code>:
      Outputs the masked language modeling loss.
  if <code>masked_lm_labels</code> is <code>None</code>:
      Outputs the masked language modeling logits of shape [batch_size, sequence_length, vocab_size].</p>
</blockquote>

<p>Example usage:</p>

<div class="pdoc-code codehilite"><pre><span></span><code><span class="c1"># Already been converted into WordPiece token ids</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">31</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">99</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">input_ent</span><span class="p">:</span> <span class="n">shape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ent_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ErnieConfig</span><span class="p">(</span><span class="n">vocab_size_or_config_json_file</span><span class="o">=</span><span class="mi">32000</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ErnieForMaskedLM</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">masked_lm_logits_scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">,</span><span class="n">input_ent</span><span class="p">,</span><span class="n">ent_mask</span><span class="p">)</span>
</code></pre></div>
</div>


                            <div id="ErnieForMaskedLM.__init__" class="classattr">
                                        <input id="ErnieForMaskedLM.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForMaskedLM</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ErnieForMaskedLM.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForMaskedLM.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForMaskedLM.__init__-337"><a href="#ErnieForMaskedLM.__init__-337"><span class="linenos">337</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForMaskedLM.__init__-338"><a href="#ErnieForMaskedLM.__init__-338"><span class="linenos">338</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM.__init__-339"><a href="#ErnieForMaskedLM.__init__-339"><span class="linenos">339</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM.__init__-340"><a href="#ErnieForMaskedLM.__init__-340"><span class="linenos">340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM.__init__-341"><a href="#ErnieForMaskedLM.__init__-341"><span class="linenos">341</span></a>        <span class="c1">#Recursively initalize all the weights</span>
</span><span id="ErnieForMaskedLM.__init__-342"><a href="#ErnieForMaskedLM.__init__-342"><span class="linenos">342</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForMaskedLM.forward" class="classattr">
                                        <input id="ErnieForMaskedLM.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">input_ents</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForMaskedLM.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForMaskedLM.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForMaskedLM.forward-344"><a href="#ErnieForMaskedLM.forward-344"><span class="linenos">344</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForMaskedLM.forward-345"><a href="#ErnieForMaskedLM.forward-345"><span class="linenos">345</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="ErnieForMaskedLM.forward-346"><a href="#ErnieForMaskedLM.forward-346"><span class="linenos">346</span></a>                                       <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM.forward-347"><a href="#ErnieForMaskedLM.forward-347"><span class="linenos">347</span></a>        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM.forward-348"><a href="#ErnieForMaskedLM.forward-348"><span class="linenos">348</span></a>
</span><span id="ErnieForMaskedLM.forward-349"><a href="#ErnieForMaskedLM.forward-349"><span class="linenos">349</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForMaskedLM.forward-350"><a href="#ErnieForMaskedLM.forward-350"><span class="linenos">350</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForMaskedLM.forward-351"><a href="#ErnieForMaskedLM.forward-351"><span class="linenos">351</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForMaskedLM.forward-352"><a href="#ErnieForMaskedLM.forward-352"><span class="linenos">352</span></a>            <span class="k">return</span> <span class="n">masked_lm_loss</span>
</span><span id="ErnieForMaskedLM.forward-353"><a href="#ErnieForMaskedLM.forward-353"><span class="linenos">353</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForMaskedLM.forward-354"><a href="#ErnieForMaskedLM.forward-354"><span class="linenos">354</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForMaskedLM.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForMaskedLM.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForMaskedLM.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForMaskedLM.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForMaskedLM.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForMaskedLM.add_module" class="function">add_module</dd>
                <dd id="ErnieForMaskedLM.apply" class="function">apply</dd>
                <dd id="ErnieForMaskedLM.cuda" class="function">cuda</dd>
                <dd id="ErnieForMaskedLM.cpu" class="function">cpu</dd>
                <dd id="ErnieForMaskedLM.type" class="function">type</dd>
                <dd id="ErnieForMaskedLM.float" class="function">float</dd>
                <dd id="ErnieForMaskedLM.double" class="function">double</dd>
                <dd id="ErnieForMaskedLM.half" class="function">half</dd>
                <dd id="ErnieForMaskedLM.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForMaskedLM.to" class="function">to</dd>
                <dd id="ErnieForMaskedLM.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForMaskedLM.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForMaskedLM.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForMaskedLM.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForMaskedLM.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForMaskedLM.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForMaskedLM.parameters" class="function">parameters</dd>
                <dd id="ErnieForMaskedLM.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForMaskedLM.buffers" class="function">buffers</dd>
                <dd id="ErnieForMaskedLM.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForMaskedLM.children" class="function">children</dd>
                <dd id="ErnieForMaskedLM.named_children" class="function">named_children</dd>
                <dd id="ErnieForMaskedLM.modules" class="function">modules</dd>
                <dd id="ErnieForMaskedLM.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForMaskedLM.train" class="function">train</dd>
                <dd id="ErnieForMaskedLM.eval" class="function">eval</dd>
                <dd id="ErnieForMaskedLM.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForMaskedLM.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForMaskedLM.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForMaskedLM.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForPreTraining">
                            <input id="ErnieForPreTraining-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForPreTraining</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForPreTraining-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForPreTraining"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForPreTraining-356"><a href="#ErnieForPreTraining-356"><span class="linenos">356</span></a><span class="k">class</span> <span class="nc">ErnieForPreTraining</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForPreTraining-357"><a href="#ErnieForPreTraining-357"><span class="linenos">357</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForPreTraining-358"><a href="#ErnieForPreTraining-358"><span class="linenos">358</span></a><span class="sd">    Ernie model with pre-training heads.</span>
</span><span id="ErnieForPreTraining-359"><a href="#ErnieForPreTraining-359"><span class="linenos">359</span></a><span class="sd">    This module comprises the Ernie model followed by the two pre-training heads:</span>
</span><span id="ErnieForPreTraining-360"><a href="#ErnieForPreTraining-360"><span class="linenos">360</span></a><span class="sd">        - the masked language modeling head, and</span>
</span><span id="ErnieForPreTraining-361"><a href="#ErnieForPreTraining-361"><span class="linenos">361</span></a><span class="sd">        - the next sentence classification head.</span>
</span><span id="ErnieForPreTraining-362"><a href="#ErnieForPreTraining-362"><span class="linenos">362</span></a>
</span><span id="ErnieForPreTraining-363"><a href="#ErnieForPreTraining-363"><span class="linenos">363</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForPreTraining-364"><a href="#ErnieForPreTraining-364"><span class="linenos">364</span></a><span class="sd">        config: an ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="ErnieForPreTraining-365"><a href="#ErnieForPreTraining-365"><span class="linenos">365</span></a>
</span><span id="ErnieForPreTraining-366"><a href="#ErnieForPreTraining-366"><span class="linenos">366</span></a><span class="sd">    Args:</span>
</span><span id="ErnieForPreTraining-367"><a href="#ErnieForPreTraining-367"><span class="linenos">367</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForPreTraining-368"><a href="#ErnieForPreTraining-368"><span class="linenos">368</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForPreTraining-369"><a href="#ErnieForPreTraining-369"><span class="linenos">369</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForPreTraining-370"><a href="#ErnieForPreTraining-370"><span class="linenos">370</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForPreTraining-371"><a href="#ErnieForPreTraining-371"><span class="linenos">371</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForPreTraining-372"><a href="#ErnieForPreTraining-372"><span class="linenos">372</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForPreTraining-373"><a href="#ErnieForPreTraining-373"><span class="linenos">373</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForPreTraining-374"><a href="#ErnieForPreTraining-374"><span class="linenos">374</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForPreTraining-375"><a href="#ErnieForPreTraining-375"><span class="linenos">375</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForPreTraining-376"><a href="#ErnieForPreTraining-376"><span class="linenos">376</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForPreTraining-377"><a href="#ErnieForPreTraining-377"><span class="linenos">377</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieForPreTraining-378"><a href="#ErnieForPreTraining-378"><span class="linenos">378</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieForPreTraining-379"><a href="#ErnieForPreTraining-379"><span class="linenos">379</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForPreTraining-380"><a href="#ErnieForPreTraining-380"><span class="linenos">380</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieForPreTraining-381"><a href="#ErnieForPreTraining-381"><span class="linenos">381</span></a><span class="sd">        `masked_lm_labels`: masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForPreTraining-382"><a href="#ErnieForPreTraining-382"><span class="linenos">382</span></a><span class="sd">            with indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss</span>
</span><span id="ErnieForPreTraining-383"><a href="#ErnieForPreTraining-383"><span class="linenos">383</span></a><span class="sd">            is only computed for the labels set in [0, ..., vocab_size]</span>
</span><span id="ErnieForPreTraining-384"><a href="#ErnieForPreTraining-384"><span class="linenos">384</span></a><span class="sd">        `next_sentence_label`: next sentence classification loss: torch.LongTensor of shape [batch_size]</span>
</span><span id="ErnieForPreTraining-385"><a href="#ErnieForPreTraining-385"><span class="linenos">385</span></a><span class="sd">            with indices selected in [0, 1].</span>
</span><span id="ErnieForPreTraining-386"><a href="#ErnieForPreTraining-386"><span class="linenos">386</span></a><span class="sd">            0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</span>
</span><span id="ErnieForPreTraining-387"><a href="#ErnieForPreTraining-387"><span class="linenos">387</span></a>
</span><span id="ErnieForPreTraining-388"><a href="#ErnieForPreTraining-388"><span class="linenos">388</span></a><span class="sd">    Returns:</span>
</span><span id="ErnieForPreTraining-389"><a href="#ErnieForPreTraining-389"><span class="linenos">389</span></a><span class="sd">        if `masked_lm_labels` and `next_sentence_label` are not `None`:</span>
</span><span id="ErnieForPreTraining-390"><a href="#ErnieForPreTraining-390"><span class="linenos">390</span></a><span class="sd">            Outputs the total_loss which is the sum of the masked language modeling loss and the next</span>
</span><span id="ErnieForPreTraining-391"><a href="#ErnieForPreTraining-391"><span class="linenos">391</span></a><span class="sd">            sentence classification loss.</span>
</span><span id="ErnieForPreTraining-392"><a href="#ErnieForPreTraining-392"><span class="linenos">392</span></a><span class="sd">        if `masked_lm_labels` or `next_sentence_label` is `None`:</span>
</span><span id="ErnieForPreTraining-393"><a href="#ErnieForPreTraining-393"><span class="linenos">393</span></a><span class="sd">            Outputs a tuple comprising</span>
</span><span id="ErnieForPreTraining-394"><a href="#ErnieForPreTraining-394"><span class="linenos">394</span></a><span class="sd">            - the masked language modeling logits of shape [batch_size, sequence_length, vocab_size], and</span>
</span><span id="ErnieForPreTraining-395"><a href="#ErnieForPreTraining-395"><span class="linenos">395</span></a><span class="sd">            - the next sentence classification logits of shape [batch_size, 2].</span>
</span><span id="ErnieForPreTraining-396"><a href="#ErnieForPreTraining-396"><span class="linenos">396</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForPreTraining-397"><a href="#ErnieForPreTraining-397"><span class="linenos">397</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForPreTraining-398"><a href="#ErnieForPreTraining-398"><span class="linenos">398</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForPreTraining-399"><a href="#ErnieForPreTraining-399"><span class="linenos">399</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForPreTraining-400"><a href="#ErnieForPreTraining-400"><span class="linenos">400</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">ErniePreTrainingHeads</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="ErnieForPreTraining-401"><a href="#ErnieForPreTraining-401"><span class="linenos">401</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForPreTraining-402"><a href="#ErnieForPreTraining-402"><span class="linenos">402</span></a>
</span><span id="ErnieForPreTraining-403"><a href="#ErnieForPreTraining-403"><span class="linenos">403</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
</span><span id="ErnieForPreTraining-404"><a href="#ErnieForPreTraining-404"><span class="linenos">404</span></a>        <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">candidate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForPreTraining-405"><a href="#ErnieForPreTraining-405"><span class="linenos">405</span></a>        <span class="c1"># the id in ent_labels should be consistent with the order of candidate.</span>
</span><span id="ErnieForPreTraining-406"><a href="#ErnieForPreTraining-406"><span class="linenos">406</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="ErnieForPreTraining-407"><a href="#ErnieForPreTraining-407"><span class="linenos">407</span></a>                                                   <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForPreTraining-408"><a href="#ErnieForPreTraining-408"><span class="linenos">408</span></a>        <span class="n">prediction_scores</span><span class="p">,</span> <span class="n">seq_relationship_score</span><span class="p">,</span> <span class="n">prediction_scores_ent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span><span class="p">,</span> <span class="n">candidate</span><span class="p">)</span>
</span><span id="ErnieForPreTraining-409"><a href="#ErnieForPreTraining-409"><span class="linenos">409</span></a>
</span><span id="ErnieForPreTraining-410"><a href="#ErnieForPreTraining-410"><span class="linenos">410</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">next_sentence_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForPreTraining-411"><a href="#ErnieForPreTraining-411"><span class="linenos">411</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForPreTraining-412"><a href="#ErnieForPreTraining-412"><span class="linenos">412</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForPreTraining-413"><a href="#ErnieForPreTraining-413"><span class="linenos">413</span></a>            <span class="n">next_sentence_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">seq_relationship_score</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">next_sentence_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForPreTraining-414"><a href="#ErnieForPreTraining-414"><span class="linenos">414</span></a>            <span class="n">ent_ae_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores_ent</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">candidate</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">ent_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForPreTraining-415"><a href="#ErnieForPreTraining-415"><span class="linenos">415</span></a>            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">masked_lm_loss</span> <span class="o">+</span> <span class="n">next_sentence_loss</span> <span class="o">+</span> <span class="n">ent_ae_loss</span>
</span><span id="ErnieForPreTraining-416"><a href="#ErnieForPreTraining-416"><span class="linenos">416</span></a>            <span class="n">original_loss</span> <span class="o">=</span> <span class="n">masked_lm_loss</span> <span class="o">+</span> <span class="n">next_sentence_loss</span>
</span><span id="ErnieForPreTraining-417"><a href="#ErnieForPreTraining-417"><span class="linenos">417</span></a>            <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">original_loss</span>
</span><span id="ErnieForPreTraining-418"><a href="#ErnieForPreTraining-418"><span class="linenos">418</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForPreTraining-419"><a href="#ErnieForPreTraining-419"><span class="linenos">419</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span><span class="p">,</span> <span class="n">seq_relationship_score</span><span class="p">,</span> <span class="n">prediction_scores_ent</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model with pre-training heads.
This module comprises the Ernie model followed by the two pre-training heads:
    - the masked language modeling head, and
    - the next sentence classification head.</p>

<h6 id="params">Params</h6>

<blockquote>
  <p>config: an ErnieConfig class instance with the configuration to build a new model.</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>masked_lm_labels</code>:</strong>  masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]
with indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss
is only computed for the labels set in [0, ..., vocab_size]</li>
<li><strong><code>next_sentence_label</code>:</strong>  next sentence classification loss: torch.LongTensor of shape [batch_size]
with indices selected in [0, 1].
0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>masked_lm_labels</code> and <code>next_sentence_label</code> are not <code>None</code>:
      Outputs the total_loss which is the sum of the masked language modeling loss and the next
      sentence classification loss.
  if <code>masked_lm_labels</code> or <code>next_sentence_label</code> is <code>None</code>:
      Outputs a tuple comprising
      - the masked language modeling logits of shape [batch_size, sequence_length, vocab_size], and
      - the next sentence classification logits of shape [batch_size, 2].</p>
</blockquote>
</div>


                            <div id="ErnieForPreTraining.__init__" class="classattr">
                                        <input id="ErnieForPreTraining.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForPreTraining</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ErnieForPreTraining.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForPreTraining.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForPreTraining.__init__-397"><a href="#ErnieForPreTraining.__init__-397"><span class="linenos">397</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForPreTraining.__init__-398"><a href="#ErnieForPreTraining.__init__-398"><span class="linenos">398</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForPreTraining.__init__-399"><a href="#ErnieForPreTraining.__init__-399"><span class="linenos">399</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForPreTraining.__init__-400"><a href="#ErnieForPreTraining.__init__-400"><span class="linenos">400</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">ErniePreTrainingHeads</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="ErnieForPreTraining.__init__-401"><a href="#ErnieForPreTraining.__init__-401"><span class="linenos">401</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForPreTraining.forward" class="classattr">
                                        <input id="ErnieForPreTraining.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">candidate</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_labels</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForPreTraining.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForPreTraining.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForPreTraining.forward-403"><a href="#ErnieForPreTraining.forward-403"><span class="linenos">403</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
</span><span id="ErnieForPreTraining.forward-404"><a href="#ErnieForPreTraining.forward-404"><span class="linenos">404</span></a>        <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">candidate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForPreTraining.forward-405"><a href="#ErnieForPreTraining.forward-405"><span class="linenos">405</span></a>        <span class="c1"># the id in ent_labels should be consistent with the order of candidate.</span>
</span><span id="ErnieForPreTraining.forward-406"><a href="#ErnieForPreTraining.forward-406"><span class="linenos">406</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="ErnieForPreTraining.forward-407"><a href="#ErnieForPreTraining.forward-407"><span class="linenos">407</span></a>                                                   <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForPreTraining.forward-408"><a href="#ErnieForPreTraining.forward-408"><span class="linenos">408</span></a>        <span class="n">prediction_scores</span><span class="p">,</span> <span class="n">seq_relationship_score</span><span class="p">,</span> <span class="n">prediction_scores_ent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span><span class="p">,</span> <span class="n">candidate</span><span class="p">)</span>
</span><span id="ErnieForPreTraining.forward-409"><a href="#ErnieForPreTraining.forward-409"><span class="linenos">409</span></a>
</span><span id="ErnieForPreTraining.forward-410"><a href="#ErnieForPreTraining.forward-410"><span class="linenos">410</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">next_sentence_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForPreTraining.forward-411"><a href="#ErnieForPreTraining.forward-411"><span class="linenos">411</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForPreTraining.forward-412"><a href="#ErnieForPreTraining.forward-412"><span class="linenos">412</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForPreTraining.forward-413"><a href="#ErnieForPreTraining.forward-413"><span class="linenos">413</span></a>            <span class="n">next_sentence_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">seq_relationship_score</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">next_sentence_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForPreTraining.forward-414"><a href="#ErnieForPreTraining.forward-414"><span class="linenos">414</span></a>            <span class="n">ent_ae_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores_ent</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">candidate</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">ent_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForPreTraining.forward-415"><a href="#ErnieForPreTraining.forward-415"><span class="linenos">415</span></a>            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">masked_lm_loss</span> <span class="o">+</span> <span class="n">next_sentence_loss</span> <span class="o">+</span> <span class="n">ent_ae_loss</span>
</span><span id="ErnieForPreTraining.forward-416"><a href="#ErnieForPreTraining.forward-416"><span class="linenos">416</span></a>            <span class="n">original_loss</span> <span class="o">=</span> <span class="n">masked_lm_loss</span> <span class="o">+</span> <span class="n">next_sentence_loss</span>
</span><span id="ErnieForPreTraining.forward-417"><a href="#ErnieForPreTraining.forward-417"><span class="linenos">417</span></a>            <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">original_loss</span>
</span><span id="ErnieForPreTraining.forward-418"><a href="#ErnieForPreTraining.forward-418"><span class="linenos">418</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForPreTraining.forward-419"><a href="#ErnieForPreTraining.forward-419"><span class="linenos">419</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span><span class="p">,</span> <span class="n">seq_relationship_score</span><span class="p">,</span> <span class="n">prediction_scores_ent</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForPreTraining.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForPreTraining.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForPreTraining.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForPreTraining.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForPreTraining.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForPreTraining.add_module" class="function">add_module</dd>
                <dd id="ErnieForPreTraining.apply" class="function">apply</dd>
                <dd id="ErnieForPreTraining.cuda" class="function">cuda</dd>
                <dd id="ErnieForPreTraining.cpu" class="function">cpu</dd>
                <dd id="ErnieForPreTraining.type" class="function">type</dd>
                <dd id="ErnieForPreTraining.float" class="function">float</dd>
                <dd id="ErnieForPreTraining.double" class="function">double</dd>
                <dd id="ErnieForPreTraining.half" class="function">half</dd>
                <dd id="ErnieForPreTraining.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForPreTraining.to" class="function">to</dd>
                <dd id="ErnieForPreTraining.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForPreTraining.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForPreTraining.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForPreTraining.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForPreTraining.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForPreTraining.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForPreTraining.parameters" class="function">parameters</dd>
                <dd id="ErnieForPreTraining.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForPreTraining.buffers" class="function">buffers</dd>
                <dd id="ErnieForPreTraining.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForPreTraining.children" class="function">children</dd>
                <dd id="ErnieForPreTraining.named_children" class="function">named_children</dd>
                <dd id="ErnieForPreTraining.modules" class="function">modules</dd>
                <dd id="ErnieForPreTraining.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForPreTraining.train" class="function">train</dd>
                <dd id="ErnieForPreTraining.eval" class="function">eval</dd>
                <dd id="ErnieForPreTraining.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForPreTraining.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForPreTraining.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForPreTraining.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForNextSentencePrediction">
                            <input id="ErnieForNextSentencePrediction-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForNextSentencePrediction</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForNextSentencePrediction-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForNextSentencePrediction"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForNextSentencePrediction-421"><a href="#ErnieForNextSentencePrediction-421"><span class="linenos">421</span></a><span class="k">class</span> <span class="nc">ErnieForNextSentencePrediction</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForNextSentencePrediction-422"><a href="#ErnieForNextSentencePrediction-422"><span class="linenos">422</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForNextSentencePrediction-423"><a href="#ErnieForNextSentencePrediction-423"><span class="linenos">423</span></a><span class="sd">    Ernie model with next sentence prediction head.</span>
</span><span id="ErnieForNextSentencePrediction-424"><a href="#ErnieForNextSentencePrediction-424"><span class="linenos">424</span></a><span class="sd">    This module comprises the Ernie model followed by the next sentence classification head.</span>
</span><span id="ErnieForNextSentencePrediction-425"><a href="#ErnieForNextSentencePrediction-425"><span class="linenos">425</span></a>
</span><span id="ErnieForNextSentencePrediction-426"><a href="#ErnieForNextSentencePrediction-426"><span class="linenos">426</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForNextSentencePrediction-427"><a href="#ErnieForNextSentencePrediction-427"><span class="linenos">427</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="ErnieForNextSentencePrediction-428"><a href="#ErnieForNextSentencePrediction-428"><span class="linenos">428</span></a>
</span><span id="ErnieForNextSentencePrediction-429"><a href="#ErnieForNextSentencePrediction-429"><span class="linenos">429</span></a><span class="sd">    Args:</span>
</span><span id="ErnieForNextSentencePrediction-430"><a href="#ErnieForNextSentencePrediction-430"><span class="linenos">430</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForNextSentencePrediction-431"><a href="#ErnieForNextSentencePrediction-431"><span class="linenos">431</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForNextSentencePrediction-432"><a href="#ErnieForNextSentencePrediction-432"><span class="linenos">432</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForNextSentencePrediction-433"><a href="#ErnieForNextSentencePrediction-433"><span class="linenos">433</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForNextSentencePrediction-434"><a href="#ErnieForNextSentencePrediction-434"><span class="linenos">434</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForNextSentencePrediction-435"><a href="#ErnieForNextSentencePrediction-435"><span class="linenos">435</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForNextSentencePrediction-436"><a href="#ErnieForNextSentencePrediction-436"><span class="linenos">436</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForNextSentencePrediction-437"><a href="#ErnieForNextSentencePrediction-437"><span class="linenos">437</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForNextSentencePrediction-438"><a href="#ErnieForNextSentencePrediction-438"><span class="linenos">438</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForNextSentencePrediction-439"><a href="#ErnieForNextSentencePrediction-439"><span class="linenos">439</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForNextSentencePrediction-440"><a href="#ErnieForNextSentencePrediction-440"><span class="linenos">440</span></a><span class="sd">        `next_sentence_label`: next sentence classification loss: torch.LongTensor of shape [batch_size]</span>
</span><span id="ErnieForNextSentencePrediction-441"><a href="#ErnieForNextSentencePrediction-441"><span class="linenos">441</span></a><span class="sd">            with indices selected in [0, 1].</span>
</span><span id="ErnieForNextSentencePrediction-442"><a href="#ErnieForNextSentencePrediction-442"><span class="linenos">442</span></a><span class="sd">            0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</span>
</span><span id="ErnieForNextSentencePrediction-443"><a href="#ErnieForNextSentencePrediction-443"><span class="linenos">443</span></a>
</span><span id="ErnieForNextSentencePrediction-444"><a href="#ErnieForNextSentencePrediction-444"><span class="linenos">444</span></a><span class="sd">    Returns:</span>
</span><span id="ErnieForNextSentencePrediction-445"><a href="#ErnieForNextSentencePrediction-445"><span class="linenos">445</span></a><span class="sd">        if `next_sentence_label` is not `None`:</span>
</span><span id="ErnieForNextSentencePrediction-446"><a href="#ErnieForNextSentencePrediction-446"><span class="linenos">446</span></a><span class="sd">            Outputs the total_loss which is the sum of the masked language modeling loss and the next</span>
</span><span id="ErnieForNextSentencePrediction-447"><a href="#ErnieForNextSentencePrediction-447"><span class="linenos">447</span></a><span class="sd">            sentence classification loss.</span>
</span><span id="ErnieForNextSentencePrediction-448"><a href="#ErnieForNextSentencePrediction-448"><span class="linenos">448</span></a><span class="sd">        if `next_sentence_label` is `None`:</span>
</span><span id="ErnieForNextSentencePrediction-449"><a href="#ErnieForNextSentencePrediction-449"><span class="linenos">449</span></a><span class="sd">            Outputs the next sentence classification logits of shape [batch_size, 2].</span>
</span><span id="ErnieForNextSentencePrediction-450"><a href="#ErnieForNextSentencePrediction-450"><span class="linenos">450</span></a>
</span><span id="ErnieForNextSentencePrediction-451"><a href="#ErnieForNextSentencePrediction-451"><span class="linenos">451</span></a><span class="sd">    Example usage:</span>
</span><span id="ErnieForNextSentencePrediction-452"><a href="#ErnieForNextSentencePrediction-452"><span class="linenos">452</span></a><span class="sd">    ```python</span>
</span><span id="ErnieForNextSentencePrediction-453"><a href="#ErnieForNextSentencePrediction-453"><span class="linenos">453</span></a><span class="sd">    # Already been converted into WordPiece token ids</span>
</span><span id="ErnieForNextSentencePrediction-454"><a href="#ErnieForNextSentencePrediction-454"><span class="linenos">454</span></a><span class="sd">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span>
</span><span id="ErnieForNextSentencePrediction-455"><a href="#ErnieForNextSentencePrediction-455"><span class="linenos">455</span></a><span class="sd">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span>
</span><span id="ErnieForNextSentencePrediction-456"><a href="#ErnieForNextSentencePrediction-456"><span class="linenos">456</span></a><span class="sd">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span>
</span><span id="ErnieForNextSentencePrediction-457"><a href="#ErnieForNextSentencePrediction-457"><span class="linenos">457</span></a>
</span><span id="ErnieForNextSentencePrediction-458"><a href="#ErnieForNextSentencePrediction-458"><span class="linenos">458</span></a><span class="sd">    config = ErnieConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span>
</span><span id="ErnieForNextSentencePrediction-459"><a href="#ErnieForNextSentencePrediction-459"><span class="linenos">459</span></a><span class="sd">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span>
</span><span id="ErnieForNextSentencePrediction-460"><a href="#ErnieForNextSentencePrediction-460"><span class="linenos">460</span></a>
</span><span id="ErnieForNextSentencePrediction-461"><a href="#ErnieForNextSentencePrediction-461"><span class="linenos">461</span></a><span class="sd">    model = ErnieForNextSentencePrediction(config)</span>
</span><span id="ErnieForNextSentencePrediction-462"><a href="#ErnieForNextSentencePrediction-462"><span class="linenos">462</span></a><span class="sd">    seq_relationship_logits = model(input_ids, token_type_ids, input_mask)</span>
</span><span id="ErnieForNextSentencePrediction-463"><a href="#ErnieForNextSentencePrediction-463"><span class="linenos">463</span></a><span class="sd">    ```</span>
</span><span id="ErnieForNextSentencePrediction-464"><a href="#ErnieForNextSentencePrediction-464"><span class="linenos">464</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForNextSentencePrediction-465"><a href="#ErnieForNextSentencePrediction-465"><span class="linenos">465</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForNextSentencePrediction-466"><a href="#ErnieForNextSentencePrediction-466"><span class="linenos">466</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction-467"><a href="#ErnieForNextSentencePrediction-467"><span class="linenos">467</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction-468"><a href="#ErnieForNextSentencePrediction-468"><span class="linenos">468</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyNSPHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction-469"><a href="#ErnieForNextSentencePrediction-469"><span class="linenos">469</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForNextSentencePrediction-470"><a href="#ErnieForNextSentencePrediction-470"><span class="linenos">470</span></a>
</span><span id="ErnieForNextSentencePrediction-471"><a href="#ErnieForNextSentencePrediction-471"><span class="linenos">471</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForNextSentencePrediction-472"><a href="#ErnieForNextSentencePrediction-472"><span class="linenos">472</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span id="ErnieForNextSentencePrediction-473"><a href="#ErnieForNextSentencePrediction-473"><span class="linenos">473</span></a>                                     <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction-474"><a href="#ErnieForNextSentencePrediction-474"><span class="linenos">474</span></a>        <span class="n">seq_relationship_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span> <span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction-475"><a href="#ErnieForNextSentencePrediction-475"><span class="linenos">475</span></a>
</span><span id="ErnieForNextSentencePrediction-476"><a href="#ErnieForNextSentencePrediction-476"><span class="linenos">476</span></a>        <span class="k">if</span> <span class="n">next_sentence_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForNextSentencePrediction-477"><a href="#ErnieForNextSentencePrediction-477"><span class="linenos">477</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction-478"><a href="#ErnieForNextSentencePrediction-478"><span class="linenos">478</span></a>            <span class="n">next_sentence_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">seq_relationship_score</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">next_sentence_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNextSentencePrediction-479"><a href="#ErnieForNextSentencePrediction-479"><span class="linenos">479</span></a>            <span class="k">return</span> <span class="n">next_sentence_loss</span>
</span><span id="ErnieForNextSentencePrediction-480"><a href="#ErnieForNextSentencePrediction-480"><span class="linenos">480</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForNextSentencePrediction-481"><a href="#ErnieForNextSentencePrediction-481"><span class="linenos">481</span></a>            <span class="k">return</span> <span class="n">seq_relationship_score</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model with next sentence prediction head.
This module comprises the Ernie model followed by the next sentence classification head.</p>

<h6 id="params">Params</h6>

<blockquote>
  <p>config: a ErnieConfig class instance with the configuration to build a new model.</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>next_sentence_label</code>:</strong>  next sentence classification loss: torch.LongTensor of shape [batch_size]
with indices selected in [0, 1].
0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>next_sentence_label</code> is not <code>None</code>:
      Outputs the total_loss which is the sum of the masked language modeling loss and the next
      sentence classification loss.
  if <code>next_sentence_label</code> is <code>None</code>:
      Outputs the next sentence classification logits of shape [batch_size, 2].</p>
</blockquote>

<p>Example usage:</p>

<div class="pdoc-code codehilite"><pre><span></span><code><span class="c1"># Already been converted into WordPiece token ids</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">31</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">99</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">input_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">ErnieConfig</span><span class="p">(</span><span class="n">vocab_size_or_config_json_file</span><span class="o">=</span><span class="mi">32000</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ErnieForNextSentencePrediction</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">seq_relationship_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">input_mask</span><span class="p">)</span>
</code></pre></div>
</div>


                            <div id="ErnieForNextSentencePrediction.__init__" class="classattr">
                                        <input id="ErnieForNextSentencePrediction.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForNextSentencePrediction</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ErnieForNextSentencePrediction.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForNextSentencePrediction.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForNextSentencePrediction.__init__-465"><a href="#ErnieForNextSentencePrediction.__init__-465"><span class="linenos">465</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForNextSentencePrediction.__init__-466"><a href="#ErnieForNextSentencePrediction.__init__-466"><span class="linenos">466</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction.__init__-467"><a href="#ErnieForNextSentencePrediction.__init__-467"><span class="linenos">467</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction.__init__-468"><a href="#ErnieForNextSentencePrediction.__init__-468"><span class="linenos">468</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyNSPHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction.__init__-469"><a href="#ErnieForNextSentencePrediction.__init__-469"><span class="linenos">469</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForNextSentencePrediction.forward" class="classattr">
                                        <input id="ErnieForNextSentencePrediction.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForNextSentencePrediction.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForNextSentencePrediction.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForNextSentencePrediction.forward-471"><a href="#ErnieForNextSentencePrediction.forward-471"><span class="linenos">471</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">next_sentence_label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForNextSentencePrediction.forward-472"><a href="#ErnieForNextSentencePrediction.forward-472"><span class="linenos">472</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span id="ErnieForNextSentencePrediction.forward-473"><a href="#ErnieForNextSentencePrediction.forward-473"><span class="linenos">473</span></a>                                     <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction.forward-474"><a href="#ErnieForNextSentencePrediction.forward-474"><span class="linenos">474</span></a>        <span class="n">seq_relationship_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span> <span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction.forward-475"><a href="#ErnieForNextSentencePrediction.forward-475"><span class="linenos">475</span></a>
</span><span id="ErnieForNextSentencePrediction.forward-476"><a href="#ErnieForNextSentencePrediction.forward-476"><span class="linenos">476</span></a>        <span class="k">if</span> <span class="n">next_sentence_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForNextSentencePrediction.forward-477"><a href="#ErnieForNextSentencePrediction.forward-477"><span class="linenos">477</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForNextSentencePrediction.forward-478"><a href="#ErnieForNextSentencePrediction.forward-478"><span class="linenos">478</span></a>            <span class="n">next_sentence_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">seq_relationship_score</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">next_sentence_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNextSentencePrediction.forward-479"><a href="#ErnieForNextSentencePrediction.forward-479"><span class="linenos">479</span></a>            <span class="k">return</span> <span class="n">next_sentence_loss</span>
</span><span id="ErnieForNextSentencePrediction.forward-480"><a href="#ErnieForNextSentencePrediction.forward-480"><span class="linenos">480</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForNextSentencePrediction.forward-481"><a href="#ErnieForNextSentencePrediction.forward-481"><span class="linenos">481</span></a>            <span class="k">return</span> <span class="n">seq_relationship_score</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForNextSentencePrediction.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForNextSentencePrediction.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForNextSentencePrediction.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForNextSentencePrediction.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForNextSentencePrediction.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForNextSentencePrediction.add_module" class="function">add_module</dd>
                <dd id="ErnieForNextSentencePrediction.apply" class="function">apply</dd>
                <dd id="ErnieForNextSentencePrediction.cuda" class="function">cuda</dd>
                <dd id="ErnieForNextSentencePrediction.cpu" class="function">cpu</dd>
                <dd id="ErnieForNextSentencePrediction.type" class="function">type</dd>
                <dd id="ErnieForNextSentencePrediction.float" class="function">float</dd>
                <dd id="ErnieForNextSentencePrediction.double" class="function">double</dd>
                <dd id="ErnieForNextSentencePrediction.half" class="function">half</dd>
                <dd id="ErnieForNextSentencePrediction.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForNextSentencePrediction.to" class="function">to</dd>
                <dd id="ErnieForNextSentencePrediction.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForNextSentencePrediction.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForNextSentencePrediction.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForNextSentencePrediction.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForNextSentencePrediction.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForNextSentencePrediction.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForNextSentencePrediction.parameters" class="function">parameters</dd>
                <dd id="ErnieForNextSentencePrediction.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForNextSentencePrediction.buffers" class="function">buffers</dd>
                <dd id="ErnieForNextSentencePrediction.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForNextSentencePrediction.children" class="function">children</dd>
                <dd id="ErnieForNextSentencePrediction.named_children" class="function">named_children</dd>
                <dd id="ErnieForNextSentencePrediction.modules" class="function">modules</dd>
                <dd id="ErnieForNextSentencePrediction.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForNextSentencePrediction.train" class="function">train</dd>
                <dd id="ErnieForNextSentencePrediction.eval" class="function">eval</dd>
                <dd id="ErnieForNextSentencePrediction.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForNextSentencePrediction.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForNextSentencePrediction.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForNextSentencePrediction.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForEntityTyping">
                            <input id="ErnieForEntityTyping-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForEntityTyping</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForEntityTyping-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForEntityTyping"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForEntityTyping-483"><a href="#ErnieForEntityTyping-483"><span class="linenos">483</span></a><span class="k">class</span> <span class="nc">ErnieForEntityTyping</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForEntityTyping-484"><a href="#ErnieForEntityTyping-484"><span class="linenos">484</span></a>
</span><span id="ErnieForEntityTyping-485"><a href="#ErnieForEntityTyping-485"><span class="linenos">485</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForEntityTyping-486"><a href="#ErnieForEntityTyping-486"><span class="linenos">486</span></a><span class="sd">    Ernie model with entity typing prediction head.</span>
</span><span id="ErnieForEntityTyping-487"><a href="#ErnieForEntityTyping-487"><span class="linenos">487</span></a><span class="sd">    This module comprises the Ernie model followed by the entity typing head.</span>
</span><span id="ErnieForEntityTyping-488"><a href="#ErnieForEntityTyping-488"><span class="linenos">488</span></a>
</span><span id="ErnieForEntityTyping-489"><a href="#ErnieForEntityTyping-489"><span class="linenos">489</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForEntityTyping-490"><a href="#ErnieForEntityTyping-490"><span class="linenos">490</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="ErnieForEntityTyping-491"><a href="#ErnieForEntityTyping-491"><span class="linenos">491</span></a><span class="sd">        `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="ErnieForEntityTyping-492"><a href="#ErnieForEntityTyping-492"><span class="linenos">492</span></a>
</span><span id="ErnieForEntityTyping-493"><a href="#ErnieForEntityTyping-493"><span class="linenos">493</span></a><span class="sd">    Args:</span>
</span><span id="ErnieForEntityTyping-494"><a href="#ErnieForEntityTyping-494"><span class="linenos">494</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForEntityTyping-495"><a href="#ErnieForEntityTyping-495"><span class="linenos">495</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForEntityTyping-496"><a href="#ErnieForEntityTyping-496"><span class="linenos">496</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForEntityTyping-497"><a href="#ErnieForEntityTyping-497"><span class="linenos">497</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForEntityTyping-498"><a href="#ErnieForEntityTyping-498"><span class="linenos">498</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForEntityTyping-499"><a href="#ErnieForEntityTyping-499"><span class="linenos">499</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForEntityTyping-500"><a href="#ErnieForEntityTyping-500"><span class="linenos">500</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForEntityTyping-501"><a href="#ErnieForEntityTyping-501"><span class="linenos">501</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForEntityTyping-502"><a href="#ErnieForEntityTyping-502"><span class="linenos">502</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForEntityTyping-503"><a href="#ErnieForEntityTyping-503"><span class="linenos">503</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForEntityTyping-504"><a href="#ErnieForEntityTyping-504"><span class="linenos">504</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieForEntityTyping-505"><a href="#ErnieForEntityTyping-505"><span class="linenos">505</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieForEntityTyping-506"><a href="#ErnieForEntityTyping-506"><span class="linenos">506</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForEntityTyping-507"><a href="#ErnieForEntityTyping-507"><span class="linenos">507</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieForEntityTyping-508"><a href="#ErnieForEntityTyping-508"><span class="linenos">508</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="ErnieForEntityTyping-509"><a href="#ErnieForEntityTyping-509"><span class="linenos">509</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="ErnieForEntityTyping-510"><a href="#ErnieForEntityTyping-510"><span class="linenos">510</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForEntityTyping-511"><a href="#ErnieForEntityTyping-511"><span class="linenos">511</span></a>
</span><span id="ErnieForEntityTyping-512"><a href="#ErnieForEntityTyping-512"><span class="linenos">512</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForEntityTyping-513"><a href="#ErnieForEntityTyping-513"><span class="linenos">513</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping-514"><a href="#ErnieForEntityTyping-514"><span class="linenos">514</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="ErnieForEntityTyping-515"><a href="#ErnieForEntityTyping-515"><span class="linenos">515</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping-516"><a href="#ErnieForEntityTyping-516"><span class="linenos">516</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping-517"><a href="#ErnieForEntityTyping-517"><span class="linenos">517</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">typing</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping-518"><a href="#ErnieForEntityTyping-518"><span class="linenos">518</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForEntityTyping-519"><a href="#ErnieForEntityTyping-519"><span class="linenos">519</span></a>
</span><span id="ErnieForEntityTyping-520"><a href="#ErnieForEntityTyping-520"><span class="linenos">520</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForEntityTyping-521"><a href="#ErnieForEntityTyping-521"><span class="linenos">521</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping-522"><a href="#ErnieForEntityTyping-522"><span class="linenos">522</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping-523"><a href="#ErnieForEntityTyping-523"><span class="linenos">523</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">typing</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping-524"><a href="#ErnieForEntityTyping-524"><span class="linenos">524</span></a>
</span><span id="ErnieForEntityTyping-525"><a href="#ErnieForEntityTyping-525"><span class="linenos">525</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForEntityTyping-526"><a href="#ErnieForEntityTyping-526"><span class="linenos">526</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="ErnieForEntityTyping-527"><a href="#ErnieForEntityTyping-527"><span class="linenos">527</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
</span><span id="ErnieForEntityTyping-528"><a href="#ErnieForEntityTyping-528"><span class="linenos">528</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForEntityTyping-529"><a href="#ErnieForEntityTyping-529"><span class="linenos">529</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForEntityTyping-530"><a href="#ErnieForEntityTyping-530"><span class="linenos">530</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model with entity typing prediction head.
This module comprises the Ernie model followed by the entity typing head.</p>

<h6 id="params">Params</h6>

<blockquote>
  <p>config: a ErnieConfig class instance with the configuration to build a new model.
  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]
with indices selected in [0, ..., num_labels].</li>
</ul>
</div>


                            <div id="ErnieForEntityTyping.__init__" class="classattr">
                                        <input id="ErnieForEntityTyping.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForEntityTyping</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span></span>)</span>

                <label class="view-source-button" for="ErnieForEntityTyping.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForEntityTyping.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForEntityTyping.__init__-512"><a href="#ErnieForEntityTyping.__init__-512"><span class="linenos">512</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForEntityTyping.__init__-513"><a href="#ErnieForEntityTyping.__init__-513"><span class="linenos">513</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping.__init__-514"><a href="#ErnieForEntityTyping.__init__-514"><span class="linenos">514</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="ErnieForEntityTyping.__init__-515"><a href="#ErnieForEntityTyping.__init__-515"><span class="linenos">515</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping.__init__-516"><a href="#ErnieForEntityTyping.__init__-516"><span class="linenos">516</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping.__init__-517"><a href="#ErnieForEntityTyping.__init__-517"><span class="linenos">517</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">typing</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping.__init__-518"><a href="#ErnieForEntityTyping.__init__-518"><span class="linenos">518</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForEntityTyping.forward" class="classattr">
                                        <input id="ErnieForEntityTyping.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForEntityTyping.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForEntityTyping.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForEntityTyping.forward-520"><a href="#ErnieForEntityTyping.forward-520"><span class="linenos">520</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForEntityTyping.forward-521"><a href="#ErnieForEntityTyping.forward-521"><span class="linenos">521</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping.forward-522"><a href="#ErnieForEntityTyping.forward-522"><span class="linenos">522</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping.forward-523"><a href="#ErnieForEntityTyping.forward-523"><span class="linenos">523</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">typing</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForEntityTyping.forward-524"><a href="#ErnieForEntityTyping.forward-524"><span class="linenos">524</span></a>
</span><span id="ErnieForEntityTyping.forward-525"><a href="#ErnieForEntityTyping.forward-525"><span class="linenos">525</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForEntityTyping.forward-526"><a href="#ErnieForEntityTyping.forward-526"><span class="linenos">526</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="ErnieForEntityTyping.forward-527"><a href="#ErnieForEntityTyping.forward-527"><span class="linenos">527</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
</span><span id="ErnieForEntityTyping.forward-528"><a href="#ErnieForEntityTyping.forward-528"><span class="linenos">528</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForEntityTyping.forward-529"><a href="#ErnieForEntityTyping.forward-529"><span class="linenos">529</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForEntityTyping.forward-530"><a href="#ErnieForEntityTyping.forward-530"><span class="linenos">530</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForEntityTyping.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForEntityTyping.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForEntityTyping.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForEntityTyping.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForEntityTyping.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForEntityTyping.add_module" class="function">add_module</dd>
                <dd id="ErnieForEntityTyping.apply" class="function">apply</dd>
                <dd id="ErnieForEntityTyping.cuda" class="function">cuda</dd>
                <dd id="ErnieForEntityTyping.cpu" class="function">cpu</dd>
                <dd id="ErnieForEntityTyping.type" class="function">type</dd>
                <dd id="ErnieForEntityTyping.float" class="function">float</dd>
                <dd id="ErnieForEntityTyping.double" class="function">double</dd>
                <dd id="ErnieForEntityTyping.half" class="function">half</dd>
                <dd id="ErnieForEntityTyping.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForEntityTyping.to" class="function">to</dd>
                <dd id="ErnieForEntityTyping.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForEntityTyping.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForEntityTyping.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForEntityTyping.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForEntityTyping.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForEntityTyping.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForEntityTyping.parameters" class="function">parameters</dd>
                <dd id="ErnieForEntityTyping.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForEntityTyping.buffers" class="function">buffers</dd>
                <dd id="ErnieForEntityTyping.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForEntityTyping.children" class="function">children</dd>
                <dd id="ErnieForEntityTyping.named_children" class="function">named_children</dd>
                <dd id="ErnieForEntityTyping.modules" class="function">modules</dd>
                <dd id="ErnieForEntityTyping.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForEntityTyping.train" class="function">train</dd>
                <dd id="ErnieForEntityTyping.eval" class="function">eval</dd>
                <dd id="ErnieForEntityTyping.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForEntityTyping.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForEntityTyping.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForEntityTyping.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForSTSB">
                            <input id="ErnieForSTSB-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForSTSB</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForSTSB-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForSTSB"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForSTSB-532"><a href="#ErnieForSTSB-532"><span class="linenos">532</span></a><span class="k">class</span> <span class="nc">ErnieForSTSB</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForSTSB-533"><a href="#ErnieForSTSB-533"><span class="linenos">533</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForSTSB-534"><a href="#ErnieForSTSB-534"><span class="linenos">534</span></a><span class="sd">    Ernie model with STSB prediction head (predict sentence similarity).</span>
</span><span id="ErnieForSTSB-535"><a href="#ErnieForSTSB-535"><span class="linenos">535</span></a><span class="sd">    This module comprises the Ernie model followed by the STSB head.</span>
</span><span id="ErnieForSTSB-536"><a href="#ErnieForSTSB-536"><span class="linenos">536</span></a>
</span><span id="ErnieForSTSB-537"><a href="#ErnieForSTSB-537"><span class="linenos">537</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForSTSB-538"><a href="#ErnieForSTSB-538"><span class="linenos">538</span></a><span class="sd">        config: a ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="ErnieForSTSB-539"><a href="#ErnieForSTSB-539"><span class="linenos">539</span></a><span class="sd">        `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="ErnieForSTSB-540"><a href="#ErnieForSTSB-540"><span class="linenos">540</span></a>
</span><span id="ErnieForSTSB-541"><a href="#ErnieForSTSB-541"><span class="linenos">541</span></a><span class="sd">    Args:</span>
</span><span id="ErnieForSTSB-542"><a href="#ErnieForSTSB-542"><span class="linenos">542</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForSTSB-543"><a href="#ErnieForSTSB-543"><span class="linenos">543</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForSTSB-544"><a href="#ErnieForSTSB-544"><span class="linenos">544</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForSTSB-545"><a href="#ErnieForSTSB-545"><span class="linenos">545</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForSTSB-546"><a href="#ErnieForSTSB-546"><span class="linenos">546</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForSTSB-547"><a href="#ErnieForSTSB-547"><span class="linenos">547</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForSTSB-548"><a href="#ErnieForSTSB-548"><span class="linenos">548</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForSTSB-549"><a href="#ErnieForSTSB-549"><span class="linenos">549</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForSTSB-550"><a href="#ErnieForSTSB-550"><span class="linenos">550</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForSTSB-551"><a href="#ErnieForSTSB-551"><span class="linenos">551</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForSTSB-552"><a href="#ErnieForSTSB-552"><span class="linenos">552</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieForSTSB-553"><a href="#ErnieForSTSB-553"><span class="linenos">553</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieForSTSB-554"><a href="#ErnieForSTSB-554"><span class="linenos">554</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForSTSB-555"><a href="#ErnieForSTSB-555"><span class="linenos">555</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieForSTSB-556"><a href="#ErnieForSTSB-556"><span class="linenos">556</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="ErnieForSTSB-557"><a href="#ErnieForSTSB-557"><span class="linenos">557</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="ErnieForSTSB-558"><a href="#ErnieForSTSB-558"><span class="linenos">558</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForSTSB-559"><a href="#ErnieForSTSB-559"><span class="linenos">559</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForSTSB-560"><a href="#ErnieForSTSB-560"><span class="linenos">560</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSTSB-561"><a href="#ErnieForSTSB-561"><span class="linenos">561</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">2</span>
</span><span id="ErnieForSTSB-562"><a href="#ErnieForSTSB-562"><span class="linenos">562</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSTSB-563"><a href="#ErnieForSTSB-563"><span class="linenos">563</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForSTSB-564"><a href="#ErnieForSTSB-564"><span class="linenos">564</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="ErnieForSTSB-565"><a href="#ErnieForSTSB-565"><span class="linenos">565</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForSTSB-566"><a href="#ErnieForSTSB-566"><span class="linenos">566</span></a>
</span><span id="ErnieForSTSB-567"><a href="#ErnieForSTSB-567"><span class="linenos">567</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForSTSB-568"><a href="#ErnieForSTSB-568"><span class="linenos">568</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForSTSB-569"><a href="#ErnieForSTSB-569"><span class="linenos">569</span></a>
</span><span id="ErnieForSTSB-570"><a href="#ErnieForSTSB-570"><span class="linenos">570</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForSTSB-571"><a href="#ErnieForSTSB-571"><span class="linenos">571</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForSTSB-572"><a href="#ErnieForSTSB-572"><span class="linenos">572</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSTSB-573"><a href="#ErnieForSTSB-573"><span class="linenos">573</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSTSB-574"><a href="#ErnieForSTSB-574"><span class="linenos">574</span></a>
</span><span id="ErnieForSTSB-575"><a href="#ErnieForSTSB-575"><span class="linenos">575</span></a>        <span class="n">probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="ErnieForSTSB-576"><a href="#ErnieForSTSB-576"><span class="linenos">576</span></a>
</span><span id="ErnieForSTSB-577"><a href="#ErnieForSTSB-577"><span class="linenos">577</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForSTSB-578"><a href="#ErnieForSTSB-578"><span class="linenos">578</span></a>            <span class="n">per_example_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">*</span> <span class="n">probs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForSTSB-579"><a href="#ErnieForSTSB-579"><span class="linenos">579</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">per_example_loss</span><span class="p">)</span>
</span><span id="ErnieForSTSB-580"><a href="#ErnieForSTSB-580"><span class="linenos">580</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForSTSB-581"><a href="#ErnieForSTSB-581"><span class="linenos">581</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForSTSB-582"><a href="#ErnieForSTSB-582"><span class="linenos">582</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model with STSB prediction head (predict sentence similarity).
This module comprises the Ernie model followed by the STSB head.</p>

<h6 id="params">Params</h6>

<blockquote>
  <p>config: a ErnieConfig class instance with the configuration to build a new model.
  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]
with indices selected in [0, ..., num_labels].</li>
</ul>
</div>


                            <div id="ErnieForSTSB.__init__" class="classattr">
                                        <input id="ErnieForSTSB.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForSTSB</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span></span>)</span>

                <label class="view-source-button" for="ErnieForSTSB.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForSTSB.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForSTSB.__init__-559"><a href="#ErnieForSTSB.__init__-559"><span class="linenos">559</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForSTSB.__init__-560"><a href="#ErnieForSTSB.__init__-560"><span class="linenos">560</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSTSB.__init__-561"><a href="#ErnieForSTSB.__init__-561"><span class="linenos">561</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">2</span>
</span><span id="ErnieForSTSB.__init__-562"><a href="#ErnieForSTSB.__init__-562"><span class="linenos">562</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSTSB.__init__-563"><a href="#ErnieForSTSB.__init__-563"><span class="linenos">563</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForSTSB.__init__-564"><a href="#ErnieForSTSB.__init__-564"><span class="linenos">564</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="ErnieForSTSB.__init__-565"><a href="#ErnieForSTSB.__init__-565"><span class="linenos">565</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForSTSB.__init__-566"><a href="#ErnieForSTSB.__init__-566"><span class="linenos">566</span></a>
</span><span id="ErnieForSTSB.__init__-567"><a href="#ErnieForSTSB.__init__-567"><span class="linenos">567</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForSTSB.__init__-568"><a href="#ErnieForSTSB.__init__-568"><span class="linenos">568</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForSTSB.forward" class="classattr">
                                        <input id="ErnieForSTSB.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForSTSB.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForSTSB.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForSTSB.forward-570"><a href="#ErnieForSTSB.forward-570"><span class="linenos">570</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForSTSB.forward-571"><a href="#ErnieForSTSB.forward-571"><span class="linenos">571</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForSTSB.forward-572"><a href="#ErnieForSTSB.forward-572"><span class="linenos">572</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSTSB.forward-573"><a href="#ErnieForSTSB.forward-573"><span class="linenos">573</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSTSB.forward-574"><a href="#ErnieForSTSB.forward-574"><span class="linenos">574</span></a>
</span><span id="ErnieForSTSB.forward-575"><a href="#ErnieForSTSB.forward-575"><span class="linenos">575</span></a>        <span class="n">probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="ErnieForSTSB.forward-576"><a href="#ErnieForSTSB.forward-576"><span class="linenos">576</span></a>
</span><span id="ErnieForSTSB.forward-577"><a href="#ErnieForSTSB.forward-577"><span class="linenos">577</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForSTSB.forward-578"><a href="#ErnieForSTSB.forward-578"><span class="linenos">578</span></a>            <span class="n">per_example_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">*</span> <span class="n">probs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForSTSB.forward-579"><a href="#ErnieForSTSB.forward-579"><span class="linenos">579</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">per_example_loss</span><span class="p">)</span>
</span><span id="ErnieForSTSB.forward-580"><a href="#ErnieForSTSB.forward-580"><span class="linenos">580</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForSTSB.forward-581"><a href="#ErnieForSTSB.forward-581"><span class="linenos">581</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForSTSB.forward-582"><a href="#ErnieForSTSB.forward-582"><span class="linenos">582</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForSTSB.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForSTSB.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForSTSB.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForSTSB.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForSTSB.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForSTSB.add_module" class="function">add_module</dd>
                <dd id="ErnieForSTSB.apply" class="function">apply</dd>
                <dd id="ErnieForSTSB.cuda" class="function">cuda</dd>
                <dd id="ErnieForSTSB.cpu" class="function">cpu</dd>
                <dd id="ErnieForSTSB.type" class="function">type</dd>
                <dd id="ErnieForSTSB.float" class="function">float</dd>
                <dd id="ErnieForSTSB.double" class="function">double</dd>
                <dd id="ErnieForSTSB.half" class="function">half</dd>
                <dd id="ErnieForSTSB.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForSTSB.to" class="function">to</dd>
                <dd id="ErnieForSTSB.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForSTSB.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForSTSB.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForSTSB.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForSTSB.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForSTSB.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForSTSB.parameters" class="function">parameters</dd>
                <dd id="ErnieForSTSB.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForSTSB.buffers" class="function">buffers</dd>
                <dd id="ErnieForSTSB.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForSTSB.children" class="function">children</dd>
                <dd id="ErnieForSTSB.named_children" class="function">named_children</dd>
                <dd id="ErnieForSTSB.modules" class="function">modules</dd>
                <dd id="ErnieForSTSB.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForSTSB.train" class="function">train</dd>
                <dd id="ErnieForSTSB.eval" class="function">eval</dd>
                <dd id="ErnieForSTSB.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForSTSB.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForSTSB.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForSTSB.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForSequenceClassification">
                            <input id="ErnieForSequenceClassification-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForSequenceClassification</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForSequenceClassification-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForSequenceClassification"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForSequenceClassification-584"><a href="#ErnieForSequenceClassification-584"><span class="linenos">584</span></a><span class="k">class</span> <span class="nc">ErnieForSequenceClassification</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForSequenceClassification-585"><a href="#ErnieForSequenceClassification-585"><span class="linenos">585</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForSequenceClassification-586"><a href="#ErnieForSequenceClassification-586"><span class="linenos">586</span></a><span class="sd">    Ernie model for classification.</span>
</span><span id="ErnieForSequenceClassification-587"><a href="#ErnieForSequenceClassification-587"><span class="linenos">587</span></a><span class="sd">    This module is composed of the Ernie model with a linear layer on top of</span>
</span><span id="ErnieForSequenceClassification-588"><a href="#ErnieForSequenceClassification-588"><span class="linenos">588</span></a><span class="sd">    the pooled output.</span>
</span><span id="ErnieForSequenceClassification-589"><a href="#ErnieForSequenceClassification-589"><span class="linenos">589</span></a>
</span><span id="ErnieForSequenceClassification-590"><a href="#ErnieForSequenceClassification-590"><span class="linenos">590</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForSequenceClassification-591"><a href="#ErnieForSequenceClassification-591"><span class="linenos">591</span></a><span class="sd">        `config`: an ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="ErnieForSequenceClassification-592"><a href="#ErnieForSequenceClassification-592"><span class="linenos">592</span></a><span class="sd">        `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="ErnieForSequenceClassification-593"><a href="#ErnieForSequenceClassification-593"><span class="linenos">593</span></a>
</span><span id="ErnieForSequenceClassification-594"><a href="#ErnieForSequenceClassification-594"><span class="linenos">594</span></a><span class="sd">    Args:</span>
</span><span id="ErnieForSequenceClassification-595"><a href="#ErnieForSequenceClassification-595"><span class="linenos">595</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForSequenceClassification-596"><a href="#ErnieForSequenceClassification-596"><span class="linenos">596</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForSequenceClassification-597"><a href="#ErnieForSequenceClassification-597"><span class="linenos">597</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForSequenceClassification-598"><a href="#ErnieForSequenceClassification-598"><span class="linenos">598</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForSequenceClassification-599"><a href="#ErnieForSequenceClassification-599"><span class="linenos">599</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForSequenceClassification-600"><a href="#ErnieForSequenceClassification-600"><span class="linenos">600</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForSequenceClassification-601"><a href="#ErnieForSequenceClassification-601"><span class="linenos">601</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForSequenceClassification-602"><a href="#ErnieForSequenceClassification-602"><span class="linenos">602</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForSequenceClassification-603"><a href="#ErnieForSequenceClassification-603"><span class="linenos">603</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForSequenceClassification-604"><a href="#ErnieForSequenceClassification-604"><span class="linenos">604</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForSequenceClassification-605"><a href="#ErnieForSequenceClassification-605"><span class="linenos">605</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieForSequenceClassification-606"><a href="#ErnieForSequenceClassification-606"><span class="linenos">606</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieForSequenceClassification-607"><a href="#ErnieForSequenceClassification-607"><span class="linenos">607</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForSequenceClassification-608"><a href="#ErnieForSequenceClassification-608"><span class="linenos">608</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieForSequenceClassification-609"><a href="#ErnieForSequenceClassification-609"><span class="linenos">609</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="ErnieForSequenceClassification-610"><a href="#ErnieForSequenceClassification-610"><span class="linenos">610</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="ErnieForSequenceClassification-611"><a href="#ErnieForSequenceClassification-611"><span class="linenos">611</span></a>
</span><span id="ErnieForSequenceClassification-612"><a href="#ErnieForSequenceClassification-612"><span class="linenos">612</span></a><span class="sd">    Returns:</span>
</span><span id="ErnieForSequenceClassification-613"><a href="#ErnieForSequenceClassification-613"><span class="linenos">613</span></a><span class="sd">        if `labels` is not `None`:</span>
</span><span id="ErnieForSequenceClassification-614"><a href="#ErnieForSequenceClassification-614"><span class="linenos">614</span></a><span class="sd">            Outputs the CrossEntropy classification loss of the output with the labels.</span>
</span><span id="ErnieForSequenceClassification-615"><a href="#ErnieForSequenceClassification-615"><span class="linenos">615</span></a><span class="sd">        if `labels` is `None`:</span>
</span><span id="ErnieForSequenceClassification-616"><a href="#ErnieForSequenceClassification-616"><span class="linenos">616</span></a><span class="sd">            Outputs the classification logits of shape [batch_size, num_labels].</span>
</span><span id="ErnieForSequenceClassification-617"><a href="#ErnieForSequenceClassification-617"><span class="linenos">617</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForSequenceClassification-618"><a href="#ErnieForSequenceClassification-618"><span class="linenos">618</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForSequenceClassification-619"><a href="#ErnieForSequenceClassification-619"><span class="linenos">619</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification-620"><a href="#ErnieForSequenceClassification-620"><span class="linenos">620</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="ErnieForSequenceClassification-621"><a href="#ErnieForSequenceClassification-621"><span class="linenos">621</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification-622"><a href="#ErnieForSequenceClassification-622"><span class="linenos">622</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification-623"><a href="#ErnieForSequenceClassification-623"><span class="linenos">623</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification-624"><a href="#ErnieForSequenceClassification-624"><span class="linenos">624</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForSequenceClassification-625"><a href="#ErnieForSequenceClassification-625"><span class="linenos">625</span></a>
</span><span id="ErnieForSequenceClassification-626"><a href="#ErnieForSequenceClassification-626"><span class="linenos">626</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForSequenceClassification-627"><a href="#ErnieForSequenceClassification-627"><span class="linenos">627</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification-628"><a href="#ErnieForSequenceClassification-628"><span class="linenos">628</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification-629"><a href="#ErnieForSequenceClassification-629"><span class="linenos">629</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification-630"><a href="#ErnieForSequenceClassification-630"><span class="linenos">630</span></a>
</span><span id="ErnieForSequenceClassification-631"><a href="#ErnieForSequenceClassification-631"><span class="linenos">631</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForSequenceClassification-632"><a href="#ErnieForSequenceClassification-632"><span class="linenos">632</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="ErnieForSequenceClassification-633"><a href="#ErnieForSequenceClassification-633"><span class="linenos">633</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForSequenceClassification-634"><a href="#ErnieForSequenceClassification-634"><span class="linenos">634</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForSequenceClassification-635"><a href="#ErnieForSequenceClassification-635"><span class="linenos">635</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForSequenceClassification-636"><a href="#ErnieForSequenceClassification-636"><span class="linenos">636</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model for classification.
This module is composed of the Ernie model with a linear layer on top of
the pooled output.</p>

<h6 id="params">Params</h6>

<blockquote>
  <p><code>config</code>: an ErnieConfig class instance with the configuration to build a new model.
  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]
with indices selected in [0, ..., num_labels].</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>labels</code> is not <code>None</code>:
      Outputs the CrossEntropy classification loss of the output with the labels.
  if <code>labels</code> is <code>None</code>:
      Outputs the classification logits of shape [batch_size, num_labels].</p>
</blockquote>
</div>


                            <div id="ErnieForSequenceClassification.__init__" class="classattr">
                                        <input id="ErnieForSequenceClassification.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForSequenceClassification</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span></span>)</span>

                <label class="view-source-button" for="ErnieForSequenceClassification.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForSequenceClassification.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForSequenceClassification.__init__-618"><a href="#ErnieForSequenceClassification.__init__-618"><span class="linenos">618</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForSequenceClassification.__init__-619"><a href="#ErnieForSequenceClassification.__init__-619"><span class="linenos">619</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification.__init__-620"><a href="#ErnieForSequenceClassification.__init__-620"><span class="linenos">620</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="ErnieForSequenceClassification.__init__-621"><a href="#ErnieForSequenceClassification.__init__-621"><span class="linenos">621</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification.__init__-622"><a href="#ErnieForSequenceClassification.__init__-622"><span class="linenos">622</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification.__init__-623"><a href="#ErnieForSequenceClassification.__init__-623"><span class="linenos">623</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification.__init__-624"><a href="#ErnieForSequenceClassification.__init__-624"><span class="linenos">624</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForSequenceClassification.forward" class="classattr">
                                        <input id="ErnieForSequenceClassification.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForSequenceClassification.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForSequenceClassification.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForSequenceClassification.forward-626"><a href="#ErnieForSequenceClassification.forward-626"><span class="linenos">626</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForSequenceClassification.forward-627"><a href="#ErnieForSequenceClassification.forward-627"><span class="linenos">627</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification.forward-628"><a href="#ErnieForSequenceClassification.forward-628"><span class="linenos">628</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification.forward-629"><a href="#ErnieForSequenceClassification.forward-629"><span class="linenos">629</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForSequenceClassification.forward-630"><a href="#ErnieForSequenceClassification.forward-630"><span class="linenos">630</span></a>
</span><span id="ErnieForSequenceClassification.forward-631"><a href="#ErnieForSequenceClassification.forward-631"><span class="linenos">631</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForSequenceClassification.forward-632"><a href="#ErnieForSequenceClassification.forward-632"><span class="linenos">632</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="ErnieForSequenceClassification.forward-633"><a href="#ErnieForSequenceClassification.forward-633"><span class="linenos">633</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForSequenceClassification.forward-634"><a href="#ErnieForSequenceClassification.forward-634"><span class="linenos">634</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForSequenceClassification.forward-635"><a href="#ErnieForSequenceClassification.forward-635"><span class="linenos">635</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForSequenceClassification.forward-636"><a href="#ErnieForSequenceClassification.forward-636"><span class="linenos">636</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForSequenceClassification.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForSequenceClassification.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForSequenceClassification.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForSequenceClassification.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForSequenceClassification.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForSequenceClassification.add_module" class="function">add_module</dd>
                <dd id="ErnieForSequenceClassification.apply" class="function">apply</dd>
                <dd id="ErnieForSequenceClassification.cuda" class="function">cuda</dd>
                <dd id="ErnieForSequenceClassification.cpu" class="function">cpu</dd>
                <dd id="ErnieForSequenceClassification.type" class="function">type</dd>
                <dd id="ErnieForSequenceClassification.float" class="function">float</dd>
                <dd id="ErnieForSequenceClassification.double" class="function">double</dd>
                <dd id="ErnieForSequenceClassification.half" class="function">half</dd>
                <dd id="ErnieForSequenceClassification.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForSequenceClassification.to" class="function">to</dd>
                <dd id="ErnieForSequenceClassification.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForSequenceClassification.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForSequenceClassification.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForSequenceClassification.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForSequenceClassification.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForSequenceClassification.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForSequenceClassification.parameters" class="function">parameters</dd>
                <dd id="ErnieForSequenceClassification.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForSequenceClassification.buffers" class="function">buffers</dd>
                <dd id="ErnieForSequenceClassification.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForSequenceClassification.children" class="function">children</dd>
                <dd id="ErnieForSequenceClassification.named_children" class="function">named_children</dd>
                <dd id="ErnieForSequenceClassification.modules" class="function">modules</dd>
                <dd id="ErnieForSequenceClassification.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForSequenceClassification.train" class="function">train</dd>
                <dd id="ErnieForSequenceClassification.eval" class="function">eval</dd>
                <dd id="ErnieForSequenceClassification.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForSequenceClassification.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForSequenceClassification.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForSequenceClassification.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForNQ">
                            <input id="ErnieForNQ-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForNQ</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForNQ-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForNQ"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForNQ-638"><a href="#ErnieForNQ-638"><span class="linenos">638</span></a><span class="k">class</span> <span class="nc">ErnieForNQ</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForNQ-639"><a href="#ErnieForNQ-639"><span class="linenos">639</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForNQ-640"><a href="#ErnieForNQ-640"><span class="linenos">640</span></a><span class="sd">    Ernie model for NQ.</span>
</span><span id="ErnieForNQ-641"><a href="#ErnieForNQ-641"><span class="linenos">641</span></a><span class="sd">    This module is composed of the Ernie model with a linear layer on top of</span>
</span><span id="ErnieForNQ-642"><a href="#ErnieForNQ-642"><span class="linenos">642</span></a><span class="sd">    the pooled output.</span>
</span><span id="ErnieForNQ-643"><a href="#ErnieForNQ-643"><span class="linenos">643</span></a>
</span><span id="ErnieForNQ-644"><a href="#ErnieForNQ-644"><span class="linenos">644</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForNQ-645"><a href="#ErnieForNQ-645"><span class="linenos">645</span></a><span class="sd">        `config`: an ErnieConfig class instance with the configuration to build a new model.</span>
</span><span id="ErnieForNQ-646"><a href="#ErnieForNQ-646"><span class="linenos">646</span></a><span class="sd">        `num_choices`: the number of classes for the classifier. Default = 2.</span>
</span><span id="ErnieForNQ-647"><a href="#ErnieForNQ-647"><span class="linenos">647</span></a>
</span><span id="ErnieForNQ-648"><a href="#ErnieForNQ-648"><span class="linenos">648</span></a><span class="sd">    Args:</span>
</span><span id="ErnieForNQ-649"><a href="#ErnieForNQ-649"><span class="linenos">649</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForNQ-650"><a href="#ErnieForNQ-650"><span class="linenos">650</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForNQ-651"><a href="#ErnieForNQ-651"><span class="linenos">651</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForNQ-652"><a href="#ErnieForNQ-652"><span class="linenos">652</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForNQ-653"><a href="#ErnieForNQ-653"><span class="linenos">653</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForNQ-654"><a href="#ErnieForNQ-654"><span class="linenos">654</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForNQ-655"><a href="#ErnieForNQ-655"><span class="linenos">655</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForNQ-656"><a href="#ErnieForNQ-656"><span class="linenos">656</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForNQ-657"><a href="#ErnieForNQ-657"><span class="linenos">657</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForNQ-658"><a href="#ErnieForNQ-658"><span class="linenos">658</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForNQ-659"><a href="#ErnieForNQ-659"><span class="linenos">659</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieForNQ-660"><a href="#ErnieForNQ-660"><span class="linenos">660</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieForNQ-661"><a href="#ErnieForNQ-661"><span class="linenos">661</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForNQ-662"><a href="#ErnieForNQ-662"><span class="linenos">662</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieForNQ-663"><a href="#ErnieForNQ-663"><span class="linenos">663</span></a><span class="sd">        `choice_mask`:</span>
</span><span id="ErnieForNQ-664"><a href="#ErnieForNQ-664"><span class="linenos">664</span></a><span class="sd">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="ErnieForNQ-665"><a href="#ErnieForNQ-665"><span class="linenos">665</span></a><span class="sd">            with indices selected in [0, ..., num_labels].</span>
</span><span id="ErnieForNQ-666"><a href="#ErnieForNQ-666"><span class="linenos">666</span></a>
</span><span id="ErnieForNQ-667"><a href="#ErnieForNQ-667"><span class="linenos">667</span></a><span class="sd">    Returns:</span>
</span><span id="ErnieForNQ-668"><a href="#ErnieForNQ-668"><span class="linenos">668</span></a><span class="sd">        if `labels` is not `None`:</span>
</span><span id="ErnieForNQ-669"><a href="#ErnieForNQ-669"><span class="linenos">669</span></a><span class="sd">            Outputs the CrossEntropy classification loss of the output with the labels.</span>
</span><span id="ErnieForNQ-670"><a href="#ErnieForNQ-670"><span class="linenos">670</span></a><span class="sd">        if `labels` is `None`:</span>
</span><span id="ErnieForNQ-671"><a href="#ErnieForNQ-671"><span class="linenos">671</span></a><span class="sd">            Outputs the classification logits of shape [batch_size, num_labels].</span>
</span><span id="ErnieForNQ-672"><a href="#ErnieForNQ-672"><span class="linenos">672</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForNQ-673"><a href="#ErnieForNQ-673"><span class="linenos">673</span></a>
</span><span id="ErnieForNQ-674"><a href="#ErnieForNQ-674"><span class="linenos">674</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_choices</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForNQ-675"><a href="#ErnieForNQ-675"><span class="linenos">675</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNQ-676"><a href="#ErnieForNQ-676"><span class="linenos">676</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_choices</span> <span class="o">=</span> <span class="n">num_choices</span>
</span><span id="ErnieForNQ-677"><a href="#ErnieForNQ-677"><span class="linenos">677</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNQ-678"><a href="#ErnieForNQ-678"><span class="linenos">678</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForNQ-679"><a href="#ErnieForNQ-679"><span class="linenos">679</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForNQ-680"><a href="#ErnieForNQ-680"><span class="linenos">680</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForNQ-681"><a href="#ErnieForNQ-681"><span class="linenos">681</span></a>
</span><span id="ErnieForNQ-682"><a href="#ErnieForNQ-682"><span class="linenos">682</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">choice_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForNQ-683"><a href="#ErnieForNQ-683"><span class="linenos">683</span></a>            
</span><span id="ErnieForNQ-684"><a href="#ErnieForNQ-684"><span class="linenos">684</span></a>        <span class="n">flat_input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ-685"><a href="#ErnieForNQ-685"><span class="linenos">685</span></a>        <span class="n">flat_token_type_ids</span> <span class="o">=</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ-686"><a href="#ErnieForNQ-686"><span class="linenos">686</span></a>        <span class="n">flat_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ-687"><a href="#ErnieForNQ-687"><span class="linenos">687</span></a>        <span class="n">flat_input_ent</span> <span class="o">=</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ-688"><a href="#ErnieForNQ-688"><span class="linenos">688</span></a>        <span class="n">flat_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ-689"><a href="#ErnieForNQ-689"><span class="linenos">689</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">flat_input_ids</span><span class="p">,</span> <span class="n">flat_token_type_ids</span><span class="p">,</span> <span class="n">flat_attention_mask</span><span class="p">,</span> <span class="n">flat_input_ent</span><span class="p">,</span> <span class="n">flat_ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForNQ-690"><a href="#ErnieForNQ-690"><span class="linenos">690</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForNQ-691"><a href="#ErnieForNQ-691"><span class="linenos">691</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForNQ-692"><a href="#ErnieForNQ-692"><span class="linenos">692</span></a>        <span class="n">reshaped_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_choices</span><span class="p">)</span>
</span><span id="ErnieForNQ-693"><a href="#ErnieForNQ-693"><span class="linenos">693</span></a>
</span><span id="ErnieForNQ-694"><a href="#ErnieForNQ-694"><span class="linenos">694</span></a>        <span class="n">null_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span><span id="ErnieForNQ-695"><a href="#ErnieForNQ-695"><span class="linenos">695</span></a>        <span class="n">reshaped_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">null_score</span><span class="p">,</span> <span class="n">reshaped_logits</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">choice_mask</span>
</span><span id="ErnieForNQ-696"><a href="#ErnieForNQ-696"><span class="linenos">696</span></a>
</span><span id="ErnieForNQ-697"><a href="#ErnieForNQ-697"><span class="linenos">697</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForNQ-698"><a href="#ErnieForNQ-698"><span class="linenos">698</span></a>            <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span><span id="ErnieForNQ-699"><a href="#ErnieForNQ-699"><span class="linenos">699</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
</span><span id="ErnieForNQ-700"><a href="#ErnieForNQ-700"><span class="linenos">700</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">reshaped_logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForNQ-701"><a href="#ErnieForNQ-701"><span class="linenos">701</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForNQ-702"><a href="#ErnieForNQ-702"><span class="linenos">702</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForNQ-703"><a href="#ErnieForNQ-703"><span class="linenos">703</span></a>            <span class="k">return</span> <span class="n">reshaped_logits</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model for NQ.
This module is composed of the Ernie model with a linear layer on top of
the pooled output.</p>

<h6 id="params">Params</h6>

<blockquote>
  <p><code>config</code>: an ErnieConfig class instance with the configuration to build a new model.
  <code>num_choices</code>: the number of classes for the classifier. Default = 2.</p>
</blockquote>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>choice_mask</code>:</strong> </li>
<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]
with indices selected in [0, ..., num_labels].</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>labels</code> is not <code>None</code>:
      Outputs the CrossEntropy classification loss of the output with the labels.
  if <code>labels</code> is <code>None</code>:
      Outputs the classification logits of shape [batch_size, num_labels].</p>
</blockquote>
</div>


                            <div id="ErnieForNQ.__init__" class="classattr">
                                        <input id="ErnieForNQ.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForNQ</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="n">num_choices</span><span class="o">=</span><span class="mi">2</span></span>)</span>

                <label class="view-source-button" for="ErnieForNQ.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForNQ.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForNQ.__init__-674"><a href="#ErnieForNQ.__init__-674"><span class="linenos">674</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_choices</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="ErnieForNQ.__init__-675"><a href="#ErnieForNQ.__init__-675"><span class="linenos">675</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNQ.__init__-676"><a href="#ErnieForNQ.__init__-676"><span class="linenos">676</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_choices</span> <span class="o">=</span> <span class="n">num_choices</span>
</span><span id="ErnieForNQ.__init__-677"><a href="#ErnieForNQ.__init__-677"><span class="linenos">677</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForNQ.__init__-678"><a href="#ErnieForNQ.__init__-678"><span class="linenos">678</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="ErnieForNQ.__init__-679"><a href="#ErnieForNQ.__init__-679"><span class="linenos">679</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForNQ.__init__-680"><a href="#ErnieForNQ.__init__-680"><span class="linenos">680</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForNQ.forward" class="classattr">
                                        <input id="ErnieForNQ.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">choice_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForNQ.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForNQ.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForNQ.forward-682"><a href="#ErnieForNQ.forward-682"><span class="linenos">682</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">choice_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForNQ.forward-683"><a href="#ErnieForNQ.forward-683"><span class="linenos">683</span></a>            
</span><span id="ErnieForNQ.forward-684"><a href="#ErnieForNQ.forward-684"><span class="linenos">684</span></a>        <span class="n">flat_input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ.forward-685"><a href="#ErnieForNQ.forward-685"><span class="linenos">685</span></a>        <span class="n">flat_token_type_ids</span> <span class="o">=</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ.forward-686"><a href="#ErnieForNQ.forward-686"><span class="linenos">686</span></a>        <span class="n">flat_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ.forward-687"><a href="#ErnieForNQ.forward-687"><span class="linenos">687</span></a>        <span class="n">flat_input_ent</span> <span class="o">=</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ.forward-688"><a href="#ErnieForNQ.forward-688"><span class="linenos">688</span></a>        <span class="n">flat_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="ErnieForNQ.forward-689"><a href="#ErnieForNQ.forward-689"><span class="linenos">689</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">flat_input_ids</span><span class="p">,</span> <span class="n">flat_token_type_ids</span><span class="p">,</span> <span class="n">flat_attention_mask</span><span class="p">,</span> <span class="n">flat_input_ent</span><span class="p">,</span> <span class="n">flat_ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForNQ.forward-690"><a href="#ErnieForNQ.forward-690"><span class="linenos">690</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForNQ.forward-691"><a href="#ErnieForNQ.forward-691"><span class="linenos">691</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="ErnieForNQ.forward-692"><a href="#ErnieForNQ.forward-692"><span class="linenos">692</span></a>        <span class="n">reshaped_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_choices</span><span class="p">)</span>
</span><span id="ErnieForNQ.forward-693"><a href="#ErnieForNQ.forward-693"><span class="linenos">693</span></a>
</span><span id="ErnieForNQ.forward-694"><a href="#ErnieForNQ.forward-694"><span class="linenos">694</span></a>        <span class="n">null_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span><span id="ErnieForNQ.forward-695"><a href="#ErnieForNQ.forward-695"><span class="linenos">695</span></a>        <span class="n">reshaped_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">null_score</span><span class="p">,</span> <span class="n">reshaped_logits</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">choice_mask</span>
</span><span id="ErnieForNQ.forward-696"><a href="#ErnieForNQ.forward-696"><span class="linenos">696</span></a>
</span><span id="ErnieForNQ.forward-697"><a href="#ErnieForNQ.forward-697"><span class="linenos">697</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForNQ.forward-698"><a href="#ErnieForNQ.forward-698"><span class="linenos">698</span></a>            <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span><span id="ErnieForNQ.forward-699"><a href="#ErnieForNQ.forward-699"><span class="linenos">699</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
</span><span id="ErnieForNQ.forward-700"><a href="#ErnieForNQ.forward-700"><span class="linenos">700</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">reshaped_logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForNQ.forward-701"><a href="#ErnieForNQ.forward-701"><span class="linenos">701</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="ErnieForNQ.forward-702"><a href="#ErnieForNQ.forward-702"><span class="linenos">702</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForNQ.forward-703"><a href="#ErnieForNQ.forward-703"><span class="linenos">703</span></a>            <span class="k">return</span> <span class="n">reshaped_logits</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForNQ.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForNQ.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForNQ.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForNQ.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForNQ.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForNQ.add_module" class="function">add_module</dd>
                <dd id="ErnieForNQ.apply" class="function">apply</dd>
                <dd id="ErnieForNQ.cuda" class="function">cuda</dd>
                <dd id="ErnieForNQ.cpu" class="function">cpu</dd>
                <dd id="ErnieForNQ.type" class="function">type</dd>
                <dd id="ErnieForNQ.float" class="function">float</dd>
                <dd id="ErnieForNQ.double" class="function">double</dd>
                <dd id="ErnieForNQ.half" class="function">half</dd>
                <dd id="ErnieForNQ.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForNQ.to" class="function">to</dd>
                <dd id="ErnieForNQ.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForNQ.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForNQ.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForNQ.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForNQ.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForNQ.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForNQ.parameters" class="function">parameters</dd>
                <dd id="ErnieForNQ.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForNQ.buffers" class="function">buffers</dd>
                <dd id="ErnieForNQ.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForNQ.children" class="function">children</dd>
                <dd id="ErnieForNQ.named_children" class="function">named_children</dd>
                <dd id="ErnieForNQ.modules" class="function">modules</dd>
                <dd id="ErnieForNQ.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForNQ.train" class="function">train</dd>
                <dd id="ErnieForNQ.eval" class="function">eval</dd>
                <dd id="ErnieForNQ.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForNQ.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForNQ.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForNQ.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ErnieForQuestionAnswering">
                            <input id="ErnieForQuestionAnswering-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ErnieForQuestionAnswering</span><wbr>(<span class="base"><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></span>):

                <label class="view-source-button" for="ErnieForQuestionAnswering-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForQuestionAnswering"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForQuestionAnswering-705"><a href="#ErnieForQuestionAnswering-705"><span class="linenos">705</span></a><span class="k">class</span> <span class="nc">ErnieForQuestionAnswering</span><span class="p">(</span><span class="n">PreTrainedErnieModel</span><span class="p">):</span>
</span><span id="ErnieForQuestionAnswering-706"><a href="#ErnieForQuestionAnswering-706"><span class="linenos">706</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="ErnieForQuestionAnswering-707"><a href="#ErnieForQuestionAnswering-707"><span class="linenos">707</span></a><span class="sd">    Ernie model for Question Answering (span extraction).</span>
</span><span id="ErnieForQuestionAnswering-708"><a href="#ErnieForQuestionAnswering-708"><span class="linenos">708</span></a><span class="sd">    This module is composed of the Ernie model with a linear layer on top of</span>
</span><span id="ErnieForQuestionAnswering-709"><a href="#ErnieForQuestionAnswering-709"><span class="linenos">709</span></a><span class="sd">    the sequence output that computes start_logits and end_logits</span>
</span><span id="ErnieForQuestionAnswering-710"><a href="#ErnieForQuestionAnswering-710"><span class="linenos">710</span></a>
</span><span id="ErnieForQuestionAnswering-711"><a href="#ErnieForQuestionAnswering-711"><span class="linenos">711</span></a><span class="sd">    Params:</span>
</span><span id="ErnieForQuestionAnswering-712"><a href="#ErnieForQuestionAnswering-712"><span class="linenos">712</span></a><span class="sd">        `config`: either</span>
</span><span id="ErnieForQuestionAnswering-713"><a href="#ErnieForQuestionAnswering-713"><span class="linenos">713</span></a><span class="sd">            - a ErnieConfig class instance with the configuration to build a new model</span>
</span><span id="ErnieForQuestionAnswering-714"><a href="#ErnieForQuestionAnswering-714"><span class="linenos">714</span></a>
</span><span id="ErnieForQuestionAnswering-715"><a href="#ErnieForQuestionAnswering-715"><span class="linenos">715</span></a><span class="sd">    Inputs:</span>
</span><span id="ErnieForQuestionAnswering-716"><a href="#ErnieForQuestionAnswering-716"><span class="linenos">716</span></a><span class="sd">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="ErnieForQuestionAnswering-717"><a href="#ErnieForQuestionAnswering-717"><span class="linenos">717</span></a><span class="sd">            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="ErnieForQuestionAnswering-718"><a href="#ErnieForQuestionAnswering-718"><span class="linenos">718</span></a><span class="sd">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="ErnieForQuestionAnswering-719"><a href="#ErnieForQuestionAnswering-719"><span class="linenos">719</span></a><span class="sd">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="ErnieForQuestionAnswering-720"><a href="#ErnieForQuestionAnswering-720"><span class="linenos">720</span></a><span class="sd">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="ErnieForQuestionAnswering-721"><a href="#ErnieForQuestionAnswering-721"><span class="linenos">721</span></a><span class="sd">            a `sentence B` token (see BERT paper for more details).</span>
</span><span id="ErnieForQuestionAnswering-722"><a href="#ErnieForQuestionAnswering-722"><span class="linenos">722</span></a><span class="sd">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForQuestionAnswering-723"><a href="#ErnieForQuestionAnswering-723"><span class="linenos">723</span></a><span class="sd">            selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="ErnieForQuestionAnswering-724"><a href="#ErnieForQuestionAnswering-724"><span class="linenos">724</span></a><span class="sd">            input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="ErnieForQuestionAnswering-725"><a href="#ErnieForQuestionAnswering-725"><span class="linenos">725</span></a><span class="sd">            a batch has varying length sentences.</span>
</span><span id="ErnieForQuestionAnswering-726"><a href="#ErnieForQuestionAnswering-726"><span class="linenos">726</span></a><span class="sd">        `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="ErnieForQuestionAnswering-727"><a href="#ErnieForQuestionAnswering-727"><span class="linenos">727</span></a><span class="sd">            with the entities embeddings</span>
</span><span id="ErnieForQuestionAnswering-728"><a href="#ErnieForQuestionAnswering-728"><span class="linenos">728</span></a><span class="sd">        `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="ErnieForQuestionAnswering-729"><a href="#ErnieForQuestionAnswering-729"><span class="linenos">729</span></a><span class="sd">            selected in [0, 1]</span>
</span><span id="ErnieForQuestionAnswering-730"><a href="#ErnieForQuestionAnswering-730"><span class="linenos">730</span></a><span class="sd">        `start_positions`: position of the first token for the labeled span: torch.LongTensor of shape [batch_size].</span>
</span><span id="ErnieForQuestionAnswering-731"><a href="#ErnieForQuestionAnswering-731"><span class="linenos">731</span></a><span class="sd">            Positions are clamped to the length of the sequence and position outside of the sequence are not taken</span>
</span><span id="ErnieForQuestionAnswering-732"><a href="#ErnieForQuestionAnswering-732"><span class="linenos">732</span></a><span class="sd">            into account for computing the loss.</span>
</span><span id="ErnieForQuestionAnswering-733"><a href="#ErnieForQuestionAnswering-733"><span class="linenos">733</span></a><span class="sd">        `end_positions`: position of the last token for the labeled span: torch.LongTensor of shape [batch_size].</span>
</span><span id="ErnieForQuestionAnswering-734"><a href="#ErnieForQuestionAnswering-734"><span class="linenos">734</span></a><span class="sd">            Positions are clamped to the length of the sequence and position outside of the sequence are not taken</span>
</span><span id="ErnieForQuestionAnswering-735"><a href="#ErnieForQuestionAnswering-735"><span class="linenos">735</span></a><span class="sd">            into account for computing the loss.</span>
</span><span id="ErnieForQuestionAnswering-736"><a href="#ErnieForQuestionAnswering-736"><span class="linenos">736</span></a>
</span><span id="ErnieForQuestionAnswering-737"><a href="#ErnieForQuestionAnswering-737"><span class="linenos">737</span></a><span class="sd">    Outputs:</span>
</span><span id="ErnieForQuestionAnswering-738"><a href="#ErnieForQuestionAnswering-738"><span class="linenos">738</span></a><span class="sd">        if `start_positions` and `end_positions` are not `None`:</span>
</span><span id="ErnieForQuestionAnswering-739"><a href="#ErnieForQuestionAnswering-739"><span class="linenos">739</span></a><span class="sd">            Outputs the total_loss which is the sum of the CrossEntropy loss for the start and end token positions.</span>
</span><span id="ErnieForQuestionAnswering-740"><a href="#ErnieForQuestionAnswering-740"><span class="linenos">740</span></a><span class="sd">        if `start_positions` or `end_positions` is `None`:</span>
</span><span id="ErnieForQuestionAnswering-741"><a href="#ErnieForQuestionAnswering-741"><span class="linenos">741</span></a><span class="sd">            Outputs a tuple of start_logits, end_logits which are the logits respectively for the start and end</span>
</span><span id="ErnieForQuestionAnswering-742"><a href="#ErnieForQuestionAnswering-742"><span class="linenos">742</span></a><span class="sd">            position tokens of shape [batch_size, sequence_length].</span>
</span><span id="ErnieForQuestionAnswering-743"><a href="#ErnieForQuestionAnswering-743"><span class="linenos">743</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ErnieForQuestionAnswering-744"><a href="#ErnieForQuestionAnswering-744"><span class="linenos">744</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForQuestionAnswering-745"><a href="#ErnieForQuestionAnswering-745"><span class="linenos">745</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-746"><a href="#ErnieForQuestionAnswering-746"><span class="linenos">746</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-747"><a href="#ErnieForQuestionAnswering-747"><span class="linenos">747</span></a>        <span class="c1"># TODO check with Google if it&#39;s normal there is no dropout on the token classifier of SQuAD in the TF version</span>
</span><span id="ErnieForQuestionAnswering-748"><a href="#ErnieForQuestionAnswering-748"><span class="linenos">748</span></a>        <span class="c1"># self.dropout = nn.Dropout(config.hidden_dropout_prob)</span>
</span><span id="ErnieForQuestionAnswering-749"><a href="#ErnieForQuestionAnswering-749"><span class="linenos">749</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">qa_outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-750"><a href="#ErnieForQuestionAnswering-750"><span class="linenos">750</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span><span id="ErnieForQuestionAnswering-751"><a href="#ErnieForQuestionAnswering-751"><span class="linenos">751</span></a>
</span><span id="ErnieForQuestionAnswering-752"><a href="#ErnieForQuestionAnswering-752"><span class="linenos">752</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end_positions</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForQuestionAnswering-753"><a href="#ErnieForQuestionAnswering-753"><span class="linenos">753</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-754"><a href="#ErnieForQuestionAnswering-754"><span class="linenos">754</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qa_outputs</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-755"><a href="#ErnieForQuestionAnswering-755"><span class="linenos">755</span></a>        <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-756"><a href="#ErnieForQuestionAnswering-756"><span class="linenos">756</span></a>        <span class="n">start_logits</span> <span class="o">=</span> <span class="n">start_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-757"><a href="#ErnieForQuestionAnswering-757"><span class="linenos">757</span></a>        <span class="n">end_logits</span> <span class="o">=</span> <span class="n">end_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-758"><a href="#ErnieForQuestionAnswering-758"><span class="linenos">758</span></a>
</span><span id="ErnieForQuestionAnswering-759"><a href="#ErnieForQuestionAnswering-759"><span class="linenos">759</span></a>        <span class="k">if</span> <span class="n">start_positions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">end_positions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering-760"><a href="#ErnieForQuestionAnswering-760"><span class="linenos">760</span></a>            <span class="c1"># If we are on multi-GPU, split add a dimension</span>
</span><span id="ErnieForQuestionAnswering-761"><a href="#ErnieForQuestionAnswering-761"><span class="linenos">761</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">start_positions</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering-762"><a href="#ErnieForQuestionAnswering-762"><span class="linenos">762</span></a>                <span class="n">start_positions</span> <span class="o">=</span> <span class="n">start_positions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-763"><a href="#ErnieForQuestionAnswering-763"><span class="linenos">763</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_positions</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering-764"><a href="#ErnieForQuestionAnswering-764"><span class="linenos">764</span></a>                <span class="n">end_positions</span> <span class="o">=</span> <span class="n">end_positions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-765"><a href="#ErnieForQuestionAnswering-765"><span class="linenos">765</span></a>            <span class="c1"># sometimes the start/end positions are outside our model inputs, we ignore these terms</span>
</span><span id="ErnieForQuestionAnswering-766"><a href="#ErnieForQuestionAnswering-766"><span class="linenos">766</span></a>            <span class="n">ignored_index</span> <span class="o">=</span> <span class="n">start_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-767"><a href="#ErnieForQuestionAnswering-767"><span class="linenos">767</span></a>            <span class="n">start_positions</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignored_index</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-768"><a href="#ErnieForQuestionAnswering-768"><span class="linenos">768</span></a>            <span class="n">end_positions</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignored_index</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-769"><a href="#ErnieForQuestionAnswering-769"><span class="linenos">769</span></a>
</span><span id="ErnieForQuestionAnswering-770"><a href="#ErnieForQuestionAnswering-770"><span class="linenos">770</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">ignored_index</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-771"><a href="#ErnieForQuestionAnswering-771"><span class="linenos">771</span></a>            <span class="n">start_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">start_positions</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-772"><a href="#ErnieForQuestionAnswering-772"><span class="linenos">772</span></a>            <span class="n">end_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">end_logits</span><span class="p">,</span> <span class="n">end_positions</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering-773"><a href="#ErnieForQuestionAnswering-773"><span class="linenos">773</span></a>            <span class="n">total_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">start_loss</span> <span class="o">+</span> <span class="n">end_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
</span><span id="ErnieForQuestionAnswering-774"><a href="#ErnieForQuestionAnswering-774"><span class="linenos">774</span></a>            <span class="k">return</span> <span class="n">total_loss</span>
</span><span id="ErnieForQuestionAnswering-775"><a href="#ErnieForQuestionAnswering-775"><span class="linenos">775</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering-776"><a href="#ErnieForQuestionAnswering-776"><span class="linenos">776</span></a>            <span class="k">return</span> <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span>
</span></pre></div>


            <div class="docstring"><p>Ernie model for Question Answering (span extraction).
This module is composed of the Ernie model with a linear layer on top of
the sequence output that computes start_logits and end_logits</p>

<h6 id="params">Params</h6>

<blockquote>
  <p><code>config</code>: either
      - a ErnieConfig class instance with the configuration to build a new model</p>
</blockquote>

<h6 id="inputs">Inputs</h6>

<blockquote>
  <p><code>input_ids</code>: a torch.LongTensor of shape [batch_size, sequence_length]
      with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
      <code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)
  <code>token_type_ids</code>: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
      types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
      a <code>sentence B</code> token (see BERT paper for more details).
  <code>attention_mask</code>: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
      selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
      input sequence length in the current batch. It's the mask that we typically use for attention when
      a batch has varying length sentences.
  <code>input_ent</code>: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
      with the entities embeddings
  <code>ent_mask</code>: a torch.LongTensor of shape [batch_size, sequence_length] with indices
      selected in [0, 1]
  <code>start_positions</code>: position of the first token for the labeled span: torch.LongTensor of shape [batch_size].
      Positions are clamped to the length of the sequence and position outside of the sequence are not taken
      into account for computing the loss.
  <code>end_positions</code>: position of the last token for the labeled span: torch.LongTensor of shape [batch_size].
      Positions are clamped to the length of the sequence and position outside of the sequence are not taken
      into account for computing the loss.</p>
</blockquote>

<h6 id="outputs">Outputs</h6>

<blockquote>
  <p>if <code>start_positions</code> and <code>end_positions</code> are not <code>None</code>:
      Outputs the total_loss which is the sum of the CrossEntropy loss for the start and end token positions.
  if <code>start_positions</code> or <code>end_positions</code> is <code>None</code>:
      Outputs a tuple of start_logits, end_logits which are the logits respectively for the start and end
      position tokens of shape [batch_size, sequence_length].</p>
</blockquote>
</div>


                            <div id="ErnieForQuestionAnswering.__init__" class="classattr">
                                        <input id="ErnieForQuestionAnswering.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ErnieForQuestionAnswering</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="ErnieForQuestionAnswering.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForQuestionAnswering.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForQuestionAnswering.__init__-744"><a href="#ErnieForQuestionAnswering.__init__-744"><span class="linenos">744</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="ErnieForQuestionAnswering.__init__-745"><a href="#ErnieForQuestionAnswering.__init__-745"><span class="linenos">745</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.__init__-746"><a href="#ErnieForQuestionAnswering.__init__-746"><span class="linenos">746</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ErnieModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.__init__-747"><a href="#ErnieForQuestionAnswering.__init__-747"><span class="linenos">747</span></a>        <span class="c1"># TODO check with Google if it&#39;s normal there is no dropout on the token classifier of SQuAD in the TF version</span>
</span><span id="ErnieForQuestionAnswering.__init__-748"><a href="#ErnieForQuestionAnswering.__init__-748"><span class="linenos">748</span></a>        <span class="c1"># self.dropout = nn.Dropout(config.hidden_dropout_prob)</span>
</span><span id="ErnieForQuestionAnswering.__init__-749"><a href="#ErnieForQuestionAnswering.__init__-749"><span class="linenos">749</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">qa_outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.__init__-750"><a href="#ErnieForQuestionAnswering.__init__-750"><span class="linenos">750</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ErnieForQuestionAnswering.forward" class="classattr">
                                        <input id="ErnieForQuestionAnswering.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">start_positions</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">end_positions</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="ErnieForQuestionAnswering.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ErnieForQuestionAnswering.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ErnieForQuestionAnswering.forward-752"><a href="#ErnieForQuestionAnswering.forward-752"><span class="linenos">752</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end_positions</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="ErnieForQuestionAnswering.forward-753"><a href="#ErnieForQuestionAnswering.forward-753"><span class="linenos">753</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-754"><a href="#ErnieForQuestionAnswering.forward-754"><span class="linenos">754</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qa_outputs</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-755"><a href="#ErnieForQuestionAnswering.forward-755"><span class="linenos">755</span></a>        <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-756"><a href="#ErnieForQuestionAnswering.forward-756"><span class="linenos">756</span></a>        <span class="n">start_logits</span> <span class="o">=</span> <span class="n">start_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-757"><a href="#ErnieForQuestionAnswering.forward-757"><span class="linenos">757</span></a>        <span class="n">end_logits</span> <span class="o">=</span> <span class="n">end_logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-758"><a href="#ErnieForQuestionAnswering.forward-758"><span class="linenos">758</span></a>
</span><span id="ErnieForQuestionAnswering.forward-759"><a href="#ErnieForQuestionAnswering.forward-759"><span class="linenos">759</span></a>        <span class="k">if</span> <span class="n">start_positions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">end_positions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering.forward-760"><a href="#ErnieForQuestionAnswering.forward-760"><span class="linenos">760</span></a>            <span class="c1"># If we are on multi-GPU, split add a dimension</span>
</span><span id="ErnieForQuestionAnswering.forward-761"><a href="#ErnieForQuestionAnswering.forward-761"><span class="linenos">761</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">start_positions</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering.forward-762"><a href="#ErnieForQuestionAnswering.forward-762"><span class="linenos">762</span></a>                <span class="n">start_positions</span> <span class="o">=</span> <span class="n">start_positions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-763"><a href="#ErnieForQuestionAnswering.forward-763"><span class="linenos">763</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_positions</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering.forward-764"><a href="#ErnieForQuestionAnswering.forward-764"><span class="linenos">764</span></a>                <span class="n">end_positions</span> <span class="o">=</span> <span class="n">end_positions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-765"><a href="#ErnieForQuestionAnswering.forward-765"><span class="linenos">765</span></a>            <span class="c1"># sometimes the start/end positions are outside our model inputs, we ignore these terms</span>
</span><span id="ErnieForQuestionAnswering.forward-766"><a href="#ErnieForQuestionAnswering.forward-766"><span class="linenos">766</span></a>            <span class="n">ignored_index</span> <span class="o">=</span> <span class="n">start_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-767"><a href="#ErnieForQuestionAnswering.forward-767"><span class="linenos">767</span></a>            <span class="n">start_positions</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignored_index</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-768"><a href="#ErnieForQuestionAnswering.forward-768"><span class="linenos">768</span></a>            <span class="n">end_positions</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignored_index</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-769"><a href="#ErnieForQuestionAnswering.forward-769"><span class="linenos">769</span></a>
</span><span id="ErnieForQuestionAnswering.forward-770"><a href="#ErnieForQuestionAnswering.forward-770"><span class="linenos">770</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">ignored_index</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-771"><a href="#ErnieForQuestionAnswering.forward-771"><span class="linenos">771</span></a>            <span class="n">start_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">start_positions</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-772"><a href="#ErnieForQuestionAnswering.forward-772"><span class="linenos">772</span></a>            <span class="n">end_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">end_logits</span><span class="p">,</span> <span class="n">end_positions</span><span class="p">)</span>
</span><span id="ErnieForQuestionAnswering.forward-773"><a href="#ErnieForQuestionAnswering.forward-773"><span class="linenos">773</span></a>            <span class="n">total_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">start_loss</span> <span class="o">+</span> <span class="n">end_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
</span><span id="ErnieForQuestionAnswering.forward-774"><a href="#ErnieForQuestionAnswering.forward-774"><span class="linenos">774</span></a>            <span class="k">return</span> <span class="n">total_loss</span>
</span><span id="ErnieForQuestionAnswering.forward-775"><a href="#ErnieForQuestionAnswering.forward-775"><span class="linenos">775</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ErnieForQuestionAnswering.forward-776"><a href="#ErnieForQuestionAnswering.forward-776"><span class="linenos">776</span></a>            <span class="k">return</span> <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span>
</span></pre></div>


            <div class="docstring"><p>Defines the computation performed at every call.</p>

<p>Should be overridden by all subclasses.</p>

<div class="pdoc-alert pdoc-alert-note">

<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>

</div>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedErnieModel">PreTrainedErnieModel</a></dt>
                                <dd id="ErnieForQuestionAnswering.init_weights" class="function"><a href="#PreTrainedErnieModel.init_weights">init_weights</a></dd>
                <dd id="ErnieForQuestionAnswering.from_pretrained" class="function"><a href="#PreTrainedErnieModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ErnieForQuestionAnswering.dump_patches" class="variable">dump_patches</dd>
                <dd id="ErnieForQuestionAnswering.register_buffer" class="function">register_buffer</dd>
                <dd id="ErnieForQuestionAnswering.register_parameter" class="function">register_parameter</dd>
                <dd id="ErnieForQuestionAnswering.add_module" class="function">add_module</dd>
                <dd id="ErnieForQuestionAnswering.apply" class="function">apply</dd>
                <dd id="ErnieForQuestionAnswering.cuda" class="function">cuda</dd>
                <dd id="ErnieForQuestionAnswering.cpu" class="function">cpu</dd>
                <dd id="ErnieForQuestionAnswering.type" class="function">type</dd>
                <dd id="ErnieForQuestionAnswering.float" class="function">float</dd>
                <dd id="ErnieForQuestionAnswering.double" class="function">double</dd>
                <dd id="ErnieForQuestionAnswering.half" class="function">half</dd>
                <dd id="ErnieForQuestionAnswering.bfloat16" class="function">bfloat16</dd>
                <dd id="ErnieForQuestionAnswering.to" class="function">to</dd>
                <dd id="ErnieForQuestionAnswering.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ErnieForQuestionAnswering.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ErnieForQuestionAnswering.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ErnieForQuestionAnswering.T_destination" class="variable">T_destination</dd>
                <dd id="ErnieForQuestionAnswering.state_dict" class="function">state_dict</dd>
                <dd id="ErnieForQuestionAnswering.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ErnieForQuestionAnswering.parameters" class="function">parameters</dd>
                <dd id="ErnieForQuestionAnswering.named_parameters" class="function">named_parameters</dd>
                <dd id="ErnieForQuestionAnswering.buffers" class="function">buffers</dd>
                <dd id="ErnieForQuestionAnswering.named_buffers" class="function">named_buffers</dd>
                <dd id="ErnieForQuestionAnswering.children" class="function">children</dd>
                <dd id="ErnieForQuestionAnswering.named_children" class="function">named_children</dd>
                <dd id="ErnieForQuestionAnswering.modules" class="function">modules</dd>
                <dd id="ErnieForQuestionAnswering.named_modules" class="function">named_modules</dd>
                <dd id="ErnieForQuestionAnswering.train" class="function">train</dd>
                <dd id="ErnieForQuestionAnswering.eval" class="function">eval</dd>
                <dd id="ErnieForQuestionAnswering.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ErnieForQuestionAnswering.zero_grad" class="function">zero_grad</dd>
                <dd id="ErnieForQuestionAnswering.share_memory" class="function">share_memory</dd>
                <dd id="ErnieForQuestionAnswering.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.type) {
                    case "function":
                        heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span><span class="signature">${doc.signature}:</span>`;
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value">${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.type}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>