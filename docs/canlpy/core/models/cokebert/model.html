<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 12.0.2"/>
    <title>canlpy.core.models.cokebert.model API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../cokebert.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;canlpy.core.models.cokebert</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



        <h2>API Documentation</h2>
            <ul class="memberlist">
            <li>
                    <a class="variable" href="#CONFIG_NAME">CONFIG_NAME</a>
            </li>
            <li>
                    <a class="variable" href="#WEIGHTS_NAME">WEIGHTS_NAME</a>
            </li>
            <li>
                    <a class="variable" href="#MAPPING_FILE">MAPPING_FILE</a>
            </li>
            <li>
                    <a class="class" href="#CokeBertConfig">CokeBertConfig</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#CokeBertConfig.__init__">CokeBertConfig</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertConfig.load_from_json">load_from_json</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertConfig.to_json_string">to_json_string</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertConfig.to_dict">to_dict</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertConfig.to_text_encoder_config">to_text_encoder_config</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertConfig.to_knowl_encoder_config">to_knowl_encoder_config</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PreTrainedCokeBertModel.__init__">PreTrainedCokeBertModel</a>
                        </li>
                        <li>
                                <a class="function" href="#PreTrainedCokeBertModel.init_weights">init_weights</a>
                        </li>
                        <li>
                                <a class="function" href="#PreTrainedCokeBertModel.from_pretrained">from_pretrained</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#CokeBertModel">CokeBertModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#CokeBertModel.__init__">CokeBertModel</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertModel.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#DKEncoder">DKEncoder</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#DKEncoder.__init__">DKEncoder</a>
                        </li>
                        <li>
                                <a class="function" href="#DKEncoder.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#DKEncoder_layer">DKEncoder_layer</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#DKEncoder_layer.__init__">DKEncoder_layer</a>
                        </li>
                        <li>
                                <a class="function" href="#DKEncoder_layer.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#DK_text">DK_text</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#DK_text.__init__">DK_text</a>
                        </li>
                        <li>
                                <a class="function" href="#DK_text.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#DK_knowledge">DK_knowledge</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#DK_knowledge.__init__">DK_knowledge</a>
                        </li>
                        <li>
                                <a class="function" href="#DK_knowledge.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#CokeBertForSequenceClassification">CokeBertForSequenceClassification</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#CokeBertForSequenceClassification.__init__">CokeBertForSequenceClassification</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertForSequenceClassification.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#CokeBertForEntityTyping">CokeBertForEntityTyping</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#CokeBertForEntityTyping.__init__">CokeBertForEntityTyping</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertForEntityTyping.forward">forward</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#CokeBertForMaskedLM">CokeBertForMaskedLM</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#CokeBertForMaskedLM.__init__">CokeBertForMaskedLM</a>
                        </li>
                        <li>
                                <a class="function" href="#CokeBertForMaskedLM.forward">forward</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../../../canlpy.html">canlpy</a><wbr>.<a href="./../../../core.html">core</a><wbr>.<a href="./../../models.html">models</a><wbr>.<a href="./../cokebert.html">cokebert</a><wbr>.model    </h1>

                        <div class="docstring"><p>Re-Implementation of the CokeBert Model (Su et al., 2020)</p>

<p>This module contains several versions of CokeBert for different 
fine-tune tasks.</p>
</div>

                        <input id="model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="model-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="c1"># -*- coding: utf-8 -*-</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="sd">&quot;&quot;&quot;Re-Implementation of the CokeBert Model (Su et al., 2020)</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="sd">This module contains several versions of CokeBert for different </span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="sd">fine-tune tasks. </span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a><span class="kn">import</span> <span class="nn">copy</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a><span class="kn">import</span> <span class="nn">json</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a><span class="kn">import</span> <span class="nn">math</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a><span class="kn">import</span> <span class="nn">logging</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="n">BCEWithLogitsLoss</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a><span class="kn">from</span> <span class="nn">canlpy.core.models.bert.model</span> <span class="kn">import</span> <span class="n">BertEmbeddings</span><span class="p">,</span> <span class="n">BertPooler</span><span class="p">,</span> <span class="n">init_weights</span><span class="p">,</span> <span class="n">LayerNorm</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a><span class="kn">from</span> <span class="nn">canlpy.core.models.ernie.components</span> <span class="kn">import</span> <span class="n">ErnieEncoder</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a><span class="kn">from</span> <span class="nn">canlpy.core.components.heads</span> <span class="kn">import</span> <span class="n">BertOnlyMLMHead</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a><span class="kn">from</span> <span class="nn">canlpy.core.components.fusion.cokebert_fusion</span> <span class="kn">import</span> <span class="n">DK_fusion</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a><span class="n">CONFIG_NAME</span> <span class="o">=</span> <span class="s1">&#39;cokebert_config.json&#39;</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a><span class="sd">&quot;&quot;&quot;str: name of the config file in the checkpoint&quot;&quot;&quot;</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a><span class="n">WEIGHTS_NAME</span> <span class="o">=</span> <span class="s1">&#39;pytorch_model.bin&#39;</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a><span class="sd">&quot;&quot;&quot;str: name of the file containing weights in the checkpoint&quot;&quot;&quot;</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a><span class="n">MAPPING_FILE</span> <span class="o">=</span> <span class="s1">&#39;mapping.json&#39;</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a><span class="sd">&quot;&quot;&quot;str: name of the file containing the mapping in the checkpoint&quot;&quot;&quot;</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a><span class="k">class</span> <span class="nc">CokeBertConfig</span><span class="p">():</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a>    <span class="sd">&quot;&quot;&quot;Configuration class to store the configuration of a `CokeBertModel`.</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a>                 <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>                 <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a>                 <span class="n">entity_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a>                 <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a>                 <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a>                 <span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a>                 <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a>                 <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a>                 <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a>                 <span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a>                 <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a>                 <span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a>                 <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a>                 <span class="n">layer_types</span><span class="o">=</span><span class="p">[],</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a>                 <span class="n">k_v_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a>                 <span class="n">q_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a>                 <span class="n">dk_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a>        <span class="sd">&quot;&quot;&quot;Constructs CokeBertConfig.</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a><span class="sd">        Args:</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a><span class="sd">            vocab_size (int): Vocabulary size of `inputs_ids` in `CokeBertModel`.</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a><span class="sd">            hidden_size (int): Size of the encoder layers and the pooler layer.</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a><span class="sd">            num_hidden_layers (int): Number of hidden layers in the Transformer encoder.</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a><span class="sd">            num_attention_heads (int): Number of attention heads for each attention layer in</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a><span class="sd">                the Transformer encoder.</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a><span class="sd">            intermediate_size (int): The size of the &quot;intermediate&quot; (i.e., feed-forward)</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a><span class="sd">                layer in the Transformer encoder.</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a><span class="sd">            hidden_act: The non-linear activation function (function or string) in the</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a><span class="sd">                encoder and pooler. If string, &quot;gelu&quot;, &quot;relu&quot; and &quot;swish&quot; are supported.</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a><span class="sd">            hidden_dropout_prob (int): The dropout probabilitiy for all fully connected</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a><span class="sd">                layers in the embeddings, encoder, and pooler.</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a><span class="sd">            attention_probs_dropout_prob (float): The dropout ratio for the attention</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a><span class="sd">                probabilities.</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a><span class="sd">            max_position_embeddings (int): The maximum sequence length that this model might</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a><span class="sd">                ever be used with. Typically set this to something large just in case</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a><span class="sd">                (e.g., 512 or 1024 or 2048).</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a><span class="sd">            type_vocab_size (int): The vocabulary size of the `token_type_ids` passed into</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a><span class="sd">                `CokeBertModel`.</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a><span class="sd">            initializer_range (float): The sttdev of the truncated_normal_initializer for</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a><span class="sd">                initializing all weight matrices.</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a><span class="sd">            layer_types (list): list of `ErnieLayer`s which can be &#39;sim&#39; (Bert encoder), </span>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a><span class="sd">                &#39;mix&#39; (Ernie encoder but no multihead attention for entites) or &#39;norm&#39; (standard Ernie encoder)</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a><span class="sd">            k_v_dim (int): Size of the hidden knowledge representation in the dynamic knowledge encoder</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a><span class="sd">            q_dim (int): Size of the hidden text representation in the dynamic knowledge encoder</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a><span class="sd">            dk_layers (int): Number of layers in the dynamic knowledge encoder</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">entity_size</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads_ent</span> <span class="o">=</span> <span class="n">num_attention_heads_ent</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span> <span class="c1">#Stores a string</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dropout_prob</span> <span class="o">=</span> <span class="n">hidden_dropout_prob</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span> <span class="o">=</span> <span class="n">attention_probs_dropout_prob</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_vocab_size</span> <span class="o">=</span> <span class="n">type_vocab_size</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="n">layer_types</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">k_v_dim</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">q_dim</span> <span class="o">=</span> <span class="n">q_dim</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dk_layers</span> <span class="o">=</span> <span class="n">dk_layers</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a>       
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>    <span class="k">def</span> <span class="nf">load_from_json</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span><span class="n">path</span><span class="p">):</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>        <span class="sd">&quot;&quot;&quot;Loads config from json file</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a><span class="sd">        </span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a><span class="sd">        Args:</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a><span class="sd">            cls: current CokeBertConfig Class</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a><span class="sd">            path (str): path to config.json file</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a><span class="sd">        Returns:</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a><span class="sd">            config: Loaded CokeBertConfig</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="c1">#Create default config</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>            <span class="n">json_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">json_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a>                <span class="n">config</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a>        <span class="k">return</span> <span class="n">config</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a>        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_json_string</span><span class="p">())</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a>    <span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a JSON string.</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a><span class="sd">        </span>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a><span class="sd">        Returns:</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a><span class="sd">            JSON-String of Config</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>        
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a Python dictionary.</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a><span class="sd">        </span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a><span class="sd">        Returns:</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a><span class="sd">            output: Python dictionary of Config</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a>    <span class="k">def</span> <span class="nf">to_text_encoder_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a>        <span class="sd">&quot;&quot;&quot;Splits Config to create `ErnieEncoder` as TextEncoder</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a><span class="sd">        </span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a><span class="sd">        Returns:</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a><span class="sd">            CokeBertConfig for TextEncoder</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a>        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;sim&#39;</span><span class="p">]</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">])</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a>        <span class="k">return</span> <span class="n">CokeBertConfig</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a>    <span class="k">def</span> <span class="nf">to_knowl_encoder_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>        <span class="sd">&quot;&quot;&quot;Splits Config to create `ErnieEncoder` as KnowledgeEncoder</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a><span class="sd">        </span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a><span class="sd">        Returns:</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a><span class="sd">            CokeBertConfig for KnowledgeEncoder</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;sim&#39;</span><span class="p">]</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">])</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a>        <span class="k">return</span> <span class="n">CokeBertConfig</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a><span class="k">class</span> <span class="nc">PreTrainedCokeBertModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>    <span class="sd">&quot;&quot;&quot; An abstract class to handle weights initialization and</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a><span class="sd">        a simple interface for downloading and loading pretrained models.</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>        <span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">CokeBertConfig</span><span class="p">):</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a>                <span class="s2">&quot;Parameter config in `</span><span class="si">{}</span><span class="s2">(config)` should be an instance of class `CokeBertConfig`. &quot;</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>                <span class="s2">&quot;To create a model from a Google pretrained model use &quot;</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>                <span class="s2">&quot;`model = </span><span class="si">{}</span><span class="s2">.from_pretrained(PRETRAINED_MODEL_NAME)`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a>                <span class="p">))</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>        <span class="sd">&quot;&quot;&quot; Initialize the weights.</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a><span class="sd">        Args:</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a><span class="sd">            module: one of `nn.Linear`, `nn.Embedding`, `LayerNorm`, module to initialize weights of</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>            <span class="c1"># Slightly different from the TF version which uses truncated_normal for initialization</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>            <span class="c1"># cf https://github.com/pytorch/pytorch/pull/5617</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">):</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dir_path</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a><span class="sd">        Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a><span class="sd">        Download and cache the pre-trained model file if needed.</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a><span class="sd">        Args:</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a><span class="sd">            dir_path (str): a path or url to a pretrained model archive containing:</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a><span class="sd">                    . `bert_config.json` a configuration file for the model</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a><span class="sd">                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a><span class="sd">            state_dict: an optional state dictionary (collections.OrderedDict object) to use instead of Google pre-trained models</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a><span class="sd">            cache_dir: an optional path to a folder in which the pre-trained models will be cached.</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a><span class="sd">            *inputs, **kwargs: additional input for the specific Bert class</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a><span class="sd">                (ex: num_labels for BertForSequenceClassification)</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>        
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>        <span class="c1"># Load config</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>        <span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">CONFIG_NAME</span><span class="p">)</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">CokeBertConfig</span><span class="o">.</span><span class="n">load_from_json</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">state_dict</span><span class="o">==</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a>            <span class="n">weights_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a>            <span class="k">if</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span><span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a>        <span class="n">missing_keys</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a>        <span class="c1"># copy state_dict so _load_from_state_dict can modify it</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a>        <span class="n">metadata</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="s1">&#39;_metadata&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a>        
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a>        <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>            <span class="n">state_dict</span><span class="o">.</span><span class="n">_metadata</span> <span class="o">=</span> <span class="n">metadata</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a>        <span class="n">mapping_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">MAPPING_FILE</span><span class="p">)</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">)):</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a>                <span class="n">mapping</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>            <span class="k">for</span> <span class="n">old_key</span><span class="p">,</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>                <span class="k">if</span><span class="p">(</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="ow">and</span> <span class="n">old_key</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>                    <span class="n">model_shape</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">new_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a>                    <span class="k">if</span><span class="p">(</span><span class="n">model_shape</span><span class="o">!=</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;model.state_dict() </span><span class="si">{</span><span class="n">new_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">model_shape</span><span class="si">}</span><span class="s1"> != state_dict </span><span class="si">{</span><span class="n">old_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>                        
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>                    <span class="n">state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>        
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>        <span class="n">missing_keys</span><span class="p">,</span><span class="n">unexpected_keys</span> <span class="o">=</span>  <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Missing keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">missing_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">missing_keys</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a><span class="k">class</span> <span class="nc">CokeBertModel</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a>    <span class="sd">&quot;&quot;&quot; A class to handle the Transformer Model (without fine-tuning head)&quot;&quot;&quot;</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a CokeBertModel</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a><span class="sd">        Args:</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a><span class="sd">            config (`CokeBertConfig`): The config that sets the model&#39;s hyperparameters</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">CokeBertModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">type_vocab_size</span><span class="p">)</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">to_text_encoder_config</span><span class="p">())</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">knowledge_encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">to_knowl_encoder_config</span><span class="p">())</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="o">=</span> <span class="n">BertPooler</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dk_encoder</span> <span class="o">=</span> <span class="n">DKEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">q_dim</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dk_layers</span><span class="p">)</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">k_v_dim</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">entity_size</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the `CokeBertModel`</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a><span class="sd">        Args:</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a><span class="sd">            input_ids: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a><span class="sd">            token_type_ids: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a><span class="sd">            attention_mask: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a><span class="sd">            ent_mask: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a><span class="sd">            output_all_encoded_layers: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a><span class="sd">        Returns:</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a><span class="sd">            sequence_output, pooled_output</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a><span class="sd">            sequence_output: the full sequence of hidden-states corresponding</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a><span class="sd">                    to the last attention block of shape [batch_size, sequence_length, hidden_size]       </span>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a><span class="sd">            pooled_output: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a><span class="sd">                classifier pretrained on top of the hidden state associated to the first character of the</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a><span class="sd">                input (`CLS`) to train on the Next-Sentence task (see BERT&#39;s paper).</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a>        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos">305</span></a>            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos">306</span></a>        <span class="k">if</span> <span class="n">token_type_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos">307</span></a>            <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos">308</span></a>
</span><span id="L-309"><a href="#L-309"><span class="linenos">309</span></a>        <span class="c1"># We create a 3D attention mask from a 2D tensor mask.</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos">310</span></a>        <span class="c1"># Sizes are [batch_size, 1, 1, to_seq_length]</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos">311</span></a>        <span class="c1"># So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos">312</span></a>        <span class="c1"># this attention mask is more simple than the triangular masking of causal attention</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos">313</span></a>        <span class="c1"># used in OpenAI GPT, we just need to prepare the broadcast dimension here.</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos">314</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos">315</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos">316</span></a>
</span><span id="L-317"><a href="#L-317"><span class="linenos">317</span></a>        <span class="c1"># Since attention_mask is 1.0 for positions we want to attend and 0.0 for</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos">318</span></a>        <span class="c1"># masked positions, this operation will create a tensor which is 0.0 for</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos">319</span></a>        <span class="c1"># positions we want to attend and -10000.0 for masked positions.</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos">320</span></a>        <span class="c1"># Since we are adding it to the raw scores before the softmax, this is</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos">321</span></a>        <span class="c1"># effectively the same as removing these entirely.</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos">322</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos">323</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos">324</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">extended_ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos">325</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_ent_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos">326</span></a>
</span><span id="L-327"><a href="#L-327"><span class="linenos">327</span></a>        <span class="c1">#############################################################</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos">328</span></a>
</span><span id="L-329"><a href="#L-329"><span class="linenos">329</span></a>        <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos">330</span></a>
</span><span id="L-331"><a href="#L-331"><span class="linenos">331</span></a>        <span class="c1">##</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos">332</span></a>        <span class="n">all_encoder_layers</span><span class="o">=</span><span class="nb">list</span><span class="p">()</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos">333</span></a>        <span class="n">ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="c1">#.unsqueeze(-1)</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos">334</span></a>        <span class="c1">##</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos">335</span></a>
</span><span id="L-336"><a href="#L-336"><span class="linenos">336</span></a>        <span class="n">all_encoder_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">,</span> <span class="n">extended_attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">extended_ent_mask</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos">337</span></a>
</span><span id="L-338"><a href="#L-338"><span class="linenos">338</span></a>        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">all_encoder_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos">339</span></a>
</span><span id="L-340"><a href="#L-340"><span class="linenos">340</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ent</span><span class="p">[</span><span class="n">input_ent</span><span class="o">!=</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos">341</span></a>            <span class="c1"># no input entities -&gt; return 0s</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos">342</span></a>            <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span><span class="p">)</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos">343</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos">344</span></a>
</span><span id="L-345"><a href="#L-345"><span class="linenos">345</span></a>            <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dk_encoder</span><span class="p">(</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">k_v_s</span><span class="p">)</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos">346</span></a>
</span><span id="L-347"><a href="#L-347"><span class="linenos">347</span></a>        <span class="n">encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">knowledge_encoder</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">extended_attention_mask</span><span class="p">,</span><span class="n">hidden_states_ent</span><span class="p">,</span> <span class="n">extended_ent_mask</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="L-348"><a href="#L-348"><span class="linenos">348</span></a>        <span class="k">if</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos">349</span></a>            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">encoded_layers</span><span class="p">:</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos">350</span></a>                <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos">351</span></a>
</span><span id="L-352"><a href="#L-352"><span class="linenos">352</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos">353</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos">354</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos">355</span></a>            <span class="n">encoded_layers</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos">356</span></a>            <span class="c1">#return encoded_layers, pooled_output</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos">357</span></a>        
</span><span id="L-358"><a href="#L-358"><span class="linenos">358</span></a>        <span class="k">return</span> <span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos">359</span></a>
</span><span id="L-360"><a href="#L-360"><span class="linenos">360</span></a><span class="k">class</span> <span class="nc">DKEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos">361</span></a>    <span class="sd">&quot;&quot;&quot; A class for the Dynamic Knowledge Encoder for a `CokeBertModel`.</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos">362</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos">363</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">no_layers</span><span class="p">):</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos">364</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a Dynamic KnowledgeEncoder</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos">365</span></a>
</span><span id="L-366"><a href="#L-366"><span class="linenos">366</span></a><span class="sd">        Args:</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos">367</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos">368</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos">369</span></a><span class="sd">            no_layers (int): Number of layers in the Dynamic Knowledge Encoder</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos">370</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos">371</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos">372</span></a>
</span><span id="L-373"><a href="#L-373"><span class="linenos">373</span></a>        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos">374</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">no_layers</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos">375</span></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DKEncoder_layer</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos">376</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</span><span id="L-377"><a href="#L-377"><span class="linenos">377</span></a>
</span><span id="L-378"><a href="#L-378"><span class="linenos">378</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="L-379"><a href="#L-379"><span class="linenos">379</span></a>
</span><span id="L-380"><a href="#L-380"><span class="linenos">380</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">k_v_dim</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos">381</span></a>
</span><span id="L-382"><a href="#L-382"><span class="linenos">382</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k_v_s</span><span class="p">):</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos">383</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos">384</span></a><span class="sd">        Forward pass through the Dynamic Knowledge Encoder</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos">385</span></a>
</span><span id="L-386"><a href="#L-386"><span class="linenos">386</span></a><span class="sd">        Args:</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos">387</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos">388</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos">389</span></a><span class="sd">            q: the full sequence of hidden-states corresponding</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos">390</span></a><span class="sd">                to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </span>
</span><span id="L-391"><a href="#L-391"><span class="linenos">391</span></a><span class="sd">            k_v_s: list of (k, v) tuples of length `no_layers`, </span>
</span><span id="L-392"><a href="#L-392"><span class="linenos">392</span></a><span class="sd">                k, v are of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos">393</span></a><span class="sd">        </span>
</span><span id="L-394"><a href="#L-394"><span class="linenos">394</span></a><span class="sd">        Returns:</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos">395</span></a><span class="sd">            hidden_states_ent: internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos">396</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos">397</span></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span> <span class="c1">#CLS token only</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos">398</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos">399</span></a>            <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">k_v_s</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos">400</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos">401</span></a>                <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="n">combined</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos">402</span></a>            <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos">403</span></a>            <span class="n">combined</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos">404</span></a>
</span><span id="L-405"><a href="#L-405"><span class="linenos">405</span></a>        <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span><span class="c1">#.cuda()</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos">406</span></a>        <span class="n">ent_pos_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_ent</span><span class="p">)</span> <span class="c1"># id start from 0</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos">407</span></a>
</span><span id="L-408"><a href="#L-408"><span class="linenos">408</span></a>        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos">409</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ent_pos_s</span><span class="p">[</span><span class="n">ent_pos_s</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">batch</span><span class="p">]):</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos">410</span></a>                <span class="n">hidden_states_ent</span><span class="p">[</span><span class="n">batch</span><span class="p">][</span><span class="nb">int</span><span class="p">(</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">=</span> <span class="n">combined</span><span class="p">[</span><span class="n">batch</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos">411</span></a>
</span><span id="L-412"><a href="#L-412"><span class="linenos">412</span></a>        <span class="k">return</span> <span class="n">hidden_states_ent</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos">413</span></a>
</span><span id="L-414"><a href="#L-414"><span class="linenos">414</span></a><span class="k">class</span> <span class="nc">DKEncoder_layer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos">415</span></a>    <span class="sd">&quot;&quot;&quot; A class for one Dynamic Knowledge Encoder Layer for a `DKEncoder` from CokeBert.</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos">416</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos">417</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">):</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos">418</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DKEncoder_layer`.</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos">419</span></a><span class="sd">        </span>
</span><span id="L-420"><a href="#L-420"><span class="linenos">420</span></a><span class="sd">        Args:</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos">421</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos">422</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos">423</span></a><span class="sd">            layer_no (int): Number of the layer (assigned in reverse order)</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos">424</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos">425</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos">426</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">DK_text</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">)</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos">427</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">knowledge</span> <span class="o">=</span> <span class="n">DK_knowledge</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">)</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos">428</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">DK_fusion</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">)</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos">429</span></a>
</span><span id="L-430"><a href="#L-430"><span class="linenos">430</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos">431</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos">432</span></a><span class="sd">        Forward pass through the Dynamic Knowledge Encoder layer</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos">433</span></a>
</span><span id="L-434"><a href="#L-434"><span class="linenos">434</span></a><span class="sd">        Args:</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos">435</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos">436</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos">437</span></a><span class="sd">            q: the representation of hidden-states corresponding</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos">438</span></a><span class="sd">                to the last text-attention block of shape [batch_size, 1, q_dim] </span>
</span><span id="L-439"><a href="#L-439"><span class="linenos">439</span></a><span class="sd">            k: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos">440</span></a><span class="sd">            v: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos">441</span></a><span class="sd">        </span>
</span><span id="L-442"><a href="#L-442"><span class="linenos">442</span></a><span class="sd">        Returns:</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos">443</span></a><span class="sd">            internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos">444</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos">445</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos">446</span></a>        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">knowledge</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span><span id="L-447"><a href="#L-447"><span class="linenos">447</span></a>
</span><span id="L-448"><a href="#L-448"><span class="linenos">448</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">q_i</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos">449</span></a>
</span><span id="L-450"><a href="#L-450"><span class="linenos">450</span></a><span class="k">class</span> <span class="nc">DK_text</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos">451</span></a>    <span class="sd">&quot;&quot;&quot; A class for the Text Processing in a `DKEncoderLayer` from CokeBert.</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos">452</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos">453</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">):</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos">454</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DK_text` module</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos">455</span></a><span class="sd">        </span>
</span><span id="L-456"><a href="#L-456"><span class="linenos">456</span></a><span class="sd">        Args:</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos">457</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos">458</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos">459</span></a><span class="sd">            layer_no (int): Number of the layer (assigned in reverse order)</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos">460</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos">461</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos">462</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">q_dim</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos">463</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos">464</span></a>
</span><span id="L-465"><a href="#L-465"><span class="linenos">465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">number</span> <span class="o">=</span> <span class="n">layer_no</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos">466</span></a>
</span><span id="L-467"><a href="#L-467"><span class="linenos">467</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos">468</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the Text Processing Module of a Dynamic Knowledge Encoder layer</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos">469</span></a><span class="sd">        </span>
</span><span id="L-470"><a href="#L-470"><span class="linenos">470</span></a><span class="sd">        Args:</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos">471</span></a><span class="sd">            q: the full sequence of hidden-states corresponding</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos">472</span></a><span class="sd">                to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </span>
</span><span id="L-473"><a href="#L-473"><span class="linenos">473</span></a>
</span><span id="L-474"><a href="#L-474"><span class="linenos">474</span></a><span class="sd">        Returns:</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos">475</span></a><span class="sd">            q_i: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos">476</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos">477</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos">478</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">q_i</span><span class="p">)</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos">479</span></a>
</span><span id="L-480"><a href="#L-480"><span class="linenos">480</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">number</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos">481</span></a>            <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_i</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos">482</span></a>
</span><span id="L-483"><a href="#L-483"><span class="linenos">483</span></a>        <span class="k">return</span> <span class="n">q_i</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos">484</span></a>
</span><span id="L-485"><a href="#L-485"><span class="linenos">485</span></a><span class="k">class</span> <span class="nc">DK_knowledge</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos">486</span></a>    <span class="sd">&quot;&quot;&quot; A class for the Knowledge Processing in a `DKEncoderLayer` from CokeBert.&quot;&quot;&quot;</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos">487</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">):</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos">488</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DK_knowledge` module</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos">489</span></a>
</span><span id="L-490"><a href="#L-490"><span class="linenos">490</span></a><span class="sd">        Args:</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos">491</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos">492</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos">493</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos">494</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos">495</span></a>    
</span><span id="L-496"><a href="#L-496"><span class="linenos">496</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos">497</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the Knowledge Processing Module of a Dynamic Knowledge Encoder layer</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos">498</span></a><span class="sd">        </span>
</span><span id="L-499"><a href="#L-499"><span class="linenos">499</span></a><span class="sd">        Args:</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos">500</span></a><span class="sd">            k: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos">501</span></a>
</span><span id="L-502"><a href="#L-502"><span class="linenos">502</span></a><span class="sd">        Returns:</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos">503</span></a><span class="sd">            hidden knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos">504</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos">505</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_v_linear</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos">506</span></a>
</span><span id="L-507"><a href="#L-507"><span class="linenos">507</span></a><span class="k">class</span> <span class="nc">CokeBertForSequenceClassification</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos">508</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos">509</span></a><span class="sd">    CokeBert model for sequence classification.  </span>
</span><span id="L-510"><a href="#L-510"><span class="linenos">510</span></a><span class="sd">    This module is composed of the CokeBert model with a linear layer on top of</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos">511</span></a><span class="sd">    the pooled output.</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos">512</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos">513</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos">514</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForSequenceClassification` model</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos">515</span></a>
</span><span id="L-516"><a href="#L-516"><span class="linenos">516</span></a><span class="sd">        Args:</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos">517</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos">518</span></a><span class="sd">            `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos">519</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos">520</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos">521</span></a>
</span><span id="L-522"><a href="#L-522"><span class="linenos">522</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos">523</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos">524</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos">525</span></a>
</span><span id="L-526"><a href="#L-526"><span class="linenos">526</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos">527</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos">528</span></a>
</span><span id="L-529"><a href="#L-529"><span class="linenos">529</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos">530</span></a>
</span><span id="L-531"><a href="#L-531"><span class="linenos">531</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos">532</span></a>
</span><span id="L-533"><a href="#L-533"><span class="linenos">533</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos">534</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos">535</span></a>
</span><span id="L-536"><a href="#L-536"><span class="linenos">536</span></a><span class="sd">        Args:</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos">537</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos">538</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos">539</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos">540</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos">541</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos">542</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos">543</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos">544</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos">545</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos">546</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos">547</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos">548</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos">549</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos">550</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos">551</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos">552</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos">553</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos">554</span></a>
</span><span id="L-555"><a href="#L-555"><span class="linenos">555</span></a><span class="sd">        Returns:</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos">556</span></a><span class="sd">            if `labels` is not `None`:  </span>
</span><span id="L-557"><a href="#L-557"><span class="linenos">557</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="L-558"><a href="#L-558"><span class="linenos">558</span></a><span class="sd">            if `labels` is `None`:  </span>
</span><span id="L-559"><a href="#L-559"><span class="linenos">559</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="L-560"><a href="#L-560"><span class="linenos">560</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos">561</span></a>        <span class="n">seq_out</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos">562</span></a>
</span><span id="L-563"><a href="#L-563"><span class="linenos">563</span></a>        <span class="n">head</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1601</span><span class="p">]</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos">564</span></a>        <span class="n">tail</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1089</span><span class="p">]</span>
</span><span id="L-565"><a href="#L-565"><span class="linenos">565</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos">566</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">head</span><span class="p">,</span><span class="n">tail</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos">567</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos">568</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos">569</span></a>        <span class="k">except</span><span class="p">:</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos">570</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos">571</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===&quot;</span><span class="p">)</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos">572</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">head</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos">573</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===&quot;</span><span class="p">)</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos">574</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">tail</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos">575</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos">576</span></a>
</span><span id="L-577"><a href="#L-577"><span class="linenos">577</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos">578</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos">579</span></a>
</span><span id="L-580"><a href="#L-580"><span class="linenos">580</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos">581</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos">582</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos">583</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos">584</span></a>            <span class="k">except</span><span class="p">:</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos">585</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">head</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos">586</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos">587</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">tail</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos">588</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="L-589"><a href="#L-589"><span class="linenos">589</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">pooled_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos">590</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos">591</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos">592</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos">593</span></a>                <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span><span id="L-594"><a href="#L-594"><span class="linenos">594</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos">595</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos">596</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos">597</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos">598</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos">599</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span><span id="L-600"><a href="#L-600"><span class="linenos">600</span></a>
</span><span id="L-601"><a href="#L-601"><span class="linenos">601</span></a><span class="k">class</span> <span class="nc">CokeBertForEntityTyping</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos">602</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-603"><a href="#L-603"><span class="linenos">603</span></a><span class="sd">    CokeBert model for classification.  </span>
</span><span id="L-604"><a href="#L-604"><span class="linenos">604</span></a><span class="sd">    This module is composed of the CokeBert model with a linear layer on top of</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos">605</span></a><span class="sd">    the pooled output.</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos">606</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos">607</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos">608</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForEntityTyping` model</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos">609</span></a>
</span><span id="L-610"><a href="#L-610"><span class="linenos">610</span></a><span class="sd">        Args:</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos">611</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="L-612"><a href="#L-612"><span class="linenos">612</span></a><span class="sd">            `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos">613</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos">614</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos">615</span></a>
</span><span id="L-616"><a href="#L-616"><span class="linenos">616</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos">617</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos">618</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos">619</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">typing</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos">620</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos">621</span></a>
</span><span id="L-622"><a href="#L-622"><span class="linenos">622</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos">623</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos">624</span></a>
</span><span id="L-625"><a href="#L-625"><span class="linenos">625</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos">626</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos">627</span></a>
</span><span id="L-628"><a href="#L-628"><span class="linenos">628</span></a><span class="sd">        Args:</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos">629</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos">630</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-631"><a href="#L-631"><span class="linenos">631</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos">632</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-633"><a href="#L-633"><span class="linenos">633</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos">634</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos">635</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos">636</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos">637</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos">638</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos">639</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos">640</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos">641</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos">642</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos">643</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos">644</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos">645</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos">646</span></a>
</span><span id="L-647"><a href="#L-647"><span class="linenos">647</span></a><span class="sd">        Returns:</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos">648</span></a><span class="sd">            if `labels` is not `None`:  </span>
</span><span id="L-649"><a href="#L-649"><span class="linenos">649</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="L-650"><a href="#L-650"><span class="linenos">650</span></a><span class="sd">            if `labels` is `None`:  </span>
</span><span id="L-651"><a href="#L-651"><span class="linenos">651</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="L-652"><a href="#L-652"><span class="linenos">652</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-653"><a href="#L-653"><span class="linenos">653</span></a>        <span class="n">seq_out</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos">654</span></a>
</span><span id="L-655"><a href="#L-655"><span class="linenos">655</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1601</span><span class="p">]</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos">656</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos">657</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-658"><a href="#L-658"><span class="linenos">658</span></a>
</span><span id="L-659"><a href="#L-659"><span class="linenos">659</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-660"><a href="#L-660"><span class="linenos">660</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">typing</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos">661</span></a>
</span><span id="L-662"><a href="#L-662"><span class="linenos">662</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos">663</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="L-664"><a href="#L-664"><span class="linenos">664</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos">665</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="L-666"><a href="#L-666"><span class="linenos">666</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos">667</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos">668</span></a>
</span><span id="L-669"><a href="#L-669"><span class="linenos">669</span></a><span class="k">class</span> <span class="nc">CokeBertForMaskedLM</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos">670</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos">671</span></a><span class="sd">    CokeBert model for masked pre-training task.  </span>
</span><span id="L-672"><a href="#L-672"><span class="linenos">672</span></a><span class="sd">    This module is composed of the CokeBert model with a linear layer on top of</span>
</span><span id="L-673"><a href="#L-673"><span class="linenos">673</span></a><span class="sd">    the sequence output.</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos">674</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos">675</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos">676</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForMaskedLM` model</span>
</span><span id="L-677"><a href="#L-677"><span class="linenos">677</span></a>
</span><span id="L-678"><a href="#L-678"><span class="linenos">678</span></a><span class="sd">        Args:</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos">679</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos">680</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-681"><a href="#L-681"><span class="linenos">681</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-682"><a href="#L-682"><span class="linenos">682</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos">683</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos">684</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="L-685"><a href="#L-685"><span class="linenos">685</span></a>
</span><span id="L-686"><a href="#L-686"><span class="linenos">686</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos">687</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos">688</span></a>
</span><span id="L-689"><a href="#L-689"><span class="linenos">689</span></a><span class="sd">        Args:</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos">690</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="L-691"><a href="#L-691"><span class="linenos">691</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos">692</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="L-693"><a href="#L-693"><span class="linenos">693</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos">694</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos">695</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="L-696"><a href="#L-696"><span class="linenos">696</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-697"><a href="#L-697"><span class="linenos">697</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos">698</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos">699</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="L-700"><a href="#L-700"><span class="linenos">700</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos">701</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos">702</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos">703</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="L-704"><a href="#L-704"><span class="linenos">704</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos">705</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="L-706"><a href="#L-706"><span class="linenos">706</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos">707</span></a>
</span><span id="L-708"><a href="#L-708"><span class="linenos">708</span></a><span class="sd">        Returns:</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos">709</span></a><span class="sd">            if `masked_lm_labels` is not `None`:  </span>
</span><span id="L-710"><a href="#L-710"><span class="linenos">710</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="L-711"><a href="#L-711"><span class="linenos">711</span></a><span class="sd">            if `masked_lm_labels` is `None`:  </span>
</span><span id="L-712"><a href="#L-712"><span class="linenos">712</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="L-713"><a href="#L-713"><span class="linenos">713</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-714"><a href="#L-714"><span class="linenos">714</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="L-715"><a href="#L-715"><span class="linenos">715</span></a>                                       <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos">716</span></a>        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="L-717"><a href="#L-717"><span class="linenos">717</span></a>
</span><span id="L-718"><a href="#L-718"><span class="linenos">718</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-719"><a href="#L-719"><span class="linenos">719</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-720"><a href="#L-720"><span class="linenos">720</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos">721</span></a>            <span class="k">return</span> <span class="n">masked_lm_loss</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos">722</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-723"><a href="#L-723"><span class="linenos">723</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span>
</span></pre></div>


            </section>
                <section id="CONFIG_NAME">
                    <div class="attr variable">
            <span class="name">CONFIG_NAME</span><span class="default_value"> = &#39;cokebert_config.json&#39;</span>

        
    </div>
    <a class="headerlink" href="#CONFIG_NAME"></a>
    
            <div class="docstring"><p>str: name of the config file in the checkpoint</p>
</div>


                </section>
                <section id="WEIGHTS_NAME">
                    <div class="attr variable">
            <span class="name">WEIGHTS_NAME</span><span class="default_value"> = &#39;pytorch_model.bin&#39;</span>

        
    </div>
    <a class="headerlink" href="#WEIGHTS_NAME"></a>
    
            <div class="docstring"><p>str: name of the file containing weights in the checkpoint</p>
</div>


                </section>
                <section id="MAPPING_FILE">
                    <div class="attr variable">
            <span class="name">MAPPING_FILE</span><span class="default_value"> = &#39;mapping.json&#39;</span>

        
    </div>
    <a class="headerlink" href="#MAPPING_FILE"></a>
    
            <div class="docstring"><p>str: name of the file containing the mapping in the checkpoint</p>
</div>


                </section>
                <section id="CokeBertConfig">
                            <input id="CokeBertConfig-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">CokeBertConfig</span>:

                <label class="view-source-button" for="CokeBertConfig-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertConfig"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertConfig-35"><a href="#CokeBertConfig-35"><span class="linenos"> 35</span></a><span class="k">class</span> <span class="nc">CokeBertConfig</span><span class="p">():</span>
</span><span id="CokeBertConfig-36"><a href="#CokeBertConfig-36"><span class="linenos"> 36</span></a>    <span class="sd">&quot;&quot;&quot;Configuration class to store the configuration of a `CokeBertModel`.</span>
</span><span id="CokeBertConfig-37"><a href="#CokeBertConfig-37"><span class="linenos"> 37</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig-38"><a href="#CokeBertConfig-38"><span class="linenos"> 38</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="CokeBertConfig-39"><a href="#CokeBertConfig-39"><span class="linenos"> 39</span></a>                 <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="CokeBertConfig-40"><a href="#CokeBertConfig-40"><span class="linenos"> 40</span></a>                 <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="CokeBertConfig-41"><a href="#CokeBertConfig-41"><span class="linenos"> 41</span></a>                 <span class="n">entity_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
</span><span id="CokeBertConfig-42"><a href="#CokeBertConfig-42"><span class="linenos"> 42</span></a>                 <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="CokeBertConfig-43"><a href="#CokeBertConfig-43"><span class="linenos"> 43</span></a>                 <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="CokeBertConfig-44"><a href="#CokeBertConfig-44"><span class="linenos"> 44</span></a>                 <span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="CokeBertConfig-45"><a href="#CokeBertConfig-45"><span class="linenos"> 45</span></a>                 <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
</span><span id="CokeBertConfig-46"><a href="#CokeBertConfig-46"><span class="linenos"> 46</span></a>                 <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
</span><span id="CokeBertConfig-47"><a href="#CokeBertConfig-47"><span class="linenos"> 47</span></a>                 <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="CokeBertConfig-48"><a href="#CokeBertConfig-48"><span class="linenos"> 48</span></a>                 <span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="CokeBertConfig-49"><a href="#CokeBertConfig-49"><span class="linenos"> 49</span></a>                 <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="CokeBertConfig-50"><a href="#CokeBertConfig-50"><span class="linenos"> 50</span></a>                 <span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="CokeBertConfig-51"><a href="#CokeBertConfig-51"><span class="linenos"> 51</span></a>                 <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
</span><span id="CokeBertConfig-52"><a href="#CokeBertConfig-52"><span class="linenos"> 52</span></a>                 <span class="n">layer_types</span><span class="o">=</span><span class="p">[],</span>
</span><span id="CokeBertConfig-53"><a href="#CokeBertConfig-53"><span class="linenos"> 53</span></a>                 <span class="n">k_v_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="CokeBertConfig-54"><a href="#CokeBertConfig-54"><span class="linenos"> 54</span></a>                 <span class="n">q_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="CokeBertConfig-55"><a href="#CokeBertConfig-55"><span class="linenos"> 55</span></a>                 <span class="n">dk_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="CokeBertConfig-56"><a href="#CokeBertConfig-56"><span class="linenos"> 56</span></a>        <span class="sd">&quot;&quot;&quot;Constructs CokeBertConfig.</span>
</span><span id="CokeBertConfig-57"><a href="#CokeBertConfig-57"><span class="linenos"> 57</span></a>
</span><span id="CokeBertConfig-58"><a href="#CokeBertConfig-58"><span class="linenos"> 58</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertConfig-59"><a href="#CokeBertConfig-59"><span class="linenos"> 59</span></a><span class="sd">            vocab_size (int): Vocabulary size of `inputs_ids` in `CokeBertModel`.</span>
</span><span id="CokeBertConfig-60"><a href="#CokeBertConfig-60"><span class="linenos"> 60</span></a><span class="sd">            hidden_size (int): Size of the encoder layers and the pooler layer.</span>
</span><span id="CokeBertConfig-61"><a href="#CokeBertConfig-61"><span class="linenos"> 61</span></a><span class="sd">            num_hidden_layers (int): Number of hidden layers in the Transformer encoder.</span>
</span><span id="CokeBertConfig-62"><a href="#CokeBertConfig-62"><span class="linenos"> 62</span></a><span class="sd">            num_attention_heads (int): Number of attention heads for each attention layer in</span>
</span><span id="CokeBertConfig-63"><a href="#CokeBertConfig-63"><span class="linenos"> 63</span></a><span class="sd">                the Transformer encoder.</span>
</span><span id="CokeBertConfig-64"><a href="#CokeBertConfig-64"><span class="linenos"> 64</span></a><span class="sd">            intermediate_size (int): The size of the &quot;intermediate&quot; (i.e., feed-forward)</span>
</span><span id="CokeBertConfig-65"><a href="#CokeBertConfig-65"><span class="linenos"> 65</span></a><span class="sd">                layer in the Transformer encoder.</span>
</span><span id="CokeBertConfig-66"><a href="#CokeBertConfig-66"><span class="linenos"> 66</span></a><span class="sd">            hidden_act: The non-linear activation function (function or string) in the</span>
</span><span id="CokeBertConfig-67"><a href="#CokeBertConfig-67"><span class="linenos"> 67</span></a><span class="sd">                encoder and pooler. If string, &quot;gelu&quot;, &quot;relu&quot; and &quot;swish&quot; are supported.</span>
</span><span id="CokeBertConfig-68"><a href="#CokeBertConfig-68"><span class="linenos"> 68</span></a><span class="sd">            hidden_dropout_prob (int): The dropout probabilitiy for all fully connected</span>
</span><span id="CokeBertConfig-69"><a href="#CokeBertConfig-69"><span class="linenos"> 69</span></a><span class="sd">                layers in the embeddings, encoder, and pooler.</span>
</span><span id="CokeBertConfig-70"><a href="#CokeBertConfig-70"><span class="linenos"> 70</span></a><span class="sd">            attention_probs_dropout_prob (float): The dropout ratio for the attention</span>
</span><span id="CokeBertConfig-71"><a href="#CokeBertConfig-71"><span class="linenos"> 71</span></a><span class="sd">                probabilities.</span>
</span><span id="CokeBertConfig-72"><a href="#CokeBertConfig-72"><span class="linenos"> 72</span></a><span class="sd">            max_position_embeddings (int): The maximum sequence length that this model might</span>
</span><span id="CokeBertConfig-73"><a href="#CokeBertConfig-73"><span class="linenos"> 73</span></a><span class="sd">                ever be used with. Typically set this to something large just in case</span>
</span><span id="CokeBertConfig-74"><a href="#CokeBertConfig-74"><span class="linenos"> 74</span></a><span class="sd">                (e.g., 512 or 1024 or 2048).</span>
</span><span id="CokeBertConfig-75"><a href="#CokeBertConfig-75"><span class="linenos"> 75</span></a><span class="sd">            type_vocab_size (int): The vocabulary size of the `token_type_ids` passed into</span>
</span><span id="CokeBertConfig-76"><a href="#CokeBertConfig-76"><span class="linenos"> 76</span></a><span class="sd">                `CokeBertModel`.</span>
</span><span id="CokeBertConfig-77"><a href="#CokeBertConfig-77"><span class="linenos"> 77</span></a><span class="sd">            initializer_range (float): The sttdev of the truncated_normal_initializer for</span>
</span><span id="CokeBertConfig-78"><a href="#CokeBertConfig-78"><span class="linenos"> 78</span></a><span class="sd">                initializing all weight matrices.</span>
</span><span id="CokeBertConfig-79"><a href="#CokeBertConfig-79"><span class="linenos"> 79</span></a><span class="sd">            layer_types (list): list of `ErnieLayer`s which can be &#39;sim&#39; (Bert encoder), </span>
</span><span id="CokeBertConfig-80"><a href="#CokeBertConfig-80"><span class="linenos"> 80</span></a><span class="sd">                &#39;mix&#39; (Ernie encoder but no multihead attention for entites) or &#39;norm&#39; (standard Ernie encoder)</span>
</span><span id="CokeBertConfig-81"><a href="#CokeBertConfig-81"><span class="linenos"> 81</span></a><span class="sd">            k_v_dim (int): Size of the hidden knowledge representation in the dynamic knowledge encoder</span>
</span><span id="CokeBertConfig-82"><a href="#CokeBertConfig-82"><span class="linenos"> 82</span></a><span class="sd">            q_dim (int): Size of the hidden text representation in the dynamic knowledge encoder</span>
</span><span id="CokeBertConfig-83"><a href="#CokeBertConfig-83"><span class="linenos"> 83</span></a><span class="sd">            dk_layers (int): Number of layers in the dynamic knowledge encoder</span>
</span><span id="CokeBertConfig-84"><a href="#CokeBertConfig-84"><span class="linenos"> 84</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig-85"><a href="#CokeBertConfig-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span><span id="CokeBertConfig-86"><a href="#CokeBertConfig-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
</span><span id="CokeBertConfig-87"><a href="#CokeBertConfig-87"><span class="linenos"> 87</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">entity_size</span>
</span><span id="CokeBertConfig-88"><a href="#CokeBertConfig-88"><span class="linenos"> 88</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
</span><span id="CokeBertConfig-89"><a href="#CokeBertConfig-89"><span class="linenos"> 89</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
</span><span id="CokeBertConfig-90"><a href="#CokeBertConfig-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads_ent</span> <span class="o">=</span> <span class="n">num_attention_heads_ent</span>
</span><span id="CokeBertConfig-91"><a href="#CokeBertConfig-91"><span class="linenos"> 91</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span> <span class="c1">#Stores a string</span>
</span><span id="CokeBertConfig-92"><a href="#CokeBertConfig-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
</span><span id="CokeBertConfig-93"><a href="#CokeBertConfig-93"><span class="linenos"> 93</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dropout_prob</span> <span class="o">=</span> <span class="n">hidden_dropout_prob</span>
</span><span id="CokeBertConfig-94"><a href="#CokeBertConfig-94"><span class="linenos"> 94</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span> <span class="o">=</span> <span class="n">attention_probs_dropout_prob</span>
</span><span id="CokeBertConfig-95"><a href="#CokeBertConfig-95"><span class="linenos"> 95</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
</span><span id="CokeBertConfig-96"><a href="#CokeBertConfig-96"><span class="linenos"> 96</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_vocab_size</span> <span class="o">=</span> <span class="n">type_vocab_size</span>
</span><span id="CokeBertConfig-97"><a href="#CokeBertConfig-97"><span class="linenos"> 97</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</span><span id="CokeBertConfig-98"><a href="#CokeBertConfig-98"><span class="linenos"> 98</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="n">layer_types</span>
</span><span id="CokeBertConfig-99"><a href="#CokeBertConfig-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">k_v_dim</span>
</span><span id="CokeBertConfig-100"><a href="#CokeBertConfig-100"><span class="linenos">100</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">q_dim</span> <span class="o">=</span> <span class="n">q_dim</span>
</span><span id="CokeBertConfig-101"><a href="#CokeBertConfig-101"><span class="linenos">101</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dk_layers</span> <span class="o">=</span> <span class="n">dk_layers</span>
</span><span id="CokeBertConfig-102"><a href="#CokeBertConfig-102"><span class="linenos">102</span></a>       
</span><span id="CokeBertConfig-103"><a href="#CokeBertConfig-103"><span class="linenos">103</span></a>    <span class="nd">@classmethod</span>
</span><span id="CokeBertConfig-104"><a href="#CokeBertConfig-104"><span class="linenos">104</span></a>    <span class="k">def</span> <span class="nf">load_from_json</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span><span class="n">path</span><span class="p">):</span>
</span><span id="CokeBertConfig-105"><a href="#CokeBertConfig-105"><span class="linenos">105</span></a>        <span class="sd">&quot;&quot;&quot;Loads config from json file</span>
</span><span id="CokeBertConfig-106"><a href="#CokeBertConfig-106"><span class="linenos">106</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig-107"><a href="#CokeBertConfig-107"><span class="linenos">107</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertConfig-108"><a href="#CokeBertConfig-108"><span class="linenos">108</span></a><span class="sd">            cls: current CokeBertConfig Class</span>
</span><span id="CokeBertConfig-109"><a href="#CokeBertConfig-109"><span class="linenos">109</span></a><span class="sd">            path (str): path to config.json file</span>
</span><span id="CokeBertConfig-110"><a href="#CokeBertConfig-110"><span class="linenos">110</span></a>
</span><span id="CokeBertConfig-111"><a href="#CokeBertConfig-111"><span class="linenos">111</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig-112"><a href="#CokeBertConfig-112"><span class="linenos">112</span></a><span class="sd">            config: Loaded CokeBertConfig</span>
</span><span id="CokeBertConfig-113"><a href="#CokeBertConfig-113"><span class="linenos">113</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig-114"><a href="#CokeBertConfig-114"><span class="linenos">114</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="c1">#Create default config</span>
</span><span id="CokeBertConfig-115"><a href="#CokeBertConfig-115"><span class="linenos">115</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
</span><span id="CokeBertConfig-116"><a href="#CokeBertConfig-116"><span class="linenos">116</span></a>            <span class="n">json_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span id="CokeBertConfig-117"><a href="#CokeBertConfig-117"><span class="linenos">117</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">json_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="CokeBertConfig-118"><a href="#CokeBertConfig-118"><span class="linenos">118</span></a>                <span class="n">config</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="CokeBertConfig-119"><a href="#CokeBertConfig-119"><span class="linenos">119</span></a>        <span class="k">return</span> <span class="n">config</span>
</span><span id="CokeBertConfig-120"><a href="#CokeBertConfig-120"><span class="linenos">120</span></a>
</span><span id="CokeBertConfig-121"><a href="#CokeBertConfig-121"><span class="linenos">121</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig-122"><a href="#CokeBertConfig-122"><span class="linenos">122</span></a>        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_json_string</span><span class="p">())</span>
</span><span id="CokeBertConfig-123"><a href="#CokeBertConfig-123"><span class="linenos">123</span></a>
</span><span id="CokeBertConfig-124"><a href="#CokeBertConfig-124"><span class="linenos">124</span></a>    <span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig-125"><a href="#CokeBertConfig-125"><span class="linenos">125</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a JSON string.</span>
</span><span id="CokeBertConfig-126"><a href="#CokeBertConfig-126"><span class="linenos">126</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig-127"><a href="#CokeBertConfig-127"><span class="linenos">127</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig-128"><a href="#CokeBertConfig-128"><span class="linenos">128</span></a><span class="sd">            JSON-String of Config</span>
</span><span id="CokeBertConfig-129"><a href="#CokeBertConfig-129"><span class="linenos">129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig-130"><a href="#CokeBertConfig-130"><span class="linenos">130</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="CokeBertConfig-131"><a href="#CokeBertConfig-131"><span class="linenos">131</span></a>        
</span><span id="CokeBertConfig-132"><a href="#CokeBertConfig-132"><span class="linenos">132</span></a>    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig-133"><a href="#CokeBertConfig-133"><span class="linenos">133</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a Python dictionary.</span>
</span><span id="CokeBertConfig-134"><a href="#CokeBertConfig-134"><span class="linenos">134</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig-135"><a href="#CokeBertConfig-135"><span class="linenos">135</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig-136"><a href="#CokeBertConfig-136"><span class="linenos">136</span></a><span class="sd">            output: Python dictionary of Config</span>
</span><span id="CokeBertConfig-137"><a href="#CokeBertConfig-137"><span class="linenos">137</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig-138"><a href="#CokeBertConfig-138"><span class="linenos">138</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</span><span id="CokeBertConfig-139"><a href="#CokeBertConfig-139"><span class="linenos">139</span></a>        <span class="k">return</span> <span class="n">output</span>
</span><span id="CokeBertConfig-140"><a href="#CokeBertConfig-140"><span class="linenos">140</span></a>
</span><span id="CokeBertConfig-141"><a href="#CokeBertConfig-141"><span class="linenos">141</span></a>    <span class="k">def</span> <span class="nf">to_text_encoder_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig-142"><a href="#CokeBertConfig-142"><span class="linenos">142</span></a>        <span class="sd">&quot;&quot;&quot;Splits Config to create `ErnieEncoder` as TextEncoder</span>
</span><span id="CokeBertConfig-143"><a href="#CokeBertConfig-143"><span class="linenos">143</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig-144"><a href="#CokeBertConfig-144"><span class="linenos">144</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig-145"><a href="#CokeBertConfig-145"><span class="linenos">145</span></a><span class="sd">            CokeBertConfig for TextEncoder</span>
</span><span id="CokeBertConfig-146"><a href="#CokeBertConfig-146"><span class="linenos">146</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig-147"><a href="#CokeBertConfig-147"><span class="linenos">147</span></a>        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</span><span id="CokeBertConfig-148"><a href="#CokeBertConfig-148"><span class="linenos">148</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;sim&#39;</span><span class="p">]</span>
</span><span id="CokeBertConfig-149"><a href="#CokeBertConfig-149"><span class="linenos">149</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">])</span>
</span><span id="CokeBertConfig-150"><a href="#CokeBertConfig-150"><span class="linenos">150</span></a>        <span class="k">return</span> <span class="n">CokeBertConfig</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span><span id="CokeBertConfig-151"><a href="#CokeBertConfig-151"><span class="linenos">151</span></a>
</span><span id="CokeBertConfig-152"><a href="#CokeBertConfig-152"><span class="linenos">152</span></a>    <span class="k">def</span> <span class="nf">to_knowl_encoder_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig-153"><a href="#CokeBertConfig-153"><span class="linenos">153</span></a>        <span class="sd">&quot;&quot;&quot;Splits Config to create `ErnieEncoder` as KnowledgeEncoder</span>
</span><span id="CokeBertConfig-154"><a href="#CokeBertConfig-154"><span class="linenos">154</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig-155"><a href="#CokeBertConfig-155"><span class="linenos">155</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig-156"><a href="#CokeBertConfig-156"><span class="linenos">156</span></a><span class="sd">            CokeBertConfig for KnowledgeEncoder</span>
</span><span id="CokeBertConfig-157"><a href="#CokeBertConfig-157"><span class="linenos">157</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig-158"><a href="#CokeBertConfig-158"><span class="linenos">158</span></a>        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</span><span id="CokeBertConfig-159"><a href="#CokeBertConfig-159"><span class="linenos">159</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;sim&#39;</span><span class="p">]</span>
</span><span id="CokeBertConfig-160"><a href="#CokeBertConfig-160"><span class="linenos">160</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">])</span>
</span><span id="CokeBertConfig-161"><a href="#CokeBertConfig-161"><span class="linenos">161</span></a>        <span class="k">return</span> <span class="n">CokeBertConfig</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Configuration class to store the configuration of a <code><a href="#CokeBertModel">CokeBertModel</a></code>.</p>
</div>


                            <div id="CokeBertConfig.__init__" class="classattr">
                                        <input id="CokeBertConfig.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">CokeBertConfig</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">vocab_size</span>,</span><span class="param">	<span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span>,</span><span class="param">	<span class="n">entity_size</span><span class="o">=</span><span class="mi">200</span>,</span><span class="param">	<span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span>,</span><span class="param">	<span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span>,</span><span class="param">	<span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span>,</span><span class="param">	<span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span>,</span><span class="param">	<span class="n">hidden_act</span><span class="o">=</span><span class="s1">&#39;gelu&#39;</span>,</span><span class="param">	<span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span>,</span><span class="param">	<span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span>,</span><span class="param">	<span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span>,</span><span class="param">	<span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span>,</span><span class="param">	<span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span>,</span><span class="param">	<span class="n">layer_types</span><span class="o">=</span><span class="p">[]</span>,</span><span class="param">	<span class="n">k_v_dim</span><span class="o">=</span><span class="mi">100</span>,</span><span class="param">	<span class="n">q_dim</span><span class="o">=</span><span class="mi">768</span>,</span><span class="param">	<span class="n">dk_layers</span><span class="o">=</span><span class="mi">2</span></span>)</span>

                <label class="view-source-button" for="CokeBertConfig.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertConfig.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertConfig.__init__-38"><a href="#CokeBertConfig.__init__-38"><span class="linenos"> 38</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-39"><a href="#CokeBertConfig.__init__-39"><span class="linenos"> 39</span></a>                 <span class="n">vocab_size</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-40"><a href="#CokeBertConfig.__init__-40"><span class="linenos"> 40</span></a>                 <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-41"><a href="#CokeBertConfig.__init__-41"><span class="linenos"> 41</span></a>                 <span class="n">entity_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-42"><a href="#CokeBertConfig.__init__-42"><span class="linenos"> 42</span></a>                 <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-43"><a href="#CokeBertConfig.__init__-43"><span class="linenos"> 43</span></a>                 <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-44"><a href="#CokeBertConfig.__init__-44"><span class="linenos"> 44</span></a>                 <span class="n">num_attention_heads_ent</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-45"><a href="#CokeBertConfig.__init__-45"><span class="linenos"> 45</span></a>                 <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-46"><a href="#CokeBertConfig.__init__-46"><span class="linenos"> 46</span></a>                 <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-47"><a href="#CokeBertConfig.__init__-47"><span class="linenos"> 47</span></a>                 <span class="n">hidden_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-48"><a href="#CokeBertConfig.__init__-48"><span class="linenos"> 48</span></a>                 <span class="n">attention_probs_dropout_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-49"><a href="#CokeBertConfig.__init__-49"><span class="linenos"> 49</span></a>                 <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-50"><a href="#CokeBertConfig.__init__-50"><span class="linenos"> 50</span></a>                 <span class="n">type_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-51"><a href="#CokeBertConfig.__init__-51"><span class="linenos"> 51</span></a>                 <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-52"><a href="#CokeBertConfig.__init__-52"><span class="linenos"> 52</span></a>                 <span class="n">layer_types</span><span class="o">=</span><span class="p">[],</span>
</span><span id="CokeBertConfig.__init__-53"><a href="#CokeBertConfig.__init__-53"><span class="linenos"> 53</span></a>                 <span class="n">k_v_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-54"><a href="#CokeBertConfig.__init__-54"><span class="linenos"> 54</span></a>                 <span class="n">q_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
</span><span id="CokeBertConfig.__init__-55"><a href="#CokeBertConfig.__init__-55"><span class="linenos"> 55</span></a>                 <span class="n">dk_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="CokeBertConfig.__init__-56"><a href="#CokeBertConfig.__init__-56"><span class="linenos"> 56</span></a>        <span class="sd">&quot;&quot;&quot;Constructs CokeBertConfig.</span>
</span><span id="CokeBertConfig.__init__-57"><a href="#CokeBertConfig.__init__-57"><span class="linenos"> 57</span></a>
</span><span id="CokeBertConfig.__init__-58"><a href="#CokeBertConfig.__init__-58"><span class="linenos"> 58</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertConfig.__init__-59"><a href="#CokeBertConfig.__init__-59"><span class="linenos"> 59</span></a><span class="sd">            vocab_size (int): Vocabulary size of `inputs_ids` in `CokeBertModel`.</span>
</span><span id="CokeBertConfig.__init__-60"><a href="#CokeBertConfig.__init__-60"><span class="linenos"> 60</span></a><span class="sd">            hidden_size (int): Size of the encoder layers and the pooler layer.</span>
</span><span id="CokeBertConfig.__init__-61"><a href="#CokeBertConfig.__init__-61"><span class="linenos"> 61</span></a><span class="sd">            num_hidden_layers (int): Number of hidden layers in the Transformer encoder.</span>
</span><span id="CokeBertConfig.__init__-62"><a href="#CokeBertConfig.__init__-62"><span class="linenos"> 62</span></a><span class="sd">            num_attention_heads (int): Number of attention heads for each attention layer in</span>
</span><span id="CokeBertConfig.__init__-63"><a href="#CokeBertConfig.__init__-63"><span class="linenos"> 63</span></a><span class="sd">                the Transformer encoder.</span>
</span><span id="CokeBertConfig.__init__-64"><a href="#CokeBertConfig.__init__-64"><span class="linenos"> 64</span></a><span class="sd">            intermediate_size (int): The size of the &quot;intermediate&quot; (i.e., feed-forward)</span>
</span><span id="CokeBertConfig.__init__-65"><a href="#CokeBertConfig.__init__-65"><span class="linenos"> 65</span></a><span class="sd">                layer in the Transformer encoder.</span>
</span><span id="CokeBertConfig.__init__-66"><a href="#CokeBertConfig.__init__-66"><span class="linenos"> 66</span></a><span class="sd">            hidden_act: The non-linear activation function (function or string) in the</span>
</span><span id="CokeBertConfig.__init__-67"><a href="#CokeBertConfig.__init__-67"><span class="linenos"> 67</span></a><span class="sd">                encoder and pooler. If string, &quot;gelu&quot;, &quot;relu&quot; and &quot;swish&quot; are supported.</span>
</span><span id="CokeBertConfig.__init__-68"><a href="#CokeBertConfig.__init__-68"><span class="linenos"> 68</span></a><span class="sd">            hidden_dropout_prob (int): The dropout probabilitiy for all fully connected</span>
</span><span id="CokeBertConfig.__init__-69"><a href="#CokeBertConfig.__init__-69"><span class="linenos"> 69</span></a><span class="sd">                layers in the embeddings, encoder, and pooler.</span>
</span><span id="CokeBertConfig.__init__-70"><a href="#CokeBertConfig.__init__-70"><span class="linenos"> 70</span></a><span class="sd">            attention_probs_dropout_prob (float): The dropout ratio for the attention</span>
</span><span id="CokeBertConfig.__init__-71"><a href="#CokeBertConfig.__init__-71"><span class="linenos"> 71</span></a><span class="sd">                probabilities.</span>
</span><span id="CokeBertConfig.__init__-72"><a href="#CokeBertConfig.__init__-72"><span class="linenos"> 72</span></a><span class="sd">            max_position_embeddings (int): The maximum sequence length that this model might</span>
</span><span id="CokeBertConfig.__init__-73"><a href="#CokeBertConfig.__init__-73"><span class="linenos"> 73</span></a><span class="sd">                ever be used with. Typically set this to something large just in case</span>
</span><span id="CokeBertConfig.__init__-74"><a href="#CokeBertConfig.__init__-74"><span class="linenos"> 74</span></a><span class="sd">                (e.g., 512 or 1024 or 2048).</span>
</span><span id="CokeBertConfig.__init__-75"><a href="#CokeBertConfig.__init__-75"><span class="linenos"> 75</span></a><span class="sd">            type_vocab_size (int): The vocabulary size of the `token_type_ids` passed into</span>
</span><span id="CokeBertConfig.__init__-76"><a href="#CokeBertConfig.__init__-76"><span class="linenos"> 76</span></a><span class="sd">                `CokeBertModel`.</span>
</span><span id="CokeBertConfig.__init__-77"><a href="#CokeBertConfig.__init__-77"><span class="linenos"> 77</span></a><span class="sd">            initializer_range (float): The sttdev of the truncated_normal_initializer for</span>
</span><span id="CokeBertConfig.__init__-78"><a href="#CokeBertConfig.__init__-78"><span class="linenos"> 78</span></a><span class="sd">                initializing all weight matrices.</span>
</span><span id="CokeBertConfig.__init__-79"><a href="#CokeBertConfig.__init__-79"><span class="linenos"> 79</span></a><span class="sd">            layer_types (list): list of `ErnieLayer`s which can be &#39;sim&#39; (Bert encoder), </span>
</span><span id="CokeBertConfig.__init__-80"><a href="#CokeBertConfig.__init__-80"><span class="linenos"> 80</span></a><span class="sd">                &#39;mix&#39; (Ernie encoder but no multihead attention for entites) or &#39;norm&#39; (standard Ernie encoder)</span>
</span><span id="CokeBertConfig.__init__-81"><a href="#CokeBertConfig.__init__-81"><span class="linenos"> 81</span></a><span class="sd">            k_v_dim (int): Size of the hidden knowledge representation in the dynamic knowledge encoder</span>
</span><span id="CokeBertConfig.__init__-82"><a href="#CokeBertConfig.__init__-82"><span class="linenos"> 82</span></a><span class="sd">            q_dim (int): Size of the hidden text representation in the dynamic knowledge encoder</span>
</span><span id="CokeBertConfig.__init__-83"><a href="#CokeBertConfig.__init__-83"><span class="linenos"> 83</span></a><span class="sd">            dk_layers (int): Number of layers in the dynamic knowledge encoder</span>
</span><span id="CokeBertConfig.__init__-84"><a href="#CokeBertConfig.__init__-84"><span class="linenos"> 84</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig.__init__-85"><a href="#CokeBertConfig.__init__-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span><span id="CokeBertConfig.__init__-86"><a href="#CokeBertConfig.__init__-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
</span><span id="CokeBertConfig.__init__-87"><a href="#CokeBertConfig.__init__-87"><span class="linenos"> 87</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">entity_size</span>
</span><span id="CokeBertConfig.__init__-88"><a href="#CokeBertConfig.__init__-88"><span class="linenos"> 88</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
</span><span id="CokeBertConfig.__init__-89"><a href="#CokeBertConfig.__init__-89"><span class="linenos"> 89</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
</span><span id="CokeBertConfig.__init__-90"><a href="#CokeBertConfig.__init__-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads_ent</span> <span class="o">=</span> <span class="n">num_attention_heads_ent</span>
</span><span id="CokeBertConfig.__init__-91"><a href="#CokeBertConfig.__init__-91"><span class="linenos"> 91</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span> <span class="c1">#Stores a string</span>
</span><span id="CokeBertConfig.__init__-92"><a href="#CokeBertConfig.__init__-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
</span><span id="CokeBertConfig.__init__-93"><a href="#CokeBertConfig.__init__-93"><span class="linenos"> 93</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dropout_prob</span> <span class="o">=</span> <span class="n">hidden_dropout_prob</span>
</span><span id="CokeBertConfig.__init__-94"><a href="#CokeBertConfig.__init__-94"><span class="linenos"> 94</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_probs_dropout_prob</span> <span class="o">=</span> <span class="n">attention_probs_dropout_prob</span>
</span><span id="CokeBertConfig.__init__-95"><a href="#CokeBertConfig.__init__-95"><span class="linenos"> 95</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
</span><span id="CokeBertConfig.__init__-96"><a href="#CokeBertConfig.__init__-96"><span class="linenos"> 96</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_vocab_size</span> <span class="o">=</span> <span class="n">type_vocab_size</span>
</span><span id="CokeBertConfig.__init__-97"><a href="#CokeBertConfig.__init__-97"><span class="linenos"> 97</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</span><span id="CokeBertConfig.__init__-98"><a href="#CokeBertConfig.__init__-98"><span class="linenos"> 98</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="n">layer_types</span>
</span><span id="CokeBertConfig.__init__-99"><a href="#CokeBertConfig.__init__-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">k_v_dim</span>
</span><span id="CokeBertConfig.__init__-100"><a href="#CokeBertConfig.__init__-100"><span class="linenos">100</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">q_dim</span> <span class="o">=</span> <span class="n">q_dim</span>
</span><span id="CokeBertConfig.__init__-101"><a href="#CokeBertConfig.__init__-101"><span class="linenos">101</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dk_layers</span> <span class="o">=</span> <span class="n">dk_layers</span>
</span></pre></div>


            <div class="docstring"><p>Constructs CokeBertConfig.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>vocab_size (int):</strong>  Vocabulary size of <code>inputs_ids</code> in <code><a href="#CokeBertModel">CokeBertModel</a></code>.</li>
<li><strong>hidden_size (int):</strong>  Size of the encoder layers and the pooler layer.</li>
<li><strong>num_hidden_layers (int):</strong>  Number of hidden layers in the Transformer encoder.</li>
<li><strong>num_attention_heads (int):</strong>  Number of attention heads for each attention layer in
the Transformer encoder.</li>
<li><strong>intermediate_size (int):</strong>  The size of the "intermediate" (i.e., feed-forward)
layer in the Transformer encoder.</li>
<li><strong>hidden_act:</strong>  The non-linear activation function (function or string) in the
encoder and pooler. If string, "gelu", "relu" and "swish" are supported.</li>
<li><strong>hidden_dropout_prob (int):</strong>  The dropout probabilitiy for all fully connected
layers in the embeddings, encoder, and pooler.</li>
<li><strong>attention_probs_dropout_prob (float):</strong>  The dropout ratio for the attention
probabilities.</li>
<li><strong>max_position_embeddings (int):</strong>  The maximum sequence length that this model might
ever be used with. Typically set this to something large just in case
(e.g., 512 or 1024 or 2048).</li>
<li><strong>type_vocab_size (int):</strong>  The vocabulary size of the <code>token_type_ids</code> passed into
<code><a href="#CokeBertModel">CokeBertModel</a></code>.</li>
<li><strong>initializer_range (float):</strong>  The sttdev of the truncated_normal_initializer for
initializing all weight matrices.</li>
<li><strong>layer_types (list):</strong>  list of <code>ErnieLayer</code>s which can be 'sim' (Bert encoder), 
'mix' (Ernie encoder but no multihead attention for entites) or 'norm' (standard Ernie encoder)</li>
<li><strong>k_v_dim (int):</strong>  Size of the hidden knowledge representation in the dynamic knowledge encoder</li>
<li><strong>q_dim (int):</strong>  Size of the hidden text representation in the dynamic knowledge encoder</li>
<li><strong>dk_layers (int):</strong>  Number of layers in the dynamic knowledge encoder</li>
</ul>
</div>


                            </div>
                            <div id="CokeBertConfig.load_from_json" class="classattr">
                                        <input id="CokeBertConfig.load_from_json-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">load_from_json</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">path</span></span>)</span>

                <label class="view-source-button" for="CokeBertConfig.load_from_json-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertConfig.load_from_json"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertConfig.load_from_json-103"><a href="#CokeBertConfig.load_from_json-103"><span class="linenos">103</span></a>    <span class="nd">@classmethod</span>
</span><span id="CokeBertConfig.load_from_json-104"><a href="#CokeBertConfig.load_from_json-104"><span class="linenos">104</span></a>    <span class="k">def</span> <span class="nf">load_from_json</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span><span class="n">path</span><span class="p">):</span>
</span><span id="CokeBertConfig.load_from_json-105"><a href="#CokeBertConfig.load_from_json-105"><span class="linenos">105</span></a>        <span class="sd">&quot;&quot;&quot;Loads config from json file</span>
</span><span id="CokeBertConfig.load_from_json-106"><a href="#CokeBertConfig.load_from_json-106"><span class="linenos">106</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig.load_from_json-107"><a href="#CokeBertConfig.load_from_json-107"><span class="linenos">107</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertConfig.load_from_json-108"><a href="#CokeBertConfig.load_from_json-108"><span class="linenos">108</span></a><span class="sd">            cls: current CokeBertConfig Class</span>
</span><span id="CokeBertConfig.load_from_json-109"><a href="#CokeBertConfig.load_from_json-109"><span class="linenos">109</span></a><span class="sd">            path (str): path to config.json file</span>
</span><span id="CokeBertConfig.load_from_json-110"><a href="#CokeBertConfig.load_from_json-110"><span class="linenos">110</span></a>
</span><span id="CokeBertConfig.load_from_json-111"><a href="#CokeBertConfig.load_from_json-111"><span class="linenos">111</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig.load_from_json-112"><a href="#CokeBertConfig.load_from_json-112"><span class="linenos">112</span></a><span class="sd">            config: Loaded CokeBertConfig</span>
</span><span id="CokeBertConfig.load_from_json-113"><a href="#CokeBertConfig.load_from_json-113"><span class="linenos">113</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig.load_from_json-114"><a href="#CokeBertConfig.load_from_json-114"><span class="linenos">114</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="c1">#Create default config</span>
</span><span id="CokeBertConfig.load_from_json-115"><a href="#CokeBertConfig.load_from_json-115"><span class="linenos">115</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
</span><span id="CokeBertConfig.load_from_json-116"><a href="#CokeBertConfig.load_from_json-116"><span class="linenos">116</span></a>            <span class="n">json_config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span><span id="CokeBertConfig.load_from_json-117"><a href="#CokeBertConfig.load_from_json-117"><span class="linenos">117</span></a>            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">json_config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="CokeBertConfig.load_from_json-118"><a href="#CokeBertConfig.load_from_json-118"><span class="linenos">118</span></a>                <span class="n">config</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span><span id="CokeBertConfig.load_from_json-119"><a href="#CokeBertConfig.load_from_json-119"><span class="linenos">119</span></a>        <span class="k">return</span> <span class="n">config</span>
</span></pre></div>


            <div class="docstring"><p>Loads config from json file</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>cls:</strong>  current CokeBertConfig Class</li>
<li><strong>path (str):</strong>  path to config.json file</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>config: Loaded CokeBertConfig</p>
</blockquote>
</div>


                            </div>
                            <div id="CokeBertConfig.to_json_string" class="classattr">
                                        <input id="CokeBertConfig.to_json_string-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_json_string</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span>)</span>

                <label class="view-source-button" for="CokeBertConfig.to_json_string-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertConfig.to_json_string"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertConfig.to_json_string-124"><a href="#CokeBertConfig.to_json_string-124"><span class="linenos">124</span></a>    <span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig.to_json_string-125"><a href="#CokeBertConfig.to_json_string-125"><span class="linenos">125</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a JSON string.</span>
</span><span id="CokeBertConfig.to_json_string-126"><a href="#CokeBertConfig.to_json_string-126"><span class="linenos">126</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig.to_json_string-127"><a href="#CokeBertConfig.to_json_string-127"><span class="linenos">127</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig.to_json_string-128"><a href="#CokeBertConfig.to_json_string-128"><span class="linenos">128</span></a><span class="sd">            JSON-String of Config</span>
</span><span id="CokeBertConfig.to_json_string-129"><a href="#CokeBertConfig.to_json_string-129"><span class="linenos">129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig.to_json_string-130"><a href="#CokeBertConfig.to_json_string-130"><span class="linenos">130</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Serializes this instance to a JSON string.</p>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>JSON-String of Config</p>
</blockquote>
</div>


                            </div>
                            <div id="CokeBertConfig.to_dict" class="classattr">
                                        <input id="CokeBertConfig.to_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_dict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span>)</span>

                <label class="view-source-button" for="CokeBertConfig.to_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertConfig.to_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertConfig.to_dict-132"><a href="#CokeBertConfig.to_dict-132"><span class="linenos">132</span></a>    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig.to_dict-133"><a href="#CokeBertConfig.to_dict-133"><span class="linenos">133</span></a>        <span class="sd">&quot;&quot;&quot;Serializes this instance to a Python dictionary.</span>
</span><span id="CokeBertConfig.to_dict-134"><a href="#CokeBertConfig.to_dict-134"><span class="linenos">134</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig.to_dict-135"><a href="#CokeBertConfig.to_dict-135"><span class="linenos">135</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig.to_dict-136"><a href="#CokeBertConfig.to_dict-136"><span class="linenos">136</span></a><span class="sd">            output: Python dictionary of Config</span>
</span><span id="CokeBertConfig.to_dict-137"><a href="#CokeBertConfig.to_dict-137"><span class="linenos">137</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig.to_dict-138"><a href="#CokeBertConfig.to_dict-138"><span class="linenos">138</span></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
</span><span id="CokeBertConfig.to_dict-139"><a href="#CokeBertConfig.to_dict-139"><span class="linenos">139</span></a>        <span class="k">return</span> <span class="n">output</span>
</span></pre></div>


            <div class="docstring"><p>Serializes this instance to a Python dictionary.</p>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>output: Python dictionary of Config</p>
</blockquote>
</div>


                            </div>
                            <div id="CokeBertConfig.to_text_encoder_config" class="classattr">
                                        <input id="CokeBertConfig.to_text_encoder_config-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_text_encoder_config</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span>)</span>

                <label class="view-source-button" for="CokeBertConfig.to_text_encoder_config-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertConfig.to_text_encoder_config"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertConfig.to_text_encoder_config-141"><a href="#CokeBertConfig.to_text_encoder_config-141"><span class="linenos">141</span></a>    <span class="k">def</span> <span class="nf">to_text_encoder_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig.to_text_encoder_config-142"><a href="#CokeBertConfig.to_text_encoder_config-142"><span class="linenos">142</span></a>        <span class="sd">&quot;&quot;&quot;Splits Config to create `ErnieEncoder` as TextEncoder</span>
</span><span id="CokeBertConfig.to_text_encoder_config-143"><a href="#CokeBertConfig.to_text_encoder_config-143"><span class="linenos">143</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig.to_text_encoder_config-144"><a href="#CokeBertConfig.to_text_encoder_config-144"><span class="linenos">144</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig.to_text_encoder_config-145"><a href="#CokeBertConfig.to_text_encoder_config-145"><span class="linenos">145</span></a><span class="sd">            CokeBertConfig for TextEncoder</span>
</span><span id="CokeBertConfig.to_text_encoder_config-146"><a href="#CokeBertConfig.to_text_encoder_config-146"><span class="linenos">146</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig.to_text_encoder_config-147"><a href="#CokeBertConfig.to_text_encoder_config-147"><span class="linenos">147</span></a>        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</span><span id="CokeBertConfig.to_text_encoder_config-148"><a href="#CokeBertConfig.to_text_encoder_config-148"><span class="linenos">148</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;sim&#39;</span><span class="p">]</span>
</span><span id="CokeBertConfig.to_text_encoder_config-149"><a href="#CokeBertConfig.to_text_encoder_config-149"><span class="linenos">149</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">])</span>
</span><span id="CokeBertConfig.to_text_encoder_config-150"><a href="#CokeBertConfig.to_text_encoder_config-150"><span class="linenos">150</span></a>        <span class="k">return</span> <span class="n">CokeBertConfig</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Splits Config to create <code>ErnieEncoder</code> as TextEncoder</p>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>CokeBertConfig for TextEncoder</p>
</blockquote>
</div>


                            </div>
                            <div id="CokeBertConfig.to_knowl_encoder_config" class="classattr">
                                        <input id="CokeBertConfig.to_knowl_encoder_config-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_knowl_encoder_config</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span>)</span>

                <label class="view-source-button" for="CokeBertConfig.to_knowl_encoder_config-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertConfig.to_knowl_encoder_config"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertConfig.to_knowl_encoder_config-152"><a href="#CokeBertConfig.to_knowl_encoder_config-152"><span class="linenos">152</span></a>    <span class="k">def</span> <span class="nf">to_knowl_encoder_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-153"><a href="#CokeBertConfig.to_knowl_encoder_config-153"><span class="linenos">153</span></a>        <span class="sd">&quot;&quot;&quot;Splits Config to create `ErnieEncoder` as KnowledgeEncoder</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-154"><a href="#CokeBertConfig.to_knowl_encoder_config-154"><span class="linenos">154</span></a><span class="sd">        </span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-155"><a href="#CokeBertConfig.to_knowl_encoder_config-155"><span class="linenos">155</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-156"><a href="#CokeBertConfig.to_knowl_encoder_config-156"><span class="linenos">156</span></a><span class="sd">            CokeBertConfig for KnowledgeEncoder</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-157"><a href="#CokeBertConfig.to_knowl_encoder_config-157"><span class="linenos">157</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-158"><a href="#CokeBertConfig.to_knowl_encoder_config-158"><span class="linenos">158</span></a>        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-159"><a href="#CokeBertConfig.to_knowl_encoder_config-159"><span class="linenos">159</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;sim&#39;</span><span class="p">]</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-160"><a href="#CokeBertConfig.to_knowl_encoder_config-160"><span class="linenos">160</span></a>        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;num_hidden_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;layer_types&#39;</span><span class="p">])</span>
</span><span id="CokeBertConfig.to_knowl_encoder_config-161"><a href="#CokeBertConfig.to_knowl_encoder_config-161"><span class="linenos">161</span></a>        <span class="k">return</span> <span class="n">CokeBertConfig</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Splits Config to create <code>ErnieEncoder</code> as KnowledgeEncoder</p>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>CokeBertConfig for KnowledgeEncoder</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="PreTrainedCokeBertModel">
                            <input id="PreTrainedCokeBertModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PreTrainedCokeBertModel</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="PreTrainedCokeBertModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedCokeBertModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedCokeBertModel-163"><a href="#PreTrainedCokeBertModel-163"><span class="linenos">163</span></a><span class="k">class</span> <span class="nc">PreTrainedCokeBertModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-164"><a href="#PreTrainedCokeBertModel-164"><span class="linenos">164</span></a>    <span class="sd">&quot;&quot;&quot; An abstract class to handle weights initialization and</span>
</span><span id="PreTrainedCokeBertModel-165"><a href="#PreTrainedCokeBertModel-165"><span class="linenos">165</span></a><span class="sd">        a simple interface for downloading and loading pretrained models.</span>
</span><span id="PreTrainedCokeBertModel-166"><a href="#PreTrainedCokeBertModel-166"><span class="linenos">166</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel-167"><a href="#PreTrainedCokeBertModel-167"><span class="linenos">167</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-168"><a href="#PreTrainedCokeBertModel-168"><span class="linenos">168</span></a>        <span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel-169"><a href="#PreTrainedCokeBertModel-169"><span class="linenos">169</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="PreTrainedCokeBertModel-170"><a href="#PreTrainedCokeBertModel-170"><span class="linenos">170</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">CokeBertConfig</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-171"><a href="#PreTrainedCokeBertModel-171"><span class="linenos">171</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="PreTrainedCokeBertModel-172"><a href="#PreTrainedCokeBertModel-172"><span class="linenos">172</span></a>                <span class="s2">&quot;Parameter config in `</span><span class="si">{}</span><span class="s2">(config)` should be an instance of class `CokeBertConfig`. &quot;</span>
</span><span id="PreTrainedCokeBertModel-173"><a href="#PreTrainedCokeBertModel-173"><span class="linenos">173</span></a>                <span class="s2">&quot;To create a model from a Google pretrained model use &quot;</span>
</span><span id="PreTrainedCokeBertModel-174"><a href="#PreTrainedCokeBertModel-174"><span class="linenos">174</span></a>                <span class="s2">&quot;`model = </span><span class="si">{}</span><span class="s2">.from_pretrained(PRETRAINED_MODEL_NAME)`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="PreTrainedCokeBertModel-175"><a href="#PreTrainedCokeBertModel-175"><span class="linenos">175</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="PreTrainedCokeBertModel-176"><a href="#PreTrainedCokeBertModel-176"><span class="linenos">176</span></a>                <span class="p">))</span>
</span><span id="PreTrainedCokeBertModel-177"><a href="#PreTrainedCokeBertModel-177"><span class="linenos">177</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="PreTrainedCokeBertModel-178"><a href="#PreTrainedCokeBertModel-178"><span class="linenos">178</span></a>
</span><span id="PreTrainedCokeBertModel-179"><a href="#PreTrainedCokeBertModel-179"><span class="linenos">179</span></a>    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-180"><a href="#PreTrainedCokeBertModel-180"><span class="linenos">180</span></a>        <span class="sd">&quot;&quot;&quot; Initialize the weights.</span>
</span><span id="PreTrainedCokeBertModel-181"><a href="#PreTrainedCokeBertModel-181"><span class="linenos">181</span></a>
</span><span id="PreTrainedCokeBertModel-182"><a href="#PreTrainedCokeBertModel-182"><span class="linenos">182</span></a><span class="sd">        Args:</span>
</span><span id="PreTrainedCokeBertModel-183"><a href="#PreTrainedCokeBertModel-183"><span class="linenos">183</span></a><span class="sd">            module: one of `nn.Linear`, `nn.Embedding`, `LayerNorm`, module to initialize weights of</span>
</span><span id="PreTrainedCokeBertModel-184"><a href="#PreTrainedCokeBertModel-184"><span class="linenos">184</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel-185"><a href="#PreTrainedCokeBertModel-185"><span class="linenos">185</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
</span><span id="PreTrainedCokeBertModel-186"><a href="#PreTrainedCokeBertModel-186"><span class="linenos">186</span></a>            <span class="c1"># Slightly different from the TF version which uses truncated_normal for initialization</span>
</span><span id="PreTrainedCokeBertModel-187"><a href="#PreTrainedCokeBertModel-187"><span class="linenos">187</span></a>            <span class="c1"># cf https://github.com/pytorch/pytorch/pull/5617</span>
</span><span id="PreTrainedCokeBertModel-188"><a href="#PreTrainedCokeBertModel-188"><span class="linenos">188</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-189"><a href="#PreTrainedCokeBertModel-189"><span class="linenos">189</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-190"><a href="#PreTrainedCokeBertModel-190"><span class="linenos">190</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span><span id="PreTrainedCokeBertModel-191"><a href="#PreTrainedCokeBertModel-191"><span class="linenos">191</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-192"><a href="#PreTrainedCokeBertModel-192"><span class="linenos">192</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel-193"><a href="#PreTrainedCokeBertModel-193"><span class="linenos">193</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span><span id="PreTrainedCokeBertModel-194"><a href="#PreTrainedCokeBertModel-194"><span class="linenos">194</span></a>
</span><span id="PreTrainedCokeBertModel-195"><a href="#PreTrainedCokeBertModel-195"><span class="linenos">195</span></a>    <span class="nd">@classmethod</span>
</span><span id="PreTrainedCokeBertModel-196"><a href="#PreTrainedCokeBertModel-196"><span class="linenos">196</span></a>    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dir_path</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-197"><a href="#PreTrainedCokeBertModel-197"><span class="linenos">197</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel-198"><a href="#PreTrainedCokeBertModel-198"><span class="linenos">198</span></a><span class="sd">        Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.</span>
</span><span id="PreTrainedCokeBertModel-199"><a href="#PreTrainedCokeBertModel-199"><span class="linenos">199</span></a><span class="sd">        Download and cache the pre-trained model file if needed.</span>
</span><span id="PreTrainedCokeBertModel-200"><a href="#PreTrainedCokeBertModel-200"><span class="linenos">200</span></a>
</span><span id="PreTrainedCokeBertModel-201"><a href="#PreTrainedCokeBertModel-201"><span class="linenos">201</span></a><span class="sd">        Args:</span>
</span><span id="PreTrainedCokeBertModel-202"><a href="#PreTrainedCokeBertModel-202"><span class="linenos">202</span></a><span class="sd">            dir_path (str): a path or url to a pretrained model archive containing:</span>
</span><span id="PreTrainedCokeBertModel-203"><a href="#PreTrainedCokeBertModel-203"><span class="linenos">203</span></a>
</span><span id="PreTrainedCokeBertModel-204"><a href="#PreTrainedCokeBertModel-204"><span class="linenos">204</span></a><span class="sd">                    . `bert_config.json` a configuration file for the model</span>
</span><span id="PreTrainedCokeBertModel-205"><a href="#PreTrainedCokeBertModel-205"><span class="linenos">205</span></a>
</span><span id="PreTrainedCokeBertModel-206"><a href="#PreTrainedCokeBertModel-206"><span class="linenos">206</span></a><span class="sd">                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance</span>
</span><span id="PreTrainedCokeBertModel-207"><a href="#PreTrainedCokeBertModel-207"><span class="linenos">207</span></a>
</span><span id="PreTrainedCokeBertModel-208"><a href="#PreTrainedCokeBertModel-208"><span class="linenos">208</span></a><span class="sd">            state_dict: an optional state dictionary (collections.OrderedDict object) to use instead of Google pre-trained models</span>
</span><span id="PreTrainedCokeBertModel-209"><a href="#PreTrainedCokeBertModel-209"><span class="linenos">209</span></a><span class="sd">            cache_dir: an optional path to a folder in which the pre-trained models will be cached.</span>
</span><span id="PreTrainedCokeBertModel-210"><a href="#PreTrainedCokeBertModel-210"><span class="linenos">210</span></a><span class="sd">            *inputs, **kwargs: additional input for the specific Bert class</span>
</span><span id="PreTrainedCokeBertModel-211"><a href="#PreTrainedCokeBertModel-211"><span class="linenos">211</span></a><span class="sd">                (ex: num_labels for BertForSequenceClassification)</span>
</span><span id="PreTrainedCokeBertModel-212"><a href="#PreTrainedCokeBertModel-212"><span class="linenos">212</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel-213"><a href="#PreTrainedCokeBertModel-213"><span class="linenos">213</span></a>        
</span><span id="PreTrainedCokeBertModel-214"><a href="#PreTrainedCokeBertModel-214"><span class="linenos">214</span></a>        <span class="c1"># Load config</span>
</span><span id="PreTrainedCokeBertModel-215"><a href="#PreTrainedCokeBertModel-215"><span class="linenos">215</span></a>        <span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">CONFIG_NAME</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-216"><a href="#PreTrainedCokeBertModel-216"><span class="linenos">216</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">CokeBertConfig</span><span class="o">.</span><span class="n">load_from_json</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-217"><a href="#PreTrainedCokeBertModel-217"><span class="linenos">217</span></a>
</span><span id="PreTrainedCokeBertModel-218"><a href="#PreTrainedCokeBertModel-218"><span class="linenos">218</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-219"><a href="#PreTrainedCokeBertModel-219"><span class="linenos">219</span></a>
</span><span id="PreTrainedCokeBertModel-220"><a href="#PreTrainedCokeBertModel-220"><span class="linenos">220</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">state_dict</span><span class="o">==</span><span class="kc">None</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-221"><a href="#PreTrainedCokeBertModel-221"><span class="linenos">221</span></a>            <span class="n">weights_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-222"><a href="#PreTrainedCokeBertModel-222"><span class="linenos">222</span></a>            <span class="k">if</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="PreTrainedCokeBertModel-223"><a href="#PreTrainedCokeBertModel-223"><span class="linenos">223</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-224"><a href="#PreTrainedCokeBertModel-224"><span class="linenos">224</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel-225"><a href="#PreTrainedCokeBertModel-225"><span class="linenos">225</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span><span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-226"><a href="#PreTrainedCokeBertModel-226"><span class="linenos">226</span></a>
</span><span id="PreTrainedCokeBertModel-227"><a href="#PreTrainedCokeBertModel-227"><span class="linenos">227</span></a>        <span class="n">missing_keys</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PreTrainedCokeBertModel-228"><a href="#PreTrainedCokeBertModel-228"><span class="linenos">228</span></a>        <span class="c1"># copy state_dict so _load_from_state_dict can modify it</span>
</span><span id="PreTrainedCokeBertModel-229"><a href="#PreTrainedCokeBertModel-229"><span class="linenos">229</span></a>        <span class="n">metadata</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="s1">&#39;_metadata&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-230"><a href="#PreTrainedCokeBertModel-230"><span class="linenos">230</span></a>        
</span><span id="PreTrainedCokeBertModel-231"><a href="#PreTrainedCokeBertModel-231"><span class="linenos">231</span></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="PreTrainedCokeBertModel-232"><a href="#PreTrainedCokeBertModel-232"><span class="linenos">232</span></a>        <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel-233"><a href="#PreTrainedCokeBertModel-233"><span class="linenos">233</span></a>            <span class="n">state_dict</span><span class="o">.</span><span class="n">_metadata</span> <span class="o">=</span> <span class="n">metadata</span>
</span><span id="PreTrainedCokeBertModel-234"><a href="#PreTrainedCokeBertModel-234"><span class="linenos">234</span></a>
</span><span id="PreTrainedCokeBertModel-235"><a href="#PreTrainedCokeBertModel-235"><span class="linenos">235</span></a>        <span class="n">mapping_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">MAPPING_FILE</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-236"><a href="#PreTrainedCokeBertModel-236"><span class="linenos">236</span></a>
</span><span id="PreTrainedCokeBertModel-237"><a href="#PreTrainedCokeBertModel-237"><span class="linenos">237</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">)):</span>
</span><span id="PreTrainedCokeBertModel-238"><a href="#PreTrainedCokeBertModel-238"><span class="linenos">238</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel-239"><a href="#PreTrainedCokeBertModel-239"><span class="linenos">239</span></a>                <span class="n">mapping</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-240"><a href="#PreTrainedCokeBertModel-240"><span class="linenos">240</span></a>
</span><span id="PreTrainedCokeBertModel-241"><a href="#PreTrainedCokeBertModel-241"><span class="linenos">241</span></a>            <span class="k">for</span> <span class="n">old_key</span><span class="p">,</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="PreTrainedCokeBertModel-242"><a href="#PreTrainedCokeBertModel-242"><span class="linenos">242</span></a>                <span class="k">if</span><span class="p">(</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="ow">and</span> <span class="n">old_key</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
</span><span id="PreTrainedCokeBertModel-243"><a href="#PreTrainedCokeBertModel-243"><span class="linenos">243</span></a>                    <span class="n">model_shape</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">new_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</span><span id="PreTrainedCokeBertModel-244"><a href="#PreTrainedCokeBertModel-244"><span class="linenos">244</span></a>                    <span class="k">if</span><span class="p">(</span><span class="n">model_shape</span><span class="o">!=</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel-245"><a href="#PreTrainedCokeBertModel-245"><span class="linenos">245</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;model.state_dict() </span><span class="si">{</span><span class="n">new_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">model_shape</span><span class="si">}</span><span class="s1"> != state_dict </span><span class="si">{</span><span class="n">old_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-246"><a href="#PreTrainedCokeBertModel-246"><span class="linenos">246</span></a>                        
</span><span id="PreTrainedCokeBertModel-247"><a href="#PreTrainedCokeBertModel-247"><span class="linenos">247</span></a>                    <span class="n">state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-248"><a href="#PreTrainedCokeBertModel-248"><span class="linenos">248</span></a>
</span><span id="PreTrainedCokeBertModel-249"><a href="#PreTrainedCokeBertModel-249"><span class="linenos">249</span></a>        
</span><span id="PreTrainedCokeBertModel-250"><a href="#PreTrainedCokeBertModel-250"><span class="linenos">250</span></a>        <span class="n">missing_keys</span><span class="p">,</span><span class="n">unexpected_keys</span> <span class="o">=</span>  <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-251"><a href="#PreTrainedCokeBertModel-251"><span class="linenos">251</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Missing keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">missing_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-252"><a href="#PreTrainedCokeBertModel-252"><span class="linenos">252</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel-253"><a href="#PreTrainedCokeBertModel-253"><span class="linenos">253</span></a>
</span><span id="PreTrainedCokeBertModel-254"><a href="#PreTrainedCokeBertModel-254"><span class="linenos">254</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">missing_keys</span>
</span></pre></div>


            <div class="docstring"><p>An abstract class to handle weights initialization and
a simple interface for downloading and loading pretrained models.</p>
</div>


                            <div id="PreTrainedCokeBertModel.__init__" class="classattr">
                                        <input id="PreTrainedCokeBertModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PreTrainedCokeBertModel</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="o">*</span><span class="n">inputs</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="PreTrainedCokeBertModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedCokeBertModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedCokeBertModel.__init__-167"><a href="#PreTrainedCokeBertModel.__init__-167"><span class="linenos">167</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel.__init__-168"><a href="#PreTrainedCokeBertModel.__init__-168"><span class="linenos">168</span></a>        <span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel.__init__-169"><a href="#PreTrainedCokeBertModel.__init__-169"><span class="linenos">169</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="PreTrainedCokeBertModel.__init__-170"><a href="#PreTrainedCokeBertModel.__init__-170"><span class="linenos">170</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">CokeBertConfig</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel.__init__-171"><a href="#PreTrainedCokeBertModel.__init__-171"><span class="linenos">171</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="PreTrainedCokeBertModel.__init__-172"><a href="#PreTrainedCokeBertModel.__init__-172"><span class="linenos">172</span></a>                <span class="s2">&quot;Parameter config in `</span><span class="si">{}</span><span class="s2">(config)` should be an instance of class `CokeBertConfig`. &quot;</span>
</span><span id="PreTrainedCokeBertModel.__init__-173"><a href="#PreTrainedCokeBertModel.__init__-173"><span class="linenos">173</span></a>                <span class="s2">&quot;To create a model from a Google pretrained model use &quot;</span>
</span><span id="PreTrainedCokeBertModel.__init__-174"><a href="#PreTrainedCokeBertModel.__init__-174"><span class="linenos">174</span></a>                <span class="s2">&quot;`model = </span><span class="si">{}</span><span class="s2">.from_pretrained(PRETRAINED_MODEL_NAME)`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
</span><span id="PreTrainedCokeBertModel.__init__-175"><a href="#PreTrainedCokeBertModel.__init__-175"><span class="linenos">175</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="PreTrainedCokeBertModel.__init__-176"><a href="#PreTrainedCokeBertModel.__init__-176"><span class="linenos">176</span></a>                <span class="p">))</span>
</span><span id="PreTrainedCokeBertModel.__init__-177"><a href="#PreTrainedCokeBertModel.__init__-177"><span class="linenos">177</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span></pre></div>


    

                            </div>
                            <div id="PreTrainedCokeBertModel.init_weights" class="classattr">
                                        <input id="PreTrainedCokeBertModel.init_weights-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">init_weights</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">module</span></span>)</span>

                <label class="view-source-button" for="PreTrainedCokeBertModel.init_weights-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedCokeBertModel.init_weights"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedCokeBertModel.init_weights-179"><a href="#PreTrainedCokeBertModel.init_weights-179"><span class="linenos">179</span></a>    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel.init_weights-180"><a href="#PreTrainedCokeBertModel.init_weights-180"><span class="linenos">180</span></a>        <span class="sd">&quot;&quot;&quot; Initialize the weights.</span>
</span><span id="PreTrainedCokeBertModel.init_weights-181"><a href="#PreTrainedCokeBertModel.init_weights-181"><span class="linenos">181</span></a>
</span><span id="PreTrainedCokeBertModel.init_weights-182"><a href="#PreTrainedCokeBertModel.init_weights-182"><span class="linenos">182</span></a><span class="sd">        Args:</span>
</span><span id="PreTrainedCokeBertModel.init_weights-183"><a href="#PreTrainedCokeBertModel.init_weights-183"><span class="linenos">183</span></a><span class="sd">            module: one of `nn.Linear`, `nn.Embedding`, `LayerNorm`, module to initialize weights of</span>
</span><span id="PreTrainedCokeBertModel.init_weights-184"><a href="#PreTrainedCokeBertModel.init_weights-184"><span class="linenos">184</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel.init_weights-185"><a href="#PreTrainedCokeBertModel.init_weights-185"><span class="linenos">185</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
</span><span id="PreTrainedCokeBertModel.init_weights-186"><a href="#PreTrainedCokeBertModel.init_weights-186"><span class="linenos">186</span></a>            <span class="c1"># Slightly different from the TF version which uses truncated_normal for initialization</span>
</span><span id="PreTrainedCokeBertModel.init_weights-187"><a href="#PreTrainedCokeBertModel.init_weights-187"><span class="linenos">187</span></a>            <span class="c1"># cf https://github.com/pytorch/pytorch/pull/5617</span>
</span><span id="PreTrainedCokeBertModel.init_weights-188"><a href="#PreTrainedCokeBertModel.init_weights-188"><span class="linenos">188</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.init_weights-189"><a href="#PreTrainedCokeBertModel.init_weights-189"><span class="linenos">189</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LayerNorm</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel.init_weights-190"><a href="#PreTrainedCokeBertModel.init_weights-190"><span class="linenos">190</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span><span id="PreTrainedCokeBertModel.init_weights-191"><a href="#PreTrainedCokeBertModel.init_weights-191"><span class="linenos">191</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.init_weights-192"><a href="#PreTrainedCokeBertModel.init_weights-192"><span class="linenos">192</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel.init_weights-193"><a href="#PreTrainedCokeBertModel.init_weights-193"><span class="linenos">193</span></a>            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initialize the weights.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>module:</strong>  one of <code>nn.Linear</code>, <code>nn.Embedding</code>, <code>LayerNorm</code>, module to initialize weights of</li>
</ul>
</div>


                            </div>
                            <div id="PreTrainedCokeBertModel.from_pretrained" class="classattr">
                                        <input id="PreTrainedCokeBertModel.from_pretrained-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">from_pretrained</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">dir_path</span>, </span><span class="param"><span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">cache_dir</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="o">*</span><span class="n">inputs</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="PreTrainedCokeBertModel.from_pretrained-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PreTrainedCokeBertModel.from_pretrained"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PreTrainedCokeBertModel.from_pretrained-195"><a href="#PreTrainedCokeBertModel.from_pretrained-195"><span class="linenos">195</span></a>    <span class="nd">@classmethod</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-196"><a href="#PreTrainedCokeBertModel.from_pretrained-196"><span class="linenos">196</span></a>    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dir_path</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-197"><a href="#PreTrainedCokeBertModel.from_pretrained-197"><span class="linenos">197</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-198"><a href="#PreTrainedCokeBertModel.from_pretrained-198"><span class="linenos">198</span></a><span class="sd">        Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-199"><a href="#PreTrainedCokeBertModel.from_pretrained-199"><span class="linenos">199</span></a><span class="sd">        Download and cache the pre-trained model file if needed.</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-200"><a href="#PreTrainedCokeBertModel.from_pretrained-200"><span class="linenos">200</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-201"><a href="#PreTrainedCokeBertModel.from_pretrained-201"><span class="linenos">201</span></a><span class="sd">        Args:</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-202"><a href="#PreTrainedCokeBertModel.from_pretrained-202"><span class="linenos">202</span></a><span class="sd">            dir_path (str): a path or url to a pretrained model archive containing:</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-203"><a href="#PreTrainedCokeBertModel.from_pretrained-203"><span class="linenos">203</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-204"><a href="#PreTrainedCokeBertModel.from_pretrained-204"><span class="linenos">204</span></a><span class="sd">                    . `bert_config.json` a configuration file for the model</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-205"><a href="#PreTrainedCokeBertModel.from_pretrained-205"><span class="linenos">205</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-206"><a href="#PreTrainedCokeBertModel.from_pretrained-206"><span class="linenos">206</span></a><span class="sd">                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-207"><a href="#PreTrainedCokeBertModel.from_pretrained-207"><span class="linenos">207</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-208"><a href="#PreTrainedCokeBertModel.from_pretrained-208"><span class="linenos">208</span></a><span class="sd">            state_dict: an optional state dictionary (collections.OrderedDict object) to use instead of Google pre-trained models</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-209"><a href="#PreTrainedCokeBertModel.from_pretrained-209"><span class="linenos">209</span></a><span class="sd">            cache_dir: an optional path to a folder in which the pre-trained models will be cached.</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-210"><a href="#PreTrainedCokeBertModel.from_pretrained-210"><span class="linenos">210</span></a><span class="sd">            *inputs, **kwargs: additional input for the specific Bert class</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-211"><a href="#PreTrainedCokeBertModel.from_pretrained-211"><span class="linenos">211</span></a><span class="sd">                (ex: num_labels for BertForSequenceClassification)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-212"><a href="#PreTrainedCokeBertModel.from_pretrained-212"><span class="linenos">212</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-213"><a href="#PreTrainedCokeBertModel.from_pretrained-213"><span class="linenos">213</span></a>        
</span><span id="PreTrainedCokeBertModel.from_pretrained-214"><a href="#PreTrainedCokeBertModel.from_pretrained-214"><span class="linenos">214</span></a>        <span class="c1"># Load config</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-215"><a href="#PreTrainedCokeBertModel.from_pretrained-215"><span class="linenos">215</span></a>        <span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">CONFIG_NAME</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-216"><a href="#PreTrainedCokeBertModel.from_pretrained-216"><span class="linenos">216</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">CokeBertConfig</span><span class="o">.</span><span class="n">load_from_json</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-217"><a href="#PreTrainedCokeBertModel.from_pretrained-217"><span class="linenos">217</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-218"><a href="#PreTrainedCokeBertModel.from_pretrained-218"><span class="linenos">218</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-219"><a href="#PreTrainedCokeBertModel.from_pretrained-219"><span class="linenos">219</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-220"><a href="#PreTrainedCokeBertModel.from_pretrained-220"><span class="linenos">220</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">state_dict</span><span class="o">==</span><span class="kc">None</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-221"><a href="#PreTrainedCokeBertModel.from_pretrained-221"><span class="linenos">221</span></a>            <span class="n">weights_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">WEIGHTS_NAME</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-222"><a href="#PreTrainedCokeBertModel.from_pretrained-222"><span class="linenos">222</span></a>            <span class="k">if</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()):</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-223"><a href="#PreTrainedCokeBertModel.from_pretrained-223"><span class="linenos">223</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-224"><a href="#PreTrainedCokeBertModel.from_pretrained-224"><span class="linenos">224</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-225"><a href="#PreTrainedCokeBertModel.from_pretrained-225"><span class="linenos">225</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">,</span><span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-226"><a href="#PreTrainedCokeBertModel.from_pretrained-226"><span class="linenos">226</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-227"><a href="#PreTrainedCokeBertModel.from_pretrained-227"><span class="linenos">227</span></a>        <span class="n">missing_keys</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-228"><a href="#PreTrainedCokeBertModel.from_pretrained-228"><span class="linenos">228</span></a>        <span class="c1"># copy state_dict so _load_from_state_dict can modify it</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-229"><a href="#PreTrainedCokeBertModel.from_pretrained-229"><span class="linenos">229</span></a>        <span class="n">metadata</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="s1">&#39;_metadata&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-230"><a href="#PreTrainedCokeBertModel.from_pretrained-230"><span class="linenos">230</span></a>        
</span><span id="PreTrainedCokeBertModel.from_pretrained-231"><a href="#PreTrainedCokeBertModel.from_pretrained-231"><span class="linenos">231</span></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-232"><a href="#PreTrainedCokeBertModel.from_pretrained-232"><span class="linenos">232</span></a>        <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-233"><a href="#PreTrainedCokeBertModel.from_pretrained-233"><span class="linenos">233</span></a>            <span class="n">state_dict</span><span class="o">.</span><span class="n">_metadata</span> <span class="o">=</span> <span class="n">metadata</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-234"><a href="#PreTrainedCokeBertModel.from_pretrained-234"><span class="linenos">234</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-235"><a href="#PreTrainedCokeBertModel.from_pretrained-235"><span class="linenos">235</span></a>        <span class="n">mapping_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">MAPPING_FILE</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-236"><a href="#PreTrainedCokeBertModel.from_pretrained-236"><span class="linenos">236</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-237"><a href="#PreTrainedCokeBertModel.from_pretrained-237"><span class="linenos">237</span></a>        <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">)):</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-238"><a href="#PreTrainedCokeBertModel.from_pretrained-238"><span class="linenos">238</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">mapping_file</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-239"><a href="#PreTrainedCokeBertModel.from_pretrained-239"><span class="linenos">239</span></a>                <span class="n">mapping</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-240"><a href="#PreTrainedCokeBertModel.from_pretrained-240"><span class="linenos">240</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-241"><a href="#PreTrainedCokeBertModel.from_pretrained-241"><span class="linenos">241</span></a>            <span class="k">for</span> <span class="n">old_key</span><span class="p">,</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-242"><a href="#PreTrainedCokeBertModel.from_pretrained-242"><span class="linenos">242</span></a>                <span class="k">if</span><span class="p">(</span><span class="n">new_key</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="ow">and</span> <span class="n">old_key</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-243"><a href="#PreTrainedCokeBertModel.from_pretrained-243"><span class="linenos">243</span></a>                    <span class="n">model_shape</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">new_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-244"><a href="#PreTrainedCokeBertModel.from_pretrained-244"><span class="linenos">244</span></a>                    <span class="k">if</span><span class="p">(</span><span class="n">model_shape</span><span class="o">!=</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-245"><a href="#PreTrainedCokeBertModel.from_pretrained-245"><span class="linenos">245</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;model.state_dict() </span><span class="si">{</span><span class="n">new_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">model_shape</span><span class="si">}</span><span class="s1"> != state_dict </span><span class="si">{</span><span class="n">old_key</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">state_dict</span><span class="p">[</span><span class="n">old_key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-246"><a href="#PreTrainedCokeBertModel.from_pretrained-246"><span class="linenos">246</span></a>                        
</span><span id="PreTrainedCokeBertModel.from_pretrained-247"><a href="#PreTrainedCokeBertModel.from_pretrained-247"><span class="linenos">247</span></a>                    <span class="n">state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">old_key</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-248"><a href="#PreTrainedCokeBertModel.from_pretrained-248"><span class="linenos">248</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-249"><a href="#PreTrainedCokeBertModel.from_pretrained-249"><span class="linenos">249</span></a>        
</span><span id="PreTrainedCokeBertModel.from_pretrained-250"><a href="#PreTrainedCokeBertModel.from_pretrained-250"><span class="linenos">250</span></a>        <span class="n">missing_keys</span><span class="p">,</span><span class="n">unexpected_keys</span> <span class="o">=</span>  <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span><span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-251"><a href="#PreTrainedCokeBertModel.from_pretrained-251"><span class="linenos">251</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Missing keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">missing_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-252"><a href="#PreTrainedCokeBertModel.from_pretrained-252"><span class="linenos">252</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected keys are: </span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="PreTrainedCokeBertModel.from_pretrained-253"><a href="#PreTrainedCokeBertModel.from_pretrained-253"><span class="linenos">253</span></a>
</span><span id="PreTrainedCokeBertModel.from_pretrained-254"><a href="#PreTrainedCokeBertModel.from_pretrained-254"><span class="linenos">254</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">missing_keys</span>
</span></pre></div>


            <div class="docstring"><p>Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.
Download and cache the pre-trained model file if needed.</p>

<h6 id="args">Args</h6>

<ul>
<li><p><strong>dir_path (str):</strong>  a path or url to a pretrained model archive containing:</p>

<p>. <code>bert_config.json</code> a configuration file for the model</p>

<p>. <code>pytorch_model.bin</code> a PyTorch dump of a BertForPreTraining instance</p></li>
<li><strong>state_dict:</strong>  an optional state dictionary (collections.OrderedDict object) to use instead of Google pre-trained models</li>
<li><strong>cache_dir:</strong>  an optional path to a folder in which the pre-trained models will be cached.</li>
<li><strong><em>inputs, *</em>kwargs:</strong>  additional input for the specific Bert class
(ex: num_labels for BertForSequenceClassification)</li>
</ul>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="PreTrainedCokeBertModel.dump_patches" class="variable">dump_patches</dd>
                <dd id="PreTrainedCokeBertModel.forward" class="function">forward</dd>
                <dd id="PreTrainedCokeBertModel.register_buffer" class="function">register_buffer</dd>
                <dd id="PreTrainedCokeBertModel.register_parameter" class="function">register_parameter</dd>
                <dd id="PreTrainedCokeBertModel.add_module" class="function">add_module</dd>
                <dd id="PreTrainedCokeBertModel.register_module" class="function">register_module</dd>
                <dd id="PreTrainedCokeBertModel.get_submodule" class="function">get_submodule</dd>
                <dd id="PreTrainedCokeBertModel.get_parameter" class="function">get_parameter</dd>
                <dd id="PreTrainedCokeBertModel.get_buffer" class="function">get_buffer</dd>
                <dd id="PreTrainedCokeBertModel.get_extra_state" class="function">get_extra_state</dd>
                <dd id="PreTrainedCokeBertModel.set_extra_state" class="function">set_extra_state</dd>
                <dd id="PreTrainedCokeBertModel.apply" class="function">apply</dd>
                <dd id="PreTrainedCokeBertModel.cuda" class="function">cuda</dd>
                <dd id="PreTrainedCokeBertModel.xpu" class="function">xpu</dd>
                <dd id="PreTrainedCokeBertModel.cpu" class="function">cpu</dd>
                <dd id="PreTrainedCokeBertModel.type" class="function">type</dd>
                <dd id="PreTrainedCokeBertModel.float" class="function">float</dd>
                <dd id="PreTrainedCokeBertModel.double" class="function">double</dd>
                <dd id="PreTrainedCokeBertModel.half" class="function">half</dd>
                <dd id="PreTrainedCokeBertModel.bfloat16" class="function">bfloat16</dd>
                <dd id="PreTrainedCokeBertModel.to_empty" class="function">to_empty</dd>
                <dd id="PreTrainedCokeBertModel.to" class="function">to</dd>
                <dd id="PreTrainedCokeBertModel.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="PreTrainedCokeBertModel.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="PreTrainedCokeBertModel.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="PreTrainedCokeBertModel.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="PreTrainedCokeBertModel.T_destination" class="variable">T_destination</dd>
                <dd id="PreTrainedCokeBertModel.state_dict" class="function">state_dict</dd>
                <dd id="PreTrainedCokeBertModel.load_state_dict" class="function">load_state_dict</dd>
                <dd id="PreTrainedCokeBertModel.parameters" class="function">parameters</dd>
                <dd id="PreTrainedCokeBertModel.named_parameters" class="function">named_parameters</dd>
                <dd id="PreTrainedCokeBertModel.buffers" class="function">buffers</dd>
                <dd id="PreTrainedCokeBertModel.named_buffers" class="function">named_buffers</dd>
                <dd id="PreTrainedCokeBertModel.children" class="function">children</dd>
                <dd id="PreTrainedCokeBertModel.named_children" class="function">named_children</dd>
                <dd id="PreTrainedCokeBertModel.modules" class="function">modules</dd>
                <dd id="PreTrainedCokeBertModel.named_modules" class="function">named_modules</dd>
                <dd id="PreTrainedCokeBertModel.train" class="function">train</dd>
                <dd id="PreTrainedCokeBertModel.eval" class="function">eval</dd>
                <dd id="PreTrainedCokeBertModel.requires_grad_" class="function">requires_grad_</dd>
                <dd id="PreTrainedCokeBertModel.zero_grad" class="function">zero_grad</dd>
                <dd id="PreTrainedCokeBertModel.share_memory" class="function">share_memory</dd>
                <dd id="PreTrainedCokeBertModel.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="CokeBertModel">
                            <input id="CokeBertModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">CokeBertModel</span><wbr>(<span class="base"><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></span>):

                <label class="view-source-button" for="CokeBertModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertModel-256"><a href="#CokeBertModel-256"><span class="linenos">256</span></a><span class="k">class</span> <span class="nc">CokeBertModel</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="CokeBertModel-257"><a href="#CokeBertModel-257"><span class="linenos">257</span></a>    <span class="sd">&quot;&quot;&quot; A class to handle the Transformer Model (without fine-tuning head)&quot;&quot;&quot;</span>
</span><span id="CokeBertModel-258"><a href="#CokeBertModel-258"><span class="linenos">258</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="CokeBertModel-259"><a href="#CokeBertModel-259"><span class="linenos">259</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a CokeBertModel</span>
</span><span id="CokeBertModel-260"><a href="#CokeBertModel-260"><span class="linenos">260</span></a>
</span><span id="CokeBertModel-261"><a href="#CokeBertModel-261"><span class="linenos">261</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertModel-262"><a href="#CokeBertModel-262"><span class="linenos">262</span></a><span class="sd">            config (`CokeBertConfig`): The config that sets the model&#39;s hyperparameters</span>
</span><span id="CokeBertModel-263"><a href="#CokeBertModel-263"><span class="linenos">263</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertModel-264"><a href="#CokeBertModel-264"><span class="linenos">264</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">CokeBertModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertModel-265"><a href="#CokeBertModel-265"><span class="linenos">265</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">type_vocab_size</span><span class="p">)</span>
</span><span id="CokeBertModel-266"><a href="#CokeBertModel-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">to_text_encoder_config</span><span class="p">())</span>
</span><span id="CokeBertModel-267"><a href="#CokeBertModel-267"><span class="linenos">267</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">knowledge_encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">to_knowl_encoder_config</span><span class="p">())</span>
</span><span id="CokeBertModel-268"><a href="#CokeBertModel-268"><span class="linenos">268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="o">=</span> <span class="n">BertPooler</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="CokeBertModel-269"><a href="#CokeBertModel-269"><span class="linenos">269</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dk_encoder</span> <span class="o">=</span> <span class="n">DKEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">q_dim</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dk_layers</span><span class="p">)</span>
</span><span id="CokeBertModel-270"><a href="#CokeBertModel-270"><span class="linenos">270</span></a>
</span><span id="CokeBertModel-271"><a href="#CokeBertModel-271"><span class="linenos">271</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">k_v_dim</span>
</span><span id="CokeBertModel-272"><a href="#CokeBertModel-272"><span class="linenos">272</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">entity_size</span>
</span><span id="CokeBertModel-273"><a href="#CokeBertModel-273"><span class="linenos">273</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="CokeBertModel-274"><a href="#CokeBertModel-274"><span class="linenos">274</span></a>
</span><span id="CokeBertModel-275"><a href="#CokeBertModel-275"><span class="linenos">275</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertModel-276"><a href="#CokeBertModel-276"><span class="linenos">276</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the `CokeBertModel`</span>
</span><span id="CokeBertModel-277"><a href="#CokeBertModel-277"><span class="linenos">277</span></a>
</span><span id="CokeBertModel-278"><a href="#CokeBertModel-278"><span class="linenos">278</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertModel-279"><a href="#CokeBertModel-279"><span class="linenos">279</span></a><span class="sd">            input_ids: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertModel-280"><a href="#CokeBertModel-280"><span class="linenos">280</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertModel-281"><a href="#CokeBertModel-281"><span class="linenos">281</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertModel-282"><a href="#CokeBertModel-282"><span class="linenos">282</span></a><span class="sd">            token_type_ids: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertModel-283"><a href="#CokeBertModel-283"><span class="linenos">283</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertModel-284"><a href="#CokeBertModel-284"><span class="linenos">284</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertModel-285"><a href="#CokeBertModel-285"><span class="linenos">285</span></a><span class="sd">            attention_mask: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertModel-286"><a href="#CokeBertModel-286"><span class="linenos">286</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertModel-287"><a href="#CokeBertModel-287"><span class="linenos">287</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertModel-288"><a href="#CokeBertModel-288"><span class="linenos">288</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertModel-289"><a href="#CokeBertModel-289"><span class="linenos">289</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertModel-290"><a href="#CokeBertModel-290"><span class="linenos">290</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertModel-291"><a href="#CokeBertModel-291"><span class="linenos">291</span></a><span class="sd">            ent_mask: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertModel-292"><a href="#CokeBertModel-292"><span class="linenos">292</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertModel-293"><a href="#CokeBertModel-293"><span class="linenos">293</span></a><span class="sd">            output_all_encoded_layers: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.</span>
</span><span id="CokeBertModel-294"><a href="#CokeBertModel-294"><span class="linenos">294</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertModel-295"><a href="#CokeBertModel-295"><span class="linenos">295</span></a>
</span><span id="CokeBertModel-296"><a href="#CokeBertModel-296"><span class="linenos">296</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertModel-297"><a href="#CokeBertModel-297"><span class="linenos">297</span></a><span class="sd">            sequence_output, pooled_output</span>
</span><span id="CokeBertModel-298"><a href="#CokeBertModel-298"><span class="linenos">298</span></a>
</span><span id="CokeBertModel-299"><a href="#CokeBertModel-299"><span class="linenos">299</span></a><span class="sd">            sequence_output: the full sequence of hidden-states corresponding</span>
</span><span id="CokeBertModel-300"><a href="#CokeBertModel-300"><span class="linenos">300</span></a><span class="sd">                    to the last attention block of shape [batch_size, sequence_length, hidden_size]       </span>
</span><span id="CokeBertModel-301"><a href="#CokeBertModel-301"><span class="linenos">301</span></a><span class="sd">            pooled_output: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a</span>
</span><span id="CokeBertModel-302"><a href="#CokeBertModel-302"><span class="linenos">302</span></a><span class="sd">                classifier pretrained on top of the hidden state associated to the first character of the</span>
</span><span id="CokeBertModel-303"><a href="#CokeBertModel-303"><span class="linenos">303</span></a><span class="sd">                input (`CLS`) to train on the Next-Sentence task (see BERT&#39;s paper).</span>
</span><span id="CokeBertModel-304"><a href="#CokeBertModel-304"><span class="linenos">304</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertModel-305"><a href="#CokeBertModel-305"><span class="linenos">305</span></a>        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertModel-306"><a href="#CokeBertModel-306"><span class="linenos">306</span></a>            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="CokeBertModel-307"><a href="#CokeBertModel-307"><span class="linenos">307</span></a>        <span class="k">if</span> <span class="n">token_type_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertModel-308"><a href="#CokeBertModel-308"><span class="linenos">308</span></a>            <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="CokeBertModel-309"><a href="#CokeBertModel-309"><span class="linenos">309</span></a>
</span><span id="CokeBertModel-310"><a href="#CokeBertModel-310"><span class="linenos">310</span></a>        <span class="c1"># We create a 3D attention mask from a 2D tensor mask.</span>
</span><span id="CokeBertModel-311"><a href="#CokeBertModel-311"><span class="linenos">311</span></a>        <span class="c1"># Sizes are [batch_size, 1, 1, to_seq_length]</span>
</span><span id="CokeBertModel-312"><a href="#CokeBertModel-312"><span class="linenos">312</span></a>        <span class="c1"># So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]</span>
</span><span id="CokeBertModel-313"><a href="#CokeBertModel-313"><span class="linenos">313</span></a>        <span class="c1"># this attention mask is more simple than the triangular masking of causal attention</span>
</span><span id="CokeBertModel-314"><a href="#CokeBertModel-314"><span class="linenos">314</span></a>        <span class="c1"># used in OpenAI GPT, we just need to prepare the broadcast dimension here.</span>
</span><span id="CokeBertModel-315"><a href="#CokeBertModel-315"><span class="linenos">315</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="CokeBertModel-316"><a href="#CokeBertModel-316"><span class="linenos">316</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="CokeBertModel-317"><a href="#CokeBertModel-317"><span class="linenos">317</span></a>
</span><span id="CokeBertModel-318"><a href="#CokeBertModel-318"><span class="linenos">318</span></a>        <span class="c1"># Since attention_mask is 1.0 for positions we want to attend and 0.0 for</span>
</span><span id="CokeBertModel-319"><a href="#CokeBertModel-319"><span class="linenos">319</span></a>        <span class="c1"># masked positions, this operation will create a tensor which is 0.0 for</span>
</span><span id="CokeBertModel-320"><a href="#CokeBertModel-320"><span class="linenos">320</span></a>        <span class="c1"># positions we want to attend and -10000.0 for masked positions.</span>
</span><span id="CokeBertModel-321"><a href="#CokeBertModel-321"><span class="linenos">321</span></a>        <span class="c1"># Since we are adding it to the raw scores before the softmax, this is</span>
</span><span id="CokeBertModel-322"><a href="#CokeBertModel-322"><span class="linenos">322</span></a>        <span class="c1"># effectively the same as removing these entirely.</span>
</span><span id="CokeBertModel-323"><a href="#CokeBertModel-323"><span class="linenos">323</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="CokeBertModel-324"><a href="#CokeBertModel-324"><span class="linenos">324</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="CokeBertModel-325"><a href="#CokeBertModel-325"><span class="linenos">325</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">extended_ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="CokeBertModel-326"><a href="#CokeBertModel-326"><span class="linenos">326</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_ent_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="CokeBertModel-327"><a href="#CokeBertModel-327"><span class="linenos">327</span></a>
</span><span id="CokeBertModel-328"><a href="#CokeBertModel-328"><span class="linenos">328</span></a>        <span class="c1">#############################################################</span>
</span><span id="CokeBertModel-329"><a href="#CokeBertModel-329"><span class="linenos">329</span></a>
</span><span id="CokeBertModel-330"><a href="#CokeBertModel-330"><span class="linenos">330</span></a>        <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
</span><span id="CokeBertModel-331"><a href="#CokeBertModel-331"><span class="linenos">331</span></a>
</span><span id="CokeBertModel-332"><a href="#CokeBertModel-332"><span class="linenos">332</span></a>        <span class="c1">##</span>
</span><span id="CokeBertModel-333"><a href="#CokeBertModel-333"><span class="linenos">333</span></a>        <span class="n">all_encoder_layers</span><span class="o">=</span><span class="nb">list</span><span class="p">()</span>
</span><span id="CokeBertModel-334"><a href="#CokeBertModel-334"><span class="linenos">334</span></a>        <span class="n">ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="c1">#.unsqueeze(-1)</span>
</span><span id="CokeBertModel-335"><a href="#CokeBertModel-335"><span class="linenos">335</span></a>        <span class="c1">##</span>
</span><span id="CokeBertModel-336"><a href="#CokeBertModel-336"><span class="linenos">336</span></a>
</span><span id="CokeBertModel-337"><a href="#CokeBertModel-337"><span class="linenos">337</span></a>        <span class="n">all_encoder_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">,</span> <span class="n">extended_attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">extended_ent_mask</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="CokeBertModel-338"><a href="#CokeBertModel-338"><span class="linenos">338</span></a>
</span><span id="CokeBertModel-339"><a href="#CokeBertModel-339"><span class="linenos">339</span></a>        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">all_encoder_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="CokeBertModel-340"><a href="#CokeBertModel-340"><span class="linenos">340</span></a>
</span><span id="CokeBertModel-341"><a href="#CokeBertModel-341"><span class="linenos">341</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ent</span><span class="p">[</span><span class="n">input_ent</span><span class="o">!=</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="CokeBertModel-342"><a href="#CokeBertModel-342"><span class="linenos">342</span></a>            <span class="c1"># no input entities -&gt; return 0s</span>
</span><span id="CokeBertModel-343"><a href="#CokeBertModel-343"><span class="linenos">343</span></a>            <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span><span class="p">)</span>
</span><span id="CokeBertModel-344"><a href="#CokeBertModel-344"><span class="linenos">344</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertModel-345"><a href="#CokeBertModel-345"><span class="linenos">345</span></a>
</span><span id="CokeBertModel-346"><a href="#CokeBertModel-346"><span class="linenos">346</span></a>            <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dk_encoder</span><span class="p">(</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertModel-347"><a href="#CokeBertModel-347"><span class="linenos">347</span></a>
</span><span id="CokeBertModel-348"><a href="#CokeBertModel-348"><span class="linenos">348</span></a>        <span class="n">encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">knowledge_encoder</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">extended_attention_mask</span><span class="p">,</span><span class="n">hidden_states_ent</span><span class="p">,</span> <span class="n">extended_ent_mask</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="CokeBertModel-349"><a href="#CokeBertModel-349"><span class="linenos">349</span></a>        <span class="k">if</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="CokeBertModel-350"><a href="#CokeBertModel-350"><span class="linenos">350</span></a>            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">encoded_layers</span><span class="p">:</span>
</span><span id="CokeBertModel-351"><a href="#CokeBertModel-351"><span class="linenos">351</span></a>                <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
</span><span id="CokeBertModel-352"><a href="#CokeBertModel-352"><span class="linenos">352</span></a>
</span><span id="CokeBertModel-353"><a href="#CokeBertModel-353"><span class="linenos">353</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="CokeBertModel-354"><a href="#CokeBertModel-354"><span class="linenos">354</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="CokeBertModel-355"><a href="#CokeBertModel-355"><span class="linenos">355</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="CokeBertModel-356"><a href="#CokeBertModel-356"><span class="linenos">356</span></a>            <span class="n">encoded_layers</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="CokeBertModel-357"><a href="#CokeBertModel-357"><span class="linenos">357</span></a>            <span class="c1">#return encoded_layers, pooled_output</span>
</span><span id="CokeBertModel-358"><a href="#CokeBertModel-358"><span class="linenos">358</span></a>        
</span><span id="CokeBertModel-359"><a href="#CokeBertModel-359"><span class="linenos">359</span></a>        <span class="k">return</span> <span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span>
</span></pre></div>


            <div class="docstring"><p>A class to handle the Transformer Model (without fine-tuning head)</p>
</div>


                            <div id="CokeBertModel.__init__" class="classattr">
                                        <input id="CokeBertModel.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">CokeBertModel</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="CokeBertModel.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertModel.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertModel.__init__-258"><a href="#CokeBertModel.__init__-258"><span class="linenos">258</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="CokeBertModel.__init__-259"><a href="#CokeBertModel.__init__-259"><span class="linenos">259</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a CokeBertModel</span>
</span><span id="CokeBertModel.__init__-260"><a href="#CokeBertModel.__init__-260"><span class="linenos">260</span></a>
</span><span id="CokeBertModel.__init__-261"><a href="#CokeBertModel.__init__-261"><span class="linenos">261</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertModel.__init__-262"><a href="#CokeBertModel.__init__-262"><span class="linenos">262</span></a><span class="sd">            config (`CokeBertConfig`): The config that sets the model&#39;s hyperparameters</span>
</span><span id="CokeBertModel.__init__-263"><a href="#CokeBertModel.__init__-263"><span class="linenos">263</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertModel.__init__-264"><a href="#CokeBertModel.__init__-264"><span class="linenos">264</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">CokeBertModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertModel.__init__-265"><a href="#CokeBertModel.__init__-265"><span class="linenos">265</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">type_vocab_size</span><span class="p">)</span>
</span><span id="CokeBertModel.__init__-266"><a href="#CokeBertModel.__init__-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">to_text_encoder_config</span><span class="p">())</span>
</span><span id="CokeBertModel.__init__-267"><a href="#CokeBertModel.__init__-267"><span class="linenos">267</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">knowledge_encoder</span> <span class="o">=</span> <span class="n">ErnieEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">to_knowl_encoder_config</span><span class="p">())</span>
</span><span id="CokeBertModel.__init__-268"><a href="#CokeBertModel.__init__-268"><span class="linenos">268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span> <span class="o">=</span> <span class="n">BertPooler</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="CokeBertModel.__init__-269"><a href="#CokeBertModel.__init__-269"><span class="linenos">269</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dk_encoder</span> <span class="o">=</span> <span class="n">DKEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">q_dim</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dk_layers</span><span class="p">)</span>
</span><span id="CokeBertModel.__init__-270"><a href="#CokeBertModel.__init__-270"><span class="linenos">270</span></a>
</span><span id="CokeBertModel.__init__-271"><a href="#CokeBertModel.__init__-271"><span class="linenos">271</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">k_v_dim</span>
</span><span id="CokeBertModel.__init__-272"><a href="#CokeBertModel.__init__-272"><span class="linenos">272</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">entity_size</span>
</span><span id="CokeBertModel.__init__-273"><a href="#CokeBertModel.__init__-273"><span class="linenos">273</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a CokeBertModel</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>config (<code><a href="#CokeBertConfig">CokeBertConfig</a></code>):</strong>  The config that sets the model's hyperparameters</li>
</ul>
</div>


                            </div>
                            <div id="CokeBertModel.forward" class="classattr">
                                        <input id="CokeBertModel.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span>,</span><span class="param">	<span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="CokeBertModel.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertModel.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertModel.forward-275"><a href="#CokeBertModel.forward-275"><span class="linenos">275</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertModel.forward-276"><a href="#CokeBertModel.forward-276"><span class="linenos">276</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the `CokeBertModel`</span>
</span><span id="CokeBertModel.forward-277"><a href="#CokeBertModel.forward-277"><span class="linenos">277</span></a>
</span><span id="CokeBertModel.forward-278"><a href="#CokeBertModel.forward-278"><span class="linenos">278</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertModel.forward-279"><a href="#CokeBertModel.forward-279"><span class="linenos">279</span></a><span class="sd">            input_ids: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertModel.forward-280"><a href="#CokeBertModel.forward-280"><span class="linenos">280</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertModel.forward-281"><a href="#CokeBertModel.forward-281"><span class="linenos">281</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertModel.forward-282"><a href="#CokeBertModel.forward-282"><span class="linenos">282</span></a><span class="sd">            token_type_ids: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertModel.forward-283"><a href="#CokeBertModel.forward-283"><span class="linenos">283</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertModel.forward-284"><a href="#CokeBertModel.forward-284"><span class="linenos">284</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertModel.forward-285"><a href="#CokeBertModel.forward-285"><span class="linenos">285</span></a><span class="sd">            attention_mask: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertModel.forward-286"><a href="#CokeBertModel.forward-286"><span class="linenos">286</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertModel.forward-287"><a href="#CokeBertModel.forward-287"><span class="linenos">287</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertModel.forward-288"><a href="#CokeBertModel.forward-288"><span class="linenos">288</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertModel.forward-289"><a href="#CokeBertModel.forward-289"><span class="linenos">289</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertModel.forward-290"><a href="#CokeBertModel.forward-290"><span class="linenos">290</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertModel.forward-291"><a href="#CokeBertModel.forward-291"><span class="linenos">291</span></a><span class="sd">            ent_mask: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertModel.forward-292"><a href="#CokeBertModel.forward-292"><span class="linenos">292</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertModel.forward-293"><a href="#CokeBertModel.forward-293"><span class="linenos">293</span></a><span class="sd">            output_all_encoded_layers: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.</span>
</span><span id="CokeBertModel.forward-294"><a href="#CokeBertModel.forward-294"><span class="linenos">294</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertModel.forward-295"><a href="#CokeBertModel.forward-295"><span class="linenos">295</span></a>
</span><span id="CokeBertModel.forward-296"><a href="#CokeBertModel.forward-296"><span class="linenos">296</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertModel.forward-297"><a href="#CokeBertModel.forward-297"><span class="linenos">297</span></a><span class="sd">            sequence_output, pooled_output</span>
</span><span id="CokeBertModel.forward-298"><a href="#CokeBertModel.forward-298"><span class="linenos">298</span></a>
</span><span id="CokeBertModel.forward-299"><a href="#CokeBertModel.forward-299"><span class="linenos">299</span></a><span class="sd">            sequence_output: the full sequence of hidden-states corresponding</span>
</span><span id="CokeBertModel.forward-300"><a href="#CokeBertModel.forward-300"><span class="linenos">300</span></a><span class="sd">                    to the last attention block of shape [batch_size, sequence_length, hidden_size]       </span>
</span><span id="CokeBertModel.forward-301"><a href="#CokeBertModel.forward-301"><span class="linenos">301</span></a><span class="sd">            pooled_output: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a</span>
</span><span id="CokeBertModel.forward-302"><a href="#CokeBertModel.forward-302"><span class="linenos">302</span></a><span class="sd">                classifier pretrained on top of the hidden state associated to the first character of the</span>
</span><span id="CokeBertModel.forward-303"><a href="#CokeBertModel.forward-303"><span class="linenos">303</span></a><span class="sd">                input (`CLS`) to train on the Next-Sentence task (see BERT&#39;s paper).</span>
</span><span id="CokeBertModel.forward-304"><a href="#CokeBertModel.forward-304"><span class="linenos">304</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertModel.forward-305"><a href="#CokeBertModel.forward-305"><span class="linenos">305</span></a>        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertModel.forward-306"><a href="#CokeBertModel.forward-306"><span class="linenos">306</span></a>            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-307"><a href="#CokeBertModel.forward-307"><span class="linenos">307</span></a>        <span class="k">if</span> <span class="n">token_type_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertModel.forward-308"><a href="#CokeBertModel.forward-308"><span class="linenos">308</span></a>            <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-309"><a href="#CokeBertModel.forward-309"><span class="linenos">309</span></a>
</span><span id="CokeBertModel.forward-310"><a href="#CokeBertModel.forward-310"><span class="linenos">310</span></a>        <span class="c1"># We create a 3D attention mask from a 2D tensor mask.</span>
</span><span id="CokeBertModel.forward-311"><a href="#CokeBertModel.forward-311"><span class="linenos">311</span></a>        <span class="c1"># Sizes are [batch_size, 1, 1, to_seq_length]</span>
</span><span id="CokeBertModel.forward-312"><a href="#CokeBertModel.forward-312"><span class="linenos">312</span></a>        <span class="c1"># So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]</span>
</span><span id="CokeBertModel.forward-313"><a href="#CokeBertModel.forward-313"><span class="linenos">313</span></a>        <span class="c1"># this attention mask is more simple than the triangular masking of causal attention</span>
</span><span id="CokeBertModel.forward-314"><a href="#CokeBertModel.forward-314"><span class="linenos">314</span></a>        <span class="c1"># used in OpenAI GPT, we just need to prepare the broadcast dimension here.</span>
</span><span id="CokeBertModel.forward-315"><a href="#CokeBertModel.forward-315"><span class="linenos">315</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-316"><a href="#CokeBertModel.forward-316"><span class="linenos">316</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-317"><a href="#CokeBertModel.forward-317"><span class="linenos">317</span></a>
</span><span id="CokeBertModel.forward-318"><a href="#CokeBertModel.forward-318"><span class="linenos">318</span></a>        <span class="c1"># Since attention_mask is 1.0 for positions we want to attend and 0.0 for</span>
</span><span id="CokeBertModel.forward-319"><a href="#CokeBertModel.forward-319"><span class="linenos">319</span></a>        <span class="c1"># masked positions, this operation will create a tensor which is 0.0 for</span>
</span><span id="CokeBertModel.forward-320"><a href="#CokeBertModel.forward-320"><span class="linenos">320</span></a>        <span class="c1"># positions we want to attend and -10000.0 for masked positions.</span>
</span><span id="CokeBertModel.forward-321"><a href="#CokeBertModel.forward-321"><span class="linenos">321</span></a>        <span class="c1"># Since we are adding it to the raw scores before the softmax, this is</span>
</span><span id="CokeBertModel.forward-322"><a href="#CokeBertModel.forward-322"><span class="linenos">322</span></a>        <span class="c1"># effectively the same as removing these entirely.</span>
</span><span id="CokeBertModel.forward-323"><a href="#CokeBertModel.forward-323"><span class="linenos">323</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="n">extended_attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-324"><a href="#CokeBertModel.forward-324"><span class="linenos">324</span></a>        <span class="n">extended_attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_attention_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="CokeBertModel.forward-325"><a href="#CokeBertModel.forward-325"><span class="linenos">325</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="n">extended_ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-326"><a href="#CokeBertModel.forward-326"><span class="linenos">326</span></a>        <span class="n">extended_ent_mask</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">extended_ent_mask</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">10000.0</span>
</span><span id="CokeBertModel.forward-327"><a href="#CokeBertModel.forward-327"><span class="linenos">327</span></a>
</span><span id="CokeBertModel.forward-328"><a href="#CokeBertModel.forward-328"><span class="linenos">328</span></a>        <span class="c1">#############################################################</span>
</span><span id="CokeBertModel.forward-329"><a href="#CokeBertModel.forward-329"><span class="linenos">329</span></a>
</span><span id="CokeBertModel.forward-330"><a href="#CokeBertModel.forward-330"><span class="linenos">330</span></a>        <span class="n">embedding_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-331"><a href="#CokeBertModel.forward-331"><span class="linenos">331</span></a>
</span><span id="CokeBertModel.forward-332"><a href="#CokeBertModel.forward-332"><span class="linenos">332</span></a>        <span class="c1">##</span>
</span><span id="CokeBertModel.forward-333"><a href="#CokeBertModel.forward-333"><span class="linenos">333</span></a>        <span class="n">all_encoder_layers</span><span class="o">=</span><span class="nb">list</span><span class="p">()</span>
</span><span id="CokeBertModel.forward-334"><a href="#CokeBertModel.forward-334"><span class="linenos">334</span></a>        <span class="n">ent_mask</span> <span class="o">=</span> <span class="n">ent_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="c1">#.unsqueeze(-1)</span>
</span><span id="CokeBertModel.forward-335"><a href="#CokeBertModel.forward-335"><span class="linenos">335</span></a>        <span class="c1">##</span>
</span><span id="CokeBertModel.forward-336"><a href="#CokeBertModel.forward-336"><span class="linenos">336</span></a>
</span><span id="CokeBertModel.forward-337"><a href="#CokeBertModel.forward-337"><span class="linenos">337</span></a>        <span class="n">all_encoder_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">,</span> <span class="n">extended_attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">extended_ent_mask</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-338"><a href="#CokeBertModel.forward-338"><span class="linenos">338</span></a>
</span><span id="CokeBertModel.forward-339"><a href="#CokeBertModel.forward-339"><span class="linenos">339</span></a>        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">all_encoder_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="CokeBertModel.forward-340"><a href="#CokeBertModel.forward-340"><span class="linenos">340</span></a>
</span><span id="CokeBertModel.forward-341"><a href="#CokeBertModel.forward-341"><span class="linenos">341</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ent</span><span class="p">[</span><span class="n">input_ent</span><span class="o">!=</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="CokeBertModel.forward-342"><a href="#CokeBertModel.forward-342"><span class="linenos">342</span></a>            <span class="c1"># no input entities -&gt; return 0s</span>
</span><span id="CokeBertModel.forward-343"><a href="#CokeBertModel.forward-343"><span class="linenos">343</span></a>            <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">entity_size</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-344"><a href="#CokeBertModel.forward-344"><span class="linenos">344</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertModel.forward-345"><a href="#CokeBertModel.forward-345"><span class="linenos">345</span></a>
</span><span id="CokeBertModel.forward-346"><a href="#CokeBertModel.forward-346"><span class="linenos">346</span></a>            <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dk_encoder</span><span class="p">(</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-347"><a href="#CokeBertModel.forward-347"><span class="linenos">347</span></a>
</span><span id="CokeBertModel.forward-348"><a href="#CokeBertModel.forward-348"><span class="linenos">348</span></a>        <span class="n">encoded_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">knowledge_encoder</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">extended_attention_mask</span><span class="p">,</span><span class="n">hidden_states_ent</span><span class="p">,</span> <span class="n">extended_ent_mask</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="n">output_all_encoded_layers</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-349"><a href="#CokeBertModel.forward-349"><span class="linenos">349</span></a>        <span class="k">if</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="CokeBertModel.forward-350"><a href="#CokeBertModel.forward-350"><span class="linenos">350</span></a>            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">encoded_layers</span><span class="p">:</span>
</span><span id="CokeBertModel.forward-351"><a href="#CokeBertModel.forward-351"><span class="linenos">351</span></a>                <span class="n">all_encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-352"><a href="#CokeBertModel.forward-352"><span class="linenos">352</span></a>
</span><span id="CokeBertModel.forward-353"><a href="#CokeBertModel.forward-353"><span class="linenos">353</span></a>        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="CokeBertModel.forward-354"><a href="#CokeBertModel.forward-354"><span class="linenos">354</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooler</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="CokeBertModel.forward-355"><a href="#CokeBertModel.forward-355"><span class="linenos">355</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_all_encoded_layers</span><span class="p">:</span>
</span><span id="CokeBertModel.forward-356"><a href="#CokeBertModel.forward-356"><span class="linenos">356</span></a>            <span class="n">encoded_layers</span> <span class="o">=</span> <span class="n">encoded_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="CokeBertModel.forward-357"><a href="#CokeBertModel.forward-357"><span class="linenos">357</span></a>            <span class="c1">#return encoded_layers, pooled_output</span>
</span><span id="CokeBertModel.forward-358"><a href="#CokeBertModel.forward-358"><span class="linenos">358</span></a>        
</span><span id="CokeBertModel.forward-359"><a href="#CokeBertModel.forward-359"><span class="linenos">359</span></a>        <span class="k">return</span> <span class="n">sequence_output</span><span class="p">,</span> <span class="n">pooled_output</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the <code><a href="#CokeBertModel">CokeBertModel</a></code></p>

<h6 id="args">Args</h6>

<ul>
<li><strong>input_ids:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong>token_type_ids:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong>attention_mask:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong>output_all_encoded_layers:</strong>  boolean which controls the content of the <code>encoded_layers</code> output as described below. Default: <code>True</code>.</li>
<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>sequence_output, pooled_output</p>
  
  <p>sequence_output: the full sequence of hidden-states corresponding
          to the last attention block of shape [batch_size, sequence_length, hidden_size] <br />
  pooled_output: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a
      classifier pretrained on top of the hidden state associated to the first character of the
      input (<code>CLS</code>) to train on the Next-Sentence task (see BERT's paper).</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></dt>
                                <dd id="CokeBertModel.init_weights" class="function"><a href="#PreTrainedCokeBertModel.init_weights">init_weights</a></dd>
                <dd id="CokeBertModel.from_pretrained" class="function"><a href="#PreTrainedCokeBertModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="CokeBertModel.dump_patches" class="variable">dump_patches</dd>
                <dd id="CokeBertModel.register_buffer" class="function">register_buffer</dd>
                <dd id="CokeBertModel.register_parameter" class="function">register_parameter</dd>
                <dd id="CokeBertModel.add_module" class="function">add_module</dd>
                <dd id="CokeBertModel.register_module" class="function">register_module</dd>
                <dd id="CokeBertModel.get_submodule" class="function">get_submodule</dd>
                <dd id="CokeBertModel.get_parameter" class="function">get_parameter</dd>
                <dd id="CokeBertModel.get_buffer" class="function">get_buffer</dd>
                <dd id="CokeBertModel.get_extra_state" class="function">get_extra_state</dd>
                <dd id="CokeBertModel.set_extra_state" class="function">set_extra_state</dd>
                <dd id="CokeBertModel.apply" class="function">apply</dd>
                <dd id="CokeBertModel.cuda" class="function">cuda</dd>
                <dd id="CokeBertModel.xpu" class="function">xpu</dd>
                <dd id="CokeBertModel.cpu" class="function">cpu</dd>
                <dd id="CokeBertModel.type" class="function">type</dd>
                <dd id="CokeBertModel.float" class="function">float</dd>
                <dd id="CokeBertModel.double" class="function">double</dd>
                <dd id="CokeBertModel.half" class="function">half</dd>
                <dd id="CokeBertModel.bfloat16" class="function">bfloat16</dd>
                <dd id="CokeBertModel.to_empty" class="function">to_empty</dd>
                <dd id="CokeBertModel.to" class="function">to</dd>
                <dd id="CokeBertModel.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="CokeBertModel.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="CokeBertModel.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="CokeBertModel.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="CokeBertModel.T_destination" class="variable">T_destination</dd>
                <dd id="CokeBertModel.state_dict" class="function">state_dict</dd>
                <dd id="CokeBertModel.load_state_dict" class="function">load_state_dict</dd>
                <dd id="CokeBertModel.parameters" class="function">parameters</dd>
                <dd id="CokeBertModel.named_parameters" class="function">named_parameters</dd>
                <dd id="CokeBertModel.buffers" class="function">buffers</dd>
                <dd id="CokeBertModel.named_buffers" class="function">named_buffers</dd>
                <dd id="CokeBertModel.children" class="function">children</dd>
                <dd id="CokeBertModel.named_children" class="function">named_children</dd>
                <dd id="CokeBertModel.modules" class="function">modules</dd>
                <dd id="CokeBertModel.named_modules" class="function">named_modules</dd>
                <dd id="CokeBertModel.train" class="function">train</dd>
                <dd id="CokeBertModel.eval" class="function">eval</dd>
                <dd id="CokeBertModel.requires_grad_" class="function">requires_grad_</dd>
                <dd id="CokeBertModel.zero_grad" class="function">zero_grad</dd>
                <dd id="CokeBertModel.share_memory" class="function">share_memory</dd>
                <dd id="CokeBertModel.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="DKEncoder">
                            <input id="DKEncoder-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">DKEncoder</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="DKEncoder-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DKEncoder"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DKEncoder-361"><a href="#DKEncoder-361"><span class="linenos">361</span></a><span class="k">class</span> <span class="nc">DKEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="DKEncoder-362"><a href="#DKEncoder-362"><span class="linenos">362</span></a>    <span class="sd">&quot;&quot;&quot; A class for the Dynamic Knowledge Encoder for a `CokeBertModel`.</span>
</span><span id="DKEncoder-363"><a href="#DKEncoder-363"><span class="linenos">363</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="DKEncoder-364"><a href="#DKEncoder-364"><span class="linenos">364</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">no_layers</span><span class="p">):</span>
</span><span id="DKEncoder-365"><a href="#DKEncoder-365"><span class="linenos">365</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a Dynamic KnowledgeEncoder</span>
</span><span id="DKEncoder-366"><a href="#DKEncoder-366"><span class="linenos">366</span></a>
</span><span id="DKEncoder-367"><a href="#DKEncoder-367"><span class="linenos">367</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder-368"><a href="#DKEncoder-368"><span class="linenos">368</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DKEncoder-369"><a href="#DKEncoder-369"><span class="linenos">369</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="DKEncoder-370"><a href="#DKEncoder-370"><span class="linenos">370</span></a><span class="sd">            no_layers (int): Number of layers in the Dynamic Knowledge Encoder</span>
</span><span id="DKEncoder-371"><a href="#DKEncoder-371"><span class="linenos">371</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder-372"><a href="#DKEncoder-372"><span class="linenos">372</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DKEncoder-373"><a href="#DKEncoder-373"><span class="linenos">373</span></a>
</span><span id="DKEncoder-374"><a href="#DKEncoder-374"><span class="linenos">374</span></a>        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="DKEncoder-375"><a href="#DKEncoder-375"><span class="linenos">375</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">no_layers</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span><span id="DKEncoder-376"><a href="#DKEncoder-376"><span class="linenos">376</span></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DKEncoder_layer</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>
</span><span id="DKEncoder-377"><a href="#DKEncoder-377"><span class="linenos">377</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</span><span id="DKEncoder-378"><a href="#DKEncoder-378"><span class="linenos">378</span></a>
</span><span id="DKEncoder-379"><a href="#DKEncoder-379"><span class="linenos">379</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="DKEncoder-380"><a href="#DKEncoder-380"><span class="linenos">380</span></a>
</span><span id="DKEncoder-381"><a href="#DKEncoder-381"><span class="linenos">381</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">k_v_dim</span>
</span><span id="DKEncoder-382"><a href="#DKEncoder-382"><span class="linenos">382</span></a>
</span><span id="DKEncoder-383"><a href="#DKEncoder-383"><span class="linenos">383</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k_v_s</span><span class="p">):</span>
</span><span id="DKEncoder-384"><a href="#DKEncoder-384"><span class="linenos">384</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="DKEncoder-385"><a href="#DKEncoder-385"><span class="linenos">385</span></a><span class="sd">        Forward pass through the Dynamic Knowledge Encoder</span>
</span><span id="DKEncoder-386"><a href="#DKEncoder-386"><span class="linenos">386</span></a>
</span><span id="DKEncoder-387"><a href="#DKEncoder-387"><span class="linenos">387</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder-388"><a href="#DKEncoder-388"><span class="linenos">388</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="DKEncoder-389"><a href="#DKEncoder-389"><span class="linenos">389</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="DKEncoder-390"><a href="#DKEncoder-390"><span class="linenos">390</span></a><span class="sd">            q: the full sequence of hidden-states corresponding</span>
</span><span id="DKEncoder-391"><a href="#DKEncoder-391"><span class="linenos">391</span></a><span class="sd">                to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </span>
</span><span id="DKEncoder-392"><a href="#DKEncoder-392"><span class="linenos">392</span></a><span class="sd">            k_v_s: list of (k, v) tuples of length `no_layers`, </span>
</span><span id="DKEncoder-393"><a href="#DKEncoder-393"><span class="linenos">393</span></a><span class="sd">                k, v are of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DKEncoder-394"><a href="#DKEncoder-394"><span class="linenos">394</span></a><span class="sd">        </span>
</span><span id="DKEncoder-395"><a href="#DKEncoder-395"><span class="linenos">395</span></a><span class="sd">        Returns:</span>
</span><span id="DKEncoder-396"><a href="#DKEncoder-396"><span class="linenos">396</span></a><span class="sd">            hidden_states_ent: internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</span>
</span><span id="DKEncoder-397"><a href="#DKEncoder-397"><span class="linenos">397</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder-398"><a href="#DKEncoder-398"><span class="linenos">398</span></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span> <span class="c1">#CLS token only</span>
</span><span id="DKEncoder-399"><a href="#DKEncoder-399"><span class="linenos">399</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
</span><span id="DKEncoder-400"><a href="#DKEncoder-400"><span class="linenos">400</span></a>            <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">k_v_s</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</span><span id="DKEncoder-401"><a href="#DKEncoder-401"><span class="linenos">401</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="DKEncoder-402"><a href="#DKEncoder-402"><span class="linenos">402</span></a>                <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="n">combined</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="DKEncoder-403"><a href="#DKEncoder-403"><span class="linenos">403</span></a>            <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="DKEncoder-404"><a href="#DKEncoder-404"><span class="linenos">404</span></a>            <span class="n">combined</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span><span id="DKEncoder-405"><a href="#DKEncoder-405"><span class="linenos">405</span></a>
</span><span id="DKEncoder-406"><a href="#DKEncoder-406"><span class="linenos">406</span></a>        <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span><span class="c1">#.cuda()</span>
</span><span id="DKEncoder-407"><a href="#DKEncoder-407"><span class="linenos">407</span></a>        <span class="n">ent_pos_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_ent</span><span class="p">)</span> <span class="c1"># id start from 0</span>
</span><span id="DKEncoder-408"><a href="#DKEncoder-408"><span class="linenos">408</span></a>
</span><span id="DKEncoder-409"><a href="#DKEncoder-409"><span class="linenos">409</span></a>        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span><span id="DKEncoder-410"><a href="#DKEncoder-410"><span class="linenos">410</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ent_pos_s</span><span class="p">[</span><span class="n">ent_pos_s</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">batch</span><span class="p">]):</span>
</span><span id="DKEncoder-411"><a href="#DKEncoder-411"><span class="linenos">411</span></a>                <span class="n">hidden_states_ent</span><span class="p">[</span><span class="n">batch</span><span class="p">][</span><span class="nb">int</span><span class="p">(</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">=</span> <span class="n">combined</span><span class="p">[</span><span class="n">batch</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
</span><span id="DKEncoder-412"><a href="#DKEncoder-412"><span class="linenos">412</span></a>
</span><span id="DKEncoder-413"><a href="#DKEncoder-413"><span class="linenos">413</span></a>        <span class="k">return</span> <span class="n">hidden_states_ent</span>
</span></pre></div>


            <div class="docstring"><p>A class for the Dynamic Knowledge Encoder for a <code><a href="#CokeBertModel">CokeBertModel</a></code>.</p>
</div>


                            <div id="DKEncoder.__init__" class="classattr">
                                        <input id="DKEncoder.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">DKEncoder</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">k_v_dim</span>, </span><span class="param"><span class="n">q_dim</span>, </span><span class="param"><span class="n">no_layers</span></span>)</span>

                <label class="view-source-button" for="DKEncoder.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DKEncoder.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DKEncoder.__init__-364"><a href="#DKEncoder.__init__-364"><span class="linenos">364</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">no_layers</span><span class="p">):</span>
</span><span id="DKEncoder.__init__-365"><a href="#DKEncoder.__init__-365"><span class="linenos">365</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a Dynamic KnowledgeEncoder</span>
</span><span id="DKEncoder.__init__-366"><a href="#DKEncoder.__init__-366"><span class="linenos">366</span></a>
</span><span id="DKEncoder.__init__-367"><a href="#DKEncoder.__init__-367"><span class="linenos">367</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder.__init__-368"><a href="#DKEncoder.__init__-368"><span class="linenos">368</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DKEncoder.__init__-369"><a href="#DKEncoder.__init__-369"><span class="linenos">369</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="DKEncoder.__init__-370"><a href="#DKEncoder.__init__-370"><span class="linenos">370</span></a><span class="sd">            no_layers (int): Number of layers in the Dynamic Knowledge Encoder</span>
</span><span id="DKEncoder.__init__-371"><a href="#DKEncoder.__init__-371"><span class="linenos">371</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder.__init__-372"><a href="#DKEncoder.__init__-372"><span class="linenos">372</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DKEncoder.__init__-373"><a href="#DKEncoder.__init__-373"><span class="linenos">373</span></a>
</span><span id="DKEncoder.__init__-374"><a href="#DKEncoder.__init__-374"><span class="linenos">374</span></a>        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="DKEncoder.__init__-375"><a href="#DKEncoder.__init__-375"><span class="linenos">375</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">no_layers</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span><span id="DKEncoder.__init__-376"><a href="#DKEncoder.__init__-376"><span class="linenos">376</span></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DKEncoder_layer</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>
</span><span id="DKEncoder.__init__-377"><a href="#DKEncoder.__init__-377"><span class="linenos">377</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</span><span id="DKEncoder.__init__-378"><a href="#DKEncoder.__init__-378"><span class="linenos">378</span></a>
</span><span id="DKEncoder.__init__-379"><a href="#DKEncoder.__init__-379"><span class="linenos">379</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="DKEncoder.__init__-380"><a href="#DKEncoder.__init__-380"><span class="linenos">380</span></a>
</span><span id="DKEncoder.__init__-381"><a href="#DKEncoder.__init__-381"><span class="linenos">381</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span> <span class="o">=</span> <span class="n">k_v_dim</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a Dynamic KnowledgeEncoder</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>
<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>
<li><strong>no_layers (int):</strong>  Number of layers in the Dynamic Knowledge Encoder</li>
</ul>
</div>


                            </div>
                            <div id="DKEncoder.forward" class="classattr">
                                        <input id="DKEncoder.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">input_ent</span>, </span><span class="param"><span class="n">q</span>, </span><span class="param"><span class="n">k_v_s</span></span>)</span>

                <label class="view-source-button" for="DKEncoder.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DKEncoder.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DKEncoder.forward-383"><a href="#DKEncoder.forward-383"><span class="linenos">383</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ent</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k_v_s</span><span class="p">):</span>
</span><span id="DKEncoder.forward-384"><a href="#DKEncoder.forward-384"><span class="linenos">384</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="DKEncoder.forward-385"><a href="#DKEncoder.forward-385"><span class="linenos">385</span></a><span class="sd">        Forward pass through the Dynamic Knowledge Encoder</span>
</span><span id="DKEncoder.forward-386"><a href="#DKEncoder.forward-386"><span class="linenos">386</span></a>
</span><span id="DKEncoder.forward-387"><a href="#DKEncoder.forward-387"><span class="linenos">387</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder.forward-388"><a href="#DKEncoder.forward-388"><span class="linenos">388</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="DKEncoder.forward-389"><a href="#DKEncoder.forward-389"><span class="linenos">389</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="DKEncoder.forward-390"><a href="#DKEncoder.forward-390"><span class="linenos">390</span></a><span class="sd">            q: the full sequence of hidden-states corresponding</span>
</span><span id="DKEncoder.forward-391"><a href="#DKEncoder.forward-391"><span class="linenos">391</span></a><span class="sd">                to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </span>
</span><span id="DKEncoder.forward-392"><a href="#DKEncoder.forward-392"><span class="linenos">392</span></a><span class="sd">            k_v_s: list of (k, v) tuples of length `no_layers`, </span>
</span><span id="DKEncoder.forward-393"><a href="#DKEncoder.forward-393"><span class="linenos">393</span></a><span class="sd">                k, v are of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DKEncoder.forward-394"><a href="#DKEncoder.forward-394"><span class="linenos">394</span></a><span class="sd">        </span>
</span><span id="DKEncoder.forward-395"><a href="#DKEncoder.forward-395"><span class="linenos">395</span></a><span class="sd">        Returns:</span>
</span><span id="DKEncoder.forward-396"><a href="#DKEncoder.forward-396"><span class="linenos">396</span></a><span class="sd">            hidden_states_ent: internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</span>
</span><span id="DKEncoder.forward-397"><a href="#DKEncoder.forward-397"><span class="linenos">397</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder.forward-398"><a href="#DKEncoder.forward-398"><span class="linenos">398</span></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,:]</span> <span class="c1">#CLS token only</span>
</span><span id="DKEncoder.forward-399"><a href="#DKEncoder.forward-399"><span class="linenos">399</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
</span><span id="DKEncoder.forward-400"><a href="#DKEncoder.forward-400"><span class="linenos">400</span></a>            <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">k_v_s</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
</span><span id="DKEncoder.forward-401"><a href="#DKEncoder.forward-401"><span class="linenos">401</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="DKEncoder.forward-402"><a href="#DKEncoder.forward-402"><span class="linenos">402</span></a>                <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="n">combined</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="DKEncoder.forward-403"><a href="#DKEncoder.forward-403"><span class="linenos">403</span></a>            <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="DKEncoder.forward-404"><a href="#DKEncoder.forward-404"><span class="linenos">404</span></a>            <span class="n">combined</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span><span id="DKEncoder.forward-405"><a href="#DKEncoder.forward-405"><span class="linenos">405</span></a>
</span><span id="DKEncoder.forward-406"><a href="#DKEncoder.forward-406"><span class="linenos">406</span></a>        <span class="n">hidden_states_ent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_v_dim</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span><span class="c1">#.cuda()</span>
</span><span id="DKEncoder.forward-407"><a href="#DKEncoder.forward-407"><span class="linenos">407</span></a>        <span class="n">ent_pos_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">input_ent</span><span class="p">)</span> <span class="c1"># id start from 0</span>
</span><span id="DKEncoder.forward-408"><a href="#DKEncoder.forward-408"><span class="linenos">408</span></a>
</span><span id="DKEncoder.forward-409"><a href="#DKEncoder.forward-409"><span class="linenos">409</span></a>        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_ent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span><span id="DKEncoder.forward-410"><a href="#DKEncoder.forward-410"><span class="linenos">410</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ent_pos_s</span><span class="p">[</span><span class="n">ent_pos_s</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">batch</span><span class="p">]):</span>
</span><span id="DKEncoder.forward-411"><a href="#DKEncoder.forward-411"><span class="linenos">411</span></a>                <span class="n">hidden_states_ent</span><span class="p">[</span><span class="n">batch</span><span class="p">][</span><span class="nb">int</span><span class="p">(</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">=</span> <span class="n">combined</span><span class="p">[</span><span class="n">batch</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
</span><span id="DKEncoder.forward-412"><a href="#DKEncoder.forward-412"><span class="linenos">412</span></a>
</span><span id="DKEncoder.forward-413"><a href="#DKEncoder.forward-413"><span class="linenos">413</span></a>        <span class="k">return</span> <span class="n">hidden_states_ent</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the Dynamic Knowledge Encoder</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong>q:</strong>  the full sequence of hidden-states corresponding
to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </li>
<li><strong>k_v_s:</strong>  list of (k, v) tuples of length <code>no_layers</code>, 
k, v are of shape [batch_size, sequence_length, k_v_dim]</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>hidden_states_ent: internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="DKEncoder.dump_patches" class="variable">dump_patches</dd>
                <dd id="DKEncoder.register_buffer" class="function">register_buffer</dd>
                <dd id="DKEncoder.register_parameter" class="function">register_parameter</dd>
                <dd id="DKEncoder.add_module" class="function">add_module</dd>
                <dd id="DKEncoder.register_module" class="function">register_module</dd>
                <dd id="DKEncoder.get_submodule" class="function">get_submodule</dd>
                <dd id="DKEncoder.get_parameter" class="function">get_parameter</dd>
                <dd id="DKEncoder.get_buffer" class="function">get_buffer</dd>
                <dd id="DKEncoder.get_extra_state" class="function">get_extra_state</dd>
                <dd id="DKEncoder.set_extra_state" class="function">set_extra_state</dd>
                <dd id="DKEncoder.apply" class="function">apply</dd>
                <dd id="DKEncoder.cuda" class="function">cuda</dd>
                <dd id="DKEncoder.xpu" class="function">xpu</dd>
                <dd id="DKEncoder.cpu" class="function">cpu</dd>
                <dd id="DKEncoder.type" class="function">type</dd>
                <dd id="DKEncoder.float" class="function">float</dd>
                <dd id="DKEncoder.double" class="function">double</dd>
                <dd id="DKEncoder.half" class="function">half</dd>
                <dd id="DKEncoder.bfloat16" class="function">bfloat16</dd>
                <dd id="DKEncoder.to_empty" class="function">to_empty</dd>
                <dd id="DKEncoder.to" class="function">to</dd>
                <dd id="DKEncoder.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="DKEncoder.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="DKEncoder.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="DKEncoder.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="DKEncoder.T_destination" class="variable">T_destination</dd>
                <dd id="DKEncoder.state_dict" class="function">state_dict</dd>
                <dd id="DKEncoder.load_state_dict" class="function">load_state_dict</dd>
                <dd id="DKEncoder.parameters" class="function">parameters</dd>
                <dd id="DKEncoder.named_parameters" class="function">named_parameters</dd>
                <dd id="DKEncoder.buffers" class="function">buffers</dd>
                <dd id="DKEncoder.named_buffers" class="function">named_buffers</dd>
                <dd id="DKEncoder.children" class="function">children</dd>
                <dd id="DKEncoder.named_children" class="function">named_children</dd>
                <dd id="DKEncoder.modules" class="function">modules</dd>
                <dd id="DKEncoder.named_modules" class="function">named_modules</dd>
                <dd id="DKEncoder.train" class="function">train</dd>
                <dd id="DKEncoder.eval" class="function">eval</dd>
                <dd id="DKEncoder.requires_grad_" class="function">requires_grad_</dd>
                <dd id="DKEncoder.zero_grad" class="function">zero_grad</dd>
                <dd id="DKEncoder.share_memory" class="function">share_memory</dd>
                <dd id="DKEncoder.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="DKEncoder_layer">
                            <input id="DKEncoder_layer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">DKEncoder_layer</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="DKEncoder_layer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DKEncoder_layer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DKEncoder_layer-415"><a href="#DKEncoder_layer-415"><span class="linenos">415</span></a><span class="k">class</span> <span class="nc">DKEncoder_layer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="DKEncoder_layer-416"><a href="#DKEncoder_layer-416"><span class="linenos">416</span></a>    <span class="sd">&quot;&quot;&quot; A class for one Dynamic Knowledge Encoder Layer for a `DKEncoder` from CokeBert.</span>
</span><span id="DKEncoder_layer-417"><a href="#DKEncoder_layer-417"><span class="linenos">417</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="DKEncoder_layer-418"><a href="#DKEncoder_layer-418"><span class="linenos">418</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">):</span>
</span><span id="DKEncoder_layer-419"><a href="#DKEncoder_layer-419"><span class="linenos">419</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DKEncoder_layer`.</span>
</span><span id="DKEncoder_layer-420"><a href="#DKEncoder_layer-420"><span class="linenos">420</span></a><span class="sd">        </span>
</span><span id="DKEncoder_layer-421"><a href="#DKEncoder_layer-421"><span class="linenos">421</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder_layer-422"><a href="#DKEncoder_layer-422"><span class="linenos">422</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DKEncoder_layer-423"><a href="#DKEncoder_layer-423"><span class="linenos">423</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="DKEncoder_layer-424"><a href="#DKEncoder_layer-424"><span class="linenos">424</span></a><span class="sd">            layer_no (int): Number of the layer (assigned in reverse order)</span>
</span><span id="DKEncoder_layer-425"><a href="#DKEncoder_layer-425"><span class="linenos">425</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder_layer-426"><a href="#DKEncoder_layer-426"><span class="linenos">426</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DKEncoder_layer-427"><a href="#DKEncoder_layer-427"><span class="linenos">427</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">DK_text</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">)</span>
</span><span id="DKEncoder_layer-428"><a href="#DKEncoder_layer-428"><span class="linenos">428</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">knowledge</span> <span class="o">=</span> <span class="n">DK_knowledge</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">)</span>
</span><span id="DKEncoder_layer-429"><a href="#DKEncoder_layer-429"><span class="linenos">429</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">DK_fusion</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">)</span>
</span><span id="DKEncoder_layer-430"><a href="#DKEncoder_layer-430"><span class="linenos">430</span></a>
</span><span id="DKEncoder_layer-431"><a href="#DKEncoder_layer-431"><span class="linenos">431</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
</span><span id="DKEncoder_layer-432"><a href="#DKEncoder_layer-432"><span class="linenos">432</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="DKEncoder_layer-433"><a href="#DKEncoder_layer-433"><span class="linenos">433</span></a><span class="sd">        Forward pass through the Dynamic Knowledge Encoder layer</span>
</span><span id="DKEncoder_layer-434"><a href="#DKEncoder_layer-434"><span class="linenos">434</span></a>
</span><span id="DKEncoder_layer-435"><a href="#DKEncoder_layer-435"><span class="linenos">435</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder_layer-436"><a href="#DKEncoder_layer-436"><span class="linenos">436</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="DKEncoder_layer-437"><a href="#DKEncoder_layer-437"><span class="linenos">437</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="DKEncoder_layer-438"><a href="#DKEncoder_layer-438"><span class="linenos">438</span></a><span class="sd">            q: the representation of hidden-states corresponding</span>
</span><span id="DKEncoder_layer-439"><a href="#DKEncoder_layer-439"><span class="linenos">439</span></a><span class="sd">                to the last text-attention block of shape [batch_size, 1, q_dim] </span>
</span><span id="DKEncoder_layer-440"><a href="#DKEncoder_layer-440"><span class="linenos">440</span></a><span class="sd">            k: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DKEncoder_layer-441"><a href="#DKEncoder_layer-441"><span class="linenos">441</span></a><span class="sd">            v: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DKEncoder_layer-442"><a href="#DKEncoder_layer-442"><span class="linenos">442</span></a><span class="sd">        </span>
</span><span id="DKEncoder_layer-443"><a href="#DKEncoder_layer-443"><span class="linenos">443</span></a><span class="sd">        Returns:</span>
</span><span id="DKEncoder_layer-444"><a href="#DKEncoder_layer-444"><span class="linenos">444</span></a><span class="sd">            internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</span>
</span><span id="DKEncoder_layer-445"><a href="#DKEncoder_layer-445"><span class="linenos">445</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder_layer-446"><a href="#DKEncoder_layer-446"><span class="linenos">446</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
</span><span id="DKEncoder_layer-447"><a href="#DKEncoder_layer-447"><span class="linenos">447</span></a>        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">knowledge</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span><span id="DKEncoder_layer-448"><a href="#DKEncoder_layer-448"><span class="linenos">448</span></a>
</span><span id="DKEncoder_layer-449"><a href="#DKEncoder_layer-449"><span class="linenos">449</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">q_i</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class for one Dynamic Knowledge Encoder Layer for a <code><a href="#DKEncoder">DKEncoder</a></code> from CokeBert.</p>
</div>


                            <div id="DKEncoder_layer.__init__" class="classattr">
                                        <input id="DKEncoder_layer.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">DKEncoder_layer</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">k_v_dim</span>, </span><span class="param"><span class="n">q_dim</span>, </span><span class="param"><span class="n">layer_no</span></span>)</span>

                <label class="view-source-button" for="DKEncoder_layer.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DKEncoder_layer.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DKEncoder_layer.__init__-418"><a href="#DKEncoder_layer.__init__-418"><span class="linenos">418</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">):</span>
</span><span id="DKEncoder_layer.__init__-419"><a href="#DKEncoder_layer.__init__-419"><span class="linenos">419</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DKEncoder_layer`.</span>
</span><span id="DKEncoder_layer.__init__-420"><a href="#DKEncoder_layer.__init__-420"><span class="linenos">420</span></a><span class="sd">        </span>
</span><span id="DKEncoder_layer.__init__-421"><a href="#DKEncoder_layer.__init__-421"><span class="linenos">421</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder_layer.__init__-422"><a href="#DKEncoder_layer.__init__-422"><span class="linenos">422</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DKEncoder_layer.__init__-423"><a href="#DKEncoder_layer.__init__-423"><span class="linenos">423</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="DKEncoder_layer.__init__-424"><a href="#DKEncoder_layer.__init__-424"><span class="linenos">424</span></a><span class="sd">            layer_no (int): Number of the layer (assigned in reverse order)</span>
</span><span id="DKEncoder_layer.__init__-425"><a href="#DKEncoder_layer.__init__-425"><span class="linenos">425</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder_layer.__init__-426"><a href="#DKEncoder_layer.__init__-426"><span class="linenos">426</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DKEncoder_layer.__init__-427"><a href="#DKEncoder_layer.__init__-427"><span class="linenos">427</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">DK_text</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">)</span>
</span><span id="DKEncoder_layer.__init__-428"><a href="#DKEncoder_layer.__init__-428"><span class="linenos">428</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">knowledge</span> <span class="o">=</span> <span class="n">DK_knowledge</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">)</span>
</span><span id="DKEncoder_layer.__init__-429"><a href="#DKEncoder_layer.__init__-429"><span class="linenos">429</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">DK_fusion</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a <code><a href="#DKEncoder_layer">DKEncoder_layer</a></code>.</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>
<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>
<li><strong>layer_no (int):</strong>  Number of the layer (assigned in reverse order)</li>
</ul>
</div>


                            </div>
                            <div id="DKEncoder_layer.forward" class="classattr">
                                        <input id="DKEncoder_layer.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">q</span>, </span><span class="param"><span class="n">k</span>, </span><span class="param"><span class="n">v</span></span>)</span>

                <label class="view-source-button" for="DKEncoder_layer.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DKEncoder_layer.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DKEncoder_layer.forward-431"><a href="#DKEncoder_layer.forward-431"><span class="linenos">431</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
</span><span id="DKEncoder_layer.forward-432"><a href="#DKEncoder_layer.forward-432"><span class="linenos">432</span></a>        <span class="sd">&quot;&quot;&quot;</span>
</span><span id="DKEncoder_layer.forward-433"><a href="#DKEncoder_layer.forward-433"><span class="linenos">433</span></a><span class="sd">        Forward pass through the Dynamic Knowledge Encoder layer</span>
</span><span id="DKEncoder_layer.forward-434"><a href="#DKEncoder_layer.forward-434"><span class="linenos">434</span></a>
</span><span id="DKEncoder_layer.forward-435"><a href="#DKEncoder_layer.forward-435"><span class="linenos">435</span></a><span class="sd">        Args:</span>
</span><span id="DKEncoder_layer.forward-436"><a href="#DKEncoder_layer.forward-436"><span class="linenos">436</span></a><span class="sd">            input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="DKEncoder_layer.forward-437"><a href="#DKEncoder_layer.forward-437"><span class="linenos">437</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="DKEncoder_layer.forward-438"><a href="#DKEncoder_layer.forward-438"><span class="linenos">438</span></a><span class="sd">            q: the representation of hidden-states corresponding</span>
</span><span id="DKEncoder_layer.forward-439"><a href="#DKEncoder_layer.forward-439"><span class="linenos">439</span></a><span class="sd">                to the last text-attention block of shape [batch_size, 1, q_dim] </span>
</span><span id="DKEncoder_layer.forward-440"><a href="#DKEncoder_layer.forward-440"><span class="linenos">440</span></a><span class="sd">            k: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DKEncoder_layer.forward-441"><a href="#DKEncoder_layer.forward-441"><span class="linenos">441</span></a><span class="sd">            v: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DKEncoder_layer.forward-442"><a href="#DKEncoder_layer.forward-442"><span class="linenos">442</span></a><span class="sd">        </span>
</span><span id="DKEncoder_layer.forward-443"><a href="#DKEncoder_layer.forward-443"><span class="linenos">443</span></a><span class="sd">        Returns:</span>
</span><span id="DKEncoder_layer.forward-444"><a href="#DKEncoder_layer.forward-444"><span class="linenos">444</span></a><span class="sd">            internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</span>
</span><span id="DKEncoder_layer.forward-445"><a href="#DKEncoder_layer.forward-445"><span class="linenos">445</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DKEncoder_layer.forward-446"><a href="#DKEncoder_layer.forward-446"><span class="linenos">446</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
</span><span id="DKEncoder_layer.forward-447"><a href="#DKEncoder_layer.forward-447"><span class="linenos">447</span></a>        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">knowledge</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span><span id="DKEncoder_layer.forward-448"><a href="#DKEncoder_layer.forward-448"><span class="linenos">448</span></a>
</span><span id="DKEncoder_layer.forward-449"><a href="#DKEncoder_layer.forward-449"><span class="linenos">449</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">q_i</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the Dynamic Knowledge Encoder layer</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong>q:</strong>  the representation of hidden-states corresponding
to the last text-attention block of shape [batch_size, 1, q_dim] </li>
<li><strong>k:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>
<li><strong>v:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="DKEncoder_layer.dump_patches" class="variable">dump_patches</dd>
                <dd id="DKEncoder_layer.register_buffer" class="function">register_buffer</dd>
                <dd id="DKEncoder_layer.register_parameter" class="function">register_parameter</dd>
                <dd id="DKEncoder_layer.add_module" class="function">add_module</dd>
                <dd id="DKEncoder_layer.register_module" class="function">register_module</dd>
                <dd id="DKEncoder_layer.get_submodule" class="function">get_submodule</dd>
                <dd id="DKEncoder_layer.get_parameter" class="function">get_parameter</dd>
                <dd id="DKEncoder_layer.get_buffer" class="function">get_buffer</dd>
                <dd id="DKEncoder_layer.get_extra_state" class="function">get_extra_state</dd>
                <dd id="DKEncoder_layer.set_extra_state" class="function">set_extra_state</dd>
                <dd id="DKEncoder_layer.apply" class="function">apply</dd>
                <dd id="DKEncoder_layer.cuda" class="function">cuda</dd>
                <dd id="DKEncoder_layer.xpu" class="function">xpu</dd>
                <dd id="DKEncoder_layer.cpu" class="function">cpu</dd>
                <dd id="DKEncoder_layer.type" class="function">type</dd>
                <dd id="DKEncoder_layer.float" class="function">float</dd>
                <dd id="DKEncoder_layer.double" class="function">double</dd>
                <dd id="DKEncoder_layer.half" class="function">half</dd>
                <dd id="DKEncoder_layer.bfloat16" class="function">bfloat16</dd>
                <dd id="DKEncoder_layer.to_empty" class="function">to_empty</dd>
                <dd id="DKEncoder_layer.to" class="function">to</dd>
                <dd id="DKEncoder_layer.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="DKEncoder_layer.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="DKEncoder_layer.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="DKEncoder_layer.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="DKEncoder_layer.T_destination" class="variable">T_destination</dd>
                <dd id="DKEncoder_layer.state_dict" class="function">state_dict</dd>
                <dd id="DKEncoder_layer.load_state_dict" class="function">load_state_dict</dd>
                <dd id="DKEncoder_layer.parameters" class="function">parameters</dd>
                <dd id="DKEncoder_layer.named_parameters" class="function">named_parameters</dd>
                <dd id="DKEncoder_layer.buffers" class="function">buffers</dd>
                <dd id="DKEncoder_layer.named_buffers" class="function">named_buffers</dd>
                <dd id="DKEncoder_layer.children" class="function">children</dd>
                <dd id="DKEncoder_layer.named_children" class="function">named_children</dd>
                <dd id="DKEncoder_layer.modules" class="function">modules</dd>
                <dd id="DKEncoder_layer.named_modules" class="function">named_modules</dd>
                <dd id="DKEncoder_layer.train" class="function">train</dd>
                <dd id="DKEncoder_layer.eval" class="function">eval</dd>
                <dd id="DKEncoder_layer.requires_grad_" class="function">requires_grad_</dd>
                <dd id="DKEncoder_layer.zero_grad" class="function">zero_grad</dd>
                <dd id="DKEncoder_layer.share_memory" class="function">share_memory</dd>
                <dd id="DKEncoder_layer.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="DK_text">
                            <input id="DK_text-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">DK_text</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="DK_text-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DK_text"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DK_text-451"><a href="#DK_text-451"><span class="linenos">451</span></a><span class="k">class</span> <span class="nc">DK_text</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="DK_text-452"><a href="#DK_text-452"><span class="linenos">452</span></a>    <span class="sd">&quot;&quot;&quot; A class for the Text Processing in a `DKEncoderLayer` from CokeBert.</span>
</span><span id="DK_text-453"><a href="#DK_text-453"><span class="linenos">453</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="DK_text-454"><a href="#DK_text-454"><span class="linenos">454</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">):</span>
</span><span id="DK_text-455"><a href="#DK_text-455"><span class="linenos">455</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DK_text` module</span>
</span><span id="DK_text-456"><a href="#DK_text-456"><span class="linenos">456</span></a><span class="sd">        </span>
</span><span id="DK_text-457"><a href="#DK_text-457"><span class="linenos">457</span></a><span class="sd">        Args:</span>
</span><span id="DK_text-458"><a href="#DK_text-458"><span class="linenos">458</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DK_text-459"><a href="#DK_text-459"><span class="linenos">459</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="DK_text-460"><a href="#DK_text-460"><span class="linenos">460</span></a><span class="sd">            layer_no (int): Number of the layer (assigned in reverse order)</span>
</span><span id="DK_text-461"><a href="#DK_text-461"><span class="linenos">461</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_text-462"><a href="#DK_text-462"><span class="linenos">462</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DK_text-463"><a href="#DK_text-463"><span class="linenos">463</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">q_dim</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="DK_text-464"><a href="#DK_text-464"><span class="linenos">464</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="DK_text-465"><a href="#DK_text-465"><span class="linenos">465</span></a>
</span><span id="DK_text-466"><a href="#DK_text-466"><span class="linenos">466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">number</span> <span class="o">=</span> <span class="n">layer_no</span>
</span><span id="DK_text-467"><a href="#DK_text-467"><span class="linenos">467</span></a>
</span><span id="DK_text-468"><a href="#DK_text-468"><span class="linenos">468</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
</span><span id="DK_text-469"><a href="#DK_text-469"><span class="linenos">469</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the Text Processing Module of a Dynamic Knowledge Encoder layer</span>
</span><span id="DK_text-470"><a href="#DK_text-470"><span class="linenos">470</span></a><span class="sd">        </span>
</span><span id="DK_text-471"><a href="#DK_text-471"><span class="linenos">471</span></a><span class="sd">        Args:</span>
</span><span id="DK_text-472"><a href="#DK_text-472"><span class="linenos">472</span></a><span class="sd">            q: the full sequence of hidden-states corresponding</span>
</span><span id="DK_text-473"><a href="#DK_text-473"><span class="linenos">473</span></a><span class="sd">                to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </span>
</span><span id="DK_text-474"><a href="#DK_text-474"><span class="linenos">474</span></a>
</span><span id="DK_text-475"><a href="#DK_text-475"><span class="linenos">475</span></a><span class="sd">        Returns:</span>
</span><span id="DK_text-476"><a href="#DK_text-476"><span class="linenos">476</span></a><span class="sd">            q_i: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DK_text-477"><a href="#DK_text-477"><span class="linenos">477</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_text-478"><a href="#DK_text-478"><span class="linenos">478</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
</span><span id="DK_text-479"><a href="#DK_text-479"><span class="linenos">479</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">q_i</span><span class="p">)</span>
</span><span id="DK_text-480"><a href="#DK_text-480"><span class="linenos">480</span></a>
</span><span id="DK_text-481"><a href="#DK_text-481"><span class="linenos">481</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">number</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span>
</span><span id="DK_text-482"><a href="#DK_text-482"><span class="linenos">482</span></a>            <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_i</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span id="DK_text-483"><a href="#DK_text-483"><span class="linenos">483</span></a>
</span><span id="DK_text-484"><a href="#DK_text-484"><span class="linenos">484</span></a>        <span class="k">return</span> <span class="n">q_i</span>
</span></pre></div>


            <div class="docstring"><p>A class for the Text Processing in a <code>DKEncoderLayer</code> from CokeBert.</p>
</div>


                            <div id="DK_text.__init__" class="classattr">
                                        <input id="DK_text.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">DK_text</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">k_v_dim</span>, </span><span class="param"><span class="n">q_dim</span>, </span><span class="param"><span class="n">layer_no</span></span>)</span>

                <label class="view-source-button" for="DK_text.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DK_text.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DK_text.__init__-454"><a href="#DK_text.__init__-454"><span class="linenos">454</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">q_dim</span><span class="p">,</span> <span class="n">layer_no</span><span class="p">):</span>
</span><span id="DK_text.__init__-455"><a href="#DK_text.__init__-455"><span class="linenos">455</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DK_text` module</span>
</span><span id="DK_text.__init__-456"><a href="#DK_text.__init__-456"><span class="linenos">456</span></a><span class="sd">        </span>
</span><span id="DK_text.__init__-457"><a href="#DK_text.__init__-457"><span class="linenos">457</span></a><span class="sd">        Args:</span>
</span><span id="DK_text.__init__-458"><a href="#DK_text.__init__-458"><span class="linenos">458</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DK_text.__init__-459"><a href="#DK_text.__init__-459"><span class="linenos">459</span></a><span class="sd">            q_dim (int): size of the q vector (Internal Text Representation)</span>
</span><span id="DK_text.__init__-460"><a href="#DK_text.__init__-460"><span class="linenos">460</span></a><span class="sd">            layer_no (int): Number of the layer (assigned in reverse order)</span>
</span><span id="DK_text.__init__-461"><a href="#DK_text.__init__-461"><span class="linenos">461</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_text.__init__-462"><a href="#DK_text.__init__-462"><span class="linenos">462</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DK_text.__init__-463"><a href="#DK_text.__init__-463"><span class="linenos">463</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">q_dim</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="DK_text.__init__-464"><a href="#DK_text.__init__-464"><span class="linenos">464</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="DK_text.__init__-465"><a href="#DK_text.__init__-465"><span class="linenos">465</span></a>
</span><span id="DK_text.__init__-466"><a href="#DK_text.__init__-466"><span class="linenos">466</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">number</span> <span class="o">=</span> <span class="n">layer_no</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a <code><a href="#DK_text">DK_text</a></code> module</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>
<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>
<li><strong>layer_no (int):</strong>  Number of the layer (assigned in reverse order)</li>
</ul>
</div>


                            </div>
                            <div id="DK_text.forward" class="classattr">
                                        <input id="DK_text.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">q</span></span>)</span>

                <label class="view-source-button" for="DK_text.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DK_text.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DK_text.forward-468"><a href="#DK_text.forward-468"><span class="linenos">468</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
</span><span id="DK_text.forward-469"><a href="#DK_text.forward-469"><span class="linenos">469</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the Text Processing Module of a Dynamic Knowledge Encoder layer</span>
</span><span id="DK_text.forward-470"><a href="#DK_text.forward-470"><span class="linenos">470</span></a><span class="sd">        </span>
</span><span id="DK_text.forward-471"><a href="#DK_text.forward-471"><span class="linenos">471</span></a><span class="sd">        Args:</span>
</span><span id="DK_text.forward-472"><a href="#DK_text.forward-472"><span class="linenos">472</span></a><span class="sd">            q: the full sequence of hidden-states corresponding</span>
</span><span id="DK_text.forward-473"><a href="#DK_text.forward-473"><span class="linenos">473</span></a><span class="sd">                to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </span>
</span><span id="DK_text.forward-474"><a href="#DK_text.forward-474"><span class="linenos">474</span></a>
</span><span id="DK_text.forward-475"><a href="#DK_text.forward-475"><span class="linenos">475</span></a><span class="sd">        Returns:</span>
</span><span id="DK_text.forward-476"><a href="#DK_text.forward-476"><span class="linenos">476</span></a><span class="sd">            q_i: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DK_text.forward-477"><a href="#DK_text.forward-477"><span class="linenos">477</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_text.forward-478"><a href="#DK_text.forward-478"><span class="linenos">478</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
</span><span id="DK_text.forward-479"><a href="#DK_text.forward-479"><span class="linenos">479</span></a>        <span class="n">q_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">q_i</span><span class="p">)</span>
</span><span id="DK_text.forward-480"><a href="#DK_text.forward-480"><span class="linenos">480</span></a>
</span><span id="DK_text.forward-481"><a href="#DK_text.forward-481"><span class="linenos">481</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">number</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span>
</span><span id="DK_text.forward-482"><a href="#DK_text.forward-482"><span class="linenos">482</span></a>            <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_i</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span id="DK_text.forward-483"><a href="#DK_text.forward-483"><span class="linenos">483</span></a>
</span><span id="DK_text.forward-484"><a href="#DK_text.forward-484"><span class="linenos">484</span></a>        <span class="k">return</span> <span class="n">q_i</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the Text Processing Module of a Dynamic Knowledge Encoder layer</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>q:</strong>  the full sequence of hidden-states corresponding
to the last text-attention block of shape [batch_size, sequence_length, hidden_size] </li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>q_i: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="DK_text.dump_patches" class="variable">dump_patches</dd>
                <dd id="DK_text.register_buffer" class="function">register_buffer</dd>
                <dd id="DK_text.register_parameter" class="function">register_parameter</dd>
                <dd id="DK_text.add_module" class="function">add_module</dd>
                <dd id="DK_text.register_module" class="function">register_module</dd>
                <dd id="DK_text.get_submodule" class="function">get_submodule</dd>
                <dd id="DK_text.get_parameter" class="function">get_parameter</dd>
                <dd id="DK_text.get_buffer" class="function">get_buffer</dd>
                <dd id="DK_text.get_extra_state" class="function">get_extra_state</dd>
                <dd id="DK_text.set_extra_state" class="function">set_extra_state</dd>
                <dd id="DK_text.apply" class="function">apply</dd>
                <dd id="DK_text.cuda" class="function">cuda</dd>
                <dd id="DK_text.xpu" class="function">xpu</dd>
                <dd id="DK_text.cpu" class="function">cpu</dd>
                <dd id="DK_text.type" class="function">type</dd>
                <dd id="DK_text.float" class="function">float</dd>
                <dd id="DK_text.double" class="function">double</dd>
                <dd id="DK_text.half" class="function">half</dd>
                <dd id="DK_text.bfloat16" class="function">bfloat16</dd>
                <dd id="DK_text.to_empty" class="function">to_empty</dd>
                <dd id="DK_text.to" class="function">to</dd>
                <dd id="DK_text.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="DK_text.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="DK_text.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="DK_text.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="DK_text.T_destination" class="variable">T_destination</dd>
                <dd id="DK_text.state_dict" class="function">state_dict</dd>
                <dd id="DK_text.load_state_dict" class="function">load_state_dict</dd>
                <dd id="DK_text.parameters" class="function">parameters</dd>
                <dd id="DK_text.named_parameters" class="function">named_parameters</dd>
                <dd id="DK_text.buffers" class="function">buffers</dd>
                <dd id="DK_text.named_buffers" class="function">named_buffers</dd>
                <dd id="DK_text.children" class="function">children</dd>
                <dd id="DK_text.named_children" class="function">named_children</dd>
                <dd id="DK_text.modules" class="function">modules</dd>
                <dd id="DK_text.named_modules" class="function">named_modules</dd>
                <dd id="DK_text.train" class="function">train</dd>
                <dd id="DK_text.eval" class="function">eval</dd>
                <dd id="DK_text.requires_grad_" class="function">requires_grad_</dd>
                <dd id="DK_text.zero_grad" class="function">zero_grad</dd>
                <dd id="DK_text.share_memory" class="function">share_memory</dd>
                <dd id="DK_text.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="DK_knowledge">
                            <input id="DK_knowledge-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">DK_knowledge</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="DK_knowledge-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DK_knowledge"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DK_knowledge-486"><a href="#DK_knowledge-486"><span class="linenos">486</span></a><span class="k">class</span> <span class="nc">DK_knowledge</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="DK_knowledge-487"><a href="#DK_knowledge-487"><span class="linenos">487</span></a>    <span class="sd">&quot;&quot;&quot; A class for the Knowledge Processing in a `DKEncoderLayer` from CokeBert.&quot;&quot;&quot;</span>
</span><span id="DK_knowledge-488"><a href="#DK_knowledge-488"><span class="linenos">488</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">):</span>
</span><span id="DK_knowledge-489"><a href="#DK_knowledge-489"><span class="linenos">489</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DK_knowledge` module</span>
</span><span id="DK_knowledge-490"><a href="#DK_knowledge-490"><span class="linenos">490</span></a>
</span><span id="DK_knowledge-491"><a href="#DK_knowledge-491"><span class="linenos">491</span></a><span class="sd">        Args:</span>
</span><span id="DK_knowledge-492"><a href="#DK_knowledge-492"><span class="linenos">492</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DK_knowledge-493"><a href="#DK_knowledge-493"><span class="linenos">493</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_knowledge-494"><a href="#DK_knowledge-494"><span class="linenos">494</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DK_knowledge-495"><a href="#DK_knowledge-495"><span class="linenos">495</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="DK_knowledge-496"><a href="#DK_knowledge-496"><span class="linenos">496</span></a>    
</span><span id="DK_knowledge-497"><a href="#DK_knowledge-497"><span class="linenos">497</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span id="DK_knowledge-498"><a href="#DK_knowledge-498"><span class="linenos">498</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the Knowledge Processing Module of a Dynamic Knowledge Encoder layer</span>
</span><span id="DK_knowledge-499"><a href="#DK_knowledge-499"><span class="linenos">499</span></a><span class="sd">        </span>
</span><span id="DK_knowledge-500"><a href="#DK_knowledge-500"><span class="linenos">500</span></a><span class="sd">        Args:</span>
</span><span id="DK_knowledge-501"><a href="#DK_knowledge-501"><span class="linenos">501</span></a><span class="sd">            k: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DK_knowledge-502"><a href="#DK_knowledge-502"><span class="linenos">502</span></a>
</span><span id="DK_knowledge-503"><a href="#DK_knowledge-503"><span class="linenos">503</span></a><span class="sd">        Returns:</span>
</span><span id="DK_knowledge-504"><a href="#DK_knowledge-504"><span class="linenos">504</span></a><span class="sd">            hidden knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DK_knowledge-505"><a href="#DK_knowledge-505"><span class="linenos">505</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_knowledge-506"><a href="#DK_knowledge-506"><span class="linenos">506</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_v_linear</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class for the Knowledge Processing in a <code>DKEncoderLayer</code> from CokeBert.</p>
</div>


                            <div id="DK_knowledge.__init__" class="classattr">
                                        <input id="DK_knowledge.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">DK_knowledge</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">k_v_dim</span></span>)</span>

                <label class="view-source-button" for="DK_knowledge.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DK_knowledge.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DK_knowledge.__init__-488"><a href="#DK_knowledge.__init__-488"><span class="linenos">488</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">):</span>
</span><span id="DK_knowledge.__init__-489"><a href="#DK_knowledge.__init__-489"><span class="linenos">489</span></a>        <span class="sd">&quot;&quot;&quot; Constructs a `DK_knowledge` module</span>
</span><span id="DK_knowledge.__init__-490"><a href="#DK_knowledge.__init__-490"><span class="linenos">490</span></a>
</span><span id="DK_knowledge.__init__-491"><a href="#DK_knowledge.__init__-491"><span class="linenos">491</span></a><span class="sd">        Args:</span>
</span><span id="DK_knowledge.__init__-492"><a href="#DK_knowledge.__init__-492"><span class="linenos">492</span></a><span class="sd">            k_v_dim (int): size of the k and v vectors (internal Knowledge representation)</span>
</span><span id="DK_knowledge.__init__-493"><a href="#DK_knowledge.__init__-493"><span class="linenos">493</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_knowledge.__init__-494"><a href="#DK_knowledge.__init__-494"><span class="linenos">494</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="DK_knowledge.__init__-495"><a href="#DK_knowledge.__init__-495"><span class="linenos">495</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_v_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">k_v_dim</span><span class="p">,</span> <span class="n">k_v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a <code><a href="#DK_knowledge">DK_knowledge</a></code> module</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>
</ul>
</div>


                            </div>
                            <div id="DK_knowledge.forward" class="classattr">
                                        <input id="DK_knowledge.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">k</span></span>)</span>

                <label class="view-source-button" for="DK_knowledge.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#DK_knowledge.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="DK_knowledge.forward-497"><a href="#DK_knowledge.forward-497"><span class="linenos">497</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span><span id="DK_knowledge.forward-498"><a href="#DK_knowledge.forward-498"><span class="linenos">498</span></a>        <span class="sd">&quot;&quot;&quot; Forward pass through the Knowledge Processing Module of a Dynamic Knowledge Encoder layer</span>
</span><span id="DK_knowledge.forward-499"><a href="#DK_knowledge.forward-499"><span class="linenos">499</span></a><span class="sd">        </span>
</span><span id="DK_knowledge.forward-500"><a href="#DK_knowledge.forward-500"><span class="linenos">500</span></a><span class="sd">        Args:</span>
</span><span id="DK_knowledge.forward-501"><a href="#DK_knowledge.forward-501"><span class="linenos">501</span></a><span class="sd">            k: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DK_knowledge.forward-502"><a href="#DK_knowledge.forward-502"><span class="linenos">502</span></a>
</span><span id="DK_knowledge.forward-503"><a href="#DK_knowledge.forward-503"><span class="linenos">503</span></a><span class="sd">        Returns:</span>
</span><span id="DK_knowledge.forward-504"><a href="#DK_knowledge.forward-504"><span class="linenos">504</span></a><span class="sd">            hidden knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</span>
</span><span id="DK_knowledge.forward-505"><a href="#DK_knowledge.forward-505"><span class="linenos">505</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="DK_knowledge.forward-506"><a href="#DK_knowledge.forward-506"><span class="linenos">506</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_v_linear</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the Knowledge Processing Module of a Dynamic Knowledge Encoder layer</p>

<h6 id="args">Args</h6>

<ul>
<li><strong>k:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>hidden knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="DK_knowledge.dump_patches" class="variable">dump_patches</dd>
                <dd id="DK_knowledge.register_buffer" class="function">register_buffer</dd>
                <dd id="DK_knowledge.register_parameter" class="function">register_parameter</dd>
                <dd id="DK_knowledge.add_module" class="function">add_module</dd>
                <dd id="DK_knowledge.register_module" class="function">register_module</dd>
                <dd id="DK_knowledge.get_submodule" class="function">get_submodule</dd>
                <dd id="DK_knowledge.get_parameter" class="function">get_parameter</dd>
                <dd id="DK_knowledge.get_buffer" class="function">get_buffer</dd>
                <dd id="DK_knowledge.get_extra_state" class="function">get_extra_state</dd>
                <dd id="DK_knowledge.set_extra_state" class="function">set_extra_state</dd>
                <dd id="DK_knowledge.apply" class="function">apply</dd>
                <dd id="DK_knowledge.cuda" class="function">cuda</dd>
                <dd id="DK_knowledge.xpu" class="function">xpu</dd>
                <dd id="DK_knowledge.cpu" class="function">cpu</dd>
                <dd id="DK_knowledge.type" class="function">type</dd>
                <dd id="DK_knowledge.float" class="function">float</dd>
                <dd id="DK_knowledge.double" class="function">double</dd>
                <dd id="DK_knowledge.half" class="function">half</dd>
                <dd id="DK_knowledge.bfloat16" class="function">bfloat16</dd>
                <dd id="DK_knowledge.to_empty" class="function">to_empty</dd>
                <dd id="DK_knowledge.to" class="function">to</dd>
                <dd id="DK_knowledge.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="DK_knowledge.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="DK_knowledge.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="DK_knowledge.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="DK_knowledge.T_destination" class="variable">T_destination</dd>
                <dd id="DK_knowledge.state_dict" class="function">state_dict</dd>
                <dd id="DK_knowledge.load_state_dict" class="function">load_state_dict</dd>
                <dd id="DK_knowledge.parameters" class="function">parameters</dd>
                <dd id="DK_knowledge.named_parameters" class="function">named_parameters</dd>
                <dd id="DK_knowledge.buffers" class="function">buffers</dd>
                <dd id="DK_knowledge.named_buffers" class="function">named_buffers</dd>
                <dd id="DK_knowledge.children" class="function">children</dd>
                <dd id="DK_knowledge.named_children" class="function">named_children</dd>
                <dd id="DK_knowledge.modules" class="function">modules</dd>
                <dd id="DK_knowledge.named_modules" class="function">named_modules</dd>
                <dd id="DK_knowledge.train" class="function">train</dd>
                <dd id="DK_knowledge.eval" class="function">eval</dd>
                <dd id="DK_knowledge.requires_grad_" class="function">requires_grad_</dd>
                <dd id="DK_knowledge.zero_grad" class="function">zero_grad</dd>
                <dd id="DK_knowledge.share_memory" class="function">share_memory</dd>
                <dd id="DK_knowledge.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="CokeBertForSequenceClassification">
                            <input id="CokeBertForSequenceClassification-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">CokeBertForSequenceClassification</span><wbr>(<span class="base"><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></span>):

                <label class="view-source-button" for="CokeBertForSequenceClassification-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForSequenceClassification"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForSequenceClassification-508"><a href="#CokeBertForSequenceClassification-508"><span class="linenos">508</span></a><span class="k">class</span> <span class="nc">CokeBertForSequenceClassification</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="CokeBertForSequenceClassification-509"><a href="#CokeBertForSequenceClassification-509"><span class="linenos">509</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="CokeBertForSequenceClassification-510"><a href="#CokeBertForSequenceClassification-510"><span class="linenos">510</span></a><span class="sd">    CokeBert model for sequence classification.  </span>
</span><span id="CokeBertForSequenceClassification-511"><a href="#CokeBertForSequenceClassification-511"><span class="linenos">511</span></a><span class="sd">    This module is composed of the CokeBert model with a linear layer on top of</span>
</span><span id="CokeBertForSequenceClassification-512"><a href="#CokeBertForSequenceClassification-512"><span class="linenos">512</span></a><span class="sd">    the pooled output.</span>
</span><span id="CokeBertForSequenceClassification-513"><a href="#CokeBertForSequenceClassification-513"><span class="linenos">513</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="CokeBertForSequenceClassification-514"><a href="#CokeBertForSequenceClassification-514"><span class="linenos">514</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="CokeBertForSequenceClassification-515"><a href="#CokeBertForSequenceClassification-515"><span class="linenos">515</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForSequenceClassification` model</span>
</span><span id="CokeBertForSequenceClassification-516"><a href="#CokeBertForSequenceClassification-516"><span class="linenos">516</span></a>
</span><span id="CokeBertForSequenceClassification-517"><a href="#CokeBertForSequenceClassification-517"><span class="linenos">517</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForSequenceClassification-518"><a href="#CokeBertForSequenceClassification-518"><span class="linenos">518</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="CokeBertForSequenceClassification-519"><a href="#CokeBertForSequenceClassification-519"><span class="linenos">519</span></a><span class="sd">            `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="CokeBertForSequenceClassification-520"><a href="#CokeBertForSequenceClassification-520"><span class="linenos">520</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForSequenceClassification-521"><a href="#CokeBertForSequenceClassification-521"><span class="linenos">521</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-522"><a href="#CokeBertForSequenceClassification-522"><span class="linenos">522</span></a>
</span><span id="CokeBertForSequenceClassification-523"><a href="#CokeBertForSequenceClassification-523"><span class="linenos">523</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="CokeBertForSequenceClassification-524"><a href="#CokeBertForSequenceClassification-524"><span class="linenos">524</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-525"><a href="#CokeBertForSequenceClassification-525"><span class="linenos">525</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-526"><a href="#CokeBertForSequenceClassification-526"><span class="linenos">526</span></a>
</span><span id="CokeBertForSequenceClassification-527"><a href="#CokeBertForSequenceClassification-527"><span class="linenos">527</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-528"><a href="#CokeBertForSequenceClassification-528"><span class="linenos">528</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification-529"><a href="#CokeBertForSequenceClassification-529"><span class="linenos">529</span></a>
</span><span id="CokeBertForSequenceClassification-530"><a href="#CokeBertForSequenceClassification-530"><span class="linenos">530</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-531"><a href="#CokeBertForSequenceClassification-531"><span class="linenos">531</span></a>
</span><span id="CokeBertForSequenceClassification-532"><a href="#CokeBertForSequenceClassification-532"><span class="linenos">532</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-533"><a href="#CokeBertForSequenceClassification-533"><span class="linenos">533</span></a>
</span><span id="CokeBertForSequenceClassification-534"><a href="#CokeBertForSequenceClassification-534"><span class="linenos">534</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertForSequenceClassification-535"><a href="#CokeBertForSequenceClassification-535"><span class="linenos">535</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="CokeBertForSequenceClassification-536"><a href="#CokeBertForSequenceClassification-536"><span class="linenos">536</span></a>
</span><span id="CokeBertForSequenceClassification-537"><a href="#CokeBertForSequenceClassification-537"><span class="linenos">537</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForSequenceClassification-538"><a href="#CokeBertForSequenceClassification-538"><span class="linenos">538</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertForSequenceClassification-539"><a href="#CokeBertForSequenceClassification-539"><span class="linenos">539</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertForSequenceClassification-540"><a href="#CokeBertForSequenceClassification-540"><span class="linenos">540</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertForSequenceClassification-541"><a href="#CokeBertForSequenceClassification-541"><span class="linenos">541</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertForSequenceClassification-542"><a href="#CokeBertForSequenceClassification-542"><span class="linenos">542</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertForSequenceClassification-543"><a href="#CokeBertForSequenceClassification-543"><span class="linenos">543</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertForSequenceClassification-544"><a href="#CokeBertForSequenceClassification-544"><span class="linenos">544</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForSequenceClassification-545"><a href="#CokeBertForSequenceClassification-545"><span class="linenos">545</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertForSequenceClassification-546"><a href="#CokeBertForSequenceClassification-546"><span class="linenos">546</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertForSequenceClassification-547"><a href="#CokeBertForSequenceClassification-547"><span class="linenos">547</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertForSequenceClassification-548"><a href="#CokeBertForSequenceClassification-548"><span class="linenos">548</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertForSequenceClassification-549"><a href="#CokeBertForSequenceClassification-549"><span class="linenos">549</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertForSequenceClassification-550"><a href="#CokeBertForSequenceClassification-550"><span class="linenos">550</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForSequenceClassification-551"><a href="#CokeBertForSequenceClassification-551"><span class="linenos">551</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertForSequenceClassification-552"><a href="#CokeBertForSequenceClassification-552"><span class="linenos">552</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="CokeBertForSequenceClassification-553"><a href="#CokeBertForSequenceClassification-553"><span class="linenos">553</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="CokeBertForSequenceClassification-554"><a href="#CokeBertForSequenceClassification-554"><span class="linenos">554</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertForSequenceClassification-555"><a href="#CokeBertForSequenceClassification-555"><span class="linenos">555</span></a>
</span><span id="CokeBertForSequenceClassification-556"><a href="#CokeBertForSequenceClassification-556"><span class="linenos">556</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertForSequenceClassification-557"><a href="#CokeBertForSequenceClassification-557"><span class="linenos">557</span></a><span class="sd">            if `labels` is not `None`:  </span>
</span><span id="CokeBertForSequenceClassification-558"><a href="#CokeBertForSequenceClassification-558"><span class="linenos">558</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="CokeBertForSequenceClassification-559"><a href="#CokeBertForSequenceClassification-559"><span class="linenos">559</span></a><span class="sd">            if `labels` is `None`:  </span>
</span><span id="CokeBertForSequenceClassification-560"><a href="#CokeBertForSequenceClassification-560"><span class="linenos">560</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="CokeBertForSequenceClassification-561"><a href="#CokeBertForSequenceClassification-561"><span class="linenos">561</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForSequenceClassification-562"><a href="#CokeBertForSequenceClassification-562"><span class="linenos">562</span></a>        <span class="n">seq_out</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-563"><a href="#CokeBertForSequenceClassification-563"><span class="linenos">563</span></a>
</span><span id="CokeBertForSequenceClassification-564"><a href="#CokeBertForSequenceClassification-564"><span class="linenos">564</span></a>        <span class="n">head</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1601</span><span class="p">]</span>
</span><span id="CokeBertForSequenceClassification-565"><a href="#CokeBertForSequenceClassification-565"><span class="linenos">565</span></a>        <span class="n">tail</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1089</span><span class="p">]</span>
</span><span id="CokeBertForSequenceClassification-566"><a href="#CokeBertForSequenceClassification-566"><span class="linenos">566</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification-567"><a href="#CokeBertForSequenceClassification-567"><span class="linenos">567</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">head</span><span class="p">,</span><span class="n">tail</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-568"><a href="#CokeBertForSequenceClassification-568"><span class="linenos">568</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-569"><a href="#CokeBertForSequenceClassification-569"><span class="linenos">569</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-570"><a href="#CokeBertForSequenceClassification-570"><span class="linenos">570</span></a>        <span class="k">except</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification-571"><a href="#CokeBertForSequenceClassification-571"><span class="linenos">571</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-572"><a href="#CokeBertForSequenceClassification-572"><span class="linenos">572</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-573"><a href="#CokeBertForSequenceClassification-573"><span class="linenos">573</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">head</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-574"><a href="#CokeBertForSequenceClassification-574"><span class="linenos">574</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-575"><a href="#CokeBertForSequenceClassification-575"><span class="linenos">575</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">tail</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-576"><a href="#CokeBertForSequenceClassification-576"><span class="linenos">576</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification-577"><a href="#CokeBertForSequenceClassification-577"><span class="linenos">577</span></a>
</span><span id="CokeBertForSequenceClassification-578"><a href="#CokeBertForSequenceClassification-578"><span class="linenos">578</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-579"><a href="#CokeBertForSequenceClassification-579"><span class="linenos">579</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-580"><a href="#CokeBertForSequenceClassification-580"><span class="linenos">580</span></a>
</span><span id="CokeBertForSequenceClassification-581"><a href="#CokeBertForSequenceClassification-581"><span class="linenos">581</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification-582"><a href="#CokeBertForSequenceClassification-582"><span class="linenos">582</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification-583"><a href="#CokeBertForSequenceClassification-583"><span class="linenos">583</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification-584"><a href="#CokeBertForSequenceClassification-584"><span class="linenos">584</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="CokeBertForSequenceClassification-585"><a href="#CokeBertForSequenceClassification-585"><span class="linenos">585</span></a>            <span class="k">except</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification-586"><a href="#CokeBertForSequenceClassification-586"><span class="linenos">586</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">head</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-587"><a href="#CokeBertForSequenceClassification-587"><span class="linenos">587</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-588"><a href="#CokeBertForSequenceClassification-588"><span class="linenos">588</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">tail</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-589"><a href="#CokeBertForSequenceClassification-589"><span class="linenos">589</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-590"><a href="#CokeBertForSequenceClassification-590"><span class="linenos">590</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">pooled_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-591"><a href="#CokeBertForSequenceClassification-591"><span class="linenos">591</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-592"><a href="#CokeBertForSequenceClassification-592"><span class="linenos">592</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-593"><a href="#CokeBertForSequenceClassification-593"><span class="linenos">593</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-594"><a href="#CokeBertForSequenceClassification-594"><span class="linenos">594</span></a>                <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-595"><a href="#CokeBertForSequenceClassification-595"><span class="linenos">595</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-596"><a href="#CokeBertForSequenceClassification-596"><span class="linenos">596</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification-597"><a href="#CokeBertForSequenceClassification-597"><span class="linenos">597</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification-598"><a href="#CokeBertForSequenceClassification-598"><span class="linenos">598</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="CokeBertForSequenceClassification-599"><a href="#CokeBertForSequenceClassification-599"><span class="linenos">599</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification-600"><a href="#CokeBertForSequenceClassification-600"><span class="linenos">600</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>CokeBert model for sequence classification. <br />
This module is composed of the CokeBert model with a linear layer on top of
the pooled output.</p>
</div>


                            <div id="CokeBertForSequenceClassification.__init__" class="classattr">
                                        <input id="CokeBertForSequenceClassification.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">CokeBertForSequenceClassification</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span></span>)</span>

                <label class="view-source-button" for="CokeBertForSequenceClassification.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForSequenceClassification.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForSequenceClassification.__init__-514"><a href="#CokeBertForSequenceClassification.__init__-514"><span class="linenos">514</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="CokeBertForSequenceClassification.__init__-515"><a href="#CokeBertForSequenceClassification.__init__-515"><span class="linenos">515</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForSequenceClassification` model</span>
</span><span id="CokeBertForSequenceClassification.__init__-516"><a href="#CokeBertForSequenceClassification.__init__-516"><span class="linenos">516</span></a>
</span><span id="CokeBertForSequenceClassification.__init__-517"><a href="#CokeBertForSequenceClassification.__init__-517"><span class="linenos">517</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForSequenceClassification.__init__-518"><a href="#CokeBertForSequenceClassification.__init__-518"><span class="linenos">518</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="CokeBertForSequenceClassification.__init__-519"><a href="#CokeBertForSequenceClassification.__init__-519"><span class="linenos">519</span></a><span class="sd">            `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="CokeBertForSequenceClassification.__init__-520"><a href="#CokeBertForSequenceClassification.__init__-520"><span class="linenos">520</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForSequenceClassification.__init__-521"><a href="#CokeBertForSequenceClassification.__init__-521"><span class="linenos">521</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.__init__-522"><a href="#CokeBertForSequenceClassification.__init__-522"><span class="linenos">522</span></a>
</span><span id="CokeBertForSequenceClassification.__init__-523"><a href="#CokeBertForSequenceClassification.__init__-523"><span class="linenos">523</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="CokeBertForSequenceClassification.__init__-524"><a href="#CokeBertForSequenceClassification.__init__-524"><span class="linenos">524</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.__init__-525"><a href="#CokeBertForSequenceClassification.__init__-525"><span class="linenos">525</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.__init__-526"><a href="#CokeBertForSequenceClassification.__init__-526"><span class="linenos">526</span></a>
</span><span id="CokeBertForSequenceClassification.__init__-527"><a href="#CokeBertForSequenceClassification.__init__-527"><span class="linenos">527</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.__init__-528"><a href="#CokeBertForSequenceClassification.__init__-528"><span class="linenos">528</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification.__init__-529"><a href="#CokeBertForSequenceClassification.__init__-529"><span class="linenos">529</span></a>
</span><span id="CokeBertForSequenceClassification.__init__-530"><a href="#CokeBertForSequenceClassification.__init__-530"><span class="linenos">530</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.__init__-531"><a href="#CokeBertForSequenceClassification.__init__-531"><span class="linenos">531</span></a>
</span><span id="CokeBertForSequenceClassification.__init__-532"><a href="#CokeBertForSequenceClassification.__init__-532"><span class="linenos">532</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a <code><a href="#CokeBertForSequenceClassification">CokeBertForSequenceClassification</a></code> model</p>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>
<li><strong><code>num_labels</code>:</strong>  the number of classes for the classifier. Default = 2.</li>
</ul>
</div>


                            </div>
                            <div id="CokeBertForSequenceClassification.forward" class="classattr">
                                        <input id="CokeBertForSequenceClassification.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="CokeBertForSequenceClassification.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForSequenceClassification.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForSequenceClassification.forward-534"><a href="#CokeBertForSequenceClassification.forward-534"><span class="linenos">534</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertForSequenceClassification.forward-535"><a href="#CokeBertForSequenceClassification.forward-535"><span class="linenos">535</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="CokeBertForSequenceClassification.forward-536"><a href="#CokeBertForSequenceClassification.forward-536"><span class="linenos">536</span></a>
</span><span id="CokeBertForSequenceClassification.forward-537"><a href="#CokeBertForSequenceClassification.forward-537"><span class="linenos">537</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForSequenceClassification.forward-538"><a href="#CokeBertForSequenceClassification.forward-538"><span class="linenos">538</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertForSequenceClassification.forward-539"><a href="#CokeBertForSequenceClassification.forward-539"><span class="linenos">539</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertForSequenceClassification.forward-540"><a href="#CokeBertForSequenceClassification.forward-540"><span class="linenos">540</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertForSequenceClassification.forward-541"><a href="#CokeBertForSequenceClassification.forward-541"><span class="linenos">541</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertForSequenceClassification.forward-542"><a href="#CokeBertForSequenceClassification.forward-542"><span class="linenos">542</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertForSequenceClassification.forward-543"><a href="#CokeBertForSequenceClassification.forward-543"><span class="linenos">543</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertForSequenceClassification.forward-544"><a href="#CokeBertForSequenceClassification.forward-544"><span class="linenos">544</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForSequenceClassification.forward-545"><a href="#CokeBertForSequenceClassification.forward-545"><span class="linenos">545</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertForSequenceClassification.forward-546"><a href="#CokeBertForSequenceClassification.forward-546"><span class="linenos">546</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertForSequenceClassification.forward-547"><a href="#CokeBertForSequenceClassification.forward-547"><span class="linenos">547</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertForSequenceClassification.forward-548"><a href="#CokeBertForSequenceClassification.forward-548"><span class="linenos">548</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertForSequenceClassification.forward-549"><a href="#CokeBertForSequenceClassification.forward-549"><span class="linenos">549</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertForSequenceClassification.forward-550"><a href="#CokeBertForSequenceClassification.forward-550"><span class="linenos">550</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForSequenceClassification.forward-551"><a href="#CokeBertForSequenceClassification.forward-551"><span class="linenos">551</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertForSequenceClassification.forward-552"><a href="#CokeBertForSequenceClassification.forward-552"><span class="linenos">552</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="CokeBertForSequenceClassification.forward-553"><a href="#CokeBertForSequenceClassification.forward-553"><span class="linenos">553</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="CokeBertForSequenceClassification.forward-554"><a href="#CokeBertForSequenceClassification.forward-554"><span class="linenos">554</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertForSequenceClassification.forward-555"><a href="#CokeBertForSequenceClassification.forward-555"><span class="linenos">555</span></a>
</span><span id="CokeBertForSequenceClassification.forward-556"><a href="#CokeBertForSequenceClassification.forward-556"><span class="linenos">556</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertForSequenceClassification.forward-557"><a href="#CokeBertForSequenceClassification.forward-557"><span class="linenos">557</span></a><span class="sd">            if `labels` is not `None`:  </span>
</span><span id="CokeBertForSequenceClassification.forward-558"><a href="#CokeBertForSequenceClassification.forward-558"><span class="linenos">558</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="CokeBertForSequenceClassification.forward-559"><a href="#CokeBertForSequenceClassification.forward-559"><span class="linenos">559</span></a><span class="sd">            if `labels` is `None`:  </span>
</span><span id="CokeBertForSequenceClassification.forward-560"><a href="#CokeBertForSequenceClassification.forward-560"><span class="linenos">560</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="CokeBertForSequenceClassification.forward-561"><a href="#CokeBertForSequenceClassification.forward-561"><span class="linenos">561</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForSequenceClassification.forward-562"><a href="#CokeBertForSequenceClassification.forward-562"><span class="linenos">562</span></a>        <span class="n">seq_out</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-563"><a href="#CokeBertForSequenceClassification.forward-563"><span class="linenos">563</span></a>
</span><span id="CokeBertForSequenceClassification.forward-564"><a href="#CokeBertForSequenceClassification.forward-564"><span class="linenos">564</span></a>        <span class="n">head</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1601</span><span class="p">]</span>
</span><span id="CokeBertForSequenceClassification.forward-565"><a href="#CokeBertForSequenceClassification.forward-565"><span class="linenos">565</span></a>        <span class="n">tail</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1089</span><span class="p">]</span>
</span><span id="CokeBertForSequenceClassification.forward-566"><a href="#CokeBertForSequenceClassification.forward-566"><span class="linenos">566</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification.forward-567"><a href="#CokeBertForSequenceClassification.forward-567"><span class="linenos">567</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">head</span><span class="p">,</span><span class="n">tail</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-568"><a href="#CokeBertForSequenceClassification.forward-568"><span class="linenos">568</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-569"><a href="#CokeBertForSequenceClassification.forward-569"><span class="linenos">569</span></a>            <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-570"><a href="#CokeBertForSequenceClassification.forward-570"><span class="linenos">570</span></a>        <span class="k">except</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification.forward-571"><a href="#CokeBertForSequenceClassification.forward-571"><span class="linenos">571</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-572"><a href="#CokeBertForSequenceClassification.forward-572"><span class="linenos">572</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-573"><a href="#CokeBertForSequenceClassification.forward-573"><span class="linenos">573</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">head</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-574"><a href="#CokeBertForSequenceClassification.forward-574"><span class="linenos">574</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;===&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-575"><a href="#CokeBertForSequenceClassification.forward-575"><span class="linenos">575</span></a>            <span class="nb">print</span><span class="p">(</span><span class="n">tail</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-576"><a href="#CokeBertForSequenceClassification.forward-576"><span class="linenos">576</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification.forward-577"><a href="#CokeBertForSequenceClassification.forward-577"><span class="linenos">577</span></a>
</span><span id="CokeBertForSequenceClassification.forward-578"><a href="#CokeBertForSequenceClassification.forward-578"><span class="linenos">578</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-579"><a href="#CokeBertForSequenceClassification.forward-579"><span class="linenos">579</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-580"><a href="#CokeBertForSequenceClassification.forward-580"><span class="linenos">580</span></a>
</span><span id="CokeBertForSequenceClassification.forward-581"><a href="#CokeBertForSequenceClassification.forward-581"><span class="linenos">581</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification.forward-582"><a href="#CokeBertForSequenceClassification.forward-582"><span class="linenos">582</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification.forward-583"><a href="#CokeBertForSequenceClassification.forward-583"><span class="linenos">583</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification.forward-584"><a href="#CokeBertForSequenceClassification.forward-584"><span class="linenos">584</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="CokeBertForSequenceClassification.forward-585"><a href="#CokeBertForSequenceClassification.forward-585"><span class="linenos">585</span></a>            <span class="k">except</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification.forward-586"><a href="#CokeBertForSequenceClassification.forward-586"><span class="linenos">586</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">head</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-587"><a href="#CokeBertForSequenceClassification.forward-587"><span class="linenos">587</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-588"><a href="#CokeBertForSequenceClassification.forward-588"><span class="linenos">588</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">tail</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-589"><a href="#CokeBertForSequenceClassification.forward-589"><span class="linenos">589</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-590"><a href="#CokeBertForSequenceClassification.forward-590"><span class="linenos">590</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">pooled_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-591"><a href="#CokeBertForSequenceClassification.forward-591"><span class="linenos">591</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-592"><a href="#CokeBertForSequenceClassification.forward-592"><span class="linenos">592</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-593"><a href="#CokeBertForSequenceClassification.forward-593"><span class="linenos">593</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-594"><a href="#CokeBertForSequenceClassification.forward-594"><span class="linenos">594</span></a>                <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-595"><a href="#CokeBertForSequenceClassification.forward-595"><span class="linenos">595</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---&quot;</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-596"><a href="#CokeBertForSequenceClassification.forward-596"><span class="linenos">596</span></a>                <span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="CokeBertForSequenceClassification.forward-597"><a href="#CokeBertForSequenceClassification.forward-597"><span class="linenos">597</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
</span><span id="CokeBertForSequenceClassification.forward-598"><a href="#CokeBertForSequenceClassification.forward-598"><span class="linenos">598</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="CokeBertForSequenceClassification.forward-599"><a href="#CokeBertForSequenceClassification.forward-599"><span class="linenos">599</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertForSequenceClassification.forward-600"><a href="#CokeBertForSequenceClassification.forward-600"><span class="linenos">600</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Performs a Forward Pass through the model</p>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]
with indices selected in [0, ..., num_labels].</li>
<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>labels</code> is not <code>None</code>: <br />
      Outputs the CrossEntropy classification loss of the output with the labels. <br />
  if <code>labels</code> is <code>None</code>: <br />
      Outputs the classification logits of shape [batch_size, num_labels].</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></dt>
                                <dd id="CokeBertForSequenceClassification.init_weights" class="function"><a href="#PreTrainedCokeBertModel.init_weights">init_weights</a></dd>
                <dd id="CokeBertForSequenceClassification.from_pretrained" class="function"><a href="#PreTrainedCokeBertModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="CokeBertForSequenceClassification.dump_patches" class="variable">dump_patches</dd>
                <dd id="CokeBertForSequenceClassification.register_buffer" class="function">register_buffer</dd>
                <dd id="CokeBertForSequenceClassification.register_parameter" class="function">register_parameter</dd>
                <dd id="CokeBertForSequenceClassification.add_module" class="function">add_module</dd>
                <dd id="CokeBertForSequenceClassification.register_module" class="function">register_module</dd>
                <dd id="CokeBertForSequenceClassification.get_submodule" class="function">get_submodule</dd>
                <dd id="CokeBertForSequenceClassification.get_parameter" class="function">get_parameter</dd>
                <dd id="CokeBertForSequenceClassification.get_buffer" class="function">get_buffer</dd>
                <dd id="CokeBertForSequenceClassification.get_extra_state" class="function">get_extra_state</dd>
                <dd id="CokeBertForSequenceClassification.set_extra_state" class="function">set_extra_state</dd>
                <dd id="CokeBertForSequenceClassification.apply" class="function">apply</dd>
                <dd id="CokeBertForSequenceClassification.cuda" class="function">cuda</dd>
                <dd id="CokeBertForSequenceClassification.xpu" class="function">xpu</dd>
                <dd id="CokeBertForSequenceClassification.cpu" class="function">cpu</dd>
                <dd id="CokeBertForSequenceClassification.type" class="function">type</dd>
                <dd id="CokeBertForSequenceClassification.float" class="function">float</dd>
                <dd id="CokeBertForSequenceClassification.double" class="function">double</dd>
                <dd id="CokeBertForSequenceClassification.half" class="function">half</dd>
                <dd id="CokeBertForSequenceClassification.bfloat16" class="function">bfloat16</dd>
                <dd id="CokeBertForSequenceClassification.to_empty" class="function">to_empty</dd>
                <dd id="CokeBertForSequenceClassification.to" class="function">to</dd>
                <dd id="CokeBertForSequenceClassification.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="CokeBertForSequenceClassification.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="CokeBertForSequenceClassification.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="CokeBertForSequenceClassification.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="CokeBertForSequenceClassification.T_destination" class="variable">T_destination</dd>
                <dd id="CokeBertForSequenceClassification.state_dict" class="function">state_dict</dd>
                <dd id="CokeBertForSequenceClassification.load_state_dict" class="function">load_state_dict</dd>
                <dd id="CokeBertForSequenceClassification.parameters" class="function">parameters</dd>
                <dd id="CokeBertForSequenceClassification.named_parameters" class="function">named_parameters</dd>
                <dd id="CokeBertForSequenceClassification.buffers" class="function">buffers</dd>
                <dd id="CokeBertForSequenceClassification.named_buffers" class="function">named_buffers</dd>
                <dd id="CokeBertForSequenceClassification.children" class="function">children</dd>
                <dd id="CokeBertForSequenceClassification.named_children" class="function">named_children</dd>
                <dd id="CokeBertForSequenceClassification.modules" class="function">modules</dd>
                <dd id="CokeBertForSequenceClassification.named_modules" class="function">named_modules</dd>
                <dd id="CokeBertForSequenceClassification.train" class="function">train</dd>
                <dd id="CokeBertForSequenceClassification.eval" class="function">eval</dd>
                <dd id="CokeBertForSequenceClassification.requires_grad_" class="function">requires_grad_</dd>
                <dd id="CokeBertForSequenceClassification.zero_grad" class="function">zero_grad</dd>
                <dd id="CokeBertForSequenceClassification.share_memory" class="function">share_memory</dd>
                <dd id="CokeBertForSequenceClassification.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="CokeBertForEntityTyping">
                            <input id="CokeBertForEntityTyping-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">CokeBertForEntityTyping</span><wbr>(<span class="base"><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></span>):

                <label class="view-source-button" for="CokeBertForEntityTyping-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForEntityTyping"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForEntityTyping-602"><a href="#CokeBertForEntityTyping-602"><span class="linenos">602</span></a><span class="k">class</span> <span class="nc">CokeBertForEntityTyping</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="CokeBertForEntityTyping-603"><a href="#CokeBertForEntityTyping-603"><span class="linenos">603</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="CokeBertForEntityTyping-604"><a href="#CokeBertForEntityTyping-604"><span class="linenos">604</span></a><span class="sd">    CokeBert model for classification.  </span>
</span><span id="CokeBertForEntityTyping-605"><a href="#CokeBertForEntityTyping-605"><span class="linenos">605</span></a><span class="sd">    This module is composed of the CokeBert model with a linear layer on top of</span>
</span><span id="CokeBertForEntityTyping-606"><a href="#CokeBertForEntityTyping-606"><span class="linenos">606</span></a><span class="sd">    the pooled output.</span>
</span><span id="CokeBertForEntityTyping-607"><a href="#CokeBertForEntityTyping-607"><span class="linenos">607</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="CokeBertForEntityTyping-608"><a href="#CokeBertForEntityTyping-608"><span class="linenos">608</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="CokeBertForEntityTyping-609"><a href="#CokeBertForEntityTyping-609"><span class="linenos">609</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForEntityTyping` model</span>
</span><span id="CokeBertForEntityTyping-610"><a href="#CokeBertForEntityTyping-610"><span class="linenos">610</span></a>
</span><span id="CokeBertForEntityTyping-611"><a href="#CokeBertForEntityTyping-611"><span class="linenos">611</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForEntityTyping-612"><a href="#CokeBertForEntityTyping-612"><span class="linenos">612</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="CokeBertForEntityTyping-613"><a href="#CokeBertForEntityTyping-613"><span class="linenos">613</span></a><span class="sd">            `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="CokeBertForEntityTyping-614"><a href="#CokeBertForEntityTyping-614"><span class="linenos">614</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForEntityTyping-615"><a href="#CokeBertForEntityTyping-615"><span class="linenos">615</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-616"><a href="#CokeBertForEntityTyping-616"><span class="linenos">616</span></a>
</span><span id="CokeBertForEntityTyping-617"><a href="#CokeBertForEntityTyping-617"><span class="linenos">617</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="CokeBertForEntityTyping-618"><a href="#CokeBertForEntityTyping-618"><span class="linenos">618</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-619"><a href="#CokeBertForEntityTyping-619"><span class="linenos">619</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-620"><a href="#CokeBertForEntityTyping-620"><span class="linenos">620</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">typing</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-621"><a href="#CokeBertForEntityTyping-621"><span class="linenos">621</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-622"><a href="#CokeBertForEntityTyping-622"><span class="linenos">622</span></a>
</span><span id="CokeBertForEntityTyping-623"><a href="#CokeBertForEntityTyping-623"><span class="linenos">623</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-624"><a href="#CokeBertForEntityTyping-624"><span class="linenos">624</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span><span id="CokeBertForEntityTyping-625"><a href="#CokeBertForEntityTyping-625"><span class="linenos">625</span></a>
</span><span id="CokeBertForEntityTyping-626"><a href="#CokeBertForEntityTyping-626"><span class="linenos">626</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertForEntityTyping-627"><a href="#CokeBertForEntityTyping-627"><span class="linenos">627</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="CokeBertForEntityTyping-628"><a href="#CokeBertForEntityTyping-628"><span class="linenos">628</span></a>
</span><span id="CokeBertForEntityTyping-629"><a href="#CokeBertForEntityTyping-629"><span class="linenos">629</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForEntityTyping-630"><a href="#CokeBertForEntityTyping-630"><span class="linenos">630</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertForEntityTyping-631"><a href="#CokeBertForEntityTyping-631"><span class="linenos">631</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertForEntityTyping-632"><a href="#CokeBertForEntityTyping-632"><span class="linenos">632</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertForEntityTyping-633"><a href="#CokeBertForEntityTyping-633"><span class="linenos">633</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertForEntityTyping-634"><a href="#CokeBertForEntityTyping-634"><span class="linenos">634</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertForEntityTyping-635"><a href="#CokeBertForEntityTyping-635"><span class="linenos">635</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertForEntityTyping-636"><a href="#CokeBertForEntityTyping-636"><span class="linenos">636</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForEntityTyping-637"><a href="#CokeBertForEntityTyping-637"><span class="linenos">637</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertForEntityTyping-638"><a href="#CokeBertForEntityTyping-638"><span class="linenos">638</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertForEntityTyping-639"><a href="#CokeBertForEntityTyping-639"><span class="linenos">639</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertForEntityTyping-640"><a href="#CokeBertForEntityTyping-640"><span class="linenos">640</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertForEntityTyping-641"><a href="#CokeBertForEntityTyping-641"><span class="linenos">641</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertForEntityTyping-642"><a href="#CokeBertForEntityTyping-642"><span class="linenos">642</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForEntityTyping-643"><a href="#CokeBertForEntityTyping-643"><span class="linenos">643</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertForEntityTyping-644"><a href="#CokeBertForEntityTyping-644"><span class="linenos">644</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="CokeBertForEntityTyping-645"><a href="#CokeBertForEntityTyping-645"><span class="linenos">645</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="CokeBertForEntityTyping-646"><a href="#CokeBertForEntityTyping-646"><span class="linenos">646</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertForEntityTyping-647"><a href="#CokeBertForEntityTyping-647"><span class="linenos">647</span></a>
</span><span id="CokeBertForEntityTyping-648"><a href="#CokeBertForEntityTyping-648"><span class="linenos">648</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertForEntityTyping-649"><a href="#CokeBertForEntityTyping-649"><span class="linenos">649</span></a><span class="sd">            if `labels` is not `None`:  </span>
</span><span id="CokeBertForEntityTyping-650"><a href="#CokeBertForEntityTyping-650"><span class="linenos">650</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="CokeBertForEntityTyping-651"><a href="#CokeBertForEntityTyping-651"><span class="linenos">651</span></a><span class="sd">            if `labels` is `None`:  </span>
</span><span id="CokeBertForEntityTyping-652"><a href="#CokeBertForEntityTyping-652"><span class="linenos">652</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="CokeBertForEntityTyping-653"><a href="#CokeBertForEntityTyping-653"><span class="linenos">653</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForEntityTyping-654"><a href="#CokeBertForEntityTyping-654"><span class="linenos">654</span></a>        <span class="n">seq_out</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-655"><a href="#CokeBertForEntityTyping-655"><span class="linenos">655</span></a>
</span><span id="CokeBertForEntityTyping-656"><a href="#CokeBertForEntityTyping-656"><span class="linenos">656</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1601</span><span class="p">]</span>
</span><span id="CokeBertForEntityTyping-657"><a href="#CokeBertForEntityTyping-657"><span class="linenos">657</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-658"><a href="#CokeBertForEntityTyping-658"><span class="linenos">658</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-659"><a href="#CokeBertForEntityTyping-659"><span class="linenos">659</span></a>
</span><span id="CokeBertForEntityTyping-660"><a href="#CokeBertForEntityTyping-660"><span class="linenos">660</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-661"><a href="#CokeBertForEntityTyping-661"><span class="linenos">661</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">typing</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping-662"><a href="#CokeBertForEntityTyping-662"><span class="linenos">662</span></a>
</span><span id="CokeBertForEntityTyping-663"><a href="#CokeBertForEntityTyping-663"><span class="linenos">663</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertForEntityTyping-664"><a href="#CokeBertForEntityTyping-664"><span class="linenos">664</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="CokeBertForEntityTyping-665"><a href="#CokeBertForEntityTyping-665"><span class="linenos">665</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
</span><span id="CokeBertForEntityTyping-666"><a href="#CokeBertForEntityTyping-666"><span class="linenos">666</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="CokeBertForEntityTyping-667"><a href="#CokeBertForEntityTyping-667"><span class="linenos">667</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertForEntityTyping-668"><a href="#CokeBertForEntityTyping-668"><span class="linenos">668</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>CokeBert model for classification. <br />
This module is composed of the CokeBert model with a linear layer on top of
the pooled output.</p>
</div>


                            <div id="CokeBertForEntityTyping.__init__" class="classattr">
                                        <input id="CokeBertForEntityTyping.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">CokeBertForEntityTyping</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span></span>)</span>

                <label class="view-source-button" for="CokeBertForEntityTyping.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForEntityTyping.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForEntityTyping.__init__-608"><a href="#CokeBertForEntityTyping.__init__-608"><span class="linenos">608</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span id="CokeBertForEntityTyping.__init__-609"><a href="#CokeBertForEntityTyping.__init__-609"><span class="linenos">609</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForEntityTyping` model</span>
</span><span id="CokeBertForEntityTyping.__init__-610"><a href="#CokeBertForEntityTyping.__init__-610"><span class="linenos">610</span></a>
</span><span id="CokeBertForEntityTyping.__init__-611"><a href="#CokeBertForEntityTyping.__init__-611"><span class="linenos">611</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForEntityTyping.__init__-612"><a href="#CokeBertForEntityTyping.__init__-612"><span class="linenos">612</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="CokeBertForEntityTyping.__init__-613"><a href="#CokeBertForEntityTyping.__init__-613"><span class="linenos">613</span></a><span class="sd">            `num_labels`: the number of classes for the classifier. Default = 2.</span>
</span><span id="CokeBertForEntityTyping.__init__-614"><a href="#CokeBertForEntityTyping.__init__-614"><span class="linenos">614</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForEntityTyping.__init__-615"><a href="#CokeBertForEntityTyping.__init__-615"><span class="linenos">615</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.__init__-616"><a href="#CokeBertForEntityTyping.__init__-616"><span class="linenos">616</span></a>
</span><span id="CokeBertForEntityTyping.__init__-617"><a href="#CokeBertForEntityTyping.__init__-617"><span class="linenos">617</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">num_labels</span>
</span><span id="CokeBertForEntityTyping.__init__-618"><a href="#CokeBertForEntityTyping.__init__-618"><span class="linenos">618</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.__init__-619"><a href="#CokeBertForEntityTyping.__init__-619"><span class="linenos">619</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.__init__-620"><a href="#CokeBertForEntityTyping.__init__-620"><span class="linenos">620</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">typing</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.__init__-621"><a href="#CokeBertForEntityTyping.__init__-621"><span class="linenos">621</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.__init__-622"><a href="#CokeBertForEntityTyping.__init__-622"><span class="linenos">622</span></a>
</span><span id="CokeBertForEntityTyping.__init__-623"><a href="#CokeBertForEntityTyping.__init__-623"><span class="linenos">623</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.__init__-624"><a href="#CokeBertForEntityTyping.__init__-624"><span class="linenos">624</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a <code><a href="#CokeBertForEntityTyping">CokeBertForEntityTyping</a></code> model</p>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>
<li><strong><code>num_labels</code>:</strong>  the number of classes for the classifier. Default = 2.</li>
</ul>
</div>


                            </div>
                            <div id="CokeBertForEntityTyping.forward" class="classattr">
                                        <input id="CokeBertForEntityTyping.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">labels</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="CokeBertForEntityTyping.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForEntityTyping.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForEntityTyping.forward-626"><a href="#CokeBertForEntityTyping.forward-626"><span class="linenos">626</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertForEntityTyping.forward-627"><a href="#CokeBertForEntityTyping.forward-627"><span class="linenos">627</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="CokeBertForEntityTyping.forward-628"><a href="#CokeBertForEntityTyping.forward-628"><span class="linenos">628</span></a>
</span><span id="CokeBertForEntityTyping.forward-629"><a href="#CokeBertForEntityTyping.forward-629"><span class="linenos">629</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForEntityTyping.forward-630"><a href="#CokeBertForEntityTyping.forward-630"><span class="linenos">630</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertForEntityTyping.forward-631"><a href="#CokeBertForEntityTyping.forward-631"><span class="linenos">631</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertForEntityTyping.forward-632"><a href="#CokeBertForEntityTyping.forward-632"><span class="linenos">632</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertForEntityTyping.forward-633"><a href="#CokeBertForEntityTyping.forward-633"><span class="linenos">633</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertForEntityTyping.forward-634"><a href="#CokeBertForEntityTyping.forward-634"><span class="linenos">634</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertForEntityTyping.forward-635"><a href="#CokeBertForEntityTyping.forward-635"><span class="linenos">635</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertForEntityTyping.forward-636"><a href="#CokeBertForEntityTyping.forward-636"><span class="linenos">636</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForEntityTyping.forward-637"><a href="#CokeBertForEntityTyping.forward-637"><span class="linenos">637</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertForEntityTyping.forward-638"><a href="#CokeBertForEntityTyping.forward-638"><span class="linenos">638</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertForEntityTyping.forward-639"><a href="#CokeBertForEntityTyping.forward-639"><span class="linenos">639</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertForEntityTyping.forward-640"><a href="#CokeBertForEntityTyping.forward-640"><span class="linenos">640</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertForEntityTyping.forward-641"><a href="#CokeBertForEntityTyping.forward-641"><span class="linenos">641</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertForEntityTyping.forward-642"><a href="#CokeBertForEntityTyping.forward-642"><span class="linenos">642</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForEntityTyping.forward-643"><a href="#CokeBertForEntityTyping.forward-643"><span class="linenos">643</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertForEntityTyping.forward-644"><a href="#CokeBertForEntityTyping.forward-644"><span class="linenos">644</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="CokeBertForEntityTyping.forward-645"><a href="#CokeBertForEntityTyping.forward-645"><span class="linenos">645</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="CokeBertForEntityTyping.forward-646"><a href="#CokeBertForEntityTyping.forward-646"><span class="linenos">646</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertForEntityTyping.forward-647"><a href="#CokeBertForEntityTyping.forward-647"><span class="linenos">647</span></a>
</span><span id="CokeBertForEntityTyping.forward-648"><a href="#CokeBertForEntityTyping.forward-648"><span class="linenos">648</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertForEntityTyping.forward-649"><a href="#CokeBertForEntityTyping.forward-649"><span class="linenos">649</span></a><span class="sd">            if `labels` is not `None`:  </span>
</span><span id="CokeBertForEntityTyping.forward-650"><a href="#CokeBertForEntityTyping.forward-650"><span class="linenos">650</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="CokeBertForEntityTyping.forward-651"><a href="#CokeBertForEntityTyping.forward-651"><span class="linenos">651</span></a><span class="sd">            if `labels` is `None`:  </span>
</span><span id="CokeBertForEntityTyping.forward-652"><a href="#CokeBertForEntityTyping.forward-652"><span class="linenos">652</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="CokeBertForEntityTyping.forward-653"><a href="#CokeBertForEntityTyping.forward-653"><span class="linenos">653</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForEntityTyping.forward-654"><a href="#CokeBertForEntityTyping.forward-654"><span class="linenos">654</span></a>        <span class="n">seq_out</span><span class="p">,</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ent</span><span class="o">=</span><span class="n">input_ent</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="n">ent_mask</span><span class="p">,</span> <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.forward-655"><a href="#CokeBertForEntityTyping.forward-655"><span class="linenos">655</span></a>
</span><span id="CokeBertForEntityTyping.forward-656"><a href="#CokeBertForEntityTyping.forward-656"><span class="linenos">656</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">seq_out</span><span class="p">[</span><span class="n">input_ids</span><span class="o">==</span><span class="mi">1601</span><span class="p">]</span>
</span><span id="CokeBertForEntityTyping.forward-657"><a href="#CokeBertForEntityTyping.forward-657"><span class="linenos">657</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.forward-658"><a href="#CokeBertForEntityTyping.forward-658"><span class="linenos">658</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.forward-659"><a href="#CokeBertForEntityTyping.forward-659"><span class="linenos">659</span></a>
</span><span id="CokeBertForEntityTyping.forward-660"><a href="#CokeBertForEntityTyping.forward-660"><span class="linenos">660</span></a>        <span class="n">pooled_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.forward-661"><a href="#CokeBertForEntityTyping.forward-661"><span class="linenos">661</span></a>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">typing</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>
</span><span id="CokeBertForEntityTyping.forward-662"><a href="#CokeBertForEntityTyping.forward-662"><span class="linenos">662</span></a>
</span><span id="CokeBertForEntityTyping.forward-663"><a href="#CokeBertForEntityTyping.forward-663"><span class="linenos">663</span></a>        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertForEntityTyping.forward-664"><a href="#CokeBertForEntityTyping.forward-664"><span class="linenos">664</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="CokeBertForEntityTyping.forward-665"><a href="#CokeBertForEntityTyping.forward-665"><span class="linenos">665</span></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
</span><span id="CokeBertForEntityTyping.forward-666"><a href="#CokeBertForEntityTyping.forward-666"><span class="linenos">666</span></a>            <span class="k">return</span> <span class="n">loss</span>
</span><span id="CokeBertForEntityTyping.forward-667"><a href="#CokeBertForEntityTyping.forward-667"><span class="linenos">667</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertForEntityTyping.forward-668"><a href="#CokeBertForEntityTyping.forward-668"><span class="linenos">668</span></a>            <span class="k">return</span> <span class="n">logits</span>
</span></pre></div>


            <div class="docstring"><p>Performs a Forward Pass through the model</p>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]
with indices selected in [0, ..., num_labels].</li>
<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>labels</code> is not <code>None</code>: <br />
      Outputs the CrossEntropy classification loss of the output with the labels. <br />
  if <code>labels</code> is <code>None</code>: <br />
      Outputs the classification logits of shape [batch_size, num_labels].</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></dt>
                                <dd id="CokeBertForEntityTyping.init_weights" class="function"><a href="#PreTrainedCokeBertModel.init_weights">init_weights</a></dd>
                <dd id="CokeBertForEntityTyping.from_pretrained" class="function"><a href="#PreTrainedCokeBertModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="CokeBertForEntityTyping.dump_patches" class="variable">dump_patches</dd>
                <dd id="CokeBertForEntityTyping.register_buffer" class="function">register_buffer</dd>
                <dd id="CokeBertForEntityTyping.register_parameter" class="function">register_parameter</dd>
                <dd id="CokeBertForEntityTyping.add_module" class="function">add_module</dd>
                <dd id="CokeBertForEntityTyping.register_module" class="function">register_module</dd>
                <dd id="CokeBertForEntityTyping.get_submodule" class="function">get_submodule</dd>
                <dd id="CokeBertForEntityTyping.get_parameter" class="function">get_parameter</dd>
                <dd id="CokeBertForEntityTyping.get_buffer" class="function">get_buffer</dd>
                <dd id="CokeBertForEntityTyping.get_extra_state" class="function">get_extra_state</dd>
                <dd id="CokeBertForEntityTyping.set_extra_state" class="function">set_extra_state</dd>
                <dd id="CokeBertForEntityTyping.apply" class="function">apply</dd>
                <dd id="CokeBertForEntityTyping.cuda" class="function">cuda</dd>
                <dd id="CokeBertForEntityTyping.xpu" class="function">xpu</dd>
                <dd id="CokeBertForEntityTyping.cpu" class="function">cpu</dd>
                <dd id="CokeBertForEntityTyping.type" class="function">type</dd>
                <dd id="CokeBertForEntityTyping.float" class="function">float</dd>
                <dd id="CokeBertForEntityTyping.double" class="function">double</dd>
                <dd id="CokeBertForEntityTyping.half" class="function">half</dd>
                <dd id="CokeBertForEntityTyping.bfloat16" class="function">bfloat16</dd>
                <dd id="CokeBertForEntityTyping.to_empty" class="function">to_empty</dd>
                <dd id="CokeBertForEntityTyping.to" class="function">to</dd>
                <dd id="CokeBertForEntityTyping.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="CokeBertForEntityTyping.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="CokeBertForEntityTyping.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="CokeBertForEntityTyping.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="CokeBertForEntityTyping.T_destination" class="variable">T_destination</dd>
                <dd id="CokeBertForEntityTyping.state_dict" class="function">state_dict</dd>
                <dd id="CokeBertForEntityTyping.load_state_dict" class="function">load_state_dict</dd>
                <dd id="CokeBertForEntityTyping.parameters" class="function">parameters</dd>
                <dd id="CokeBertForEntityTyping.named_parameters" class="function">named_parameters</dd>
                <dd id="CokeBertForEntityTyping.buffers" class="function">buffers</dd>
                <dd id="CokeBertForEntityTyping.named_buffers" class="function">named_buffers</dd>
                <dd id="CokeBertForEntityTyping.children" class="function">children</dd>
                <dd id="CokeBertForEntityTyping.named_children" class="function">named_children</dd>
                <dd id="CokeBertForEntityTyping.modules" class="function">modules</dd>
                <dd id="CokeBertForEntityTyping.named_modules" class="function">named_modules</dd>
                <dd id="CokeBertForEntityTyping.train" class="function">train</dd>
                <dd id="CokeBertForEntityTyping.eval" class="function">eval</dd>
                <dd id="CokeBertForEntityTyping.requires_grad_" class="function">requires_grad_</dd>
                <dd id="CokeBertForEntityTyping.zero_grad" class="function">zero_grad</dd>
                <dd id="CokeBertForEntityTyping.share_memory" class="function">share_memory</dd>
                <dd id="CokeBertForEntityTyping.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="CokeBertForMaskedLM">
                            <input id="CokeBertForMaskedLM-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">CokeBertForMaskedLM</span><wbr>(<span class="base"><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></span>):

                <label class="view-source-button" for="CokeBertForMaskedLM-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForMaskedLM"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForMaskedLM-670"><a href="#CokeBertForMaskedLM-670"><span class="linenos">670</span></a><span class="k">class</span> <span class="nc">CokeBertForMaskedLM</span><span class="p">(</span><span class="n">PreTrainedCokeBertModel</span><span class="p">):</span>
</span><span id="CokeBertForMaskedLM-671"><a href="#CokeBertForMaskedLM-671"><span class="linenos">671</span></a>    <span class="sd">&quot;&quot;&quot;</span>
</span><span id="CokeBertForMaskedLM-672"><a href="#CokeBertForMaskedLM-672"><span class="linenos">672</span></a><span class="sd">    CokeBert model for masked pre-training task.  </span>
</span><span id="CokeBertForMaskedLM-673"><a href="#CokeBertForMaskedLM-673"><span class="linenos">673</span></a><span class="sd">    This module is composed of the CokeBert model with a linear layer on top of</span>
</span><span id="CokeBertForMaskedLM-674"><a href="#CokeBertForMaskedLM-674"><span class="linenos">674</span></a><span class="sd">    the sequence output.</span>
</span><span id="CokeBertForMaskedLM-675"><a href="#CokeBertForMaskedLM-675"><span class="linenos">675</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="CokeBertForMaskedLM-676"><a href="#CokeBertForMaskedLM-676"><span class="linenos">676</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="CokeBertForMaskedLM-677"><a href="#CokeBertForMaskedLM-677"><span class="linenos">677</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForMaskedLM` model</span>
</span><span id="CokeBertForMaskedLM-678"><a href="#CokeBertForMaskedLM-678"><span class="linenos">678</span></a>
</span><span id="CokeBertForMaskedLM-679"><a href="#CokeBertForMaskedLM-679"><span class="linenos">679</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForMaskedLM-680"><a href="#CokeBertForMaskedLM-680"><span class="linenos">680</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="CokeBertForMaskedLM-681"><a href="#CokeBertForMaskedLM-681"><span class="linenos">681</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForMaskedLM-682"><a href="#CokeBertForMaskedLM-682"><span class="linenos">682</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM-683"><a href="#CokeBertForMaskedLM-683"><span class="linenos">683</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM-684"><a href="#CokeBertForMaskedLM-684"><span class="linenos">684</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM-685"><a href="#CokeBertForMaskedLM-685"><span class="linenos">685</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM-686"><a href="#CokeBertForMaskedLM-686"><span class="linenos">686</span></a>
</span><span id="CokeBertForMaskedLM-687"><a href="#CokeBertForMaskedLM-687"><span class="linenos">687</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertForMaskedLM-688"><a href="#CokeBertForMaskedLM-688"><span class="linenos">688</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="CokeBertForMaskedLM-689"><a href="#CokeBertForMaskedLM-689"><span class="linenos">689</span></a>
</span><span id="CokeBertForMaskedLM-690"><a href="#CokeBertForMaskedLM-690"><span class="linenos">690</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForMaskedLM-691"><a href="#CokeBertForMaskedLM-691"><span class="linenos">691</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertForMaskedLM-692"><a href="#CokeBertForMaskedLM-692"><span class="linenos">692</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertForMaskedLM-693"><a href="#CokeBertForMaskedLM-693"><span class="linenos">693</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertForMaskedLM-694"><a href="#CokeBertForMaskedLM-694"><span class="linenos">694</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertForMaskedLM-695"><a href="#CokeBertForMaskedLM-695"><span class="linenos">695</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertForMaskedLM-696"><a href="#CokeBertForMaskedLM-696"><span class="linenos">696</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertForMaskedLM-697"><a href="#CokeBertForMaskedLM-697"><span class="linenos">697</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForMaskedLM-698"><a href="#CokeBertForMaskedLM-698"><span class="linenos">698</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertForMaskedLM-699"><a href="#CokeBertForMaskedLM-699"><span class="linenos">699</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertForMaskedLM-700"><a href="#CokeBertForMaskedLM-700"><span class="linenos">700</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertForMaskedLM-701"><a href="#CokeBertForMaskedLM-701"><span class="linenos">701</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertForMaskedLM-702"><a href="#CokeBertForMaskedLM-702"><span class="linenos">702</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertForMaskedLM-703"><a href="#CokeBertForMaskedLM-703"><span class="linenos">703</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForMaskedLM-704"><a href="#CokeBertForMaskedLM-704"><span class="linenos">704</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertForMaskedLM-705"><a href="#CokeBertForMaskedLM-705"><span class="linenos">705</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="CokeBertForMaskedLM-706"><a href="#CokeBertForMaskedLM-706"><span class="linenos">706</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="CokeBertForMaskedLM-707"><a href="#CokeBertForMaskedLM-707"><span class="linenos">707</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertForMaskedLM-708"><a href="#CokeBertForMaskedLM-708"><span class="linenos">708</span></a>
</span><span id="CokeBertForMaskedLM-709"><a href="#CokeBertForMaskedLM-709"><span class="linenos">709</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertForMaskedLM-710"><a href="#CokeBertForMaskedLM-710"><span class="linenos">710</span></a><span class="sd">            if `masked_lm_labels` is not `None`:  </span>
</span><span id="CokeBertForMaskedLM-711"><a href="#CokeBertForMaskedLM-711"><span class="linenos">711</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="CokeBertForMaskedLM-712"><a href="#CokeBertForMaskedLM-712"><span class="linenos">712</span></a><span class="sd">            if `masked_lm_labels` is `None`:  </span>
</span><span id="CokeBertForMaskedLM-713"><a href="#CokeBertForMaskedLM-713"><span class="linenos">713</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="CokeBertForMaskedLM-714"><a href="#CokeBertForMaskedLM-714"><span class="linenos">714</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForMaskedLM-715"><a href="#CokeBertForMaskedLM-715"><span class="linenos">715</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="CokeBertForMaskedLM-716"><a href="#CokeBertForMaskedLM-716"><span class="linenos">716</span></a>                                       <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM-717"><a href="#CokeBertForMaskedLM-717"><span class="linenos">717</span></a>        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM-718"><a href="#CokeBertForMaskedLM-718"><span class="linenos">718</span></a>
</span><span id="CokeBertForMaskedLM-719"><a href="#CokeBertForMaskedLM-719"><span class="linenos">719</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertForMaskedLM-720"><a href="#CokeBertForMaskedLM-720"><span class="linenos">720</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM-721"><a href="#CokeBertForMaskedLM-721"><span class="linenos">721</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="CokeBertForMaskedLM-722"><a href="#CokeBertForMaskedLM-722"><span class="linenos">722</span></a>            <span class="k">return</span> <span class="n">masked_lm_loss</span>
</span><span id="CokeBertForMaskedLM-723"><a href="#CokeBertForMaskedLM-723"><span class="linenos">723</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertForMaskedLM-724"><a href="#CokeBertForMaskedLM-724"><span class="linenos">724</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span>
</span></pre></div>


            <div class="docstring"><p>CokeBert model for masked pre-training task. <br />
This module is composed of the CokeBert model with a linear layer on top of
the sequence output.</p>
</div>


                            <div id="CokeBertForMaskedLM.__init__" class="classattr">
                                        <input id="CokeBertForMaskedLM.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">CokeBertForMaskedLM</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span></span>)</span>

                <label class="view-source-button" for="CokeBertForMaskedLM.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForMaskedLM.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForMaskedLM.__init__-676"><a href="#CokeBertForMaskedLM.__init__-676"><span class="linenos">676</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="CokeBertForMaskedLM.__init__-677"><a href="#CokeBertForMaskedLM.__init__-677"><span class="linenos">677</span></a>        <span class="sd">&quot;&quot;&quot;Constructs a `CokeBertForMaskedLM` model</span>
</span><span id="CokeBertForMaskedLM.__init__-678"><a href="#CokeBertForMaskedLM.__init__-678"><span class="linenos">678</span></a>
</span><span id="CokeBertForMaskedLM.__init__-679"><a href="#CokeBertForMaskedLM.__init__-679"><span class="linenos">679</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForMaskedLM.__init__-680"><a href="#CokeBertForMaskedLM.__init__-680"><span class="linenos">680</span></a><span class="sd">            `config`: a CokeBertConfig class instance with the configuration to build a new model.</span>
</span><span id="CokeBertForMaskedLM.__init__-681"><a href="#CokeBertForMaskedLM.__init__-681"><span class="linenos">681</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForMaskedLM.__init__-682"><a href="#CokeBertForMaskedLM.__init__-682"><span class="linenos">682</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM.__init__-683"><a href="#CokeBertForMaskedLM.__init__-683"><span class="linenos">683</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CokeBertModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM.__init__-684"><a href="#CokeBertForMaskedLM.__init__-684"><span class="linenos">684</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM.__init__-685"><a href="#CokeBertForMaskedLM.__init__-685"><span class="linenos">685</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Constructs a <code><a href="#CokeBertForMaskedLM">CokeBertForMaskedLM</a></code> model</p>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>
</ul>
</div>


                            </div>
                            <div id="CokeBertForMaskedLM.forward" class="classattr">
                                        <input id="CokeBertForMaskedLM.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">input_ids</span>,</span><span class="param">	<span class="n">input_ents</span>,</span><span class="param">	<span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="CokeBertForMaskedLM.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#CokeBertForMaskedLM.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="CokeBertForMaskedLM.forward-687"><a href="#CokeBertForMaskedLM.forward-687"><span class="linenos">687</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_lm_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="CokeBertForMaskedLM.forward-688"><a href="#CokeBertForMaskedLM.forward-688"><span class="linenos">688</span></a>        <span class="sd">&quot;&quot;&quot; Performs a Forward Pass through the model</span>
</span><span id="CokeBertForMaskedLM.forward-689"><a href="#CokeBertForMaskedLM.forward-689"><span class="linenos">689</span></a>
</span><span id="CokeBertForMaskedLM.forward-690"><a href="#CokeBertForMaskedLM.forward-690"><span class="linenos">690</span></a><span class="sd">        Args:</span>
</span><span id="CokeBertForMaskedLM.forward-691"><a href="#CokeBertForMaskedLM.forward-691"><span class="linenos">691</span></a><span class="sd">            `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span>
</span><span id="CokeBertForMaskedLM.forward-692"><a href="#CokeBertForMaskedLM.forward-692"><span class="linenos">692</span></a><span class="sd">                with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts</span>
</span><span id="CokeBertForMaskedLM.forward-693"><a href="#CokeBertForMaskedLM.forward-693"><span class="linenos">693</span></a><span class="sd">                `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span>
</span><span id="CokeBertForMaskedLM.forward-694"><a href="#CokeBertForMaskedLM.forward-694"><span class="linenos">694</span></a><span class="sd">            `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span>
</span><span id="CokeBertForMaskedLM.forward-695"><a href="#CokeBertForMaskedLM.forward-695"><span class="linenos">695</span></a><span class="sd">                types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span>
</span><span id="CokeBertForMaskedLM.forward-696"><a href="#CokeBertForMaskedLM.forward-696"><span class="linenos">696</span></a><span class="sd">                a `sentence B` token (see BERT paper for more details).</span>
</span><span id="CokeBertForMaskedLM.forward-697"><a href="#CokeBertForMaskedLM.forward-697"><span class="linenos">697</span></a><span class="sd">            `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForMaskedLM.forward-698"><a href="#CokeBertForMaskedLM.forward-698"><span class="linenos">698</span></a><span class="sd">                selected in [0, 1]. It&#39;s a mask to be used if the input sequence length is smaller than the max</span>
</span><span id="CokeBertForMaskedLM.forward-699"><a href="#CokeBertForMaskedLM.forward-699"><span class="linenos">699</span></a><span class="sd">                input sequence length in the current batch. It&#39;s the mask that we typically use for attention when</span>
</span><span id="CokeBertForMaskedLM.forward-700"><a href="#CokeBertForMaskedLM.forward-700"><span class="linenos">700</span></a><span class="sd">                a batch has varying length sentences.</span>
</span><span id="CokeBertForMaskedLM.forward-701"><a href="#CokeBertForMaskedLM.forward-701"><span class="linenos">701</span></a><span class="sd">            `input_ent`: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]</span>
</span><span id="CokeBertForMaskedLM.forward-702"><a href="#CokeBertForMaskedLM.forward-702"><span class="linenos">702</span></a><span class="sd">                with the entities embeddings</span>
</span><span id="CokeBertForMaskedLM.forward-703"><a href="#CokeBertForMaskedLM.forward-703"><span class="linenos">703</span></a><span class="sd">            `ent_mask`: a torch.LongTensor of shape [batch_size, sequence_length] with indices</span>
</span><span id="CokeBertForMaskedLM.forward-704"><a href="#CokeBertForMaskedLM.forward-704"><span class="linenos">704</span></a><span class="sd">                selected in [0, 1]</span>
</span><span id="CokeBertForMaskedLM.forward-705"><a href="#CokeBertForMaskedLM.forward-705"><span class="linenos">705</span></a><span class="sd">            `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span>
</span><span id="CokeBertForMaskedLM.forward-706"><a href="#CokeBertForMaskedLM.forward-706"><span class="linenos">706</span></a><span class="sd">                with indices selected in [0, ..., num_labels].</span>
</span><span id="CokeBertForMaskedLM.forward-707"><a href="#CokeBertForMaskedLM.forward-707"><span class="linenos">707</span></a><span class="sd">            k_v_s: list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</span>
</span><span id="CokeBertForMaskedLM.forward-708"><a href="#CokeBertForMaskedLM.forward-708"><span class="linenos">708</span></a>
</span><span id="CokeBertForMaskedLM.forward-709"><a href="#CokeBertForMaskedLM.forward-709"><span class="linenos">709</span></a><span class="sd">        Returns:</span>
</span><span id="CokeBertForMaskedLM.forward-710"><a href="#CokeBertForMaskedLM.forward-710"><span class="linenos">710</span></a><span class="sd">            if `masked_lm_labels` is not `None`:  </span>
</span><span id="CokeBertForMaskedLM.forward-711"><a href="#CokeBertForMaskedLM.forward-711"><span class="linenos">711</span></a><span class="sd">                Outputs the CrossEntropy classification loss of the output with the labels.  </span>
</span><span id="CokeBertForMaskedLM.forward-712"><a href="#CokeBertForMaskedLM.forward-712"><span class="linenos">712</span></a><span class="sd">            if `masked_lm_labels` is `None`:  </span>
</span><span id="CokeBertForMaskedLM.forward-713"><a href="#CokeBertForMaskedLM.forward-713"><span class="linenos">713</span></a><span class="sd">                Outputs the classification logits of shape [batch_size, num_labels].  </span>
</span><span id="CokeBertForMaskedLM.forward-714"><a href="#CokeBertForMaskedLM.forward-714"><span class="linenos">714</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="CokeBertForMaskedLM.forward-715"><a href="#CokeBertForMaskedLM.forward-715"><span class="linenos">715</span></a>        <span class="n">sequence_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_ents</span><span class="p">,</span> <span class="n">ent_mask</span><span class="p">,</span>
</span><span id="CokeBertForMaskedLM.forward-716"><a href="#CokeBertForMaskedLM.forward-716"><span class="linenos">716</span></a>                                       <span class="n">output_all_encoded_layers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k_v_s</span><span class="o">=</span><span class="n">k_v_s</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM.forward-717"><a href="#CokeBertForMaskedLM.forward-717"><span class="linenos">717</span></a>        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM.forward-718"><a href="#CokeBertForMaskedLM.forward-718"><span class="linenos">718</span></a>
</span><span id="CokeBertForMaskedLM.forward-719"><a href="#CokeBertForMaskedLM.forward-719"><span class="linenos">719</span></a>        <span class="k">if</span> <span class="n">masked_lm_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="CokeBertForMaskedLM.forward-720"><a href="#CokeBertForMaskedLM.forward-720"><span class="linenos">720</span></a>            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="CokeBertForMaskedLM.forward-721"><a href="#CokeBertForMaskedLM.forward-721"><span class="linenos">721</span></a>            <span class="n">masked_lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">prediction_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">masked_lm_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="CokeBertForMaskedLM.forward-722"><a href="#CokeBertForMaskedLM.forward-722"><span class="linenos">722</span></a>            <span class="k">return</span> <span class="n">masked_lm_loss</span>
</span><span id="CokeBertForMaskedLM.forward-723"><a href="#CokeBertForMaskedLM.forward-723"><span class="linenos">723</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="CokeBertForMaskedLM.forward-724"><a href="#CokeBertForMaskedLM.forward-724"><span class="linenos">724</span></a>            <span class="k">return</span> <span class="n">prediction_scores</span>
</span></pre></div>


            <div class="docstring"><p>Performs a Forward Pass through the model</p>

<h6 id="args">Args</h6>

<ul>
<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]
with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts
<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>
<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token
types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to
a <code>sentence B</code> token (see BERT paper for more details).</li>
<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max
input sequence length in the current batch. It's the mask that we typically use for attention when
a batch has varying length sentences.</li>
<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]
with the entities embeddings</li>
<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices
selected in [0, 1]</li>
<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]
with indices selected in [0, ..., num_labels].</li>
<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
  <p>if <code>masked_lm_labels</code> is not <code>None</code>: <br />
      Outputs the CrossEntropy classification loss of the output with the labels. <br />
  if <code>masked_lm_labels</code> is <code>None</code>: <br />
      Outputs the classification logits of shape [batch_size, num_labels].</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#PreTrainedCokeBertModel">PreTrainedCokeBertModel</a></dt>
                                <dd id="CokeBertForMaskedLM.init_weights" class="function"><a href="#PreTrainedCokeBertModel.init_weights">init_weights</a></dd>
                <dd id="CokeBertForMaskedLM.from_pretrained" class="function"><a href="#PreTrainedCokeBertModel.from_pretrained">from_pretrained</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="CokeBertForMaskedLM.dump_patches" class="variable">dump_patches</dd>
                <dd id="CokeBertForMaskedLM.register_buffer" class="function">register_buffer</dd>
                <dd id="CokeBertForMaskedLM.register_parameter" class="function">register_parameter</dd>
                <dd id="CokeBertForMaskedLM.add_module" class="function">add_module</dd>
                <dd id="CokeBertForMaskedLM.register_module" class="function">register_module</dd>
                <dd id="CokeBertForMaskedLM.get_submodule" class="function">get_submodule</dd>
                <dd id="CokeBertForMaskedLM.get_parameter" class="function">get_parameter</dd>
                <dd id="CokeBertForMaskedLM.get_buffer" class="function">get_buffer</dd>
                <dd id="CokeBertForMaskedLM.get_extra_state" class="function">get_extra_state</dd>
                <dd id="CokeBertForMaskedLM.set_extra_state" class="function">set_extra_state</dd>
                <dd id="CokeBertForMaskedLM.apply" class="function">apply</dd>
                <dd id="CokeBertForMaskedLM.cuda" class="function">cuda</dd>
                <dd id="CokeBertForMaskedLM.xpu" class="function">xpu</dd>
                <dd id="CokeBertForMaskedLM.cpu" class="function">cpu</dd>
                <dd id="CokeBertForMaskedLM.type" class="function">type</dd>
                <dd id="CokeBertForMaskedLM.float" class="function">float</dd>
                <dd id="CokeBertForMaskedLM.double" class="function">double</dd>
                <dd id="CokeBertForMaskedLM.half" class="function">half</dd>
                <dd id="CokeBertForMaskedLM.bfloat16" class="function">bfloat16</dd>
                <dd id="CokeBertForMaskedLM.to_empty" class="function">to_empty</dd>
                <dd id="CokeBertForMaskedLM.to" class="function">to</dd>
                <dd id="CokeBertForMaskedLM.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="CokeBertForMaskedLM.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="CokeBertForMaskedLM.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="CokeBertForMaskedLM.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="CokeBertForMaskedLM.T_destination" class="variable">T_destination</dd>
                <dd id="CokeBertForMaskedLM.state_dict" class="function">state_dict</dd>
                <dd id="CokeBertForMaskedLM.load_state_dict" class="function">load_state_dict</dd>
                <dd id="CokeBertForMaskedLM.parameters" class="function">parameters</dd>
                <dd id="CokeBertForMaskedLM.named_parameters" class="function">named_parameters</dd>
                <dd id="CokeBertForMaskedLM.buffers" class="function">buffers</dd>
                <dd id="CokeBertForMaskedLM.named_buffers" class="function">named_buffers</dd>
                <dd id="CokeBertForMaskedLM.children" class="function">children</dd>
                <dd id="CokeBertForMaskedLM.named_children" class="function">named_children</dd>
                <dd id="CokeBertForMaskedLM.modules" class="function">modules</dd>
                <dd id="CokeBertForMaskedLM.named_modules" class="function">named_modules</dd>
                <dd id="CokeBertForMaskedLM.train" class="function">train</dd>
                <dd id="CokeBertForMaskedLM.eval" class="function">eval</dd>
                <dd id="CokeBertForMaskedLM.requires_grad_" class="function">requires_grad_</dd>
                <dd id="CokeBertForMaskedLM.zero_grad" class="function">zero_grad</dd>
                <dd id="CokeBertForMaskedLM.share_memory" class="function">share_memory</dd>
                <dd id="CokeBertForMaskedLM.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.type) {
                    case "function":
                        heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span><span class="signature">${doc.signature}:</span>`;
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value">${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.type}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>