window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = {"version": "0.9.5", "fields": ["qualname", "fullname", "annotation", "default_value", "signature", "bases", "doc"], "ref": "fullname", "documentStore": {"docs": {"canlpy": {"fullname": "canlpy", "modulename": "canlpy", "type": "module", "doc": "<p>This is canlpy, a python library for building and testing knowledge enhanced language models. </p>\n\n<h3 id=\"requirements\">Requirements:</h3>\n\n<p>Pytorch <br />\nPython3 &gt;=3.6.9</p>\n\n<h2 id=\"setup\">Setup</h2>\n\n<p>Run <code>pip install -e .</code> in the home directory to setup the project</p>\n\n<h2 id=\"quick-start-guide\">Quick-start guide</h2>\n\n<h3 id=\"ernie\">ERNIE</h3>\n\n<p>Download pre-trained knowledge embedding from <a href=\"https://drive.google.com/open?id=14VNvGMtYWxuqT-PWDa8sD0e7hO486i8Y\">Google Drive</a>/<a href=\"https://cloud.tsinghua.edu.cn/f/229e8cccedc2419f987e/\">Tsinghua Cloud</a> and extract it.</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code>tar -xvzf kg_embed.tar.gz\n</code></pre></div>\n\n<p>Store the content of kg_embed in <code>canlpy/knowledge/ernie/</code></p>\n\n<p>Download pre-trained ERNIE from <a href=\"https://drive.google.com/uc?export=download&amp;id=1Hdp_iqsF3xjFcWSRvklC5ppvvd2C0qim\">Google Drive</a> and extract it.</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code>tar -xvzf ernie_base.tar.gz\n</code></pre></div>\n\n<p>Store the content of ernie_base in <code>pretrained_models/ernie/</code></p>\n\n<p>Add your TAGME token in a tokens.py file located in the canlpy/helpers folder <br />\nToken name is TAGME_TOKEN</p>\n\n<p>Once that is done, you can run <code>ernie.ipynb</code> from the examples/ folder. </p>\n\n<h3 id=\"cokebert\">CokeBert</h3>\n\n<p>You can find the pretrained CokeBert model provided by the authors of the CokeBert paper, which is available from <a href=\"https://drive.google.com/file/d/1Ce7Nq7vJ83l4lOV9SiiN2Kq831z_phsV/view?usp=sharing\">here</a>. \nThen unzip the file, and copy the content of the <code>DKPLM_BERTbase_2layer</code> folder into <code>canlpy/canlpy/pretrained_models/cokebert</code> </p>\n\n<p>From the same file, copy the <code>load_data_n</code> folder into <code>canlpy/canlpy/knowledge/cokebert/</code></p>\n\n<p>You can find the datasets for the knowledge graph representation used by the authors of the ERNIE paper, download them into this folder from <a href=\"https://drive.google.com/open?id=1HlWw7Q6-dFSm9jNSCh4VaBf1PlGqt9im\">here</a> and run </p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code>tar -xvzf data.tar.gz\n</code></pre></div>\n\n<p>to extract it. </p>\n\n<p>Then copy <code>kg_embed</code> into <code>canlpy/canlpy/knowledge/cokebert/</code></p>\n\n<p>Add your TAGME token in a tokens.py file located in the canlpy/helpers folder <br />\nToken name is TAGME_TOKEN</p>\n\n<p>Once that is done, you can run <code>cokebert.ipynb</code> from the examples folder.</p>\n"}, "canlpy.core": {"fullname": "canlpy.core", "modulename": "canlpy.core", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components": {"fullname": "canlpy.core.components", "modulename": "canlpy.core.components", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.activation_functions": {"fullname": "canlpy.core.components.activation_functions", "modulename": "canlpy.core.components.activation_functions", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.activation_functions.gelu": {"fullname": "canlpy.core.components.activation_functions.gelu", "modulename": "canlpy.core.components.activation_functions", "qualname": "gelu", "type": "function", "doc": "<p>Implementation of the gelu activation function.\nFor information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))</p>\n", "signature": "(x)", "funcdef": "def"}, "canlpy.core.components.activation_functions.get_activation_function": {"fullname": "canlpy.core.components.activation_functions.get_activation_function", "modulename": "canlpy.core.components.activation_functions", "qualname": "get_activation_function", "type": "function", "doc": "<p></p>\n", "signature": "(name: str)", "funcdef": "def"}, "canlpy.core.components.fusion": {"fullname": "canlpy.core.components.fusion", "modulename": "canlpy.core.components.fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.cokebert_fusion": {"fullname": "canlpy.core.components.fusion.cokebert_fusion", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"fullname": "canlpy.core.components.fusion.cokebert_fusion.DK_fusion", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "qualname": "DK_fusion", "type": "class", "doc": "<p>A class for the Text and Knowledge Fusion in a <code>DKEncoderLayer</code> from CokeBert.</p>\n", "bases": "canlpy.core.components.fusion.fusion.Fusion"}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"fullname": "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "qualname": "DK_fusion.__init__", "type": "function", "doc": "<p>Constructs a <code>DK_fusion</code> module</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n<li><strong>layer_no (int):</strong>  Number of the layer (assigned in reverse order)</li>\n</ul>\n", "signature": "(self, k_v_dim, layer_no)", "funcdef": "def"}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"fullname": "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "qualname": "DK_fusion.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>q_i:</strong>  internal text representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n<li><strong>k:</strong>  internal knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n<li><strong>v:</strong>  internal knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>sentence_entity_reps: internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</p>\n</blockquote>\n", "signature": "(self, q_i, k, v)", "funcdef": "def"}, "canlpy.core.components.fusion.ernie_fusion": {"fullname": "canlpy.core.components.fusion.ernie_fusion", "modulename": "canlpy.core.components.fusion.ernie_fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"fullname": "canlpy.core.components.fusion.ernie_fusion.ErnieFusion", "modulename": "canlpy.core.components.fusion.ernie_fusion", "qualname": "ErnieFusion", "type": "class", "doc": "<p>Class for the Fusion of Text and Knowledge representations in ERNIE</p>\n", "bases": "canlpy.core.components.fusion.fusion.Fusion"}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"fullname": "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__", "modulename": "canlpy.core.components.fusion.ernie_fusion", "qualname": "ErnieFusion.__init__", "type": "function", "doc": "<p>Constructs an <code>ErnieFusion</code> module</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_size (int):</strong>  size of the Text representations</li>\n<li><strong>entity_size (int):</strong>  size of the Knowledge representations</li>\n<li><strong>intermediate_size (int):</strong>  hidden size of the Fusion layer</li>\n<li><strong>hidden_dropout_prob (float):</strong>  dropout probability</li>\n<li><strong>activation_fn:</strong>  str or function: activation function of Fusion layer</li>\n</ul>\n", "signature": "(\n    self,\n    hidden_size,\n    entity_size,\n    intermediate_size,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"fullname": "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward", "modulename": "canlpy.core.components.fusion.ernie_fusion", "qualname": "ErnieFusion.forward", "type": "function", "doc": "<p>Forward pass through the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>attention_tokens:</strong>  text representations, a torch.FloatTensor of shape [batch_size, sequence_length, hidden_size]</li>\n<li><strong>attention_ent:</strong>  entity representations, a torch.FloatTensor of shape [batch_size, sequence_length, entity_size]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: New text representations, a torch.FloatTensor of shape [batch_size, sequence_length, hidden_size]\n  hidden_states_ent: New entity representations, a torch.FloatTensor of shape [batch_size, sequence_length, entity_size]</p>\n</blockquote>\n", "signature": "(self, attention_tokens, attention_ent)", "funcdef": "def"}, "canlpy.core.components.fusion.fusion": {"fullname": "canlpy.core.components.fusion.fusion", "modulename": "canlpy.core.components.fusion.fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.fusion.Fusion": {"fullname": "canlpy.core.components.fusion.fusion.Fusion", "modulename": "canlpy.core.components.fusion.fusion", "qualname": "Fusion", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"fullname": "canlpy.core.components.fusion.fusion.Fusion.__init__", "modulename": "canlpy.core.components.fusion.fusion", "qualname": "Fusion.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"fullname": "canlpy.core.components.fusion.fusion.Fusion.forward", "modulename": "canlpy.core.components.fusion.fusion", "qualname": "Fusion.forward", "type": "function", "doc": "<p>Performs the information fusion between the token and entity emmbeddings</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>May contain:</strong> </li>\n<li><strong>token_embeddings:</strong>  the tokens embeddings</li>\n<li><strong>entity_embeddings:</strong>  the entity embeddings</li>\n<li>token/entity masks</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>token_embeddings: the enhanced embeddings of the tokens \n  entity embeddings(Optional): the enhanced embeddings of the entities</p>\n</blockquote>\n", "signature": "(self, args)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion": {"fullname": "canlpy.core.components.fusion.knowbert_fusion", "modulename": "canlpy.core.components.fusion.knowbert_fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "DotAttentionWithPrior", "type": "class", "doc": "<p>Performs a MLP on the entity prior and the cosine similarity between the span and entity embedding to compute an entity score</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>output_feed_forward_hidden_dim:</strong>  the MLP hidden dim</li>\n<li><strong>weighted_entity_threshold:</strong>  the entity linking score threshold under which an entity is no longer considered</li>\n<li><strong>null_embedding:</strong>  the default embedding for a null entity</li>\n<li><strong>initializer_range:</strong>  the std range for the linear layer initialization</li>\n</ul>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "DotAttentionWithPrior.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    output_feed_forward_hidden_dim: int = 100,\n    weighted_entity_threshold: float = None,\n    null_embedding: torch.Tensor = None,\n    initializer_range: float = 0.02\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "DotAttentionWithPrior.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>projected_span_representations:</strong>  (batch_size, num_spans, entity_dim)</li>\n<li><strong>candidate_entity_embeddings:</strong>  (batch_size, num_spans, num_candidates, entity_embedding_dim)</li>\n<li><strong>candidate_entity_prior:</strong>  (batch_size, num_spans, num_candidates)\nwith prior probability of each candidate entity.\n0 &lt;= candidate_entity_prior &lt;= 1 and candidate_entity_prior.sum(dim=-1) == 1\nentity_mask = (batch_size, num_spans, num_candidates)\n   with 0/1 bool of whether it is a valid candidate</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>dict with:\n  linking_scores: linking score to each entity in each span (batch_size, num_spans, num_candidates)\n          masked with -10000 for invalid links\n  weighted_entity_embeddings: weighted entity embedding (batch_size, num_spans, entity_dim)</p>\n</blockquote>\n", "signature": "(\n    self,\n    projected_span_representations,\n    candidate_entity_embeddings,\n    candidate_entity_prior,\n    entity_mask\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityDisambiguator", "type": "class", "doc": "<p>Aligns the bert and KG vector space by learning a mapping between them.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityDisambiguator.__init__", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>contextual_embedding_dim:</strong>  dimension of token embeddding</li>\n<li><strong>entity_embedding_dim:</strong>  dimension of entity embeddings</li>\n<li><strong>entity_embeddings:</strong>  contains embeddings of entity id to vector</li>\n<li><strong>max_sequence_length:</strong>  length of max sequence (unused)</li>\n<li><strong>span_encoder_config:</strong>  configuraton of span encoder (hidden_size,num_hidden_layers,num_attention_heads,intermediate_size)</li>\n<li><strong>dropout:</strong>  dropout probability in training </li>\n<li><strong>output_feed_forward_hidden_dim:</strong>  #hidden dim of 1 hidden layer MLP to compute similarity between mention and KB entity \nMLP(prior,mention_embedding @ entity_embedding)</li>\n<li><strong>initializer_range:</strong>  std of normal weight initialization</li>\n<li><strong>weighted_entity_threshold:</strong>  similarity threshold (computed using MLP (DotAttentionWithPrior)) \nunder which an entity is not considered for the weighted sum representation of entity</li>\n<li><strong>null_embedding:</strong>  enbedding of null entity</li>\n</ul>\n", "signature": "(\n    self,\n    contextual_embedding_dim: int,\n    entity_embedding_dim: int,\n    entity_embeddings: canlpy.core.models.knowbert.knowledge.EntityEmbedder,\n    max_sequence_length: int = 512,\n    span_encoder_config: Dict[str, int] = None,\n    dropout: float = 0.1,\n    output_feed_forward_hidden_dim: int = 100,\n    initializer_range: float = 0.02,\n    weighted_entity_threshold: float = None,\n    null_embedding: torch.Tensor = None\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityDisambiguator.unfreeze", "type": "function", "doc": "<p>Freezes or unfreezes some of the weights depending on the provided mode</p>\n\n<p><code>entity_linking</code>: only unfreezes the entity linker weights\n<code>freeze</code>: freezes all the weights\nelse: unfreezes all the weights</p>\n", "signature": "(self, mode)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityDisambiguator.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>contextual_embeddings:</strong>  (batch_size, timesteps, dim) output from language model</li>\n<li><strong>mask:</strong>  (batch_size, num_times)</li>\n<li><strong>candidate_spans:</strong>  (batch_size, max_num_spans, 2) with candidate\nmention spans. This gives the start / end location for each\nspan such span i in row k has:\n   start, end = candidate_spans[k, i, :]\n   span_embeddings = contextual_embeddings[k, start:end, :]\nit is padded with -1</li>\n<li><strong>candidate_entities:</strong>  (batch_size, max_num_spans, max_entity_ids), padded with 0</li>\n<li><strong>candidate_entity_prior:</strong>  (batch_size, max_num_spans, max_entity_ids) with prior probability of each candidate entity.\n0 &lt;= candidate_entity_prior &lt;= 1 and candidate_entity_prior.sum(dim=-1) == 1</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>linking sccore to each entity in each span\n      (batch_size, max_num_spans, max_entity_ids)\n  masked with -10000 for invalid links</p>\n</blockquote>\n", "signature": "(\n    self,\n    contextual_embeddings: torch.Tensor,\n    mask: torch.Tensor,\n    candidate_spans: torch.Tensor,\n    candidate_entities: torch.Tensor,\n    candidate_entity_priors: torch.Tensor,\n    candidate_segment_ids: torch.Tensor,\n    **kwargs\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingBase", "type": "class", "doc": "<p>Base class to compute the loss of the entity linking module</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>null_entity_id: the id of the null_entity\n  margin: the margin if margin loss is used\n  decode_threshold: the attention score threshold\n  loss_type: the type of loss, <code>margin</code> or <code>threshold</code></p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingBase.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    null_entity_id: int,\n    margin: float = 0.2,\n    decode_threshold: float = 0.0,\n    loss_type: str = 'margin'\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingBase.get_metrics", "type": "function", "doc": "<p></p>\n", "signature": "(self, reset: bool = False)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingWithCandidateMentions", "type": "class", "doc": "<p>Class with no parameters that forwards arguments to entity disambiguator and computes the loss</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li>see <code>EntityDisambiguator</code></li>\n</ul>\n", "bases": "EntityLinkingBase"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingWithCandidateMentions.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    null_entity_id: int,\n    entity_embedding: canlpy.core.models.knowbert.knowledge.EntityEmbedder = None,\n    contextual_embedding_dim: int = None,\n    span_encoder_config: Dict[str, int] = None,\n    margin: float = 0.2,\n    decode_threshold: float = 0.0,\n    loss_type: str = 'margin',\n    max_sequence_length: int = 512,\n    dropout: float = 0.1,\n    output_feed_forward_hidden_dim: int = 100,\n    initializer_range: float = 0.02\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingWithCandidateMentions.get_metrics", "type": "function", "doc": "<p></p>\n", "signature": "(self, reset: bool = False)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingWithCandidateMentions.unfreeze", "type": "function", "doc": "<p></p>\n", "signature": "(self, mode)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "EntityLinkingWithCandidateMentions.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    contextual_embeddings: torch.Tensor,\n    tokens_mask: torch.Tensor,\n    candidate_spans: torch.Tensor,\n    candidate_entities: torch.Tensor,\n    candidate_entity_priors: torch.Tensor,\n    candidate_segment_ids: torch.Tensor,\n    **kwargs\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "SolderedKG", "type": "class", "doc": "<p>KnowBert's Fusion class</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>entity_linker: the module that computes the entity scores\n  span_attention_config: the configuration for the span attention layer\n  should_init_kg_to_bert_inverse: whether to init the second projection layer to the inverse of the first\n      see equation (7) of paper for more details\n  freeze: whether to freeze the parameters of the model</p>\n</blockquote>\n", "bases": "canlpy.core.components.fusion.fusion.Fusion"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "SolderedKG.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    entity_linker: torch.nn.modules.module.Module,\n    span_attention_config: Dict[str, int],\n    should_init_kg_to_bert_inverse: bool = True,\n    freeze: bool = False\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "SolderedKG.from_config", "type": "function", "doc": "<p>Creates a SolderedKG from a config class</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>config:</strong>  the config class</li>\n<li><strong>entity_vocabulary:</strong>  the Vocabulary class for the entities</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>model: a SolderedKG class</p>\n</blockquote>\n", "signature": "(cls, config, entity_vocabulary)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "SolderedKG.unfreeze", "type": "function", "doc": "<p>Freezes/unfreezes specific weights of the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>mode:</strong>  the freezing mode, if <code>entity_linking</code>, freeze all parameters except the entity linker, \nelse, unfreeze all the parameterss</li>\n</ul>\n", "signature": "(self, mode)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.soldered_kg", "qualname": "SolderedKG.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>contextual_embeddings:</strong>  the token embeddings</li>\n<li><strong>tokens_mask:</strong>  the tokens mask</li>\n<li><strong>candidate_spans:</strong>  the spans of the candidate entities</li>\n<li><strong>candidate_entities:</strong>  the embeddings of the candidate entities</li>\n<li><strong>candidate_entity_priors:</strong>  the prior of the candidate entities</li>\n<li><strong>candidate_segment_ids:</strong>  the segment ids of the candidate entities</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>a dictionnary: \n  {'entity_attention_probs': entity_attention_probs,\n  'contextual_embeddings': new_contextual_embeddings,\n  'linking_scores': linker_output['linking_scores']}</p>\n</blockquote>\n", "signature": "(\n    self,\n    contextual_embeddings: torch.Tensor,\n    tokens_mask: torch.Tensor,\n    candidate_spans: torch.Tensor,\n    candidate_entities: torch.Tensor,\n    candidate_entity_priors: torch.Tensor,\n    candidate_segment_ids: torch.Tensor,\n    **kwargs\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanWordAttention", "type": "class", "doc": "<p>Performs a special attention mechanism on the token embeddings and entity embeddings</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>config: contains the necessary configuration (hidden_size and num_attention_heads)</p>\n</blockquote>\n", "bases": "canlpy.core.components.fusion.fusion.Fusion"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanWordAttention.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanWordAttention.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  (batch_size, timesteps, dim), contains the embeddings the attention is performed on </li>\n<li><strong>entity_embeddings:</strong>  (batch_size, num_entities, dim), contains the embeddings the attention is performed on </li>\n<li><strong>entity_mask:</strong>  (batch_size, num_entities) with 0/1, the mask to apply on the attention scores</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>context_layer: the token embeddings after the attention mechanism\n  attention_probs: the attention scores</p>\n</blockquote>\n", "signature": "(self, hidden_states, entity_embeddings, entity_mask)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanAttention", "type": "class", "doc": "<p>Combines SpanWordAttention and a linear layer</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanAttention.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanAttention.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_tensor:</strong>  the token embeddings</li>\n<li><strong>entity_embeddings:</strong>  the embeddings of the entities</li>\n<li><strong>entity_mask:</strong>  a mask of 0,1 to apply on the entities</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>context_layer: the enhanced token embeddings\n  attention_probs: the attention scores</p>\n</blockquote>\n", "signature": "(self, input_tensor, entity_embeddings, entity_mask)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanAttentionLayer", "type": "class", "doc": "<p>Combines SpanWordAttention and BERT linear layers</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanAttentionLayer.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer", "qualname": "SpanAttentionLayer.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  the token embeddings</li>\n<li><strong>entity_embeddings:</strong>  the embeddings of the entities</li>\n<li><strong>entity_mask:</strong>  a mask of 0,1 to apply on the entities</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>{\"output\": layer_output, \"attention_probs\": attention_probs}\n  layer_output: the enhanced token embeddings\n  attention_probs: the attention scores</p>\n</blockquote>\n", "signature": "(self, hidden_states, entity_embeddings, entity_mask)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SpanExtractor", "type": "class", "doc": "<p>Many NLP models deal with representations of spans inside a sentence.\nSpanExtractors define methods for extracting and representing spans\nfrom a sentence.</p>\n\n<p>SpanExtractors take a sequence tensor of shape (batch_size, timesteps, embedding_dim)\nand indices of shape (batch_size, num_spans, 2) and return a tensor of\nshape (batch_size, num_spans, ...), forming some representation of the\nspans.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SpanExtractor.forward", "type": "function", "doc": "<p>Given a sequence tensor, extract spans and return representations of\nthem. Span representation can be computed in many different ways,\nsuch as concatenation of the start and end spans, attention over the\nvectors contained inside the span, etc.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>sequence_tensor :</strong>  <code>torch.FloatTensor</code>, required.\nA tensor of shape (batch_size, sequence_length, embedding_size)\nrepresenting an embedded sequence of words.</li>\n<li><strong>span_indices :</strong>  <code>torch.LongTensor</code>, required.\nA tensor of shape <code>(batch_size, num_spans, 2)</code>, where the last\ndimension represents the inclusive start and end indices of the\nspan to be extracted from the <code>sequence_tensor</code>.</li>\n<li><strong>sequence_mask :</strong>  <code>torch.LongTensor</code>, optional (default = <code>None</code>).\nA tensor of shape (batch_size, sequence_length) representing padded\nelements of the sequence.</li>\n<li><strong>span_indices_mask :</strong>  <code>torch.LongTensor</code>, optional (default = <code>None</code>).\nA tensor of shape (batch_size, num_spans) representing the valid\nspans in the <code>indices</code> tensor. This mask is optional because\nsometimes it's easier to worry about masking after calling this\nfunction, rather than passing a mask directly.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A tensor of shape <code>(batch_size, num_spans, embedded_span_size)</code>,\n  where <code>embedded_span_size</code> depends on the way spans are represented.</p>\n</blockquote>\n", "signature": "(\n    self,\n    sequence_tensor: torch.FloatTensor,\n    span_indices: torch.LongTensor,\n    sequence_mask: torch.LongTensor = None,\n    span_indices_mask: torch.LongTensor = None\n)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SpanExtractor.get_input_dim", "type": "function", "doc": "<p>Returns the expected final dimension of the <code>sequence_tensor</code>.</p>\n", "signature": "(self) -> int", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SpanExtractor.get_output_dim", "type": "function", "doc": "<p>Returns the expected final dimension of the returned span representation.</p>\n", "signature": "(self) -> int", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SelfAttentiveSpanExtractor", "type": "class", "doc": "<p>Computes span representations by generating an unnormalized attention score for each\nword in the document. Spans representations are computed with respect to these\nscores by normalising the attention scores for words inside the span.</p>\n\n<p>Given these attention distributions over every span, this module weights the\ncorresponding vector representations of the words in the span by this distribution,\nreturning a weighted representation of each span.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>input_dim : <code>int</code>, required.\n      The final dimension of the <code>sequence_tensor</code>.</p>\n</blockquote>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>attended_text_embeddings : <code>torch.FloatTensor</code>.\n      A tensor of shape (batch_size, num_spans, input_dim), which each span representation\n      is formed by locally normalising a global attention over the sequence. The only way\n      in which the attention distribution differs over different spans is in the set of words\n      over which they are normalized.</p>\n</blockquote>\n", "bases": "SpanExtractor"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SelfAttentiveSpanExtractor.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, input_dim: int)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SelfAttentiveSpanExtractor.get_input_dim", "type": "function", "doc": "<p>Returns the expected final dimension of the <code>sequence_tensor</code>.</p>\n", "signature": "(self) -> int", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SelfAttentiveSpanExtractor.get_output_dim", "type": "function", "doc": "<p>Returns the expected final dimension of the returned span representation.</p>\n", "signature": "(self) -> int", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "SelfAttentiveSpanExtractor.forward", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    sequence_tensor: torch.FloatTensor,\n    span_indices: torch.LongTensor,\n    sequence_mask: torch.LongTensor = None,\n    span_indices_mask: torch.LongTensor = None\n) -> torch.FloatTensor", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "flatten_and_batch_shift_indices", "type": "function", "doc": "<p>This is a subroutine for <code>~batched_index_select</code>. The given <code>indices</code> of size\n<code>(batch_size, d_1, ..., d_n)</code> indexes into dimension 2 of a target tensor, which has size\n<code>(batch_size, sequence_length, embedding_size)</code>. This function returns a vector that\ncorrectly indexes into the flattened target. The sequence length of the target must be\nprovided to compute the appropriate offsets.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>indices : <code>torch.LongTensor</code>, required.\n  sequence_length : <code>int</code>, required.\n      The length of the sequence the indices index into.\n      This must be the second dimension of the tensor.</p>\n</blockquote>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>offset_indices : <code>torch.LongTensor</code></p>\n</blockquote>\n", "signature": "(indices: torch.Tensor, sequence_length: int) -> torch.Tensor", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "batched_index_select", "type": "function", "doc": "<p>The given <code>indices</code> of size <code>(batch_size, d_1, ..., d_n)</code> indexes into the sequence\ndimension (dimension 2) of the target, which has size <code>(batch_size, sequence_length,\nembedding_size)</code>.</p>\n\n<p>This function returns selected values in the target with respect to the provided indices, which\nhave size <code>(batch_size, d_1, ..., d_n, embedding_size)</code>. This can use the optionally\nprecomputed <code>~flattened_indices</code> with size <code>(batch_size * d_1 * ... * d_n)</code> if given.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>target : <code>torch.Tensor</code>, required.\n      A 3 dimensional tensor of shape (batch_size, sequence_length, embedding_size).\n      This is the tensor to be indexed.\n  indices : <code>torch.LongTensor</code>\n      A tensor of shape (batch_size, ...), where each element is an index into the\n      <code>sequence_length</code> dimension of the <code>target</code> tensor.\n  flattened_indices : Optional[torch.Tensor], optional (default = None)\n      An optional tensor representing the result of calling ~<code>flatten_and_batch_shift_indices</code>\n      on <code>indices</code>. This is helpful in the case that the indices can be flattened once and\n      cached for many batch lookups.</p>\n</blockquote>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>selected_targets : <code>torch.Tensor</code>\n      A tensor with shape [indices.size(), target.size(-1)] representing the embedded indices\n      extracted from the batch flattened target tensor.</p>\n</blockquote>\n", "signature": "(\n    target: torch.Tensor,\n    indices: torch.LongTensor,\n    flattened_indices: torch.LongTensor = None\n) -> torch.Tensor", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"fullname": "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax", "modulename": "canlpy.core.components.fusion.knowbert_fusion.span_extractor", "qualname": "masked_softmax", "type": "function", "doc": "<p><code>torch.nn.functional.softmax(vector)</code> does not work if some elements of <code>vector</code> should be\nmasked.  This performs a softmax on just the non-masked portions of <code>vector</code>.  Passing\n<code>None</code> in for the mask is also acceptable; you'll just get a regular softmax.\nIn the case that the input vector is completely masked and <code>memory_efficient</code> is false, this function\nreturns an array of <code>0.0</code>. This behavior may cause <code>NaN</code> if this is used as the last layer of\na model that uses categorical cross-entropy loss. Instead, if <code>memory_efficient</code> is true, this function\nwill treat every element as equal, and do softmax over equal numbers.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>vector:</strong>  tensor of arbitrary number of dimensions; the only requirement is that <code>mask</code> is\nbroadcastable to <code>vector's</code> shape.  If <code>mask</code> has fewer dimensions than <code>vector</code>, we will\nunsqueeze on dimension 1 until they match.  If you need a different unsqueezing of your mask,\ndo it yourself before passing the mask into this function.</li>\n<li><strong>mask:</strong>  tensor determining what values of <code>vector</code> should be masked</li>\n<li><strong>memory_efficient:</strong>  if set to true, simply use a very large negative number for those\nmasked positions so that the probabilities of those positions would be approximately 0.\nThis is not accurate in math, but works for most cases and consumes less memory.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>result: the result of applying softmax on the input vector</p>\n</blockquote>\n", "signature": "(\n    vector: torch.Tensor,\n    mask: torch.Tensor,\n    dim: int = -1,\n    memory_efficient: bool = False,\n    mask_fill_value: float = -1e+32\n) -> torch.Tensor", "funcdef": "def"}, "canlpy.core.components.heads": {"fullname": "canlpy.core.components.heads", "modulename": "canlpy.core.components.heads", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.heads.BertLMPredictionHead": {"fullname": "canlpy.core.components.heads.BertLMPredictionHead", "modulename": "canlpy.core.components.heads", "qualname": "BertLMPredictionHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"fullname": "canlpy.core.components.heads.BertLMPredictionHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertLMPredictionHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, bert_model_embedding_weights)", "funcdef": "def"}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"fullname": "canlpy.core.components.heads.BertLMPredictionHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertLMPredictionHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyMLMHead": {"fullname": "canlpy.core.components.heads.BertOnlyMLMHead", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyMLMHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"fullname": "canlpy.core.components.heads.BertOnlyMLMHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyMLMHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, bert_model_embedding_weights)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"fullname": "canlpy.core.components.heads.BertOnlyMLMHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyMLMHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, sequence_output)", "funcdef": "def"}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"fullname": "canlpy.core.components.heads.BertPredictionHeadTransform", "modulename": "canlpy.core.components.heads", "qualname": "BertPredictionHeadTransform", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"fullname": "canlpy.core.components.heads.BertPredictionHeadTransform.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertPredictionHeadTransform.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"fullname": "canlpy.core.components.heads.BertPredictionHeadTransform.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertPredictionHeadTransform.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyNSPHead": {"fullname": "canlpy.core.components.heads.BertOnlyNSPHead", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyNSPHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"fullname": "canlpy.core.components.heads.BertOnlyNSPHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyNSPHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"fullname": "canlpy.core.components.heads.BertOnlyNSPHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyNSPHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, pooled_output)", "funcdef": "def"}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"fullname": "canlpy.core.components.heads.ErnieEntPredictionHead", "modulename": "canlpy.core.components.heads", "qualname": "ErnieEntPredictionHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"fullname": "canlpy.core.components.heads.ErnieEntPredictionHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "ErnieEntPredictionHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"fullname": "canlpy.core.components.heads.ErnieEntPredictionHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "ErnieEntPredictionHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, candidate)", "funcdef": "def"}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"fullname": "canlpy.core.components.heads.ErniePreTrainingHeads", "modulename": "canlpy.core.components.heads", "qualname": "ErniePreTrainingHeads", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>As per the example above, an <code>__init__()</code> call to the parent class\nmust be made before assignment on the child.</p>\n\n</div>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"fullname": "canlpy.core.components.heads.ErniePreTrainingHeads.__init__", "modulename": "canlpy.core.components.heads", "qualname": "ErniePreTrainingHeads.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, bert_model_embedding_weights)", "funcdef": "def"}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"fullname": "canlpy.core.components.heads.ErniePreTrainingHeads.forward", "modulename": "canlpy.core.components.heads", "qualname": "ErniePreTrainingHeads.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, sequence_output, pooled_output, candidate)", "funcdef": "def"}, "canlpy.core.models": {"fullname": "canlpy.core.models", "modulename": "canlpy.core.models", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.bert": {"fullname": "canlpy.core.models.bert", "modulename": "canlpy.core.models.bert", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.bert.model": {"fullname": "canlpy.core.models.bert.model", "modulename": "canlpy.core.models.bert.model", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.bert.model.MultiHeadAttention": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention", "type": "class", "doc": "<p>A multi-head attention layer</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the token embeddings.\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>context_layer: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size], the embeddings \n  after the attention.</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, hidden_size, num_attention_heads, attention_probs_dropout_prob)", "funcdef": "def"}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention.transpose_for_scores", "type": "function", "doc": "<p></p>\n", "signature": "(self, x)", "funcdef": "def"}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, attention_mask)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertAttention": {"fullname": "canlpy.core.models.bert.model.BertAttention", "modulename": "canlpy.core.models.bert.model", "qualname": "BertAttention", "type": "class", "doc": "<p>A BERT attention layer</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the token embeddings.\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probability for the fully connected\n      layer.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings.</li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size] the produced embeddings.</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertAttention.__init__": {"fullname": "canlpy.core.models.bert.model.BertAttention.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertAttention.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    num_attention_heads,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob\n)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertAttention.forward": {"fullname": "canlpy.core.models.bert.model.BertAttention.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertAttention.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, attention_mask)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertEmbeddings": {"fullname": "canlpy.core.models.bert.model.BertEmbeddings", "modulename": "canlpy.core.models.bert.model", "qualname": "BertEmbeddings", "type": "class", "doc": "<p>Construct the BERT embeddings of the token_ids from word, position and token_type embeddings.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>vocab_size: the number of tokens in the vocabulary.\n  hidden_size: dimension of the token embeddings.\n  max_position_embeddings: the maximum sequence length that this model might ever be used with.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probability for the embeddings.\n  type_vocab_size: the vocabulary size of the <code>token_type_ids</code>.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ids:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary</li>\n<li><strong>token_type_ids:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>embeddings: a torch.FloatTensor of shape [batch_size, sequence_length,embedding_dimension], \n  the embedding corresponding to the provided ids.</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"fullname": "canlpy.core.models.bert.model.BertEmbeddings.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertEmbeddings.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    vocab_size,\n    hidden_size,\n    max_position_embeddings,\n    hidden_dropout_prob,\n    type_vocab_size\n)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"fullname": "canlpy.core.models.bert.model.BertEmbeddings.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertEmbeddings.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, input_ids, token_type_ids=None)", "funcdef": "def"}, "canlpy.core.models.bert.model.DenseSkipLayer": {"fullname": "canlpy.core.models.bert.model.DenseSkipLayer", "modulename": "canlpy.core.models.bert.model", "qualname": "DenseSkipLayer", "type": "class", "doc": "<p>Performs Linear + Dropout + SkipLayer + LayerNorm</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>input_size: the size of the input embeddings.\n  output_size: the size of the output embeddings.\n  dropout_prob: the dropout ratio.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>input_size</code>]\ncontaining the token embeddings</li>\n<li><strong>skip_tensor:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>output_size</code>] that is added\nto the tensor after the dense layer</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,<code>output_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"fullname": "canlpy.core.models.bert.model.DenseSkipLayer.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "DenseSkipLayer.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, input_size, output_size, dropout_prob)", "funcdef": "def"}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"fullname": "canlpy.core.models.bert.model.DenseSkipLayer.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "DenseSkipLayer.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, skip_tensor)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertLayer": {"fullname": "canlpy.core.models.bert.model.BertLayer", "modulename": "canlpy.core.models.bert.model", "qualname": "BertLayer", "type": "class", "doc": "<p>Correspond to a standard encoder BERT layer</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: Size of the encoder layers and the pooler layer.\n  intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n      layer in the Transformer encoder.\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probabilitiy for all fully connected\n      layers.\n  activation_fn: The non-linear activation function (function or string). \n      If string, \"gelu\", \"relu\" and \"swish\" are supported.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>input_size</code>]\ncontaining the token embeddings</li>\n<li><strong>attention_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,<code>hidden_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertLayer.__init__": {"fullname": "canlpy.core.models.bert.model.BertLayer.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertLayer.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    intermediate_size,\n    num_attention_heads,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertLayer.forward": {"fullname": "canlpy.core.models.bert.model.BertLayer.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertLayer.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, attention_mask)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertPooler": {"fullname": "canlpy.core.models.bert.model.BertPooler", "modulename": "canlpy.core.models.bert.model", "qualname": "BertPooler", "type": "class", "doc": "<p>Does the classification of the CLS token (first token)</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the CLS token</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>hidden_size</code>]\ncontaining the token embeddings</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>pooled_output: a torch.FloatTensor of shape [batch_size,<code>hidden_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertPooler.__init__": {"fullname": "canlpy.core.models.bert.model.BertPooler.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertPooler.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, hidden_size)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertPooler.forward": {"fullname": "canlpy.core.models.bert.model.BertPooler.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertPooler.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states)", "funcdef": "def"}, "canlpy.core.models.bert.model.LayerNorm": {"fullname": "canlpy.core.models.bert.model.LayerNorm", "modulename": "canlpy.core.models.bert.model", "qualname": "LayerNorm", "type": "class", "doc": "<p>Performs a layer nornlizationon the tensor</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the token embeddings.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>x:</strong>  a torch.FloatTensor to perform layer norm on.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>res: the normalized tensor.</p>\n</blockquote>\n\n<h6 id=\"returns-2\">Returns</h6>\n\n<blockquote>\n  <p>pooled_output: a torch.FloatTensor of shape [batch_size,<code>hidden_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"fullname": "canlpy.core.models.bert.model.LayerNorm.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "LayerNorm.__init__", "type": "function", "doc": "<p>Construct a layernorm module in the TF style (epsilon inside the square root).</p>\n", "signature": "(self, hidden_size, eps=1e-12)", "funcdef": "def"}, "canlpy.core.models.bert.model.LayerNorm.forward": {"fullname": "canlpy.core.models.bert.model.LayerNorm.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "LayerNorm.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, x)", "funcdef": "def"}, "canlpy.core.models.bert.model.init_weights": {"fullname": "canlpy.core.models.bert.model.init_weights", "modulename": "canlpy.core.models.bert.model", "qualname": "init_weights", "type": "function", "doc": "<p>Recursively initialize all weights </p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>module:</strong>  the nn.Module to recursively initialize.</li>\n<li><strong>initializer_range:</strong>  the std_dev of the normal initializer for\ninitializing all weight matrices.</li>\n</ul>\n", "signature": "(module, initializer_range)", "funcdef": "def"}, "canlpy.core.models.cokebert": {"fullname": "canlpy.core.models.cokebert", "modulename": "canlpy.core.models.cokebert", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.cokebert.model": {"fullname": "canlpy.core.models.cokebert.model", "modulename": "canlpy.core.models.cokebert.model", "type": "module", "doc": "<p>Re-Implementation of the CokeBert Model (Su et al., 2020)</p>\n\n<p>This module contains several versions of CokeBert for different \nfine-tune tasks.</p>\n"}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"fullname": "canlpy.core.models.cokebert.model.CONFIG_NAME", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CONFIG_NAME", "type": "variable", "doc": "<p>str: name of the config file in the checkpoint</p>\n", "default_value": " = 'cokebert_config.json'"}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"fullname": "canlpy.core.models.cokebert.model.WEIGHTS_NAME", "modulename": "canlpy.core.models.cokebert.model", "qualname": "WEIGHTS_NAME", "type": "variable", "doc": "<p>str: name of the file containing weights in the checkpoint</p>\n", "default_value": " = 'pytorch_model.bin'"}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"fullname": "canlpy.core.models.cokebert.model.MAPPING_FILE", "modulename": "canlpy.core.models.cokebert.model", "qualname": "MAPPING_FILE", "type": "variable", "doc": "<p>str: name of the file containing the mapping in the checkpoint</p>\n", "default_value": " = 'mapping.json'"}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig", "type": "class", "doc": "<p>Configuration class to store the configuration of a <code>CokeBertModel</code>.</p>\n"}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.__init__", "type": "function", "doc": "<p>Constructs CokeBertConfig.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>vocab_size (int):</strong>  Vocabulary size of <code>inputs_ids</code> in <code>CokeBertModel</code>.</li>\n<li><strong>hidden_size (int):</strong>  Size of the encoder layers and the pooler layer.</li>\n<li><strong>num_hidden_layers (int):</strong>  Number of hidden layers in the Transformer encoder.</li>\n<li><strong>num_attention_heads (int):</strong>  Number of attention heads for each attention layer in\nthe Transformer encoder.</li>\n<li><strong>intermediate_size (int):</strong>  The size of the \"intermediate\" (i.e., feed-forward)\nlayer in the Transformer encoder.</li>\n<li><strong>hidden_act:</strong>  The non-linear activation function (function or string) in the\nencoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</li>\n<li><strong>hidden_dropout_prob (int):</strong>  The dropout probabilitiy for all fully connected\nlayers in the embeddings, encoder, and pooler.</li>\n<li><strong>attention_probs_dropout_prob (float):</strong>  The dropout ratio for the attention\nprobabilities.</li>\n<li><strong>max_position_embeddings (int):</strong>  The maximum sequence length that this model might\never be used with. Typically set this to something large just in case\n(e.g., 512 or 1024 or 2048).</li>\n<li><strong>type_vocab_size (int):</strong>  The vocabulary size of the <code>token_type_ids</code> passed into\n<code>CokeBertModel</code>.</li>\n<li><strong>initializer_range (float):</strong>  The sttdev of the truncated_normal_initializer for\ninitializing all weight matrices.</li>\n<li><strong>layer_types (list):</strong>  list of <code>ErnieLayer</code>s which can be 'sim' (Bert encoder), \n'mix' (Ernie encoder but no multihead attention for entites) or 'norm' (standard Ernie encoder)</li>\n<li><strong>k_v_dim (int):</strong>  Size of the hidden knowledge representation in the dynamic knowledge encoder</li>\n<li><strong>q_dim (int):</strong>  Size of the hidden text representation in the dynamic knowledge encoder</li>\n<li><strong>dk_layers (int):</strong>  Number of layers in the dynamic knowledge encoder</li>\n</ul>\n", "signature": "(\n    self,\n    vocab_size,\n    hidden_size=768,\n    entity_size=200,\n    num_hidden_layers=12,\n    num_attention_heads=12,\n    num_attention_heads_ent=4,\n    intermediate_size=3072,\n    hidden_act='gelu',\n    hidden_dropout_prob=0.1,\n    attention_probs_dropout_prob=0.1,\n    max_position_embeddings=512,\n    type_vocab_size=2,\n    initializer_range=0.02,\n    layer_types=[],\n    k_v_dim=100,\n    q_dim=768,\n    dk_layers=2\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.load_from_json", "type": "function", "doc": "<p>Loads config from json file</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>cls:</strong>  current CokeBertConfig Class</li>\n<li><strong>path (str):</strong>  path to config.json file</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>config: Loaded CokeBertConfig</p>\n</blockquote>\n", "signature": "(cls, path)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_json_string", "type": "function", "doc": "<p>Serializes this instance to a JSON string.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>JSON-String of Config</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_dict", "type": "function", "doc": "<p>Serializes this instance to a Python dictionary.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>output: Python dictionary of Config</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_text_encoder_config", "type": "function", "doc": "<p>Splits Config to create <code>ErnieEncoder</code> as TextEncoder</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>CokeBertConfig for TextEncoder</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_knowl_encoder_config", "type": "function", "doc": "<p>Splits Config to create <code>ErnieEncoder</code> as KnowledgeEncoder</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>CokeBertConfig for KnowledgeEncoder</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel", "type": "class", "doc": "<p>An abstract class to handle weights initialization and\na simple interface for downloading and loading pretrained models.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, config, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel.init_weights", "type": "function", "doc": "<p>Initialize the weights.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>module:</strong>  one of <code>nn.Linear</code>, <code>nn.Embedding</code>, <code>LayerNorm</code>, module to initialize weights of</li>\n</ul>\n", "signature": "(self, module)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel.from_pretrained", "type": "function", "doc": "<p>Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.\nDownload and cache the pre-trained model file if needed.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><p><strong>dir_path (str):</strong>  a path or url to a pretrained model archive containing:</p>\n\n<p>. <code>bert_config.json</code> a configuration file for the model</p>\n\n<p>. <code>pytorch_model.bin</code> a PyTorch dump of a BertForPreTraining instance</p></li>\n<li><strong>state_dict:</strong>  an optional state dictionary (collections.OrderedDict object) to use instead of Google pre-trained models</li>\n<li><strong>cache_dir:</strong>  an optional path to a folder in which the pre-trained models will be cached.</li>\n<li><strong><em>inputs, *</em>kwargs:</strong>  additional input for the specific Bert class\n(ex: num_labels for BertForSequenceClassification)</li>\n</ul>\n", "signature": "(cls, dir_path, state_dict=None, cache_dir=None, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertModel": {"fullname": "canlpy.core.models.cokebert.model.CokeBertModel", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertModel", "type": "class", "doc": "<p>A class to handle the Transformer Model (without fine-tuning head)</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertModel.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertModel.__init__", "type": "function", "doc": "<p>Constructs a CokeBertModel</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>config (<code>CokeBertConfig</code>):</strong>  The config that sets the model's hyperparameters</li>\n</ul>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertModel.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertModel.forward", "type": "function", "doc": "<p>Forward pass through the <code>CokeBertModel</code></p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ids:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong>token_type_ids:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong>attention_mask:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong>output_all_encoded_layers:</strong>  boolean which controls the content of the <code>encoded_layers</code> output as described below. Default: <code>True</code>.</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>sequence_output, pooled_output</p>\n  \n  <p>sequence_output: the full sequence of hidden-states corresponding\n          to the last attention block of shape [batch_size, sequence_length, hidden_size] <br />\n  pooled_output: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n      classifier pretrained on top of the hidden state associated to the first character of the\n      input (<code>CLS</code>) to train on the Next-Sentence task (see BERT's paper).</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    output_all_encoded_layers=True,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder", "type": "class", "doc": "<p>A class for the Dynamic Knowledge Encoder for a <code>CokeBertModel</code>.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder.__init__", "type": "function", "doc": "<p>Constructs a Dynamic KnowledgeEncoder</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>\n<li><strong>no_layers (int):</strong>  Number of layers in the Dynamic Knowledge Encoder</li>\n</ul>\n", "signature": "(self, k_v_dim, q_dim, no_layers)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder.forward", "type": "function", "doc": "<p>Forward pass through the Dynamic Knowledge Encoder</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong>q:</strong>  the full sequence of hidden-states corresponding\nto the last text-attention block of shape [batch_size, sequence_length, hidden_size] </li>\n<li><strong>k_v_s:</strong>  list of (k, v) tuples of length <code>no_layers</code>, \nk, v are of shape [batch_size, sequence_length, k_v_dim]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states_ent: internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</p>\n</blockquote>\n", "signature": "(self, input_ent, q, k_v_s)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder_layer", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder_layer", "type": "class", "doc": "<p>A class for one Dynamic Knowledge Encoder Layer for a <code>DKEncoder</code> from CokeBert.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder_layer.__init__", "type": "function", "doc": "<p>Constructs a <code>DKEncoder_layer</code>.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>\n<li><strong>layer_no (int):</strong>  Number of the layer (assigned in reverse order)</li>\n</ul>\n", "signature": "(self, k_v_dim, q_dim, layer_no)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder_layer.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder_layer.forward", "type": "function", "doc": "<p>Forward pass through the Dynamic Knowledge Encoder layer</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong>q:</strong>  the representation of hidden-states corresponding\nto the last text-attention block of shape [batch_size, 1, q_dim] </li>\n<li><strong>k:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n<li><strong>v:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</p>\n</blockquote>\n", "signature": "(self, q, k, v)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_text": {"fullname": "canlpy.core.models.cokebert.model.DK_text", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_text", "type": "class", "doc": "<p>A class for the Text Processing in a <code>DKEncoderLayer</code> from CokeBert.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"fullname": "canlpy.core.models.cokebert.model.DK_text.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_text.__init__", "type": "function", "doc": "<p>Constructs a <code>DK_text</code> module</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>\n<li><strong>layer_no (int):</strong>  Number of the layer (assigned in reverse order)</li>\n</ul>\n", "signature": "(self, k_v_dim, q_dim, layer_no)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_text.forward": {"fullname": "canlpy.core.models.cokebert.model.DK_text.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_text.forward", "type": "function", "doc": "<p>Forward pass through the Text Processing Module of a Dynamic Knowledge Encoder layer</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>q:</strong>  the full sequence of hidden-states corresponding\nto the last text-attention block of shape [batch_size, sequence_length, hidden_size] </li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>q_i: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</p>\n</blockquote>\n", "signature": "(self, q)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_knowledge": {"fullname": "canlpy.core.models.cokebert.model.DK_knowledge", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_knowledge", "type": "class", "doc": "<p>A class for the Knowledge Processing in a <code>DKEncoderLayer</code> from CokeBert.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"fullname": "canlpy.core.models.cokebert.model.DK_knowledge.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_knowledge.__init__", "type": "function", "doc": "<p>Constructs a <code>DK_knowledge</code> module</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n</ul>\n", "signature": "(self, k_v_dim)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"fullname": "canlpy.core.models.cokebert.model.DK_knowledge.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_knowledge.forward", "type": "function", "doc": "<p>Forward pass through the Knowledge Processing Module of a Dynamic Knowledge Encoder layer</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</p>\n</blockquote>\n", "signature": "(self, k)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForSequenceClassification", "type": "class", "doc": "<p>CokeBert model for sequence classification. <br />\nThis module is composed of the CokeBert model with a linear layer on top of\nthe pooled output.</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForSequenceClassification.__init__", "type": "function", "doc": "<p>Constructs a <code>CokeBertForSequenceClassification</code> model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>\n<li><strong><code>num_labels</code>:</strong>  the number of classes for the classifier. Default = 2.</li>\n</ul>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForSequenceClassification.forward", "type": "function", "doc": "<p>Performs a Forward Pass through the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>: <br />\n      Outputs the CrossEntropy classification loss of the output with the labels. <br />\n  if <code>labels</code> is <code>None</code>: <br />\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids=None,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForEntityTyping", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForEntityTyping", "type": "class", "doc": "<p>CokeBert model for classification. <br />\nThis module is composed of the CokeBert model with a linear layer on top of\nthe pooled output.</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForEntityTyping.__init__", "type": "function", "doc": "<p>Constructs a <code>CokeBertForEntityTyping</code> model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>\n<li><strong><code>num_labels</code>:</strong>  the number of classes for the classifier. Default = 2.</li>\n</ul>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForEntityTyping.forward", "type": "function", "doc": "<p>Performs a Forward Pass through the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>: <br />\n      Outputs the CrossEntropy classification loss of the output with the labels. <br />\n  if <code>labels</code> is <code>None</code>: <br />\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids=None,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForMaskedLM", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForMaskedLM", "type": "class", "doc": "<p>CokeBert model for masked pre-training task. <br />\nThis module is composed of the CokeBert model with a linear layer on top of\nthe sequence output.</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForMaskedLM.__init__", "type": "function", "doc": "<p>Constructs a <code>CokeBertForMaskedLM</code> model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>\n</ul>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForMaskedLM.forward", "type": "function", "doc": "<p>Performs a Forward Pass through the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>masked_lm_labels</code> is not <code>None</code>: <br />\n      Outputs the CrossEntropy classification loss of the output with the labels. <br />\n  if <code>masked_lm_labels</code> is <code>None</code>: <br />\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids,\n    input_ents,\n    ent_mask=None,\n    token_type_ids=None,\n    attention_mask=None,\n    masked_lm_labels=None,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie": {"fullname": "canlpy.core.models.ernie", "modulename": "canlpy.core.models.ernie", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.ernie.components": {"fullname": "canlpy.core.models.ernie.components", "modulename": "canlpy.core.models.ernie.components", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.ernie.components.ErnieLayer": {"fullname": "canlpy.core.models.ernie.components.ErnieLayer", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayer", "type": "class", "doc": "<p>An Ernie Layer, takes as input tokens/entity embeddings and masks and outputs tokens/entity embeddings</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: Size of the encoder layers and the pooler layer.\n  entity_size: Size of the entity embeddings,\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  num_attention_heads_ent: Number of attention heads for each attention layer in\n      the Transformer encoder for the entities.\n  intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n      layer in the Transformer encoder.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probabilitiy for all fully connected\n      layers in the embeddings, encoder, and pooler.\n  activation_fn: The non-linear activation function (function or string) in the\n      encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>hidden_states_ent:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the entity embeddings </li>\n<li><strong>attention_mask_ent:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1] used to indicate which position correspond to entities or not</li>\n</ul>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"fullname": "canlpy.core.models.ernie.components.ErnieLayer.__init__", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayer.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    entity_size,\n    intermediate_size,\n    num_attention_heads,\n    num_attention_heads_ent,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"fullname": "canlpy.core.models.ernie.components.ErnieLayer.forward", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayer.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    hidden_states,\n    attention_mask,\n    hidden_states_ent,\n    attention_mask_ent,\n    ent_mask\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"fullname": "canlpy.core.models.ernie.components.ErnieLayerMix", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayerMix", "type": "class", "doc": "<p>An Ernie Layer, takes as input tokens/entity embeddings and masks and outputs tokens/entity embeddings. \nDiffers from ErnieLayer by not applying any multi-head attention and dense layer on the entities before fusion.  </p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: Size of the encoder layers and the pooler layer.\n  entity_size: Size of the entity embeddings,\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  num_attention_heads_ent: Number of attention heads for each attention layer in\n      the Transformer encoder for the entities.\n  intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n      layer in the Transformer encoder.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probabilitiy for all fully connected\n      layers in the embeddings, encoder, and pooler.\n  activation_fn: The non-linear activation function (function or string) in the\n      encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>hidden_states_ent:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the entity embeddings </li>\n<li><strong>attention_mask_ent:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1] used to indicate which position correspond to entities or not</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\n      containing the new tokens embeddings \n  hidden_states_ent: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\n      containing the new entity embeddings</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"fullname": "canlpy.core.models.ernie.components.ErnieLayerMix.__init__", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayerMix.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    entity_size,\n    intermediate_size,\n    num_attention_heads,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"fullname": "canlpy.core.models.ernie.components.ErnieLayerMix.forward", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayerMix.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    hidden_states,\n    attention_mask,\n    hidden_states_ent,\n    attention_mask_ent,\n    ent_mask\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieEncoder": {"fullname": "canlpy.core.models.ernie.components.ErnieEncoder", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieEncoder", "type": "class", "doc": "<p>An ErnieEncoder takes as input tokens/entity embeddings and masks and outputs tokens/entity embeddings</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>config: an <code>ErnieConfig</code> file</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>hidden_states_ent:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the entity embeddings </li>\n<li><strong>attention_mask_ent:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1] used to indicate which position correspond to entities or not</li>\n<li><strong>output_all_encoded_layers:</strong>  whether to output all encoder layers or not</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if output_all_encoded_layers:\n      the tokens embeddings at each layer\n  if not output_all_encoded_layers\n      the tokens embeddings at the last layer</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"fullname": "canlpy.core.models.ernie.components.ErnieEncoder.__init__", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieEncoder.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"fullname": "canlpy.core.models.ernie.components.ErnieEncoder.forward", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieEncoder.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    hidden_states,\n    attention_mask,\n    hidden_states_ent,\n    attention_mask_ent,\n    ent_mask,\n    output_all_encoded_layers=True\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model": {"fullname": "canlpy.core.models.ernie.model", "modulename": "canlpy.core.models.ernie.model", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.ernie.model.ErnieConfig": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig", "type": "class", "doc": "<p>Configuration class to store the configuration of an <code>ErnieModel</code>.</p>\n"}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.__init__", "type": "function", "doc": "<p>Constructs ErnieConfig.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>vocab_size:</strong>  Vocabulary size of <code>inputs_ids</code> in <code>ErnieModel</code>.</li>\n<li><strong>hidden_size:</strong>  Size of the encoder layers and the pooler layer.</li>\n<li><strong>entity_size:</strong>  Size of the entity embeddings,</li>\n<li><strong>num_hidden_layers:</strong>  Number of hidden layers in the Transformer encoder.</li>\n<li><strong>num_attention_heads:</strong>  Number of attention heads for each attention layer in\nthe Transformer encoder for the tokens.</li>\n<li><strong>num_attention_heads_ent:</strong>  Number of attention heads for each attention layer in\nthe Transformer encoder for the entities.</li>\n<li><strong>intermediate_size:</strong>  The size of the \"intermediate\" (i.e., feed-forward)\nlayer in the Transformer encoder.</li>\n<li><strong>hidden_act:</strong>  The non-linear activation function (function or string) in the\nencoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</li>\n<li><strong>hidden_dropout_prob:</strong>  The dropout probabilitiy for all fully connected\nlayers in the embeddings, encoder, and pooler.</li>\n<li><strong>attention_probs_dropout_prob:</strong>  The dropout ratio for the attention\nprobabilities.</li>\n<li><strong>max_position_embeddings:</strong>  The maximum sequence length that this model might\never be used with. Typically set this to something large just in case\n(e.g., 512 or 1024 or 2048).</li>\n<li><strong>type_vocab_size:</strong>  The vocabulary size of the <code>token_type_ids</code> passed into\n<code>ErnieModel</code>.</li>\n<li><strong>initializer_range:</strong>  The sttdev of the truncated_normal_initializer for\ninitializing all weight matrices.</li>\n<li><strong>layer_types:</strong>  list() of ErnieEncoders which can be 'sim' (Bert encoder), </li>\n<li>'mix' (Ernie encoder but no multihead attention for entities) or 'norm' (standard Ernie encoder)</li>\n</ul>\n", "signature": "(\n    self,\n    vocab_size,\n    hidden_size=768,\n    entity_size=100,\n    num_hidden_layers=12,\n    num_attention_heads=12,\n    num_attention_heads_ent=4,\n    intermediate_size=3072,\n    hidden_act='gelu',\n    hidden_dropout_prob=0.1,\n    attention_probs_dropout_prob=0.1,\n    max_position_embeddings=512,\n    type_vocab_size=2,\n    initializer_range=0.02,\n    layer_types=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.load_from_json", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.load_from_json", "type": "function", "doc": "<p>Loads and returns a config class from a json file located at path</p>\n", "signature": "(cls, path)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.to_json_string", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.to_json_string", "type": "function", "doc": "<p>Serializes this instance to a JSON string.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.to_dict", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.to_dict", "type": "function", "doc": "<p>Serializes this instance to a Python dictionary.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel", "type": "class", "doc": "<p>An abstract class to handle weights initialization and\n    a simple interface for downloading and loading pretrained models.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel.init_weights", "type": "function", "doc": "<p>Initialize the weights.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel.from_pretrained", "type": "function", "doc": "<p>Instantiate a PreTrainedErnieModel from a pre-trained model file or a pytorch state dict.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>dir_path:</strong>  - a path to a pretrained model archive containing:\n   . <code>ernie_config.json</code>: a configuration file for the model\n   . <code>pytorch_model.bin</code>: a PyTorch dump of a ErnieForPreTraining instance\n   .  <code>mapping.json</code>: an Optional file to remap the weights from the pre-trained weights to this implementation </li>\n<li><strong>state_dict:</strong>  an optional state dictionnary (collections.OrderedDict object) to use instead of the PyTorch dump</li>\n<li><strong><em>inputs, *</em>kwargs:</strong>  additional input for the specific Ernie class\n(ex: num_labels for ErnieForSequenceClassification)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The loaded pretrained model</p>\n</blockquote>\n", "signature": "(cls, dir_path, state_dict=None, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieModel": {"fullname": "canlpy.core.models.ernie.model.ErnieModel", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieModel", "type": "class", "doc": "<p>Ernie model</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: an ErnieConfig class instance with the configuration to build a new model</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>output_all_encoded_layers</code>:</strong>  boolean which controls the content of the <code>encoded_layers</code> output as described below. Default: <code>True</code>.</li>\n</ul>\n\n<p>Returns: Tuple of (encoded_layers, pooled_output)\n    <code>encoded_layers</code>: controled by <code>output_all_encoded_layers</code> argument:\n        - <code>output_all_encoded_layers=True</code>: outputs a list of the full sequences of encoded-hidden-states at the end\n            of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n            encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n        - <code>output_all_encoded_layers=False</code>: outputs only the full sequence of hidden-states corresponding\n            to the last attention block of shape [batch_size, sequence_length, hidden_size],\n    <code>pooled_output</code>: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n         classifier pretrained on top of the hidden state associated to the first character of the\n         input (<code>CLS</code>) to train on the Next-Sentence task (see BERT's paper).</p>\n\n<p>Example usage:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"c1\"># Already been converted into WordPiece token ids</span>\n<span class=\"n\">input_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"mi\">51</span><span class=\"p\">,</span> <span class=\"mi\">99</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_mask</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">token_type_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_ent</span><span class=\"p\">:</span> <span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n<span class=\"n\">ent_mask</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">modeling</span><span class=\"o\">.</span><span class=\"n\">ErnieConfig</span><span class=\"p\">(</span><span class=\"n\">vocab_size_or_config_json_file</span><span class=\"o\">=</span><span class=\"mi\">32000</span><span class=\"p\">,</span> <span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">768</span><span class=\"p\">,</span>\n    <span class=\"n\">num_hidden_layers</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"mi\">3072</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">modeling</span><span class=\"o\">.</span><span class=\"n\">ErnieModel</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">all_encoder_layers</span><span class=\"p\">,</span> <span class=\"n\">pooled_output</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">token_type_ids</span><span class=\"p\">,</span> <span class=\"n\">input_mask</span><span class=\"p\">,</span> <span class=\"n\">input_ent</span><span class=\"p\">,</span> <span class=\"n\">ent_mask</span><span class=\"p\">)</span>\n</code></pre></div>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieModel.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieModel.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieModel.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieModel.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    output_all_encoded_layers=True\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"fullname": "canlpy.core.models.ernie.model.ErnieForMaskedLM", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForMaskedLM", "type": "class", "doc": "<p>Ernie model with the masked language modeling head.</p>\n\n<p>This module comprises the Ernie model followed by the masked language modeling head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>masked_lm_labels</code>:</strong>  masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]\nwith indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss\nis only computed for the labels set in [0, ..., vocab_size]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>masked_lm_labels</code> is <code>None</code>:\n      Outputs the masked language modeling loss.\n  if <code>masked_lm_labels</code> is <code>None</code>:\n      Outputs the masked language modeling logits of shape [batch_size, sequence_length, vocab_size].</p>\n</blockquote>\n\n<p>Example usage:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"c1\"># Already been converted into WordPiece token ids</span>\n<span class=\"n\">input_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"mi\">51</span><span class=\"p\">,</span> <span class=\"mi\">99</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_mask</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">token_type_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_ent</span><span class=\"p\">:</span> <span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n<span class=\"n\">ent_mask</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">ErnieConfig</span><span class=\"p\">(</span><span class=\"n\">vocab_size_or_config_json_file</span><span class=\"o\">=</span><span class=\"mi\">32000</span><span class=\"p\">,</span> <span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">768</span><span class=\"p\">,</span>\n    <span class=\"n\">num_hidden_layers</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"mi\">3072</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ErnieForMaskedLM</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">masked_lm_logits_scores</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">token_type_ids</span><span class=\"p\">,</span> <span class=\"n\">input_mask</span><span class=\"p\">,</span><span class=\"n\">input_ent</span><span class=\"p\">,</span><span class=\"n\">ent_mask</span><span class=\"p\">)</span>\n</code></pre></div>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForMaskedLM.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForMaskedLM.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    input_ents,\n    ent_mask=None,\n    token_type_ids=None,\n    attention_mask=None,\n    masked_lm_labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"fullname": "canlpy.core.models.ernie.model.ErnieForPreTraining", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForPreTraining", "type": "class", "doc": "<p>Ernie model with pre-training heads.\nThis module comprises the Ernie model followed by the two pre-training heads:\n    - the masked language modeling head, and\n    - the next sentence classification head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: an ErnieConfig class instance with the configuration to build a new model.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>masked_lm_labels</code>:</strong>  masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]\nwith indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss\nis only computed for the labels set in [0, ..., vocab_size]</li>\n<li><strong><code>next_sentence_label</code>:</strong>  next sentence classification loss: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, 1].\n0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>masked_lm_labels</code> and <code>next_sentence_label</code> are not <code>None</code>:\n      Outputs the total_loss which is the sum of the masked language modeling loss and the next\n      sentence classification loss.\n  if <code>masked_lm_labels</code> or <code>next_sentence_label</code> is <code>None</code>:\n      Outputs a tuple comprising\n      - the masked language modeling logits of shape [batch_size, sequence_length, vocab_size], and\n      - the next sentence classification logits of shape [batch_size, 2].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForPreTraining.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForPreTraining.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForPreTraining.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    masked_lm_labels=None,\n    input_ent=None,\n    ent_mask=None,\n    next_sentence_label=None,\n    candidate=None,\n    ent_labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"fullname": "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNextSentencePrediction", "type": "class", "doc": "<p>Ernie model with next sentence prediction head.\nThis module comprises the Ernie model followed by the next sentence classification head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>next_sentence_label</code>:</strong>  next sentence classification loss: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, 1].\n0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>next_sentence_label</code> is not <code>None</code>:\n      Outputs the total_loss which is the sum of the masked language modeling loss and the next\n      sentence classification loss.\n  if <code>next_sentence_label</code> is <code>None</code>:\n      Outputs the next sentence classification logits of shape [batch_size, 2].</p>\n</blockquote>\n\n<p>Example usage:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"c1\"># Already been converted into WordPiece token ids</span>\n<span class=\"n\">input_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"mi\">51</span><span class=\"p\">,</span> <span class=\"mi\">99</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_mask</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">token_type_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">ErnieConfig</span><span class=\"p\">(</span><span class=\"n\">vocab_size_or_config_json_file</span><span class=\"o\">=</span><span class=\"mi\">32000</span><span class=\"p\">,</span> <span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">768</span><span class=\"p\">,</span>\n    <span class=\"n\">num_hidden_layers</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"mi\">3072</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ErnieForNextSentencePrediction</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">seq_relationship_logits</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">token_type_ids</span><span class=\"p\">,</span> <span class=\"n\">input_mask</span><span class=\"p\">)</span>\n</code></pre></div>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNextSentencePrediction.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNextSentencePrediction.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    next_sentence_label=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"fullname": "canlpy.core.models.ernie.model.ErnieForEntityTyping", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForEntityTyping", "type": "class", "doc": "<p>Ernie model with entity typing prediction head.\nThis module comprises the Ernie model followed by the entity typing head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.\n  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForEntityTyping.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForEntityTyping.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"fullname": "canlpy.core.models.ernie.model.ErnieForSTSB", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSTSB", "type": "class", "doc": "<p>Ernie model with STSB prediction head (predict sentence similarity).\nThis module comprises the Ernie model followed by the STSB head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.\n  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForSTSB.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSTSB.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForSTSB.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSTSB.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"fullname": "canlpy.core.models.ernie.model.ErnieForSequenceClassification", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSequenceClassification", "type": "class", "doc": "<p>Ernie model for classification.\nThis module is composed of the Ernie model with a linear layer on top of\nthe pooled output.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p><code>config</code>: an ErnieConfig class instance with the configuration to build a new model.\n  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>:\n      Outputs the CrossEntropy classification loss of the output with the labels.\n  if <code>labels</code> is <code>None</code>:\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSequenceClassification.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSequenceClassification.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNQ": {"fullname": "canlpy.core.models.ernie.model.ErnieForNQ", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNQ", "type": "class", "doc": "<p>Ernie model for NQ.\nThis module is composed of the Ernie model with a linear layer on top of\nthe pooled output.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p><code>config</code>: an ErnieConfig class instance with the configuration to build a new model.\n  <code>num_choices</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>choice_mask</code>:</strong> </li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>:\n      Outputs the CrossEntropy classification loss of the output with the labels.\n  if <code>labels</code> is <code>None</code>:\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForNQ.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNQ.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_choices=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForNQ.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNQ.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    choice_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"fullname": "canlpy.core.models.ernie.model.ErnieForQuestionAnswering", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForQuestionAnswering", "type": "class", "doc": "<p>Ernie model for Question Answering (span extraction).\nThis module is composed of the Ernie model with a linear layer on top of\nthe sequence output that computes start_logits and end_logits</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p><code>config</code>: either\n      - a ErnieConfig class instance with the configuration to build a new model</p>\n</blockquote>\n\n<h6 id=\"inputs\">Inputs</h6>\n\n<blockquote>\n  <p><code>input_ids</code>: a torch.LongTensor of shape [batch_size, sequence_length]\n      with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n      <code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)\n  <code>token_type_ids</code>: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n      types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\n      a <code>sentence B</code> token (see BERT paper for more details).\n  <code>attention_mask</code>: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n      selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n      input sequence length in the current batch. It's the mask that we typically use for attention when\n      a batch has varying length sentences.\n  <code>input_ent</code>: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\n      with the entities embeddings\n  <code>ent_mask</code>: a torch.LongTensor of shape [batch_size, sequence_length] with indices\n      selected in [0, 1]\n  <code>start_positions</code>: position of the first token for the labeled span: torch.LongTensor of shape [batch_size].\n      Positions are clamped to the length of the sequence and position outside of the sequence are not taken\n      into account for computing the loss.\n  <code>end_positions</code>: position of the last token for the labeled span: torch.LongTensor of shape [batch_size].\n      Positions are clamped to the length of the sequence and position outside of the sequence are not taken\n      into account for computing the loss.</p>\n</blockquote>\n\n<h6 id=\"outputs\">Outputs</h6>\n\n<blockquote>\n  <p>if <code>start_positions</code> and <code>end_positions</code> are not <code>None</code>:\n      Outputs the total_loss which is the sum of the CrossEntropy loss for the start and end token positions.\n  if <code>start_positions</code> or <code>end_positions</code> is <code>None</code>:\n      Outputs a tuple of start_logits, end_logits which are the logits respectively for the start and end\n      position tokens of shape [batch_size, sequence_length].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForQuestionAnswering.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForQuestionAnswering.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    start_positions=None,\n    end_positions=None\n)", "funcdef": "def"}, "canlpy.core.models.knowbert": {"fullname": "canlpy.core.models.knowbert", "modulename": "canlpy.core.models.knowbert", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.knowbert_heads": {"fullname": "canlpy.core.models.knowbert.knowbert_heads", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"fullname": "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "qualname": "KnowBertForPreTraining", "type": "class", "doc": "<p>A knowbert model with Masked LM and NSP loss used for pretraining </p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>knowbert_model: the underlying knowbert model</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"fullname": "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "qualname": "KnowBertForPreTraining.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, knowbert_model)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"fullname": "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "qualname": "KnowBertForPreTraining.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    tokens=None,\n    segment_ids=None,\n    candidates=None,\n    lm_label_ids=None,\n    next_sentence_label=None,\n    **kwargs\n)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge": {"fullname": "canlpy.core.models.knowbert.knowledge", "modulename": "canlpy.core.models.knowbert.knowledge", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"fullname": "canlpy.core.models.knowbert.knowledge.EntityEmbedder", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "EntityEmbedder", "type": "class", "doc": "<p>An extension to nn.Embedding but allow for more functionalities</p>\n"}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"fullname": "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "EntityEmbedder.__init__", "type": "function", "doc": "<p></p>\n", "signature": "()", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"fullname": "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "read_embeddings_from_text_file", "type": "function", "doc": "<p>Read pre-trained word vectors from a compressed text file, possibly contained\ninside an archive with multiple files. The text file is assumed to be utf-8 encoded with\nspace-separated fields: [word] [dim 1] [dim 2] ...</p>\n\n<p>Lines that contain more numerical tokens than <code>embedding_dim</code> raise a warning and are skipped.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>gzip_filename:</strong>  the file name containing the embeddings</li>\n<li><strong>embedding_dim:</strong>  the dimension of the embeddings</li>\n<li><strong>vocab:</strong>  a vocabulary object containing the index to token mapping</li>\n<li><strong>namespace:</strong>  the namespace the embeddings correpond to, eg: entity</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>embeddings: nn.Embedding, the extracted embeddings</p>\n</blockquote>\n", "signature": "(\n    gzip_filename: str,\n    embedding_dim: int,\n    vocab: canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary,\n    namespace: str = 'tokens'\n) -> torch.nn.modules.sparse.Embedding", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding", "type": "class", "doc": "<p>Combines pretrained fixed embeddings with learned POS embeddings.</p>\n\n<h6 id=\"given-entity-candidate-list\">Given entity candidate list</h6>\n\n<blockquote>\n  <ul>\n  <li>get list of unique entity ids</li>\n  <li>look up</li>\n  <li>concat POS embedding</li>\n  <li>linear project to candidate embedding shape</li>\n  </ul>\n</blockquote>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>embedding_file: a file containing the embeddings\n  entity_dim: the dimension of the entities\n  entity_file: the file containing the entities\n  vocab_file: the file containing the vocabulary\n  entity_h5_key: unknown\n  dropout: dropout to apply on the embeddings\n  pos_embedding_dim: the dimension of the position embedding\n  include_null_embedding: whether to include null embedding</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module, EntityEmbedder"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.__init__", "type": "function", "doc": "<p>pass pos_emedding_dim = None to skip POS embeddings and all the\n    entity stuff, using this as a pretrained embedding file\n    with feedforward</p>\n", "signature": "(\n    self,\n    embedding_file: str,\n    entity_dim: int,\n    entity_file: str = None,\n    vocab_file: str = None,\n    entity_h5_key: str = 'conve_tucker_infersent_bert',\n    dropout: float = 0.1,\n    pos_embedding_dim: int = 25,\n    include_null_embedding: bool = False\n)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.POS_MAP", "type": "variable", "doc": "<p></p>\n", "default_value": " = {'@@PADDING@@': 0, 'n': 1, 'v': 2, 'a': 3, 'r': 4, 's': 5, '@@MASK@@': 6, '@@NULL@@': 7, '@@UNKNOWN@@': 8}"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.get_output_dim", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.get_null_embedding", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.forward", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>entity_ids:</strong>  torch.LongTensor (batch_size, num_candidates, num_entities) of entity ids</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>entity_embeddings:  torch.LongTensor (batch_size, num_candidates, num_entities, embed_dim)</p>\n</blockquote>\n", "signature": "(self, entity_ids)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics": {"fullname": "canlpy.core.models.knowbert.metrics", "modulename": "canlpy.core.models.knowbert.metrics", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.metrics.Metric": {"fullname": "canlpy.core.models.knowbert.metrics.Metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric", "type": "class", "doc": "<p>A very general abstract class representing a metric which can be\naccumulated.</p>\n"}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.__init__", "type": "function", "doc": "<p></p>\n", "signature": "()", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.get_metric", "type": "function", "doc": "<p>Compute and return the metric. Optionally also call <code>self.reset</code>.</p>\n", "signature": "(self, reset: bool) -> Union[float, Tuple[float, ...], Dict[str, float]]", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self) -> None", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.unwrap_to_tensors", "type": "function", "doc": "<p>If you actually passed gradient-tracking Tensors to a Metric, there will be\na huge memory leak, because it will prevent garbage collection for the computation\ngraph. This method ensures that you're using tensors directly and that they are on\nthe CPU.</p>\n\n<p>In addition, all tensors are cast to float32 as torch does not\nimplement many operations for HalfTensor on CPU.</p>\n", "signature": "(*tensors: torch.Tensor)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Average": {"fullname": "canlpy.core.models.knowbert.metrics.Average", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average", "type": "class", "doc": "<p>This <code>Metric</code> breaks with the typical <code>Metric</code> API and just stores values that were\ncomputed in some fashion outside of a <code>Metric</code>.  If you have some external code that computes\nthe metric for you, for instance, you can use this to report the average result using our\n<code>Metric</code> API.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.Average.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.Average.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The average of all values that were passed to <code>__call__</code>.</p>\n", "signature": "(self, reset: bool = False) -> float", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Average.reset": {"fullname": "canlpy.core.models.knowbert.metrics.Average.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy", "type": "class", "doc": "<p>Categorical Top-K accuracy. Assumes integer labels, with\neach item to be classified having a single correct class.\nTie break enables equal distribution of scores among the\nclasses with same maximum predicted scores.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, top_k: int = 1, tie_break: bool = False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The accumulated accuracy.</p>\n", "signature": "(self, reset: bool = False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage", "type": "class", "doc": "<p>This <code>Metric</code> breaks with the typical <code>Metric</code> API and just stores values that were\ncomputed in some fashion outside of a <code>Metric</code>.  If you have some external code that computes\nthe metric for you, for instance, you can use this to report the average result using our\n<code>Metric</code> API.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The average of all values that were passed to <code>__call__</code>.</p>\n", "signature": "(self, reset: bool = False) -> float", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage", "type": "class", "doc": "<p>Keep an exponentially weighted moving average.\nalpha is the decay constant. Alpha = 1 means just keep the most recent value.\nalpha = 0.5 will have almost no contribution from 10 time steps ago.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, alpha: float = 0.5)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The average of all values that were passed to <code>__call__</code>.</p>\n", "signature": "(self, reset: bool = False) -> float", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.F1Metric": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric", "type": "class", "doc": "<p>A generic set based F1 metric.\nTakes two lists of predicted and gold elements and computes F1.\nOnly requirements are that the elements are hashable.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, filter_func=None)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>A tuple of the following metrics based on the accumulated count statistics:\nprecision : float\nrecall : float\nf1-measure : float</p>\n", "signature": "(self, reset: bool = False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank", "type": "class", "doc": "<p>A very general abstract class representing a metric which can be\naccumulated.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank.get_metric", "type": "function", "doc": "<p>Compute and return the metric. Optionally also call <code>self.reset</code>.</p>\n", "signature": "(self, reset=False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.model": {"fullname": "canlpy.core.models.knowbert.model", "modulename": "canlpy.core.models.knowbert.model", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.model.KnowBert": {"fullname": "canlpy.core.models.knowbert.model.KnowBert", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert", "type": "class", "doc": "<p>KnowBert\nCombines BERT with one or more SolderedKG</p>\n\n<p>each SolderedKG is inserted at a particular level, given by an index,\nsuch that we run Bert to the index, then the SolderedKG, then the rest\nof bert.  Indices such that index 0 means run the first contextual layer,\nthen add KG, and index 11 means run to the top of BERT, then the KG\n(for bert base with 12 layers).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>soldered_kgs: a dictionnary of named SolderedKG\n  soldered_layers: a dictionnary indicating at which index the SolderedKG is inserted\n  bert_model_name: the name of the bert model, eg: <code>bert_base_uncased</code>.\n  mode: <code>None</code> or <code>entity_linking</code>, <code>entity_linking</code> then only unfreeze the SolderedKB layer, \n      else, unfreeze the entire model.\n  state_dict_file: a file containing the state dictionnary.\n  strict_load_archive: whether to allow unmapped weights to the loaded model.\n  remap_segment_embeddings: determines how many segment embeddings BERT can have (if None, the default of 2 is kept).\n  state_dict_map: a dictionnary used to remap embedding weights.</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.__init__", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    soldered_kgs: Dict[str, canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG],\n    soldered_layers: Dict[str, int],\n    bert_model_name: str,\n    mode: str = None,\n    state_dict_file: str = None,\n    strict_load_archive: bool = True,\n    remap_segment_embeddings: int = None,\n    state_dict_map: Dict[str, str] = None\n)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.from_pretrained", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.from_pretrained", "type": "function", "doc": "<p>Loads a pretrained knowbert model from an archive file</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>file_or_url:</strong>  a file path or url to the archive</li>\n<li><strong>strict_load_archive:</strong>  whether to allow unmapped weights to the loaded model.</li>\n</ul>\n", "signature": "(cls, file_or_url, strict_load_archive=True)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.load_state_dict", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.load_state_dict", "type": "function", "doc": "<p>Initialize the model's weights with the provided state_dict</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>state_dict:</strong>  the PyTorch state dict.</li>\n<li><strong>strict:</strong>  whether to allow unmapped weights to the loaded model.</li>\n</ul>\n", "signature": "(self, state_dict, strict=True)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.unfreeze", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.unfreeze", "type": "function", "doc": "<p>Unfreezes the weights depending of <code>self.mode</code>, if <code>entity_linking</code>only unfreezes SolderedKGs\nelse, unfreezes all weights</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.forward", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.forward", "type": "function", "doc": "<p>Args: \n    tokens['tokens']: a torch.LongTensor of shape , shape: (batch_size, max_seq_len), tokens indices (used to index an embedding).\n    Because a batch contains multiple sentences with varying # of tokens, all tokens tensors are padded with zeros.</p>\n\n<pre><code>segment_ids: a torch.LongTensor of shape (batch_size,max_seq_len) indicating the segments_ids for each token (0 for first segment and 1 for second)\n\ncandidates, for each SolderedKB contains:\nExample:\n    candidates['wordnet']['candidate_entity_priors']: torch.FloatTensor of shape (batch_size, max # detected entities, max # KB candidate entities)\n    Correctness probabilities estimated by the entity extractor (sums to 1 (or 0 if padding) on axis 2)\n    Adds 0 padding to axis 1 when there is less detected entities in the sentence than in the max sentence\n    Adds 0 padding to axis 2 when there is less detected KB entities for an entity in the sentence than in the max candidate KB entities entity\n\n    candidates['wordnet']['ids']: torch.LongTensor of shape (batch_size, max # detected entities, max # KB candidate entities)\n    ids of the KB candidate entities + 0 padding on axis 1 or 2 if necessary.\n\n    candidates['wordnet']['candidate_spans']: torch.LongTensorshape of shape (batch_size, max # detected entities, 2)\n    Spans of which sequence of tokens correspond to an entity in the sentence, eg: [1,2] for Michael Jackson (both bounds are included)\n    Padding with [-1,-1] when no more detected entities\n\n    candidates['wordnet']['candidate_segment_ids']: a torch.LongTensorshape of shape (batch_size, max # detected entities)\n    indicates the segments_ids for each entity\n</code></pre>\n\n<p>kwargs:\n    gold_entities: id of the correct corresponding entity, used by the entity linker to train</p>\n", "signature": "(self, tokens=None, segment_ids=None, candidates=None, **kwargs)", "funcdef": "def"}, "canlpy.core.util": {"fullname": "canlpy.core.util", "modulename": "canlpy.core.util", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.file_utils": {"fullname": "canlpy.core.util.file_utils", "modulename": "canlpy.core.util.file_utils", "type": "module", "doc": "<p>Utilities for working with the local dataset cache.\nThis file is adapted from the AllenNLP library at <a href=\"https://github.com/allenai/allennlp\">https://github.com/allenai/allennlp</a>\nCopyright by the AllenNLP authors.</p>\n"}, "canlpy.core.util.file_utils.url_to_filename": {"fullname": "canlpy.core.util.file_utils.url_to_filename", "modulename": "canlpy.core.util.file_utils", "qualname": "url_to_filename", "type": "function", "doc": "<p>Convert <code>url</code> into a hashed filename in a repeatable way.\nIf <code>etag</code> is specified, append its hash to the url's, delimited\nby a period.</p>\n", "signature": "(url: str, etag: str = None) -> str", "funcdef": "def"}, "canlpy.core.util.file_utils.filename_to_url": {"fullname": "canlpy.core.util.file_utils.filename_to_url", "modulename": "canlpy.core.util.file_utils", "qualname": "filename_to_url", "type": "function", "doc": "<p>Return the url and etag (which may be <code>None</code>) stored for <code>filename</code>.\nRaise <code>FileNotFoundError</code> if <code>filename</code> or its stored metadata do not exist.</p>\n", "signature": "(\n    filename: str,\n    cache_dir: Union[str, pathlib.Path] = None\n) -> Tuple[str, str]", "funcdef": "def"}, "canlpy.core.util.file_utils.cached_path": {"fullname": "canlpy.core.util.file_utils.cached_path", "modulename": "canlpy.core.util.file_utils", "qualname": "cached_path", "type": "function", "doc": "<p>Given something that might be a URL (or might be a local path),\ndetermine which. If it's a URL, download the file and cache it, and\nreturn the path to the cached file. If it's already a local path,\nmake sure the file exists and then return the path.</p>\n", "signature": "(\n    url_or_filename: Union[str, pathlib.Path],\n    cache_dir: Union[str, pathlib.Path] = None\n) -> str", "funcdef": "def"}, "canlpy.core.util.file_utils.split_s3_path": {"fullname": "canlpy.core.util.file_utils.split_s3_path", "modulename": "canlpy.core.util.file_utils", "qualname": "split_s3_path", "type": "function", "doc": "<p>Split a full s3 path into the bucket name and path.</p>\n", "signature": "(url: str) -> Tuple[str, str]", "funcdef": "def"}, "canlpy.core.util.file_utils.s3_request": {"fullname": "canlpy.core.util.file_utils.s3_request", "modulename": "canlpy.core.util.file_utils", "qualname": "s3_request", "type": "function", "doc": "<p>Wrapper function for s3 requests in order to create more helpful error\nmessages.</p>\n", "signature": "(func: Callable)", "funcdef": "def"}, "canlpy.core.util.file_utils.s3_etag": {"fullname": "canlpy.core.util.file_utils.s3_etag", "modulename": "canlpy.core.util.file_utils", "qualname": "s3_etag", "type": "function", "doc": "<p>Check ETag on S3 object.</p>\n", "signature": "(url: str) -> Union[str, NoneType]", "funcdef": "def"}, "canlpy.core.util.file_utils.s3_get": {"fullname": "canlpy.core.util.file_utils.s3_get", "modulename": "canlpy.core.util.file_utils", "qualname": "s3_get", "type": "function", "doc": "<p>Pull a file directly from S3.</p>\n", "signature": "(url: str, temp_file: <class 'IO'>) -> None", "funcdef": "def"}, "canlpy.core.util.file_utils.http_get": {"fullname": "canlpy.core.util.file_utils.http_get", "modulename": "canlpy.core.util.file_utils", "qualname": "http_get", "type": "function", "doc": "<p></p>\n", "signature": "(url: str, temp_file: <class 'IO'>) -> None", "funcdef": "def"}, "canlpy.core.util.file_utils.get_from_cache": {"fullname": "canlpy.core.util.file_utils.get_from_cache", "modulename": "canlpy.core.util.file_utils", "qualname": "get_from_cache", "type": "function", "doc": "<p>Given a URL, look for the corresponding dataset in the local cache.\nIf it's not there, download it. Then return the path to the cached file.</p>\n", "signature": "(url: str, cache_dir: Union[str, pathlib.Path] = None) -> str", "funcdef": "def"}, "canlpy.core.util.file_utils.read_set_from_file": {"fullname": "canlpy.core.util.file_utils.read_set_from_file", "modulename": "canlpy.core.util.file_utils", "qualname": "read_set_from_file", "type": "function", "doc": "<p>Extract a de-duped collection (set) of text from a file.\nExpected file format is one item per line.</p>\n", "signature": "(filename: str) -> Set[str]", "funcdef": "def"}, "canlpy.core.util.file_utils.get_file_extension": {"fullname": "canlpy.core.util.file_utils.get_file_extension", "modulename": "canlpy.core.util.file_utils", "qualname": "get_file_extension", "type": "function", "doc": "<p></p>\n", "signature": "(path: str, dot=True, lower: bool = True)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer": {"fullname": "canlpy.core.util.knowbert_tokenizer", "modulename": "canlpy.core.util.knowbert_tokenizer", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "truncate_sequence_pair", "type": "function", "doc": "<p>Truncates <code>word_piece_tokens_a</code> and <code>word_piece_tokens_b</code> until so that they have almost the same size\nand len(a) + len(b) = <code>max_word_piece_sequence_length</code></p>\n", "signature": "(\n    word_piece_tokens_a,\n    word_piece_tokens_b,\n    max_word_piece_sequence_length\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "TokenizerAndCandidateGenerator", "type": "class", "doc": "<p>A class that can process a sentence and returns its tokens as well as the corresponding candidate entities</p>\n"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "TokenizerAndCandidateGenerator.__init__", "type": "function", "doc": "<p></p>\n", "signature": "()", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "MentionGenerator", "type": "class", "doc": "<p>A class that can detect entity mentions in a string</p>\n"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "MentionGenerator.__init__", "type": "function", "doc": "<p></p>\n", "signature": "()", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "BertTokenizerAndCandidateGenerator", "type": "class", "doc": "<p>A class that can tokenize a sentence for BERT-like models and well as detect the candidate entities in the text</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>entity_candidate_generators: a dictionnary of entity detectors\n  bert_model_type: the bert model type to tokenize for\n  do_lower_case: whether to lowercase the sentence\n  whitespace_tokenize: whether to whitespace tokenize\n  max_word_piece_sequence_length: the maximum number of tokens allowed</p>\n</blockquote>\n", "bases": "TokenizerAndCandidateGenerator"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "BertTokenizerAndCandidateGenerator.__init__", "type": "function", "doc": "<p>Note: the fields need to be used with a pre-generated vocabulary\nthat contains the entity id namespaces and the bert name space.\nentity_indexers = {'wordnet': indexer for wordnet entities,\n                  'wiki': indexer for wiki entities}</p>\n", "signature": "(\n    self,\n    entity_candidate_generators: Dict[str, canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator],\n    bert_model_type: str,\n    do_lower_case: bool,\n    whitespace_tokenize: bool = True,\n    max_word_piece_sequence_length: int = 512\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates", "type": "function", "doc": "<p>Run BertTokenizer.basic_tokenizer.tokenize on sentence1 and sentence2 to word tokenization\ngenerate candidate mentions for each of the generators and for each of sentence1 and 2 from word tokenized text\nrun BertTokenizer.wordpiece_tokenizer on sentence1 and sentence2\ntruncate length, add [CLS] and [SEP] to word pieces\ncompute token offsets\ncombine candidate mention spans from sentence1 and sentence2 and remap to word piece indices</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>text_a:</strong>  the first sentence</li>\n<li><strong>text_b:</strong>  optional, the second sentence</li>\n</ul>\n\n<p>Returns: \n    {'tokens': List[str], the word piece strings with [CLS] [SEP]\n    'segment_ids': List[int] the same length as 'tokens' with 0/1 for sentence1 vs 2\n    'candidates': Dict[str, Dict[str, Any]],\n        {'wordnet': {'candidate_spans': List[List[int]],\n                    'candidate_entities': List[List[str]],\n                    'candidate_entity_prior': List[List[float]],\n                    'segment_ids': List[int]},\n        'wiki': ...}\n    }</p>\n", "signature": "(self, text_a: str, text_b: str = None)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array", "type": "function", "doc": "<p>Converts the dict to a dict of numpy array</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>tokens_and_candidates:</strong>  the return from a previous call togenerate_sentence_entity_candidates. </li>\n<li><strong>entity_vocabulary:</strong>  is the vocabulary used to convert from text entiy to ids.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>a dictionnary of numpy arrays</p>\n</blockquote>\n", "signature": "(self, tokens_and_candidates, entity_vocabulary)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"fullname": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator", "modulename": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator", "qualname": "PretokenizedTokenizerAndCandidateGenerator", "type": "class", "doc": "<p>Simple modification to the <code>BertTokenizerAndCandidateGenerator</code>. We assume data comes\npre-tokenized, so only wordpiece splitting is performed.</p>\n", "bases": "BertTokenizerAndCandidateGenerator"}, "canlpy.core.util.knowbert_tokenizer.common": {"fullname": "canlpy.core.util.knowbert_tokenizer.common", "modulename": "canlpy.core.util.knowbert_tokenizer.common", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"fullname": "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates", "modulename": "canlpy.core.util.knowbert_tokenizer.common", "qualname": "get_empty_candidates", "type": "function", "doc": "<p>Returns the values corresponding to an empty candidate</p>\n", "signature": "()", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"fullname": "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer", "modulename": "canlpy.core.util.knowbert_tokenizer.common", "qualname": "WhitespaceTokenizer", "type": "class", "doc": "<p>Simple whitespace tokenizer useable by spacy</p>\n"}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.common", "qualname": "WhitespaceTokenizer.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, vocab)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"fullname": "canlpy.core.util.knowbert_tokenizer.tokenizer", "modulename": "canlpy.core.util.knowbert_tokenizer.tokenizer", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"fullname": "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier", "modulename": "canlpy.core.util.knowbert_tokenizer.tokenizer", "qualname": "KnowBertBatchifier", "type": "class", "doc": "<p>Takes a list of sentence strings and returns a tensor dict usable with\na KnowBert model</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>tokenizer_and_candidate_generator: object that tokenizes a string and finds its corresponding candidate entities\n  entity_vocabulary: a Vocaublary object corresponding to the entities\n  batch_size: the batch size\n  masking_strategy: the masking strategy: None or full_mask, if full_mask, when a token is masked, mask the correspobding entity</p>\n</blockquote>\n"}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.tokenizer", "qualname": "KnowBertBatchifier.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    tokenizer_and_candidate_generator,\n    entity_vocabulary,\n    batch_size=32,\n    masking_strategy=None\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"fullname": "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches", "modulename": "canlpy.core.util.knowbert_tokenizer.tokenizer", "qualname": "KnowBertBatchifier.iter_batches", "type": "function", "doc": "<p>Takes in as input sentences_or_sentence_pairs and yields batches for a KnowBert model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>sentences_or_sentence_pairs:</strong>  sentence of pair of sentences</li>\n<li><strong>verbose:</strong>  whether to print the processed tokens </li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>yield KnowBert batches, see <code>KnowBert</code> for more details</p>\n</blockquote>\n", "signature": "(\n    self,\n    sentences_or_sentence_pairs: Union[List[str], List[List[str]]],\n    verbose=True\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"fullname": "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify", "modulename": "canlpy.core.util.knowbert_tokenizer.tokenizer", "qualname": "KnowBertBatchifier.batchify", "type": "function", "doc": "<p>Takes a list of arguments (numpy arrays) corresponding to the processing \nof each sentence and outputs dictionnary of tensor batches of those model input's. \nAdds padding to numpy arrays if input arrays in same batch are of different length</p>\n", "signature": "(self, instances)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"fullname": "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier", "modulename": "canlpy.core.util.knowbert_tokenizer.tokenizer", "qualname": "KnowBertBatchifier.get_wiki_batchifier", "type": "function", "doc": "<p>Returns a wiki batchifier</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>entity_vocab:</strong>  optional, a Vocabulary class for the entities</li>\n<li><strong>max_word_piece_sequence_length:</strong>  the maximum allowed sequence length, the rest is truncated</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>a KnowBert batchifier for wiki</p>\n</blockquote>\n", "signature": "(cls, entity_vocab=None, max_word_piece_sequence_length=512)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "type": "module", "doc": "<p>A Vocabulary maps strings to integers, allowing for strings to be mapped to an\nout-of-vocabulary token.</p>\n"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "pop_max_vocab_size", "type": "function", "doc": "<p>max_vocab_size is allowed to be either an int or a Dict[str, int] (or nothing).\nBut it could also be a string representing an int (in the case of environment variable\nsubstitution). So we need some complex logic to handle it.</p>\n", "signature": "(params: Dict[str, Any]) -> Union[int, Dict[str, int]]", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "namespace_match", "type": "function", "doc": "<p>Matches a namespace pattern against a namespace string.  For example, <code>*tags</code> matches\n<code>passage_tags</code> and <code>question_tags</code> and <code>tokens</code> matches <code>tokens</code> but not\n<code>stemmed_tokens</code>.</p>\n", "signature": "(pattern: str, namespace: str)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary", "type": "class", "doc": "<p>A Vocabulary maps strings to integers, allowing for strings to be mapped to an\nout-of-vocabulary token.</p>\n\n<p>Vocabularies are fit to a particular dataset, which we use to decide which tokens are\nin-vocabulary.</p>\n\n<p>Vocabularies also allow for several different namespaces, so you can have separate indices for\n'a' as a word, and 'a' as a character, for instance, and so we can use this object to also map\ntag and label strings to indices.  Most of the\nmethods on this class allow you to pass in a namespace; by default we use the 'tokens'\nnamespace, and you can omit the namespace argument everywhere and just use the default.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>counter : <code>Dict[str, Dict[str, int]]</code>, optional (default=<code>None</code>)\n    A collection of counts from which to initialize this vocabulary.  We will examine the\n    counts and, together with the other parameters to this class, use them to decide which\n    words are in-vocabulary.  If this is <code>None</code>, we just won't initialize the vocabulary with\n    anything.\nmin_count : <code>Dict[str, int]</code>, optional (default=None)\n    When initializing the vocab from a counter, you can specify a minimum count, and every\n    token with a count less than this will not be added to the dictionary.  These minimum\n    counts are <code>namespace-specific</code>, so you can specify different minimums for labels versus\n    words tokens, for example.  If a namespace does not have a key in the given dictionary, we\n    will add all seen tokens to that namespace.\nmax_vocab_size : <code>Union[int, Dict[str, int]]</code>, optional (default=<code>None</code>)\n    If you want to cap the number of tokens in your vocabulary, you can do so with this\n    parameter.  If you specify a single integer, every namespace will have its vocabulary fixed\n    to be no larger than this.  If you specify a dictionary, then each namespace in the\n    <code>counter</code> can have a separate maximum vocabulary size.  Any missing key will have a value\n    of <code>None</code>, which means no cap on the vocabulary size.\nnon_padded_namespaces : <code>Iterable[str]</code>, optional\n    By default, we assume you are mapping word / character tokens to integers, and so you want\n    to reserve word indices for padding and out-of-vocabulary tokens.  However, if you are\n    mapping NER or SRL tags, or class labels, to integers, you probably do not want to reserve\n    indices for padding and out-of-vocabulary tokens.  Use this field to specify which\n    namespaces should <code>not</code> have padding and OOV tokens added.</p>\n\n<pre><code>The format of each element of this is either a string, which must match field names\nexactly,  or ``*`` followed by a string, which we match as a suffix against field names.\n\nWe try to make the default here reasonable, so that you don't have to think about this.\nThe default is ``(\"*tags\", \"*labels\")``, so as long as your namespace ends in \"tags\" or\n\"labels\" (which is true by default for all tag and label fields in this code), you don't\nhave to specify anything here.\n</code></pre>\n\n<p>pretrained_files : <code>Dict[str, str]</code>, optional\n    If provided, this map specifies the path to optional pretrained embedding files for each\n    namespace. This can be used to either restrict the vocabulary to only words which appear\n    in this file, or to ensure that any words in this file are included in the vocabulary\n    regardless of their count, depending on the value of <code>only_include_pretrained_words</code>.\n    Words which appear in the pretrained embedding file but not in the data are NOT included\n    in the Vocabulary.\nmin_pretrained_embeddings : <code>Dict[str, int]</code>, optional\n    If provided, specifies for each namespace a minimum number of lines (typically the\n    most common words) to keep from pretrained embedding files, even for words not\n    appearing in the data.\nonly_include_pretrained_words : <code>bool</code>, optional (default=False)\n    This defines the strategy for using any pretrained embedding files which may have been\n    specified in <code>pretrained_files</code>. If False, an inclusive strategy is used: and words\n    which are in the <code>counter</code> and in the pretrained file are added to the <code>Vocabulary</code>,\n    regardless of whether their count exceeds <code>min_count</code> or not. If True, we use an\n    exclusive strategy: words are only included in the Vocabulary if they are in the pretrained\n    embedding file (their count must still be at least <code>min_count</code>).\ntokens_to_add : <code>Dict[str, List[str]]</code>, optional (default=None)\n    If given, this is a list of tokens to add to the vocabulary, keyed by the namespace to add\n    the tokens to.  This is a way to be sure that certain items appear in your vocabulary,\n    regardless of any other vocabulary computation.</p>\n"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    counter: Dict[str, Dict[str, int]] = None,\n    min_count: Dict[str, int] = None,\n    max_vocab_size: Union[int, Dict[str, int]] = None,\n    non_padded_namespaces: Iterable[str] = ('*tags', '*labels'),\n    pretrained_files: Union[Dict[str, str], NoneType] = None,\n    only_include_pretrained_words: bool = False,\n    tokens_to_add: Dict[str, List[str]] = None,\n    min_pretrained_embeddings: Dict[str, int] = None\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.default_implementation", "type": "variable", "doc": "<p></p>\n", "default_value": " = 'default'"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.save_to_files", "type": "function", "doc": "<p>Persist this Vocabulary to files so it can be reloaded later.\nEach namespace corresponds to one file.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>directory : <code>str</code>\n    The directory where we save the serialized vocabulary.</p>\n", "signature": "(self, directory: str) -> None", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.from_files", "type": "function", "doc": "<p>Loads a <code>Vocabulary</code> that was serialized using <code>save_to_files</code>.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>directory : <code>str</code>\n    The directory containing the serialized vocabulary.</p>\n", "signature": "(\n    cls,\n    directory: str\n) -> canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.set_from_file", "type": "function", "doc": "<p>If you already have a vocabulary file for a trained model somewhere, and you really want to\nuse that vocabulary file instead of just setting the vocabulary from a dataset, for\nwhatever reason, you can do that with this method.  You must specify the namespace to use,\nand we assume that you want to use padding and OOV tokens for this.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>filename : <code>str</code>\n    The file containing the vocabulary to load.  It should be formatted as one token per\n    line, with nothing else in the line.  The index we assign to the token is the line\n    number in the file (1-indexed if <code>is_padded</code>, 0-indexed otherwise).  Note that this\n    file should contain the OOV token string!\nis_padded : <code>bool</code>, optional (default=True)\n    Is this vocabulary padded?  For token / word / character vocabularies, this should be\n    <code>True</code>; while for tag or label vocabularies, this should typically be <code>False</code>.  If\n    <code>True</code>, we add a padding token with index 0, and we enforce that the <code>oov_token</code> is\n    present in the file.\noov_token : <code>str</code>, optional (default=DEFAULT_OOV_TOKEN)\n    What token does this vocabulary use to represent out-of-vocabulary characters?  This\n    must show up as a line in the vocabulary file.  When we find it, we replace\n    <code>oov_token</code> with <code>self._oov_token</code>, because we only use one OOV token across\n    namespaces.\nnamespace : <code>str</code>, optional (default=\"tokens\")\n    What namespace should we overwrite with this vocab file?</p>\n", "signature": "(\n    self,\n    filename: str,\n    is_padded: bool = True,\n    oov_token: str = '@@UNKNOWN@@',\n    namespace: str = 'tokens'\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.is_padded", "type": "function", "doc": "<p>Returns whether or not there are padding and OOV tokens added to the given namespace.</p>\n", "signature": "(self, namespace: str) -> bool", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.add_token_to_namespace", "type": "function", "doc": "<p>Adds <code>token</code> to the index, if it is not already present.  Either way, we return the index of\nthe token.</p>\n", "signature": "(self, token: str, namespace: str = 'tokens') -> int", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_index_to_token_vocabulary", "type": "function", "doc": "<p></p>\n", "signature": "(self, namespace: str = 'tokens') -> Dict[int, str]", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_token_to_index_vocabulary", "type": "function", "doc": "<p></p>\n", "signature": "(self, namespace: str = 'tokens') -> Dict[str, int]", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_token_index", "type": "function", "doc": "<p></p>\n", "signature": "(self, token: str, namespace: str = 'tokens') -> int", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_token_from_index", "type": "function", "doc": "<p></p>\n", "signature": "(self, index: int, namespace: str = 'tokens') -> str", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_vocab_size", "type": "function", "doc": "<p></p>\n", "signature": "(self, namespace: str = 'tokens') -> int", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.print_statistics", "type": "function", "doc": "<p></p>\n", "signature": "(self) -> None", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "prior_entity_candidates", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>candidates_file:</strong>  a file that contains all the entity candidates</li>\n<li><strong>max_candidates:</strong>  how many candidate entities to keep for each mention</li>\n<li><strong>allowed_entities_set:</strong>  restrict the candidate entities to only this set. for example</li>\n<li>the most frequent 1M entities. First this restiction applies and then the 'max_mentions'.</li>\n</ul>\n", "signature": "(\n    candidates_file: str,\n    max_candidates: int = 30,\n    allowed_entities_set=None,\n    max_mentions=None\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "enumerate_spans", "type": "function", "doc": "<p>Given a sentence, return all token spans within the sentence. Spans are <code>inclusive</code>.\nAdditionally, you can provide a maximum and minimum span width, which will be used\nto exclude spans outside of this range.</p>\n\n<p>Finally, you can provide a function mapping <code>List[T] -&gt; bool</code>, which will\nbe applied to every span to decide whether that span should be included. This\nallows filtering by length, regex matches, pos tags or any Spacy <code>Token</code>\nattributes, for example.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>sentence : <code>List[T]</code>, required.\n    The sentence to generate spans for. The type is generic, as this function\n    can be used with strings, or Spacy <code>Tokens</code> or other sequences.\noffset : <code>int</code>, optional (default = 0)\n    A numeric offset to add to all span start and end indices. This is helpful\n    if the sentence is part of a larger structure, such as a document, which\n    the indices need to respect.\nmax_span_width : <code>int</code>, optional (default = None)\n    The maximum length of spans which should be included. Defaults to len(sentence).\nmin_span_width : <code>int</code>, optional (default = 1)\n    The minimum length of spans which should be included. Defaults to 1.\nfilter_function : <code>Callable[[List[T]], bool]</code>, optional (default = None)\n    A function mapping sequences of the passed type T to a boolean value.\n    If <code>True</code>, the span is included in the returned spans from the\n    sentence, otherwise it is excluded..</p>\n", "signature": "(\n    sentence: List[str],\n    offset: int = 0,\n    max_span_width: int = None,\n    min_span_width: int = 1,\n    filter_function: Callable[[List[str]], bool] = None\n) -> List[Tuple[int, int]]", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "span_filter_func", "type": "function", "doc": "<p>This function halves the number of suggested mention spans whilst not affecting\ngold span recall at all. It can probably be improved further.</p>\n", "signature": "(span: List[str])", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "WikiCandidateMentionGenerator", "type": "class", "doc": "<p>A class that can detect entity mentions in a string</p>\n", "bases": "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "WikiCandidateMentionGenerator.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    candidates_file: str = None,\n    entity_world_path: str = None,\n    lowercase_candidates: bool = True,\n    random_candidates: bool = False,\n    pickle_cache_file: str = None\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "WikiCandidateMentionGenerator.defaults", "type": "variable", "doc": "<p></p>\n", "default_value": " = {'candidates_file': 'https://allennlp.s3-us-west-2.amazonaws.com/knowbert/wiki_entity_linking/prob_yago_crosswikis_wikipedia_p_e_m.txt', 'wiki_file': 'https://allennlp.s3-us-west-2.amazonaws.com/knowbert/wiki_entity_linking/wiki_name_id_map.txt', 'redirections_file': 'https://allennlp.s3-us-west-2.amazonaws.com/knowbert/wiki_entity_linking/wiki_redirects.txt', 'disambiguations_file': 'https://allennlp.s3-us-west-2.amazonaws.com/knowbert/wiki_entity_linking/wiki_disambiguation_pages.txt', 'entity_world_path': 'https://allennlp.s3-us-west-2.amazonaws.com/knowbert/wiki_entity_linking/wiki_id_to_string.json'}"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "WikiCandidateMentionGenerator.get_mentions_raw_text", "type": "function", "doc": "<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>text:</strong>  the text to get the mentions from</li>\n<li><strong>whitespace_tokenize:</strong>  whether to whitespace tokenize the text</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>{'tokenized_text': List[str],\n   'candidate_spans': List[List[int]] list of (start, end) indices for candidates,\n          where span is tokenized_text[start:(end + 1)]\n   'candidate_entities': List[List[str]] = for each entity,\n          the candidates to link to. value is synset id, e.g\n          able.a.02 or hot_dog.n.01\n   'candidate_entity_priors': List[List[float]]</p>\n</blockquote>\n\n<p>}</p>\n", "signature": "(self, text: str, whitespace_tokenize=False)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"fullname": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold", "modulename": "canlpy.core.util.knowbert_tokenizer.wiki_linking_util", "qualname": "WikiCandidateMentionGenerator.get_mentions_with_gold", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    text: str,\n    gold_spans,\n    gold_entities,\n    whitespace_tokenize=True,\n    keep_gold_only: bool = False\n)", "funcdef": "def"}, "canlpy.core.util.tokenization": {"fullname": "canlpy.core.util.tokenization", "modulename": "canlpy.core.util.tokenization", "type": "module", "doc": "<p>Tokenization classes used for ERNIE and CokeBERT.</p>\n"}, "canlpy.core.util.tokenization.load_vocab": {"fullname": "canlpy.core.util.tokenization.load_vocab", "modulename": "canlpy.core.util.tokenization", "qualname": "load_vocab", "type": "function", "doc": "<p>Loads a vocabulary file into a dictionary.</p>\n", "signature": "(vocab_file)", "funcdef": "def"}, "canlpy.core.util.tokenization.whitespace_tokenize": {"fullname": "canlpy.core.util.tokenization.whitespace_tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "whitespace_tokenize", "type": "function", "doc": "<p>Runs basic whitespace cleaning and splitting on a piece of text.</p>\n", "signature": "(text)", "funcdef": "def"}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"fullname": "canlpy.core.util.tokenization.whitespace_tokenize_ent", "modulename": "canlpy.core.util.tokenization", "qualname": "whitespace_tokenize_ent", "type": "function", "doc": "<p></p>\n", "signature": "(text, ents, label=False)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer": {"fullname": "canlpy.core.util.tokenization.BertTokenizer", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer", "type": "class", "doc": "<p>Runs end-to-end tokenization: punctuation splitting + wordpiece</p>\n"}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.__init__", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, vocab_file, do_lower_case=True, max_len=None, label=False)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.tokenize", "type": "function", "doc": "<p></p>\n", "signature": "(self, text, ents)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.convert_tokens_to_ids", "type": "function", "doc": "<p>Converts a sequence of tokens into ids using the vocab.</p>\n", "signature": "(self, tokens)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.convert_ids_to_tokens", "type": "function", "doc": "<p>Converts a sequence of ids in wordpiece tokens using the vocab.</p>\n", "signature": "(self, ids)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.from_pretrained", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.from_pretrained", "type": "function", "doc": "<p>Instantiate a PreTrainedBertModel from a pre-trained model file.\nDownload and cache the pre-trained model file if needed.</p>\n", "signature": "(cls, pretrained_model_name, cache_dir=None, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.util.tokenization.BasicTokenizer": {"fullname": "canlpy.core.util.tokenization.BasicTokenizer", "modulename": "canlpy.core.util.tokenization", "qualname": "BasicTokenizer", "type": "class", "doc": "<p>Runs basic tokenization (punctuation splitting, lower casing, etc.).</p>\n"}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"fullname": "canlpy.core.util.tokenization.BasicTokenizer.__init__", "modulename": "canlpy.core.util.tokenization", "qualname": "BasicTokenizer.__init__", "type": "function", "doc": "<p>Constructs a BasicTokenizer.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>do_lower_case:</strong>  Whether to lower case the input.</li>\n</ul>\n", "signature": "(self, do_lower_case=True, label=False)", "funcdef": "def"}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"fullname": "canlpy.core.util.tokenization.BasicTokenizer.tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "BasicTokenizer.tokenize", "type": "function", "doc": "<p>Tokenizes a piece of text.</p>\n", "signature": "(self, text, ents)", "funcdef": "def"}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"fullname": "canlpy.core.util.tokenization.WordpieceTokenizer", "modulename": "canlpy.core.util.tokenization", "qualname": "WordpieceTokenizer", "type": "class", "doc": "<p>Runs WordPiece tokenization.</p>\n"}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"fullname": "canlpy.core.util.tokenization.WordpieceTokenizer.__init__", "modulename": "canlpy.core.util.tokenization", "qualname": "WordpieceTokenizer.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, vocab, unk_token='[UNK]', max_input_chars_per_word=100)", "funcdef": "def"}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"fullname": "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "WordpieceTokenizer.tokenize", "type": "function", "doc": "<p>Tokenizes a piece of text into its word pieces.</p>\n\n<p>This uses a greedy longest-match-first algorithm to perform tokenization\nusing the given vocabulary.</p>\n\n<h6 id=\"for-example\">For example</h6>\n\n<blockquote>\n  <p>input = \"unaffable\"\n  output = [\"un\", \"##aff\", \"##able\"]</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>text:</strong>  A single token or whitespace separated tokens. This should have\nalready been passed through <code>BasicTokenizer</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A list of wordpiece tokens.</p>\n</blockquote>\n", "signature": "(self, text)", "funcdef": "def"}, "canlpy.core.util.util": {"fullname": "canlpy.core.util.util", "modulename": "canlpy.core.util.util", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.util.get_dtype_for_module": {"fullname": "canlpy.core.util.util.get_dtype_for_module", "modulename": "canlpy.core.util.util", "qualname": "get_dtype_for_module", "type": "function", "doc": "<p>Returns the datatype of the parameters of a module</p>\n", "signature": "(module)", "funcdef": "def"}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"fullname": "canlpy.core.util.util.extend_attention_mask_for_bert", "modulename": "canlpy.core.util.util", "qualname": "extend_attention_mask_for_bert", "type": "function", "doc": "<p>Returns an attention_mask useable with BERT, </p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>mask:</strong>  tensor of positions to be masked (0,1)</li>\n<li><strong>dtype:</strong>  the dtype of the returned mask</li>\n</ul>\n", "signature": "(mask, dtype)", "funcdef": "def"}, "canlpy.core.util.util.find_value": {"fullname": "canlpy.core.util.util.find_value", "modulename": "canlpy.core.util.util", "qualname": "find_value", "type": "function", "doc": "<p>Finds a specific value in a configuration object of nested dictionnaries</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>config:</strong>  the configuration object</li>\n<li><strong>key:</strong>  the key the value corresponds to</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>the corresponding value or None if it is not found</p>\n</blockquote>\n", "signature": "(config, key)", "funcdef": "def"}, "canlpy.helpers": {"fullname": "canlpy.helpers", "modulename": "canlpy.helpers", "type": "module", "doc": "<p></p>\n"}, "canlpy.helpers.cokebert_helpers": {"fullname": "canlpy.helpers.cokebert_helpers", "modulename": "canlpy.helpers.cokebert_helpers", "type": "module", "doc": "<p></p>\n"}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"fullname": "canlpy.helpers.cokebert_helpers.load_k_v_queryR", "modulename": "canlpy.helpers.cokebert_helpers", "qualname": "load_k_v_queryR", "type": "function", "doc": "<p>Get k and v vectors for <code>CokeBert</code>.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ent:</strong>  input_ent: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong>ent_to_neighbors:</strong>  map from entity to neighbors in Knowledge Graph (loaded from <code>e1_e2_list_2D_Tensor.pkl</code>)</li>\n<li><strong>ent_to_relations:</strong>  map from entity to neighboring relations in Knowledge Graph (loaded from <code>e1_r_list_2D_Tensor.pkl</code>)</li>\n<li><strong>ent_to_outORin:</strong>  direction of arc in knowledge graph (1: out of ent, -1: into ent) (loaded from <code>e1_outORin_list_2D_Tensor.pkl</code>)</li>\n<li><strong>embed_ent:</strong>  Map of entity embeddings</li>\n<li><strong>r_embed:</strong>  Map of relation embeddings</li>\n<li><strong>device:</strong>  The device to load the resulting vectors onto (default: <code>cpu</code>) </li>\n<li><strong>dk_layers (int):</strong>  The number of layers in the dynamic knowledge encoder, therefore also half the number of output vectors (default: 2)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>list of k_i, v_i vectors as input for the dynamic knowledge encoder</p>\n</blockquote>\n", "signature": "(\n    input_ent,\n    ent_to_neighbors,\n    ent_to_relations,\n    ent_to_outORin,\n    embed_ent,\n    r_embed,\n    device='cpu',\n    dk_layers=2\n)", "funcdef": "def"}, "canlpy.helpers.ernie_helpers": {"fullname": "canlpy.helpers.ernie_helpers", "modulename": "canlpy.helpers.ernie_helpers", "type": "module", "doc": "<p></p>\n"}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"fullname": "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "create_model_mapping_ERNIE", "type": "function", "doc": "<p>Returns a dictionnary mapping the original ERNIE model weights to custom ERNIE model weights</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>model_old:</strong>  the old model's state dict</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>model_mapping: a dictionnary mapping the original ERNIE model weights to custom ERNIE model weights</p>\n</blockquote>\n", "signature": "(model_old) -> Dict[str, str]", "funcdef": "def"}, "canlpy.helpers.ernie_helpers.get_ents": {"fullname": "canlpy.helpers.ernie_helpers.get_ents", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "get_ents", "type": "function", "doc": "<p>Returns a list of [entity_QID,character_idx_start,character_idx_end,entity_score] for each entity detect in the text</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>text:</strong>  string, the text to extract entities from</li>\n<li><strong>name_to_QID:</strong>  a dictionary mapping entity names to their QID</li>\n</ul>\n", "signature": "(\n    text: str,\n    name_to_QID: Dict[str, str],\n    keep_proba: float = 0.3\n) -> List[Tuple[str, int, int, float]]", "funcdef": "def"}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"fullname": "canlpy.helpers.ernie_helpers.load_name_to_QID", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "load_name_to_QID", "type": "function", "doc": "<p>Loads the dictionnary mapping entity names to their QID</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>filename:</strong>  the path to the file containing the dictionnary</li>\n</ul>\n", "signature": "(filename: str) -> Dict[str, str]", "funcdef": "def"}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"fullname": "canlpy.helpers.ernie_helpers.load_QID_to_eid", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "load_QID_to_eid", "type": "function", "doc": "<p>Loads the dictionnary mapping entity QID to their eid (idx in an embedding vector)</p>\n\n<p>Args:\n    filename: the path to the file containing the dictionnary</p>\n", "signature": "(filename: str) -> Dict[str, int]", "funcdef": "def"}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"fullname": "canlpy.helpers.ernie_helpers.load_eid_to_vec", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "load_eid_to_vec", "type": "function", "doc": "<p>Loads the pytorch embedding mapping entity idx to their pre-trained vector representation</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>filename:</strong>  the path to the file containing the dictionnary</li>\n</ul>\n", "signature": "(filename: str) -> torch.FloatTensor", "funcdef": "def"}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"fullname": "canlpy.helpers.ernie_helpers.concatenate_tokens_entities", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "concatenate_tokens_entities", "type": "function", "doc": "<p>Returns the merged tokens and entities as well as a list representing their segments_ids and the input mask</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>tokens_a:</strong>  a list of tokens</li>\n<li><strong>tokens_b:</strong>  a list of tokens</li>\n<li><strong>entities_a:</strong>  a list of entities QID </li>\n<li><strong>entities_b:</strong>  a list of entities QID</li>\n</ul>\n", "signature": "(\n    tokens_a: List[str],\n    tokens_b: List[str],\n    entities_a: List[str],\n    entities_b: List[str]\n) -> Tuple[List[str], List[str], List[int], List[int]]", "funcdef": "def"}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"fullname": "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "get_entities_embeddings_and_mask", "type": "function", "doc": "<p>Returns the merged tokens and entities as well as a list representing their segments_ids and the input mask</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>entities:</strong>  a list of tokens</li>\n<li><strong>QID_to_eid:</strong>  a list of tokens</li>\n<li><strong>eid_to_embeddings:</strong>  a list of entities QID</li>\n</ul>\n", "signature": "(\n    entities: List[str],\n    QID_to_eid: Dict[str, int],\n    eid_to_embeddings: torch.nn.modules.sparse.Embedding,\n    device: str\n) -> Tuple[torch.Tensor, torch.Tensor]", "funcdef": "def"}, "canlpy.helpers.ernie_helpers.process_sentences": {"fullname": "canlpy.helpers.ernie_helpers.process_sentences", "modulename": "canlpy.helpers.ernie_helpers", "qualname": "process_sentences", "type": "function", "doc": "<p>Returns the ERNIE model input for the sentence</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>text_a:</strong>  the first sentence</li>\n<li><strong>text_b:</strong>  the second sentence</li>\n<li><strong>masked_indices:</strong>  the indices to mask in the sentences</li>\n<li><strong>name_to_QID:</strong>  a dictionnary mapping entity name to the QID (wikipedia id)</li>\n<li><strong>QID_to_eid:</strong>  a dictionnary mapping QID to embedding indices</li>\n<li><strong>eid_to_embeddings:</strong>  the nn.Embedding containing the entity embeddings</li>\n<li><strong>tokenizer:</strong>  the bert tokenizer to use on the sentences</li>\n<li><strong>device:</strong>  the PyTorch device to place the resulting tensor on</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>tokens_tensor: a torch.LongTensor containing the tokens ids\n  ents_tensor: a torch.FloatTensor containing the entity embeddings\n  ent_mask: a tensor of [0,1] containing the mask on the entities\n  segments_tensors: a tensor of [0,1] indicating to which sentence the corresponding tokens belongs to</p>\n</blockquote>\n", "signature": "(\n    text_a: str,\n    text_b: str,\n    masked_indices: List[int],\n    name_to_QID: Dict[str, str],\n    QID_to_eid: Dict[str, int],\n    eid_to_embeddings: torch.nn.modules.sparse.Embedding,\n    tokenizer: canlpy.core.util.tokenization.BertTokenizer,\n    device: str\n) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]", "funcdef": "def"}, "canlpy.helpers.tokens": {"fullname": "canlpy.helpers.tokens", "modulename": "canlpy.helpers.tokens", "type": "module", "doc": "<p></p>\n"}, "canlpy.train": {"fullname": "canlpy.train", "modulename": "canlpy.train", "type": "module", "doc": "<p></p>\n"}, "canlpy.train.optimization": {"fullname": "canlpy.train.optimization", "modulename": "canlpy.train.optimization", "type": "module", "doc": "<p></p>\n"}, "canlpy.train.optimization.warmup_cosine": {"fullname": "canlpy.train.optimization.warmup_cosine", "modulename": "canlpy.train.optimization", "qualname": "warmup_cosine", "type": "function", "doc": "<p></p>\n", "signature": "(x, warmup=0.002)", "funcdef": "def"}, "canlpy.train.optimization.warmup_constant": {"fullname": "canlpy.train.optimization.warmup_constant", "modulename": "canlpy.train.optimization", "qualname": "warmup_constant", "type": "function", "doc": "<p></p>\n", "signature": "(x, warmup=0.002)", "funcdef": "def"}, "canlpy.train.optimization.warmup_linear": {"fullname": "canlpy.train.optimization.warmup_linear", "modulename": "canlpy.train.optimization", "qualname": "warmup_linear", "type": "function", "doc": "<p></p>\n", "signature": "(x, warmup=0.002)", "funcdef": "def"}, "canlpy.train.optimization.BertAdam": {"fullname": "canlpy.train.optimization.BertAdam", "modulename": "canlpy.train.optimization", "qualname": "BertAdam", "type": "class", "doc": "<p>Implements BERT version of Adam algorithm with weight decay fix.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>lr: learning rate\n  warmup: portion of t_total for the warmup, -1  means no warmup. Default: -1\n  t_total: total number of training steps for the learning\n      rate schedule, -1  means constant learning rate. Default: -1\n  schedule: schedule to use for the warmup (see above). Default: 'warmup_linear'\n  b1: Adams b1. Default: 0.9\n  b2: Adams b2. Default: 0.999\n  e: Adams epsilon. Default: 1e-6\n  weight_decay: Weight decay. Default: 0.01\n  max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0</p>\n</blockquote>\n", "bases": "torch.optim.optimizer.Optimizer"}, "canlpy.train.optimization.BertAdam.__init__": {"fullname": "canlpy.train.optimization.BertAdam.__init__", "modulename": "canlpy.train.optimization", "qualname": "BertAdam.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    params,\n    lr=<required parameter>,\n    warmup=-1,\n    t_total=-1,\n    schedule='warmup_linear',\n    b1=0.9,\n    b2=0.999,\n    e=1e-06,\n    weight_decay=0.01,\n    max_grad_norm=1.0\n)", "funcdef": "def"}, "canlpy.train.optimization.BertAdam.get_lr": {"fullname": "canlpy.train.optimization.BertAdam.get_lr", "modulename": "canlpy.train.optimization", "qualname": "BertAdam.get_lr", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.train.optimization.BertAdam.step": {"fullname": "canlpy.train.optimization.BertAdam.step", "modulename": "canlpy.train.optimization", "qualname": "BertAdam.step", "type": "function", "doc": "<p>Performs a single optimization step.</p>\n\n<h6 id=\"arguments\">Arguments</h6>\n\n<blockquote>\n  <p>closure (callable, optional): A closure that reevaluates the model\n      and returns the loss.</p>\n</blockquote>\n", "signature": "(self, closure=None)", "funcdef": "def"}}, "docInfo": {"canlpy": {"qualname": 0, "fullname": 1, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 360}, "canlpy.core": {"qualname": 0, "fullname": 2, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.activation_functions": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.activation_functions.gelu": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 49}, "canlpy.core.components.activation_functions.get_activation_function": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.components.fusion": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.cokebert_fusion": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 18}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 53}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 90}, "canlpy.core.components.fusion.ernie_fusion": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 13}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 14, "bases": 0, "doc": 80}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 94}, "canlpy.core.components.fusion.fusion": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.fusion.Fusion": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 176}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 75}, "canlpy.core.components.fusion.knowbert_fusion": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"qualname": 0, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 91}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 14, "bases": 0, "doc": 137}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 16}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 56, "bases": 0, "doc": 167}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 38}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 29, "bases": 0, "doc": 166}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 58}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 29}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 61, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 30, "bases": 0, "doc": 67}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 70}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 26, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 49}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 40}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 30, "bases": 0, "doc": 109}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"qualname": 0, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"qualname": 1, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 35}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"qualname": 3, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"qualname": 2, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 89}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"qualname": 1, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 8}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"qualname": 3, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"qualname": 2, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 63}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"qualname": 1, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 8}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"qualname": 3, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"qualname": 2, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 73}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"qualname": 0, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 65}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 22, "bases": 0, "doc": 254}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"qualname": 4, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"qualname": 4, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 13}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 162}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"qualname": 4, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"qualname": 4, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 13}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 24, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"qualname": 5, "fullname": 13, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 135}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 253}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 22, "bases": 0, "doc": 286}, "canlpy.core.components.heads": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.heads.BertLMPredictionHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 176}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.BertOnlyMLMHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 176}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 176}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.BertOnlyNSPHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 176}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 176}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 67}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 176}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 14}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 67}, "canlpy.core.models": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.bert": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.bert.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.bert.model.MultiHeadAttention": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 133}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 12, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertAttention": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 141}, "canlpy.core.models.bert.model.BertAttention.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertAttention.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertEmbeddings": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 204}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 16, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.DenseSkipLayer": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 124}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertLayer": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 180}, "canlpy.core.models.bert.model.BertLayer.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 19, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertLayer.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertPooler": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 80}, "canlpy.core.models.bert.model.BertPooler.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertPooler.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.LayerNorm": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 82}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 16}, "canlpy.core.models.bert.model.LayerNorm.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.init_weights": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 45}, "canlpy.core.models.cokebert": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.cokebert.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 28}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 5, "signature": 0, "bases": 0, "doc": 11}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 5, "signature": 0, "bases": 0, "doc": 12}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 4, "signature": 0, "bases": 0, "doc": 13}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 14}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 66, "bases": 0, "doc": 356}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 46}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 23}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 24}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"qualname": 5, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 23}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"qualname": 5, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 23}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 20}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 36}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 13, "bases": 0, "doc": 147}, "canlpy.core.models.cokebert.model.CokeBertModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 14}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 29}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 27, "bases": 0, "doc": 359}, "canlpy.core.models.cokebert.model.DKEncoder": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 15}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 66}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 119}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 18}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 70}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 117}, "canlpy.core.models.cokebert.model.DK_text": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 16}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 70}, "canlpy.core.models.cokebert.model.DK_text.forward": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 71}, "canlpy.core.models.cokebert.model.DK_knowledge": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 16}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 36}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 61}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 28}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 53}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 334}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 27}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 53}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 334}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 30}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 35}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 338}, "canlpy.core.models.ernie": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.ernie.components": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 276}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 343}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 21, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.components.ErnieEncoder": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 207}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.ernie.model.ErnieConfig": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 56, "bases": 0, "doc": 320}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 15}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 10}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 10}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 20}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 6}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 135}, "canlpy.core.models.ernie.model.ErnieModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 875}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 23, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 793}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 21, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 463}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 31, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 651}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 16, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 308}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 309}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 361}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForNQ": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 370}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 23, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 433}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 24, "bases": 0, "doc": 67}, "canlpy.core.models.knowbert": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowbert_heads": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 30}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 14}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 19, "bases": 0, "doc": 67}, "canlpy.core.models.knowbert.knowledge": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 12}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 2, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"qualname": 5, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 24, "bases": 0, "doc": 132}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 115}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 39, "bases": 0, "doc": 25}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 29, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 46}, "canlpy.core.models.knowbert.metrics": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.Metric": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 15}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 2, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 15}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 68}, "canlpy.core.models.knowbert.metrics.Average": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 60}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 20}, "canlpy.core.models.knowbert.metrics.Average.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 36}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 60}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 20}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 36}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 20}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.F1Metric": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 28}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 27}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 15}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 15}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.model.KnowBert": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 192}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 47, "bases": 0, "doc": 14}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 50}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 45}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 22}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 296}, "canlpy.core.util": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.file_utils": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 29}, "canlpy.core.util.file_utils.url_to_filename": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 32}, "canlpy.core.util.file_utils.filename_to_url": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 12, "bases": 0, "doc": 34}, "canlpy.core.util.file_utils.cached_path": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 54}, "canlpy.core.util.file_utils.split_s3_path": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 14}, "canlpy.core.util.file_utils.s3_request": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 16}, "canlpy.core.util.file_utils.s3_etag": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 8}, "canlpy.core.util.file_utils.s3_get": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 9}, "canlpy.core.util.file_utils.http_get": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.file_utils.get_from_cache": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 30}, "canlpy.core.util.file_utils.read_set_from_file": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 22}, "canlpy.core.util.file_utils.get_file_extension": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"qualname": 0, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"qualname": 3, "fullname": 13, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 38}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"qualname": 1, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 20}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"qualname": 3, "fullname": 13, "annotation": 0, "default_value": 0, "signature": 2, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"qualname": 1, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 12}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"qualname": 3, "fullname": 13, "annotation": 0, "default_value": 0, "signature": 2, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"qualname": 1, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 75}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"qualname": 3, "fullname": 13, "annotation": 0, "default_value": 0, "signature": 37, "bases": 0, "doc": 40}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"qualname": 5, "fullname": 15, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 152}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"qualname": 6, "fullname": 16, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 68}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"qualname": 1, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 22}, "canlpy.core.util.knowbert_tokenizer.common": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 2, "bases": 0, "doc": 10}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 8}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 77}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 68}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 42}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 12, "bases": 0, "doc": 58}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 21}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 45}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 40}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 821}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 50, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 3, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 39}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 12, "bases": 0, "doc": 34}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 16, "bases": 0, "doc": 271}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 18}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"qualname": 5, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 25}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"qualname": 6, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"qualname": 6, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"qualname": 5, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"qualname": 0, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 16, "bases": 0, "doc": 70}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 24, "bases": 0, "doc": 254}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 26}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"qualname": 1, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 0, "bases": 11, "doc": 12}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"qualname": 3, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"qualname": 2, "fullname": 10, "annotation": 0, "default_value": 84, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"qualname": 5, "fullname": 13, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 99}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"qualname": 5, "fullname": 13, "annotation": 0, "default_value": 0, "signature": 17, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 10}, "canlpy.core.util.tokenization.load_vocab": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 10}, "canlpy.core.util.tokenization.whitespace_tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 14}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.BertTokenizer": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 11}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 14, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"qualname": 5, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 13}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"qualname": 5, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 22}, "canlpy.core.util.tokenization.BasicTokenizer": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 11}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 27}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 8}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 6}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 13, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 93}, "canlpy.core.util.util": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.util.get_dtype_for_module": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 11}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"qualname": 5, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 42}, "canlpy.core.util.util.find_value": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 58}, "canlpy.helpers": {"qualname": 0, "fullname": 2, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.helpers.cokebert_helpers": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 22, "bases": 0, "doc": 215}, "canlpy.helpers.ernie_helpers": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 59}, "canlpy.helpers.ernie_helpers.get_ents": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 18, "bases": 0, "doc": 57}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 31}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 29}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 35}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 18, "bases": 0, "doc": 71}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"qualname": 5, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 23, "bases": 0, "doc": 60}, "canlpy.helpers.ernie_helpers.process_sentences": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 45, "bases": 0, "doc": 177}, "canlpy.helpers.tokens": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.train": {"qualname": 0, "fullname": 2, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.train.optimization": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.train.optimization.warmup_cosine": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.train.optimization.warmup_constant": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.train.optimization.warmup_linear": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.train.optimization.BertAdam": {"qualname": 1, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 4, "doc": 110}, "canlpy.train.optimization.BertAdam.__init__": {"qualname": 3, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 33, "bases": 0, "doc": 3}, "canlpy.train.optimization.BertAdam.get_lr": {"qualname": 3, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.train.optimization.BertAdam.step": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 32}}, "length": 352, "save": true}, "index": {"qualname": {"root": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 71, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "t": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 33}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 1}}}}}}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 3}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}}, "df": 4}}}}}}, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}}}}}}, "f": {"1": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 4}}}}}}}, "docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 6}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 3, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 48}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 13}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 5, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 9, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 6}}}}}}}}, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 5}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 74}}, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}}, "df": 2}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 5}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 1, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}}, "df": 3}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}}, "df": 3}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}}, "df": 3, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}}, "df": 3}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 5}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3}}}}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}}, "df": 3}}}}, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}}, "df": 2}}}}}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 2}}}}}, "s": {"docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 2}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 2}}}}}}}}, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}}, "df": 1}}}}, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 2}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}}, "df": 4}}}}}}, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 11, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}}, "df": 2}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}}, "df": 2}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 2}}}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 2}}}}}, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 1}}}}}, "s": {"3": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 4}, "docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}}, "df": 5}}}}}}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}}, "df": 3, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}}, "df": 4}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 2}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 2}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 4}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 3}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.train.optimization.warmup_constant": {"tf": 1}}, "df": 1}}}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 7}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}}, "df": 3}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 1, "d": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 4}}}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 1}}}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 3}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}}, "df": 3}}}}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}}, "df": 3}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}}, "df": 3}}}}}}}}, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 4}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}}, "df": 3}}}}}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 19, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 5, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 6, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}}, "df": 4}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 6}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 3, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}}, "df": 3}}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 8}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {"canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 1}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 6}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 1, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 3}}}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}}, "df": 3, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 2}}}}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1}}}}, "j": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 4}}}}, "k": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 3}}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 6, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 4, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 1}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 2}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 7}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1}}}, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils.http_get": {"tf": 1}}, "df": 1}}}}, "v": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}}, "df": 3, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 14}}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 1}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}}, "df": 2}}}}}, "fullname": {"root": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 71, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy": {"tf": 1}, "canlpy.core": {"tf": 1}, "canlpy.core.components": {"tf": 1}, "canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models": {"tf": 1}, "canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}, "canlpy.helpers.tokens": {"tf": 1}, "canlpy.train": {"tf": 1}, "canlpy.train.optimization": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 352}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 11, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 4}}}}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 1, "d": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core": {"tf": 1}, "canlpy.core.components": {"tf": 1}, "canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models": {"tf": 1}, "canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 329}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components": {"tf": 1}, "canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}}, "df": 91}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.common": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}}, "df": 4}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.helpers.cokebert_helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 46, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 7}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}}, "df": 3}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 4}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 3}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.train.optimization.warmup_constant": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 11}}}}}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 13}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}}, "df": 4}}}}}}, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 1}}}, "f": {"1": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 4}}}}}}}, "docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 3}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}}, "df": 58}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 3, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 48}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 13}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 15, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "t": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 33}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 11}}, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 9, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 6}}}}}}}}, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 5}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 74}}, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}}, "df": 2}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 5}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.helpers.ernie_helpers": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 61, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}}, "df": 3}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}}, "df": 3}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}}, "df": 3, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}}, "df": 3}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 5}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3}}}}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}}, "df": 3}}}}, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}}, "df": 2}}}}}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 2}}}}}, "s": {"docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 2}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}}}, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 13}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 2}}}}}}}}, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 2}}}, "k": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 145, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 13}}}}}}}}, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}}, "df": 21}}, "s": {"3": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 4}, "docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}}, "df": 21, "k": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}}, "df": 5}}}}}}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 24, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}}, "df": 3, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}}, "df": 4}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 2}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 2}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}}, "df": 4}}}}}}, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util": {"tf": 1.4142135623730951}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}}, "df": 81, "s": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 12}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 11, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 32}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}}, "df": 2}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 2}}}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 2}}}}}, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 108, "s": {"docs": {"canlpy.core.models": {"tf": 1}, "canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 166}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 13, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}}, "df": 3}}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 8}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 9}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {"canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 3}}}}}, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 8}}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 37, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}}, "df": 3}}}}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}}, "df": 3}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}}, "df": 3}}}}}}}}, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 4}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}}, "df": 3}}}}}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 23}}}, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}, "canlpy.helpers.tokens": {"tf": 1}}, "df": 13}}}}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils.http_get": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train": {"tf": 1}, "canlpy.train.optimization": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 9}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 19, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 5, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 6, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.common": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 48, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 16}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.tokens": {"tf": 1}}, "df": 5}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 6}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 6}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 10, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 5}}}}}}}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 3}}}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}}, "df": 3, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 2}}}}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1}}}}, "j": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 4}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 4, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 1}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 2}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 7}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1}}}, "v": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}}, "df": 3, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1.4142135623730951}}, "df": 17}}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 1}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}}, "df": 2}}}}}, "annotation": {"root": {"docs": {}, "df": 0}}, "default_value": {"root": {"0": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "1": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.23606797749979}}, "df": 2}, "3": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "4": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "5": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "6": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "7": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "8": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.8284271247461903}}, "df": 6, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.23606797749979}}, "df": 1}}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}}}}}, "j": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 3}}}}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 1}}}, "n": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}, "v": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "a": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.23606797749979}}, "df": 1}}}}}}}}}, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}}}}, "s": {"3": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.23606797749979}}, "df": 1}, "docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.23606797749979}}, "df": 1}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, ":": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.23606797749979}}, "df": 1}}}}}}}}}}}}}}}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.23606797749979}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2.449489742783178}}, "df": 1}}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2}}, "df": 1}}}}}}}}}}}}, "y": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 2}}, "df": 1}}, "o": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1.4142135623730951}}, "df": 1}}}}, "signature": {"root": {"0": {"0": {"2": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "1": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5}, "6": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 2}}, "df": 14}, "1": {"0": {"0": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 6}, "docs": {}, "df": 0}, "2": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 3}, "docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1.7320508075688772}}, "df": 9, "e": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 2, "+": {"3": {"2": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {}, "df": 0}}}, "2": {"0": {"0": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "5": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 11}, "3": {"0": {"7": {"2": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 1}, "4": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "5": {"1": {"2": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 6}, "docs": {}, "df": 0}, "docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}}, "df": 1}, "7": {"6": {"8": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "9": {"9": {"9": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_request": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_get": {"tf": 2}, "canlpy.core.util.file_utils.http_get": {"tf": 2}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}, "canlpy.train.optimization.warmup_cosine": {"tf": 1.4142135623730951}, "canlpy.train.optimization.warmup_constant": {"tf": 1.4142135623730951}, "canlpy.train.optimization.warmup_linear": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 2}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 231, "x": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 6}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 5, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 10, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "o": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}}, "df": 4, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 47, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 2}}}}}}, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 5}}, "m": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}}, "df": 13}}, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 3}}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 5, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 2}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2}}, "df": 41, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}}, "df": 13}}}, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 174}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 10}}}}}}, "g": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 6}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}}}}, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 14}}}, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 8, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 4}}, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 3}}}}}, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}}, "df": 1}}}}}, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.7320508075688772}}, "df": 1, "k": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}}}}}, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 15, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 7}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 2}}}}}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 10}}}}}, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}, "e": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 2}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 2}}}}, "v": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 13, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 11, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}}, "df": 5}}}}}}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}}, "df": 13}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 4, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 15}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 13}}}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 2}}}, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 3}}}}}, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 2}, "o": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 3, "t": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 8}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 6, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 15}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}}, "df": 1, "g": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 6}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 2}}, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}}, "df": 2}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 4, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}}, "df": 1}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 5}}}, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 1}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 2}}}}}}}, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 4}, "r": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}, "q": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}}, "df": 8, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 3}}}, "i": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 30, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}}}}}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 20, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 5}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 5}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 1}}}, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}}}}, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 2}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 1}}}}}}}}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 21}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}, "h": {"5": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}}, "df": 27}}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 7}}}}}, "e": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.23606797749979}}, "df": 21, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}}, "df": 25, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 2}}}}}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 7}}}}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}}, "df": 5}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 2}, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3}}}}}, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 1}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 1, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 10, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 15}}}}}}}}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}}}, "p": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 2}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 10, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 7}, "a": {"docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 1}}, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}}, "df": 3}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}}, "df": 9, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 3}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 2}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 3}}}, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 1}}}, "a": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 4, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}}, "df": 4}}}}}}}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 28}}}}}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}}, "df": 2}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}}, "df": 3}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}, "f": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 3}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 3}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}}, "df": 12, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 3}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 19}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}}, "df": 9, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 8}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "t": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1, "o": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.7320508075688772}}, "df": 6, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 18, "s": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}}, "df": 18}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 3, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 5}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}}}}}}, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2}}, "df": 16}}}, "p": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 4}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2}}, "df": 15, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}}, "df": 2}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 10}}}, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 20, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}}, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 15}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 2}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}}, "df": 1}}}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 2}}}}}}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 10}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 3}, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "v": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 1}}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 2}}, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}}, "df": 3}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 3}}}}}}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1.4142135623730951}}, "df": 4}}}}}}, "r": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}}, "df": 1}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 9}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 2}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}}, "df": 9, "s": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.7320508075688772}}, "df": 5}}}}}}}, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 7}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1, "[": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 3}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}}, "df": 5}}}}}}}, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 30}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 7}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}, "l": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 9}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}}}}, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 30, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 4}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}}, "df": 1}}}}}, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 14}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.4142135623730951}}, "df": 2}}}}, "p": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 4, "l": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 8, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}}, "df": 2}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 4}}}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}, "b": {"1": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 4, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1}}, "df": 21}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}}, "df": 7, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}}, "df": 1}}}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "z": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1.7320508075688772}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 4}}}, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 4}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 2}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "k": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1.4142135623730951}}, "df": 1, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 8}}}}}, "bases": {"root": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 5}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 1}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 5}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}}, "df": 4}}}}}}}}}}, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1.7320508075688772}}, "df": 4}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 33}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1.4142135623730951}}, "df": 1, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 32}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 32, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 32}}}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 6}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}}, "df": 1}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 9}}}}}}}}}}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 1}}}}, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 1}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 1}}}}}}}}}, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}}}}, "doc": {"root": {"0": {"1": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}, "2": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1}, "4": {"4": {"7": {"1": {"5": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.7416573867739413}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 2}}, "df": 34, "/": {"1": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}}, "1": {"0": {"0": {"0": {"0": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}}, "df": 2}, "2": {"4": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}, "1": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 4}, "5": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.7416573867739413}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.4641016151377544}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 2.449489742783178}}, "df": 47, "m": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}, "e": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}, "2": {"0": {"2": {"0": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "4": {"8": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}}, "df": 7}, "4": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 19, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}, "d": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}}, "df": 1}}, "3": {"0": {"7": {"2": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "1": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "2": {"0": {"0": {"0": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {"canlpy": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 3}, "5": {"1": {"2": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 12}, "6": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 4}, "7": {"6": {"8": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}}, "df": 1}, "8": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}, "9": {"9": {"9": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {"canlpy": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}, "docs": {"canlpy": {"tf": 10.723805294763608}, "canlpy.core": {"tf": 1.7320508075688772}, "canlpy.core.components": {"tf": 1.7320508075688772}, "canlpy.core.components.activation_functions": {"tf": 1.7320508075688772}, "canlpy.core.components.activation_functions.gelu": {"tf": 3.3166247903554}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 4.69041575982343}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 5.0990195135927845}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 5.830951894845301}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 4.898979485566356}, "canlpy.core.components.fusion.fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 5.830951894845301}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 5.656854249492381}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 4.898979485566356}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 5.385164807134504}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 7.14142842854285}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 6.164414002968976}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 3.7416573867739413}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.get_metrics": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 3.4641016151377544}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.get_metrics": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.unfreeze": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 3.872983346207417}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 3.1622776601683795}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 4.898979485566356}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 3.7416573867739413}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 6.557438524302}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 3.3166247903554}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 5.291502622129181}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 5.0990195135927845}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 5.385164807134504}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 8.246211251235321}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 5.656854249492381}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 6.4031242374328485}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 8.12403840463596}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 7.615773105863909}, "canlpy.core.components.heads": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 5.830951894845301}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 5.830951894845301}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 5.830951894845301}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 5.830951894845301}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 5.830951894845301}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 5.830951894845301}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 3.872983346207417}, "canlpy.core.models": {"tf": 1.7320508075688772}, "canlpy.core.models.bert": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 6}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertAttention": {"tf": 6}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 6.48074069840786}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 6.48074069840786}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertLayer": {"tf": 6.164414002968976}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertPooler": {"tf": 5.744562646538029}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 6.4031242374328485}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.init_weights": {"tf": 4.358898943540674}, "canlpy.core.models.cokebert": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 10.198039027185569}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 5}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 3.4641016151377544}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 3.4641016151377544}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 4.358898943540674}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 6.48074069840786}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 3.872983346207417}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 8.426149773176359}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 5}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 5.5677643628300215}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 5.385164807134504}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 5.744562646538029}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 5.291502622129181}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 4.58257569495584}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 4}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 4.47213595499958}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 4.898979485566356}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 9.219544457292887}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 4.898979485566356}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 9.219544457292887}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 4.123105625617661}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 9.219544457292887}, "canlpy.core.models.ernie": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 6.4031242374328485}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 7.0710678118654755}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 7.3484692283495345}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 9.539392014169456}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 6.244997998398398}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 20.591260281974}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 20.199009876724155}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 9.797958971132712}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 17.88854381999832}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 8.366600265340756}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 8.366600265340756}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 9.433981132056603}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 9.797958971132712}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 8.12403840463596}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 3.872983346207417}, "canlpy.core.models.knowbert": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 3.3166247903554}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 3.872983346207417}, "canlpy.core.models.knowbert.knowledge": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 6.164414002968976}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 5.385164807134504}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 4.358898943540674}, "canlpy.core.models.knowbert.metrics": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 3.3166247903554}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 3}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 3.3166247903554}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 3}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 3}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 4.69041575982343}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 4.123105625617661}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 4.242640687119285}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 5.291502622129181}, "canlpy.core.util": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils": {"tf": 2.23606797749979}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 2.6457513110645907}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 3.3166247903554}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_request": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_get": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.http_get": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 3}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 3.1622776601683795}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 5.656854249492381}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 5.0990195135927845}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.common": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 3.1622776601683795}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 5.196152422706632}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 4.898979485566356}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 8.717797887081348}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 5.916079783099616}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 4.58257569495584}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 6}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.defaults": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 5.656854249492381}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_with_gold": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 3.7416573867739413}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 6.164414002968976}, "canlpy.core.util.util": {"tf": 1.7320508075688772}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 4.242640687119285}, "canlpy.core.util.util.find_value": {"tf": 4.898979485566356}, "canlpy.helpers": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 8.06225774829855}, "canlpy.helpers.ernie_helpers": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 4.47213595499958}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 4}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 3.4641016151377544}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 3.4641016151377544}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 5}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 4.47213595499958}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 7}, "canlpy.helpers.tokens": {"tf": 1.7320508075688772}, "canlpy.train": {"tf": 1.7320508075688772}, "canlpy.train.optimization": {"tf": 1.7320508075688772}, "canlpy.train.optimization.warmup_cosine": {"tf": 1.7320508075688772}, "canlpy.train.optimization.warmup_constant": {"tf": 1.7320508075688772}, "canlpy.train.optimization.warmup_linear": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam": {"tf": 3.3166247903554}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam.step": {"tf": 3.605551275463989}}, "df": 352, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 3, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2.6457513110645907}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.358898943540674}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 3}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}}, "df": 73}, "n": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "e": {"docs": {"canlpy": {"tf": 4.47213595499958}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 3}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 3.1622776601683795}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 3}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 3.3166247903554}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 3.4641016151377544}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 3.1622776601683795}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 3.7416573867739413}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 3.1622776601683795}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertAttention": {"tf": 3}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 4.123105625617661}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertLayer": {"tf": 3.4641016151377544}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 4.795831523312719}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 4.58257569495584}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 4.123105625617661}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 4.123105625617661}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 4.58257569495584}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 4.69041575982343}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 4.69041575982343}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 4.898979485566356}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 4.47213595499958}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 4.47213595499958}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 5.5677643628300215}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 3.1622776601683795}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 3.7416573867739413}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3.3166247903554}, "canlpy.core.util.file_utils": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 2.23606797749979}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 5.830951894845301}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 3.605551275463989}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 2}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 2}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.6457513110645907}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 2}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 2}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 2}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 4.242640687119285}, "canlpy.train.optimization.BertAdam": {"tf": 2}, "canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 193, "n": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.23606797749979}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 6}, "m": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 38}, "i": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 14}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 5}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 4, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 47}, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 18}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 10}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.7320508075688772}}, "df": 3}}}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 2}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 2}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 25, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1}}}}}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 3}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 3.1622776601683795}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2.23606797749979}}, "df": 21, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 3}}}}}}, "o": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 5.916079783099616}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 3.1622776601683795}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 2}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.449489742783178}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 3.1622776601683795}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 147, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 40, "s": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.7320508075688772}}, "df": 44, "/": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}}, "/": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}}, "df": 3, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 4}, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}}, "df": 3}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 3}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 6}}}}}}}}}}, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 47}}}, "o": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}, "p": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 10}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 4}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 3, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 7}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 11}}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}}, "df": 8}}}}}}}}, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 6}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 1, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 3}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 1}}}}}}}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy": {"tf": 2.449489742783178}}, "df": 1, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2.449489742783178}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}}, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 2}}, "df": 1}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 3}}, "n": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "k": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 34}, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}}, "df": 3}}}}}}}, "e": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 19, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 16}}, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 17}}}}}, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "f": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}}, "df": 1}}}}}, "w": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 2}}}, "i": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 14, "s": {"docs": {"canlpy": {"tf": 2.449489742783178}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2.8284271247461903}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 55}, "n": {"docs": {"canlpy": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.58257569495584}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 72, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 48}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 3}}}}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 31}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 5}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 13, "o": {"docs": {"canlpy": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 16}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 51}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 10}}}}}}}, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 2}}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 2}}}}}}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}}, "df": 8, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 5, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 36}, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 5}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 4}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 4}}}}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 2}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 34, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 5}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 3.1622776601683795}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.7320508075688772}}, "df": 31}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 3}}}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}}, "df": 7, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 2}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 2}, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 1}}}}}}, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 3}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 2, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2}}, "df": 3}}}}}}}, "t": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 28, "e": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 6}}, "p": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "b": {"docs": {"canlpy": {"tf": 1.4142135623730951}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 3}}}}}, "s": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}}, "df": 7}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 6, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 28}, "x": {"docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 3}}, "f": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 42}, "g": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}}, "df": 2}}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 26, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy": {"tf": 1}}, "df": 1, "/": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}}}}}}, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.7320508075688772}}, "df": 12, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}}, "df": 7}}}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 40, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 2}}}, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1, "[": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1.4142135623730951}}, "df": 7, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 5, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 4}}}}, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 2}}}}}}}}}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 2}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}}, "df": 47, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}}, "df": 12}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 15}, "d": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}}, "df": 8}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "s": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}}, "df": 5}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 3}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}}, "df": 3, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 4}}}}}}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 10, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 7}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2}}, "df": 21}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 2}}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 13}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 2}}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}, "v": {"1": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}}, "df": 7}, "2": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}}, "df": 7, "d": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}}, "df": 7}}, "docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 10}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 3}}}}}, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 28, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}}, "df": 19}}}}}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}}}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 2}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 11, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}}, "df": 5}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}}, "df": 8}}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy": {"tf": 1.7320508075688772}}, "df": 1, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 7, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 7}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 7}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 29}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 6}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 5}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 4}}}}}, "/": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 5, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 15}}}, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 16}}}, "b": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}}, "df": 1}}}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.8284271247461903}}, "df": 2, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 1}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}}, "df": 3}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}}, "df": 5, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}}, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 6}}}}}}}}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 14}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 2}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2.23606797749979}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.1622776601683795}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.4641016151377544}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.cached_path": {"tf": 2}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.795831523312719}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 2}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 2.6457513110645907}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 2}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2.6457513110645907}, "canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 139, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}}, "df": 48, "d": {"docs": {"canlpy": {"tf": 2.23606797749979}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.7416573867739413}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 126}, "y": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 11, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 1}}}}}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 6, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 3}}, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}}}}, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 3}}, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils": {"tf": 1}}, "df": 2}}}}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}}, "df": 6}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 7}}}}}}}, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}}, "df": 2}}}}, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 4}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 7}}}}}}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 83}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 3}}}}}}}, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 19}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1.7320508075688772}}, "df": 2}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}}, "c": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.7320508075688772}}, "df": 5}}}}}}, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}}, "df": 31, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 8, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}}, "df": 10}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}}}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}}}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 3, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}, "s": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 34, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2.6457513110645907}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 37}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 8}}}}}}}}}, "l": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1, "l": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 58, "o": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 5, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 9}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 4}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 13}}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 7}}}}}, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.7320508075688772}}, "df": 1}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 2}}}}, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}}}}}}}, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 8}}, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 4}}}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}}, "df": 4, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}}}}}}, "f": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}}}}}}, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 4, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}}}, "x": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}}, "df": 2}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}}}, "x": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}}, "df": 14, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"3": {"docs": {"canlpy": {"tf": 1}}, "df": 1}, "docs": {"canlpy": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 3}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 6}}}}}}, "i": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1, "p": {"docs": {"canlpy": {"tf": 1}}, "df": 1}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 7, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}}, "df": 1}}}}}}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 1, "d": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 7}}}}}, "b": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 10, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}}, "df": 6}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 10}}, "y": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5}}}}}}, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 12}}, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 5}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}}}}, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 10, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.3166247903554}}, "df": 11, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}}, "df": 1}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}}}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 2}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 2}}}}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 6, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 3}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 16}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 38, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 8}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 36, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 10}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}}, "df": 5}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 5}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 2}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 12}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.4142135623730951}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 3, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 8, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 3}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}}, "df": 5}, "d": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 8}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 9, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 10}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 29}}}}}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 1}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 2}}}}}}}}}}, "k": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}}, "df": 1}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}}, "df": 2}}}}}, "n": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}}, "df": 9}}}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 2}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 5}}}, "e": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}}, "df": 2, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 18}}, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 2}}, "df": 18, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 1}, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 3}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 2}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 2}}}, "f": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 2}}}}}}}}}}, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 1}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 5}}}}}}, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 33, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 16}, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}}, "df": 3}}}}}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 9}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 4, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 15}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 3, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 8}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}}, "df": 6}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}}}, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}}, "df": 1}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 29, "s": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 14}}, "o": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 2, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}}, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 14}, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.23606797749979}}, "df": 9}}}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1.4142135623730951}}, "df": 3, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 3, "g": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 41}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}}, "k": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}}, "df": 2}, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}}, "df": 4}, "r": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}, "f": {"1": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 2}, "docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}}, "df": 7, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.605551275463989}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 2}}, "df": 116, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 50, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}}, "df": 1}}}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 2}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 6}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 31}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1.4142135623730951}}, "df": 1, "/": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}}, "df": 1}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 2}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 31, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 4}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 7}}}, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 2}}, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}}, "df": 5, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}}, "df": 2}}, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 11}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}}}}, "x": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 41, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 8, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}}, "df": 1}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 7}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}}, "df": 6, "y": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"3": {"2": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1.7320508075688772}}, "df": 3, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 17}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2}}, "df": 2}}}}}}}}, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 7, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 4}}}, "s": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}}}}}, "b": {"1": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 1}, "2": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 1}, "docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 18, "u": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 12, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 7}, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11, "d": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 3, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 3}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.1622776601683795}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 42, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}}, "y": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 80}, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 71, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 3}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 28, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}}, "df": 1, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 9}}}}, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 4}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 4}}}}}, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 11, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 10}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 37}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}}, "df": 5}}}}}, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 18, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.23606797749979}}, "df": 23, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 7}}}}}}}, "g": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 4, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}}, "b": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}}, "df": 2}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 3}}}}}, "e": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}}, "df": 3, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 3}}, "p": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}}}}, "e": {"1": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}}, "df": 1}, "2": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}, "docs": {"canlpy": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 9, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}}, "df": 4}}}}}}, "t": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.8284271247461903}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 21, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 3.4641016151377544}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 3.1622776601683795}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 2}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.7320508075688772}}, "df": 49, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 41}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}, "s": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.4641016151377544}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 22}, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 4}}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 1}}}}}}}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 8, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 2}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 19, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}}, "df": 1}}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 1}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 11}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 3}}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 3, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 40, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 2}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.7320508075688772}}, "df": 45, "[": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 1}}}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 2}}}}}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 1}}}}}}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}}, "df": 1}}}}, "x": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 17, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 3}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}}}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 16, "s": {"docs": {"canlpy": {"tf": 1.4142135623730951}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}}, "df": 1}}, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 5}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1, "c": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 9}, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 3}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 31, "w": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 23}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 5}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 2}}}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}}, "df": 1}}}}}}}}, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 4}}}}, "d": {"docs": {"canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 3}}, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 3}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}}, "df": 11, "l": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 2.6457513110645907}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 53, "s": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 13, "/": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 4}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 95, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}}, "df": 7}}}}, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 21}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 4}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 2}, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 3, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3}}}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}, "y": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 4}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.7320508075688772}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.7320508075688772}}, "df": 32, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 12}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}}, "df": 2}}}}}, "p": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2}}, "df": 3, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 12}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3.1622776601683795}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 27, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 9}}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 2}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 6}}, "k": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 10}}, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 2}}}}}}}, "l": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.7320508075688772}}, "df": 2}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 5}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}}, "df": 2}}}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 8, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 1}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 2}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 4}}, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 2}}}}}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}}, "df": 4}}}, "x": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "r": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 1, "e": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 2, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 2}}}}}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 5}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 17, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 10}}}}}}, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 8}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 8}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}}, "df": 1}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 1, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 2}}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 3, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 1}}}}}}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 9}, "r": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}}, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}}, "df": 2, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 2}}}}, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 1}}}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}}, "df": 3}}}}}, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 17, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 76}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 4}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}}}}}, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 8}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 34}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1}}}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 12}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 1, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 1}}}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}}}}, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 2}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 3}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {"canlpy": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}}, "df": 16, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}}, "s": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}}, "df": 4}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 6}}, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 2}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 9}}, "e": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 1}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}}, "o": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 1}, "o": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 3, "t": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 4}, "u": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 2}}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 3}}}, "z": {"docs": {"canlpy": {"tf": 1.7320508075688772}}, "df": 1, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "h": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}}, "df": 3}}, "d": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}}}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 2}}}, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 1}}}, "l": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}}}, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 4}}, "p": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 2}, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 12}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}, "s": {"3": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 4}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 26, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1.4142135623730951}}, "df": 9, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy": {"tf": 1.4142135623730951}}, "df": 1}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 2, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.605551275463989}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 47, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"1": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 2.23606797749979}}, "df": 1}, "2": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.7320508075688772}}, "df": 1}, "docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.4641016151377544}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.6457513110645907}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2}}, "df": 26, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 16}}}}}}}, "l": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 11}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}}, "df": 21}}}}}}, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 18, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 5}}}}, "g": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}}, "df": 4, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 4}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 4}, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}}, "df": 1, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 7, ":": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 50, "s": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}}, "df": 16}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}, "d": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}}, "df": 1}}}}, "r": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}}, "df": 10, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 8}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 15, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 5}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 2}}}}}}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}}, "df": 3}, "y": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "v": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}}, "df": 1}}, "u": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}, "m": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 5}}, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}, "q": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.6457513110645907}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 3.1622776601683795}, "canlpy.core.models.bert.model.BertLayer": {"tf": 3}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.7416573867739413}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 54}}, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 3}}}}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}}, "df": 4}}}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}, "g": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 4}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}}}}}, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.8284271247461903}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 37}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 36}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 40}}}, "w": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1, "b": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}}, "df": 7}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}}, "df": 1}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}}}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5}}}}}}}, "m": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 6, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 4}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}}}}}}, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 36}}}}}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1.4142135623730951}}, "df": 9}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 1}}}}}}}, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 13, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 11, "[": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}}, "df": 1}}}, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer": {"tf": 1}}, "df": 2}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}}, "df": 3}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 5}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 2}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 4}}}}}}}}, "o": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 6, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 6, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 3}}}}}, "w": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 1, "k": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.23606797749979}}, "df": 2, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}}, "df": 1}}, "b": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 2}}}}}}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 2.23606797749979}}, "df": 1}}}}}}, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "y": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1}}}}}}, "h": {"5": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}, "w": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 2}}, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}}, "df": 8, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 13}}}, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 3}}}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}}, "df": 27}}}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 16}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 17, "h": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 4}}}}, "l": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}}}, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "u": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, ":": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2.449489742783178}}, "df": 2, "i": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}}, "df": 3}}}, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 3}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 7}}}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2}}}}}, "m": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 2}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 22, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}}, "df": 17, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1}}, "df": 8, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 11}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 6}}}}}}, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}}, "df": 3}}}}}}, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}}, "df": 1}}}}}}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "o": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 6, "w": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 5, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}}}}}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}}, "df": 1}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 5}}, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}}, "df": 12}}}}}}, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 5, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}}, "df": 3}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 3, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}}}, "e": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 1, "f": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}}, "df": 7, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 2.8284271247461903}}, "df": 17, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 28}, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}}}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 2}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 16}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}, "e": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.MentionGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}}, "df": 4, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}}, "df": 1}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}}, "df": 1}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2}}}, "v": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 2}}}}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}}}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}}}}}, "y": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 13}}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}}, "df": 2}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "q": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}}, "df": 8, "u": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 2}}}}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.get_ents": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 2}}, "df": 6}}}, "x": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 2}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 9, "v": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "f": {"docs": {"canlpy": {"tf": 1.7320508075688772}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "f": {"docs": {"canlpy": {"tf": 2.23606797749979}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 3}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 3.1622776601683795}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_input_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.get_output_dim": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 3.1622776601683795}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.6457513110645907}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.605551275463989}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 3.4641016151377544}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3.3166247903554}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.8284271247461903}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 2}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1.7320508075688772}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 148, "f": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 2}}}}}}, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.7320508075688772}}, "df": 35, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 2}}, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.prior_entity_candidates": {"tf": 1}}, "df": 13}}, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 33}, "t": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 25, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 3}}, "[": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}}, "df": 1}}}}}}}}}}, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}}}}}}}}}, "r": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 45, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 4, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 9, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 2}}}}}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 4, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 25, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1}}, "df": 14}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 4}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "r": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 3, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}}}}}}, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}}, "b": {"docs": {}, "df": 0, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}}, "df": 7}}}}}, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "v": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 3}}, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 1.4142135623730951}}, "df": 1}}}, "y": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {"canlpy": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 15, "r": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 10, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 4, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1.4142135623730951}}, "df": 10, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.get_ents": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_name_to_QID": {"tf": 1}}, "df": 3, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 6, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 3}}}}}}, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}}}, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}, "o": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 13, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 4, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 4, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.4142135623730951}}, "df": 1}}}}, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 2}}}}}}}, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 22, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}}}}, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 7, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 19}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 3.1622776601683795}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 2}}, "df": 30, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 25, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.batchify": {"tf": 1.4142135623730951}}, "df": 2}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}}, "df": 4}}}, "e": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 15}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}}, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 27}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 2}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 2}}}}}}}, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.1622776601683795}}, "df": 4}}, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}}}}, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttention.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanAttentionLayer.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 49}, "l": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}}, "df": 1}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 1}, "s": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}}, "df": 1}}}, "w": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.605551275463989}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 26}}, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 28}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.span_filter_func": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 24}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 21}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}}, "df": 4}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 2, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 12, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 2.23606797749979}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 2}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}}, "df": 13}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.forward": {"tf": 2.23606797749979}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_attention_layer.SpanWordAttention.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 57, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingWithCandidateMentions.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}}, "df": 28}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}}, "df": 1}}}}}, "k": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1.4142135623730951}}, "df": 3, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}}, "df": 1}}}}}}}, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.7320508075688772}}, "df": 1}}}}, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.1622776601683795}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 21, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 5, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 5}}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 2}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1.4142135623730951}, "canlpy.helpers.ernie_helpers.create_model_mapping_ERNIE": {"tf": 2}}, "df": 15}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}}, "df": 5}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.TokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.helpers.ernie_helpers.concatenate_tokens_entities": {"tf": 1}, "canlpy.helpers.ernie_helpers.get_entities_embeddings_and_mask": {"tf": 1}}, "df": 4}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 23, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.3166247903554}}, "df": 3}, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.PretokenizedTokenizerAndCandidateGenerator": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 9}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 3}}}}, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 1}}, "k": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1, "z": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy": {"tf": 1}}, "df": 1}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}}, "df": 1}}}}}}}}, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}}, "df": 1}}}}, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.unfreeze": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1.7320508075688772}}, "df": 2}}}}}}}, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}}, "df": 1}}}}}}}}}}, "s": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}}, "df": 1}}}}}}}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.truncate_sequence_pair": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 1}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}}}}}, "a": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.helpers.ernie_helpers.process_sentences": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 23, "d": {"docs": {"canlpy": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityLinkingBase": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization": {"tf": 1}}, "df": 30}, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.common.WhitespaceTokenizer": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 2}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 10}}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}}, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 6}}, "t": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}}, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}, "v": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 16, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.soldered_kg.EntityDisambiguator.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SelfAttentiveSpanExtractor": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.flatten_and_batch_shift_indices": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 3}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_QID_to_eid": {"tf": 1}, "canlpy.helpers.ernie_helpers.load_eid_to_vec": {"tf": 1}}, "df": 10, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2}}, "df": 12}}}}}, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 3}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.iter_batches": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}}, "df": 7}}}}, "y": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 14}}}}, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.DotAttentionWithPrior.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.SpanExtractor.forward": {"tf": 1}}, "df": 2}}, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.enumerate_spans": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.wiki_linking_util.WikiCandidateMentionGenerator.get_mentions_raw_text": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1.7320508075688772}}, "df": 5, "s": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.batched_index_select": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.common.get_empty_candidates": {"tf": 1}}, "df": 8}}}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 15, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG.from_config": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.convert_tokens_candidates_to_array": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier.get_wiki_batchifier": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.47213595499958}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 30}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}}, "u": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.tokenizer.KnowBertBatchifier": {"tf": 1}}, "df": 1}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.bert_tokenizer_and_candidate_generator.BertTokenizerAndCandidateGenerator.tokenize_and_generate_candidates": {"tf": 1}}, "df": 1}}, "j": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion.span_extractor.masked_softmax": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 8}}}, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 9}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}}, "pipeline": ["trimmer"], "_isPrebuiltIndex": true};

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();