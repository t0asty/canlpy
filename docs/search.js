window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = {"version": "0.9.5", "fields": ["qualname", "fullname", "annotation", "default_value", "signature", "bases", "doc"], "ref": "fullname", "documentStore": {"docs": {"canlpy": {"fullname": "canlpy", "modulename": "canlpy", "type": "module", "doc": "<p></p>\n"}, "canlpy.core": {"fullname": "canlpy.core", "modulename": "canlpy.core", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components": {"fullname": "canlpy.core.components", "modulename": "canlpy.core.components", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.activation_functions": {"fullname": "canlpy.core.components.activation_functions", "modulename": "canlpy.core.components.activation_functions", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.activation_functions.gelu": {"fullname": "canlpy.core.components.activation_functions.gelu", "modulename": "canlpy.core.components.activation_functions", "qualname": "gelu", "type": "function", "doc": "<p>Implementation of the gelu activation function.\nFor information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))</p>\n", "signature": "(x)", "funcdef": "def"}, "canlpy.core.components.activation_functions.get_activation_function": {"fullname": "canlpy.core.components.activation_functions.get_activation_function", "modulename": "canlpy.core.components.activation_functions", "qualname": "get_activation_function", "type": "function", "doc": "<p></p>\n", "signature": "(name: str)", "funcdef": "def"}, "canlpy.core.components.fusion": {"fullname": "canlpy.core.components.fusion", "modulename": "canlpy.core.components.fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.cokebert_fusion": {"fullname": "canlpy.core.components.fusion.cokebert_fusion", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"fullname": "canlpy.core.components.fusion.cokebert_fusion.DK_fusion", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "qualname": "DK_fusion", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "canlpy.core.components.fusion.fusion.Fusion"}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"fullname": "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "qualname": "DK_fusion.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, k_v_dim, layer_no)", "funcdef": "def"}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"fullname": "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward", "modulename": "canlpy.core.components.fusion.cokebert_fusion", "qualname": "DK_fusion.forward", "type": "function", "doc": "<p>Performs the information fusion between the token and entity emmbeddings</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>May contain:</strong> </li>\n<li><strong>token_embeddings:</strong>  the tokens embeddings</li>\n<li><strong>entity_embeddings:</strong>  the entity embeddings</li>\n<li>token/entity masks</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>token_embeddings: the enhanced embeddings of the tokens \n  entity embeddings(Optional): the enhanced embeddings of the entities</p>\n</blockquote>\n", "signature": "(self, q_i, k, v)", "funcdef": "def"}, "canlpy.core.components.fusion.ernie_fusion": {"fullname": "canlpy.core.components.fusion.ernie_fusion", "modulename": "canlpy.core.components.fusion.ernie_fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"fullname": "canlpy.core.components.fusion.ernie_fusion.ErnieFusion", "modulename": "canlpy.core.components.fusion.ernie_fusion", "qualname": "ErnieFusion", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "canlpy.core.components.fusion.fusion.Fusion"}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"fullname": "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__", "modulename": "canlpy.core.components.fusion.ernie_fusion", "qualname": "ErnieFusion.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    entity_size,\n    intermediate_size,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"fullname": "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward", "modulename": "canlpy.core.components.fusion.ernie_fusion", "qualname": "ErnieFusion.forward", "type": "function", "doc": "<p>Performs the information fusion between the token and entity emmbeddings</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>May contain:</strong> </li>\n<li><strong>token_embeddings:</strong>  the tokens embeddings</li>\n<li><strong>entity_embeddings:</strong>  the entity embeddings</li>\n<li>token/entity masks</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>token_embeddings: the enhanced embeddings of the tokens \n  entity embeddings(Optional): the enhanced embeddings of the entities</p>\n</blockquote>\n", "signature": "(self, attention_tokens, attention_ent)", "funcdef": "def"}, "canlpy.core.components.fusion.fusion": {"fullname": "canlpy.core.components.fusion.fusion", "modulename": "canlpy.core.components.fusion.fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.fusion.fusion.Fusion": {"fullname": "canlpy.core.components.fusion.fusion.Fusion", "modulename": "canlpy.core.components.fusion.fusion", "qualname": "Fusion", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"fullname": "canlpy.core.components.fusion.fusion.Fusion.__init__", "modulename": "canlpy.core.components.fusion.fusion", "qualname": "Fusion.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"fullname": "canlpy.core.components.fusion.fusion.Fusion.forward", "modulename": "canlpy.core.components.fusion.fusion", "qualname": "Fusion.forward", "type": "function", "doc": "<p>Performs the information fusion between the token and entity emmbeddings</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>May contain:</strong> </li>\n<li><strong>token_embeddings:</strong>  the tokens embeddings</li>\n<li><strong>entity_embeddings:</strong>  the entity embeddings</li>\n<li>token/entity masks</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>token_embeddings: the enhanced embeddings of the tokens \n  entity embeddings(Optional): the enhanced embeddings of the entities</p>\n</blockquote>\n", "signature": "(self, args)", "funcdef": "def"}, "canlpy.core.components.fusion.knowbert_fusion": {"fullname": "canlpy.core.components.fusion.knowbert_fusion", "modulename": "canlpy.core.components.fusion.knowbert_fusion", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.heads": {"fullname": "canlpy.core.components.heads", "modulename": "canlpy.core.components.heads", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.components.heads.BertLMPredictionHead": {"fullname": "canlpy.core.components.heads.BertLMPredictionHead", "modulename": "canlpy.core.components.heads", "qualname": "BertLMPredictionHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"fullname": "canlpy.core.components.heads.BertLMPredictionHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertLMPredictionHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, bert_model_embedding_weights)", "funcdef": "def"}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"fullname": "canlpy.core.components.heads.BertLMPredictionHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertLMPredictionHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyMLMHead": {"fullname": "canlpy.core.components.heads.BertOnlyMLMHead", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyMLMHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"fullname": "canlpy.core.components.heads.BertOnlyMLMHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyMLMHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, bert_model_embedding_weights)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"fullname": "canlpy.core.components.heads.BertOnlyMLMHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyMLMHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, sequence_output)", "funcdef": "def"}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"fullname": "canlpy.core.components.heads.BertPredictionHeadTransform", "modulename": "canlpy.core.components.heads", "qualname": "BertPredictionHeadTransform", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"fullname": "canlpy.core.components.heads.BertPredictionHeadTransform.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertPredictionHeadTransform.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"fullname": "canlpy.core.components.heads.BertPredictionHeadTransform.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertPredictionHeadTransform.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyNSPHead": {"fullname": "canlpy.core.components.heads.BertOnlyNSPHead", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyNSPHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"fullname": "canlpy.core.components.heads.BertOnlyNSPHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyNSPHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"fullname": "canlpy.core.components.heads.BertOnlyNSPHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "BertOnlyNSPHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, pooled_output)", "funcdef": "def"}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"fullname": "canlpy.core.components.heads.ErnieEntPredictionHead", "modulename": "canlpy.core.components.heads", "qualname": "ErnieEntPredictionHead", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"fullname": "canlpy.core.components.heads.ErnieEntPredictionHead.__init__", "modulename": "canlpy.core.components.heads", "qualname": "ErnieEntPredictionHead.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"fullname": "canlpy.core.components.heads.ErnieEntPredictionHead.forward", "modulename": "canlpy.core.components.heads", "qualname": "ErnieEntPredictionHead.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, candidate)", "funcdef": "def"}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"fullname": "canlpy.core.components.heads.ErniePreTrainingHeads", "modulename": "canlpy.core.components.heads", "qualname": "ErniePreTrainingHeads", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"fullname": "canlpy.core.components.heads.ErniePreTrainingHeads.__init__", "modulename": "canlpy.core.components.heads", "qualname": "ErniePreTrainingHeads.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, bert_model_embedding_weights)", "funcdef": "def"}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"fullname": "canlpy.core.components.heads.ErniePreTrainingHeads.forward", "modulename": "canlpy.core.components.heads", "qualname": "ErniePreTrainingHeads.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, sequence_output, pooled_output, candidate)", "funcdef": "def"}, "canlpy.core.models": {"fullname": "canlpy.core.models", "modulename": "canlpy.core.models", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.bert": {"fullname": "canlpy.core.models.bert", "modulename": "canlpy.core.models.bert", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.bert.model": {"fullname": "canlpy.core.models.bert.model", "modulename": "canlpy.core.models.bert.model", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.bert.model.MultiHeadAttention": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention", "type": "class", "doc": "<p>A multi-head attention layer</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the token embeddings.\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>context_layer: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size], the embeddings \n  after the attention.</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, hidden_size, num_attention_heads, attention_probs_dropout_prob)", "funcdef": "def"}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention.transpose_for_scores", "type": "function", "doc": "<p></p>\n", "signature": "(self, x)", "funcdef": "def"}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"fullname": "canlpy.core.models.bert.model.MultiHeadAttention.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "MultiHeadAttention.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, attention_mask)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertAttention": {"fullname": "canlpy.core.models.bert.model.BertAttention", "modulename": "canlpy.core.models.bert.model", "qualname": "BertAttention", "type": "class", "doc": "<p>A BERT attention layer</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the token embeddings.\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probability for the fully connected\n      layer.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings.</li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size] the produced embeddings.</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertAttention.__init__": {"fullname": "canlpy.core.models.bert.model.BertAttention.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertAttention.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    num_attention_heads,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob\n)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertAttention.forward": {"fullname": "canlpy.core.models.bert.model.BertAttention.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertAttention.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, attention_mask)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertEmbeddings": {"fullname": "canlpy.core.models.bert.model.BertEmbeddings", "modulename": "canlpy.core.models.bert.model", "qualname": "BertEmbeddings", "type": "class", "doc": "<p>Construct the BERT embeddings of the token_ids from word, position and token_type embeddings.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>vocab_size: the number of tokens in the vocabulary.\n  hidden_size: dimension of the token embeddings.\n  max_position_embeddings: the maximum sequence length that this model might ever be used with.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probability for the embeddings.\n  type_vocab_size: the vocabulary size of the <code>token_type_ids</code>.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ids:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary</li>\n<li><strong>token_type_ids:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>embeddings: a torch.FloatTensor of shape [batch_size, sequence_length,embedding_dimension], \n  the embedding corresponding to the provided ids.</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"fullname": "canlpy.core.models.bert.model.BertEmbeddings.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertEmbeddings.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    vocab_size,\n    hidden_size,\n    max_position_embeddings,\n    hidden_dropout_prob,\n    type_vocab_size\n)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"fullname": "canlpy.core.models.bert.model.BertEmbeddings.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertEmbeddings.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, input_ids, token_type_ids=None)", "funcdef": "def"}, "canlpy.core.models.bert.model.DenseSkipLayer": {"fullname": "canlpy.core.models.bert.model.DenseSkipLayer", "modulename": "canlpy.core.models.bert.model", "qualname": "DenseSkipLayer", "type": "class", "doc": "<p>Performs Linear + Dropout + SkipLayer + LayerNorm</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>input_size: the size of the input embeddings.\n  output_size: the size of the output embeddings.\n  dropout_prob: the dropout ratio.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>input_size</code>]\ncontaining the token embeddings</li>\n<li><strong>skip_tensor:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>output_size</code>] that is added\nto the tensor after the dense layer</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,<code>output_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"fullname": "canlpy.core.models.bert.model.DenseSkipLayer.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "DenseSkipLayer.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, input_size, output_size, dropout_prob)", "funcdef": "def"}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"fullname": "canlpy.core.models.bert.model.DenseSkipLayer.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "DenseSkipLayer.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, skip_tensor)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertLayer": {"fullname": "canlpy.core.models.bert.model.BertLayer", "modulename": "canlpy.core.models.bert.model", "qualname": "BertLayer", "type": "class", "doc": "<p>Correspond to a standard encoder BERT layer</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: Size of the encoder layers and the pooler layer.\n  intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n      layer in the Transformer encoder.\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probabilitiy for all fully connected\n      layers.\n  activation_fn: The non-linear activation function (function or string). \n      If string, \"gelu\", \"relu\" and \"swish\" are supported.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>input_size</code>]\ncontaining the token embeddings</li>\n<li><strong>attention_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,<code>hidden_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertLayer.__init__": {"fullname": "canlpy.core.models.bert.model.BertLayer.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertLayer.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    intermediate_size,\n    num_attention_heads,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertLayer.forward": {"fullname": "canlpy.core.models.bert.model.BertLayer.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertLayer.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states, attention_mask)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertPooler": {"fullname": "canlpy.core.models.bert.model.BertPooler", "modulename": "canlpy.core.models.bert.model", "qualname": "BertPooler", "type": "class", "doc": "<p>Does the classification of the CLS token (first token)</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the CLS token</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,<code>hidden_size</code>]\ncontaining the token embeddings</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>pooled_output: a torch.FloatTensor of shape [batch_size,<code>hidden_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.BertPooler.__init__": {"fullname": "canlpy.core.models.bert.model.BertPooler.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "BertPooler.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, hidden_size)", "funcdef": "def"}, "canlpy.core.models.bert.model.BertPooler.forward": {"fullname": "canlpy.core.models.bert.model.BertPooler.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "BertPooler.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, hidden_states)", "funcdef": "def"}, "canlpy.core.models.bert.model.LayerNorm": {"fullname": "canlpy.core.models.bert.model.LayerNorm", "modulename": "canlpy.core.models.bert.model", "qualname": "LayerNorm", "type": "class", "doc": "<p>Performs a layer nornlizationon the tensor</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: dimension of the token embeddings.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>x:</strong>  a torch.FloatTensor to perform layer norm on.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>res: the normalized tensor.</p>\n</blockquote>\n\n<h6 id=\"returns-2\">Returns</h6>\n\n<blockquote>\n  <p>pooled_output: a torch.FloatTensor of shape [batch_size,<code>hidden_size</code>]</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"fullname": "canlpy.core.models.bert.model.LayerNorm.__init__", "modulename": "canlpy.core.models.bert.model", "qualname": "LayerNorm.__init__", "type": "function", "doc": "<p>Construct a layernorm module in the TF style (epsilon inside the square root).</p>\n", "signature": "(self, hidden_size, eps=1e-12)", "funcdef": "def"}, "canlpy.core.models.bert.model.LayerNorm.forward": {"fullname": "canlpy.core.models.bert.model.LayerNorm.forward", "modulename": "canlpy.core.models.bert.model", "qualname": "LayerNorm.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(self, x)", "funcdef": "def"}, "canlpy.core.models.bert.model.init_weights": {"fullname": "canlpy.core.models.bert.model.init_weights", "modulename": "canlpy.core.models.bert.model", "qualname": "init_weights", "type": "function", "doc": "<p>Recursively initialize all weights </p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>module:</strong>  the nn.Module to recursively initialize.</li>\n<li><strong>initializer_range:</strong>  the std_dev of the normal initializer for\ninitializing all weight matrices.</li>\n</ul>\n", "signature": "(module, initializer_range)", "funcdef": "def"}, "canlpy.core.models.cokebert": {"fullname": "canlpy.core.models.cokebert", "modulename": "canlpy.core.models.cokebert", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.cokebert.model": {"fullname": "canlpy.core.models.cokebert.model", "modulename": "canlpy.core.models.cokebert.model", "type": "module", "doc": "<p>Re-Implementation of the CokeBert Model (Su et al., 2020)</p>\n\n<p>This module contains several versions of CokeBert for different \nfine-tune tasks.</p>\n"}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"fullname": "canlpy.core.models.cokebert.model.CONFIG_NAME", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CONFIG_NAME", "type": "variable", "doc": "<p>str: name of the config file in the checkpoint</p>\n", "default_value": " = 'cokebert_config.json'"}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"fullname": "canlpy.core.models.cokebert.model.WEIGHTS_NAME", "modulename": "canlpy.core.models.cokebert.model", "qualname": "WEIGHTS_NAME", "type": "variable", "doc": "<p>str: name of the file containing weights in the checkpoint</p>\n", "default_value": " = 'pytorch_model.bin'"}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"fullname": "canlpy.core.models.cokebert.model.MAPPING_FILE", "modulename": "canlpy.core.models.cokebert.model", "qualname": "MAPPING_FILE", "type": "variable", "doc": "<p>str: name of the file containing the mapping in the checkpoint</p>\n", "default_value": " = 'mapping.json'"}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig", "type": "class", "doc": "<p>Configuration class to store the configuration of a <code>CokeBertModel</code>.</p>\n"}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.__init__", "type": "function", "doc": "<p>Constructs CokeBertConfig.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>vocab_size (int):</strong>  Vocabulary size of <code>inputs_ids</code> in <code>CokeBertModel</code>.</li>\n<li><strong>hidden_size (int):</strong>  Size of the encoder layers and the pooler layer.</li>\n<li><strong>num_hidden_layers (int):</strong>  Number of hidden layers in the Transformer encoder.</li>\n<li><strong>num_attention_heads (int):</strong>  Number of attention heads for each attention layer in\nthe Transformer encoder.</li>\n<li><strong>intermediate_size (int):</strong>  The size of the \"intermediate\" (i.e., feed-forward)\nlayer in the Transformer encoder.</li>\n<li><strong>hidden_act:</strong>  The non-linear activation function (function or string) in the\nencoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</li>\n<li><strong>hidden_dropout_prob (int):</strong>  The dropout probabilitiy for all fully connected\nlayers in the embeddings, encoder, and pooler.</li>\n<li><strong>attention_probs_dropout_prob (float):</strong>  The dropout ratio for the attention\nprobabilities.</li>\n<li><strong>max_position_embeddings (int):</strong>  The maximum sequence length that this model might\never be used with. Typically set this to something large just in case\n(e.g., 512 or 1024 or 2048).</li>\n<li><strong>type_vocab_size (int):</strong>  The vocabulary size of the <code>token_type_ids</code> passed into\n<code>CokeBertModel</code>.</li>\n<li><strong>initializer_range (float):</strong>  The sttdev of the truncated_normal_initializer for\ninitializing all weight matrices.</li>\n<li><strong>layer_types (list):</strong>  list of <code>ErnieLayer</code>s which can be 'sim' (Bert encoder), \n'mix' (Ernie encoder but no multihead attention for entites) or 'norm' (standard Ernie encoder)</li>\n<li><strong>k_v_dim (int):</strong>  Size of the hidden knowledge representation in the dynamic knowledge encoder</li>\n<li><strong>q_dim (int):</strong>  Size of the hidden text representation in the dynamic knowledge encoder</li>\n<li><strong>dk_layers (int):</strong>  Number of layers in the dynamic knowledge encoder</li>\n</ul>\n", "signature": "(\n    self,\n    vocab_size,\n    hidden_size=768,\n    entity_size=200,\n    num_hidden_layers=12,\n    num_attention_heads=12,\n    num_attention_heads_ent=4,\n    intermediate_size=3072,\n    hidden_act='gelu',\n    hidden_dropout_prob=0.1,\n    attention_probs_dropout_prob=0.1,\n    max_position_embeddings=512,\n    type_vocab_size=2,\n    initializer_range=0.02,\n    layer_types=[],\n    k_v_dim=100,\n    q_dim=768,\n    dk_layers=2\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.load_from_json", "type": "function", "doc": "<p>Loads config from json file</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>cls:</strong>  current CokeBertConfig Class</li>\n<li><strong>path (str):</strong>  path to config.json file</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>config: Loaded CokeBertConfig</p>\n</blockquote>\n", "signature": "(cls, path)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_json_string", "type": "function", "doc": "<p>Serializes this instance to a JSON string.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>JSON-String of Config</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_dict", "type": "function", "doc": "<p>Serializes this instance to a Python dictionary.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>output: Python dictionary of Config</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_text_encoder_config", "type": "function", "doc": "<p>Splits Config to create <code>ErnieEncoder</code> as TextEncoder</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>CokeBertConfig for TextEncoder</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"fullname": "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertConfig.to_knowl_encoder_config", "type": "function", "doc": "<p>Splits Config to create <code>ErnieEncoder</code> as KnowledgeEncoder</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>CokeBertConfig for KnowledgeEncoder</p>\n</blockquote>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel", "type": "class", "doc": "<p>An abstract class to handle weights initialization and\na simple interface for downloading and loading pretrained models.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, config, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel.init_weights", "type": "function", "doc": "<p>Initialize the weights.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>module:</strong>  one of <code>nn.Linear</code>, <code>nn.Embedding</code>, <code>LayerNorm</code>, module to initialize weights of</li>\n</ul>\n", "signature": "(self, module)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"fullname": "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained", "modulename": "canlpy.core.models.cokebert.model", "qualname": "PreTrainedCokeBertModel.from_pretrained", "type": "function", "doc": "<p>Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.\nDownload and cache the pre-trained model file if needed.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><p><strong>dir_path (str):</strong>  a path or url to a pretrained model archive containing:</p>\n\n<p>. <code>bert_config.json</code> a configuration file for the model</p>\n\n<p>. <code>pytorch_model.bin</code> a PyTorch dump of a BertForPreTraining instance</p></li>\n<li><strong>state_dict:</strong>  an optional state dictionary (collections.OrderedDict object) to use instead of Google pre-trained models</li>\n<li><strong>cache_dir:</strong>  an optional path to a folder in which the pre-trained models will be cached.</li>\n<li><strong><em>inputs, *</em>kwargs:</strong>  additional input for the specific Bert class\n(ex: num_labels for BertForSequenceClassification)</li>\n</ul>\n", "signature": "(cls, dir_path, state_dict=None, cache_dir=None, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertModel": {"fullname": "canlpy.core.models.cokebert.model.CokeBertModel", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertModel", "type": "class", "doc": "<p>A class to handle the Transformer Model (without fine-tuning head)</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertModel.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertModel.__init__", "type": "function", "doc": "<p>Constructs a CokeBertModel</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>config (<code>CokeBertConfig</code>):</strong>  The config that sets the model's hyperparameters</li>\n</ul>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertModel.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertModel.forward", "type": "function", "doc": "<p>Forward pass through the <code>CokeBertModel</code></p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ids:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong>token_type_ids:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong>attention_mask:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong>output_all_encoded_layers:</strong>  boolean which controls the content of the <code>encoded_layers</code> output as described below. Default: <code>True</code>.</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>sequence_output, pooled_output</p>\n  \n  <p>sequence_output: the full sequence of hidden-states corresponding\n          to the last attention block of shape [batch_size, sequence_length, hidden_size] <br />\n  pooled_output: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n      classifier pretrained on top of the hidden state associated to the first character of the\n      input (<code>CLS</code>) to train on the Next-Sentence task (see BERT's paper).</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    output_all_encoded_layers=True,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder", "type": "class", "doc": "<p>A class for the Dynamic Knowledge Encoder for a <code>CokeBertModel</code>.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder.__init__", "type": "function", "doc": "<p>Constructs a Dynamic KnowledgeEncoder</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>\n<li><strong>no_layers (int):</strong>  Number of layers in the Dynamic Knowledge Encoder</li>\n</ul>\n", "signature": "(self, k_v_dim, q_dim, no_layers)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder.forward", "type": "function", "doc": "<p>Forward pass through the Dynamic Knowledge Encoder</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong>q:</strong>  the full sequence of hidden-states corresponding\nto the last text-attention block of shape [batch_size, sequence_length, hidden_size] </li>\n<li><strong>k_v_s:</strong>  list of (k, v) tuples of length <code>no_layers</code>, \nk, v are of shape [batch_size, sequence_length, k_v_dim]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states_ent: internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</p>\n</blockquote>\n", "signature": "(self, input_ent, q, k_v_s)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder_layer", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder_layer", "type": "class", "doc": "<p>A class for one Dynamic Knowledge Encoder Layer for a <code>DKEncoder</code> from CokeBert.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder_layer.__init__", "type": "function", "doc": "<p>Constructs a <code>DKEncoder_layer</code>.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>\n<li><strong>layer_no (int):</strong>  Number of the layer (assigned in reverse order)</li>\n</ul>\n", "signature": "(self, k_v_dim, q_dim, layer_no)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"fullname": "canlpy.core.models.cokebert.model.DKEncoder_layer.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DKEncoder_layer.forward", "type": "function", "doc": "<p>Forward pass through the Dynamic Knowledge Encoder layer</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>input_ent:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong>q:</strong>  the representation of hidden-states corresponding\nto the last text-attention block of shape [batch_size, 1, q_dim] </li>\n<li><strong>k:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n<li><strong>v:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>internal entity representations: torch.Tensor of shape [batch_size, sequence_length, entity_size]</p>\n</blockquote>\n", "signature": "(self, q, k, v)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_text": {"fullname": "canlpy.core.models.cokebert.model.DK_text", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_text", "type": "class", "doc": "<p>A class for the Text Processing in a <code>DKEncoderLayer</code> from CokeBert.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"fullname": "canlpy.core.models.cokebert.model.DK_text.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_text.__init__", "type": "function", "doc": "<p>Constructs a <code>DK_text</code> module</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n<li><strong>q_dim (int):</strong>  size of the q vector (Internal Text Representation)</li>\n<li><strong>layer_no (int):</strong>  Number of the layer (assigned in reverse order)</li>\n</ul>\n", "signature": "(self, k_v_dim, q_dim, layer_no)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_text.forward": {"fullname": "canlpy.core.models.cokebert.model.DK_text.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_text.forward", "type": "function", "doc": "<p>Forward pass through the Text Processing Module of a Dynamic Knowledge Encoder layer</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>q:</strong>  the full sequence of hidden-states corresponding\nto the last text-attention block of shape [batch_size, sequence_length, hidden_size] </li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>q_i: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</p>\n</blockquote>\n", "signature": "(self, q)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_knowledge": {"fullname": "canlpy.core.models.cokebert.model.DK_knowledge", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_knowledge", "type": "class", "doc": "<p>A class for the Knowledge Processing in a <code>DKEncoderLayer</code> from CokeBert.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"fullname": "canlpy.core.models.cokebert.model.DK_knowledge.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_knowledge.__init__", "type": "function", "doc": "<p>Constructs a <code>DK_knowledge</code> module</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k_v_dim (int):</strong>  size of the k and v vectors (internal Knowledge representation)</li>\n</ul>\n", "signature": "(self, k_v_dim)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"fullname": "canlpy.core.models.cokebert.model.DK_knowledge.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "DK_knowledge.forward", "type": "function", "doc": "<p>Forward pass through the Knowledge Processing Module of a Dynamic Knowledge Encoder layer</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>k:</strong>  torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden knowledge representation: torch.Tensor of shape [batch_size, sequence_length, k_v_dim]</p>\n</blockquote>\n", "signature": "(self, k)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForSequenceClassification", "type": "class", "doc": "<p>CokeBert model for sequence classification. <br />\nThis module is composed of the CokeBert model with a linear layer on top of\nthe pooled output.</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForSequenceClassification.__init__", "type": "function", "doc": "<p>Constructs a <code>CokeBertForSequenceClassification</code> model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>\n<li><strong><code>num_labels</code>:</strong>  the number of classes for the classifier. Default = 2.</li>\n</ul>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForSequenceClassification.forward", "type": "function", "doc": "<p>Performs a Forward Pass through the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>: <br />\n      Outputs the CrossEntropy classification loss of the output with the labels. <br />\n  if <code>labels</code> is <code>None</code>: <br />\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids=None,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForEntityTyping", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForEntityTyping", "type": "class", "doc": "<p>CokeBert model for classification. <br />\nThis module is composed of the CokeBert model with a linear layer on top of\nthe pooled output.</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForEntityTyping.__init__", "type": "function", "doc": "<p>Constructs a <code>CokeBertForEntityTyping</code> model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>\n<li><strong><code>num_labels</code>:</strong>  the number of classes for the classifier. Default = 2.</li>\n</ul>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForEntityTyping.forward", "type": "function", "doc": "<p>Performs a Forward Pass through the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>: <br />\n      Outputs the CrossEntropy classification loss of the output with the labels. <br />\n  if <code>labels</code> is <code>None</code>: <br />\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids=None,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForMaskedLM", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForMaskedLM", "type": "class", "doc": "<p>CokeBert model for masked pre-training task. <br />\nThis module is composed of the CokeBert model with a linear layer on top of\nthe sequence output.</p>\n", "bases": "PreTrainedCokeBertModel"}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForMaskedLM.__init__", "type": "function", "doc": "<p>Constructs a <code>CokeBertForMaskedLM</code> model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>config</code>:</strong>  a CokeBertConfig class instance with the configuration to build a new model.</li>\n</ul>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"fullname": "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward", "modulename": "canlpy.core.models.cokebert.model", "qualname": "CokeBertForMaskedLM.forward", "type": "function", "doc": "<p>Performs a Forward Pass through the model</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n<li><strong>k_v_s:</strong>  list of (k_i, v_i) vectors as input for the dynamic knowledge encoder</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>masked_lm_labels</code> is not <code>None</code>: <br />\n      Outputs the CrossEntropy classification loss of the output with the labels. <br />\n  if <code>masked_lm_labels</code> is <code>None</code>: <br />\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "signature": "(\n    self,\n    input_ids,\n    input_ents,\n    ent_mask=None,\n    token_type_ids=None,\n    attention_mask=None,\n    masked_lm_labels=None,\n    k_v_s=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie": {"fullname": "canlpy.core.models.ernie", "modulename": "canlpy.core.models.ernie", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.ernie.components": {"fullname": "canlpy.core.models.ernie.components", "modulename": "canlpy.core.models.ernie.components", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.ernie.components.ErnieLayer": {"fullname": "canlpy.core.models.ernie.components.ErnieLayer", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayer", "type": "class", "doc": "<p>An Ernie Layer, takes as input tokens/entity embeddings and masks and outputs tokens/entity embeddings</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: Size of the encoder layers and the pooler layer.\n  entity_size: Size of the entity embeddings,\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  num_attention_heads_ent: Number of attention heads for each attention layer in\n      the Transformer encoder for the entities.\n  intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n      layer in the Transformer encoder.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probabilitiy for all fully connected\n      layers in the embeddings, encoder, and pooler.\n  activation_fn: The non-linear activation function (function or string) in the\n      encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>hidden_states_ent:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the entity embeddings </li>\n<li><strong>attention_mask_ent:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1] used to indicate which position correspond to entities or not</li>\n</ul>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"fullname": "canlpy.core.models.ernie.components.ErnieLayer.__init__", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayer.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    entity_size,\n    intermediate_size,\n    num_attention_heads,\n    num_attention_heads_ent,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"fullname": "canlpy.core.models.ernie.components.ErnieLayer.forward", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayer.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    hidden_states,\n    attention_mask,\n    hidden_states_ent,\n    attention_mask_ent,\n    ent_mask\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"fullname": "canlpy.core.models.ernie.components.ErnieLayerMix", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayerMix", "type": "class", "doc": "<p>An Ernie Layer, takes as input tokens/entity embeddings and masks and outputs tokens/entity embeddings. \nDiffers from ErnieLayer by not applying any multi-head attention and dense layer on the entities before fusion.  </p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>hidden_size: Size of the encoder layers and the pooler layer.\n  entity_size: Size of the entity embeddings,\n  num_attention_heads: Number of attention heads for each attention layer in\n      the Transformer encoder for the tokens.\n  num_attention_heads_ent: Number of attention heads for each attention layer in\n      the Transformer encoder for the entities.\n  intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n      layer in the Transformer encoder.\n  attention_probs_dropout_prob: The dropout ratio for the attention\n      probabilities.\n  hidden_dropout_prob: The dropout probabilitiy for all fully connected\n      layers in the embeddings, encoder, and pooler.\n  activation_fn: The non-linear activation function (function or string) in the\n      encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>hidden_states_ent:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the entity embeddings </li>\n<li><strong>attention_mask_ent:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1] used to indicate which position correspond to entities or not</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>hidden_states: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\n      containing the new tokens embeddings \n  hidden_states_ent: a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\n      containing the new entity embeddings</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"fullname": "canlpy.core.models.ernie.components.ErnieLayerMix.__init__", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayerMix.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(\n    self,\n    hidden_size,\n    entity_size,\n    intermediate_size,\n    num_attention_heads,\n    attention_probs_dropout_prob,\n    hidden_dropout_prob,\n    activation_fn\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"fullname": "canlpy.core.models.ernie.components.ErnieLayerMix.forward", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieLayerMix.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    hidden_states,\n    attention_mask,\n    hidden_states_ent,\n    attention_mask_ent,\n    ent_mask\n)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieEncoder": {"fullname": "canlpy.core.models.ernie.components.ErnieEncoder", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieEncoder", "type": "class", "doc": "<p>An ErnieEncoder takes as input tokens/entity embeddings and masks and outputs tokens/entity embeddings</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<blockquote>\n  <p>config: an <code>ErnieConfig</code> file</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>hidden_states:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the tokens embeddings </li>\n<li><strong>attention_mask:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>hidden_states_ent:</strong>  a torch.FloatTensor of shape [batch_size, sequence_length,tokens_embedding_size]\ncontaining the entity embeddings </li>\n<li><strong>attention_mask_ent:</strong>  torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1].</li>\n<li><strong>ent_mask:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1] used to indicate which position correspond to entities or not</li>\n<li><strong>output_all_encoded_layers:</strong>  whether to output all encoder layers or not</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if output_all_encoded_layers:\n      the tokens embeddings at each layer\n  if not output_all_encoded_layers\n      the tokens embeddings at the last layer</p>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"fullname": "canlpy.core.models.ernie.components.ErnieEncoder.__init__", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieEncoder.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"fullname": "canlpy.core.models.ernie.components.ErnieEncoder.forward", "modulename": "canlpy.core.models.ernie.components", "qualname": "ErnieEncoder.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    hidden_states,\n    attention_mask,\n    hidden_states_ent,\n    attention_mask_ent,\n    ent_mask,\n    output_all_encoded_layers=True\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model": {"fullname": "canlpy.core.models.ernie.model", "modulename": "canlpy.core.models.ernie.model", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.ernie.model.ErnieConfig": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig", "type": "class", "doc": "<p>Configuration class to store the configuration of an <code>ErnieModel</code>.</p>\n"}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.__init__", "type": "function", "doc": "<p>Constructs ErnieConfig.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>vocab_size:</strong>  Vocabulary size of <code>inputs_ids</code> in <code>ErnieModel</code>.</li>\n<li><strong>hidden_size:</strong>  Size of the encoder layers and the pooler layer.</li>\n<li><strong>entity_size:</strong>  Size of the entity embeddings,</li>\n<li><strong>num_hidden_layers:</strong>  Number of hidden layers in the Transformer encoder.</li>\n<li><strong>num_attention_heads:</strong>  Number of attention heads for each attention layer in\nthe Transformer encoder for the tokens.</li>\n<li><strong>num_attention_heads_ent:</strong>  Number of attention heads for each attention layer in\nthe Transformer encoder for the entities.</li>\n<li><strong>intermediate_size:</strong>  The size of the \"intermediate\" (i.e., feed-forward)\nlayer in the Transformer encoder.</li>\n<li><strong>hidden_act:</strong>  The non-linear activation function (function or string) in the\nencoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.</li>\n<li><strong>hidden_dropout_prob:</strong>  The dropout probabilitiy for all fully connected\nlayers in the embeddings, encoder, and pooler.</li>\n<li><strong>attention_probs_dropout_prob:</strong>  The dropout ratio for the attention\nprobabilities.</li>\n<li><strong>max_position_embeddings:</strong>  The maximum sequence length that this model might\never be used with. Typically set this to something large just in case\n(e.g., 512 or 1024 or 2048).</li>\n<li><strong>type_vocab_size:</strong>  The vocabulary size of the <code>token_type_ids</code> passed into\n<code>ErnieModel</code>.</li>\n<li><strong>initializer_range:</strong>  The sttdev of the truncated_normal_initializer for\ninitializing all weight matrices.</li>\n<li><strong>layer_types:</strong>  list() of ErnieEncoders which can be 'sim' (Bert encoder), </li>\n<li>'mix' (Ernie encoder but no multihead attention for entities) or 'norm' (standard Ernie encoder)</li>\n</ul>\n", "signature": "(\n    self,\n    vocab_size,\n    hidden_size=768,\n    entity_size=100,\n    num_hidden_layers=12,\n    num_attention_heads=12,\n    num_attention_heads_ent=4,\n    intermediate_size=3072,\n    hidden_act='gelu',\n    hidden_dropout_prob=0.1,\n    attention_probs_dropout_prob=0.1,\n    max_position_embeddings=512,\n    type_vocab_size=2,\n    initializer_range=0.02,\n    layer_types=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.load_from_json", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.load_from_json", "type": "function", "doc": "<p>Loads and returns a config class from a json file located at path</p>\n", "signature": "(cls, path)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.to_json_string", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.to_json_string", "type": "function", "doc": "<p>Serializes this instance to a JSON string.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"fullname": "canlpy.core.models.ernie.model.ErnieConfig.to_dict", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieConfig.to_dict", "type": "function", "doc": "<p>Serializes this instance to a Python dictionary.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel", "type": "class", "doc": "<p>An abstract class to handle weights initialization and\n    a simple interface for downloading and loading pretrained models.</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel.init_weights", "type": "function", "doc": "<p>Initialize the weights.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"fullname": "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained", "modulename": "canlpy.core.models.ernie.model", "qualname": "PreTrainedErnieModel.from_pretrained", "type": "function", "doc": "<p>Instantiate a PreTrainedErnieModel from a pre-trained model file or a pytorch state dict.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>dir_path:</strong>  - a path to a pretrained model archive containing:\n   . <code>ernie_config.json</code>: a configuration file for the model\n   . <code>pytorch_model.bin</code>: a PyTorch dump of a ErnieForPreTraining instance\n   .  <code>mapping.json</code>: an Optional file to remap the weights from the pre-trained weights to this implementation </li>\n<li><strong>state_dict:</strong>  an optional state dictionnary (collections.OrderedDict object) to use instead of the PyTorch dump</li>\n<li><strong><em>inputs, *</em>kwargs:</strong>  additional input for the specific Ernie class\n(ex: num_labels for ErnieForSequenceClassification)</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>The loaded pretrained model</p>\n</blockquote>\n", "signature": "(cls, dir_path, state_dict=None, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieModel": {"fullname": "canlpy.core.models.ernie.model.ErnieModel", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieModel", "type": "class", "doc": "<p>Ernie model</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: an ErnieConfig class instance with the configuration to build a new model</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>output_all_encoded_layers</code>:</strong>  boolean which controls the content of the <code>encoded_layers</code> output as described below. Default: <code>True</code>.</li>\n</ul>\n\n<p>Returns: Tuple of (encoded_layers, pooled_output)\n    <code>encoded_layers</code>: controled by <code>output_all_encoded_layers</code> argument:\n        - <code>output_all_encoded_layers=True</code>: outputs a list of the full sequences of encoded-hidden-states at the end\n            of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n            encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n        - <code>output_all_encoded_layers=False</code>: outputs only the full sequence of hidden-states corresponding\n            to the last attention block of shape [batch_size, sequence_length, hidden_size],\n    <code>pooled_output</code>: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n         classifier pretrained on top of the hidden state associated to the first character of the\n         input (<code>CLS</code>) to train on the Next-Sentence task (see BERT's paper).</p>\n\n<p>Example usage:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"c1\"># Already been converted into WordPiece token ids</span>\n<span class=\"n\">input_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"mi\">51</span><span class=\"p\">,</span> <span class=\"mi\">99</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_mask</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">token_type_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_ent</span><span class=\"p\">:</span> <span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n<span class=\"n\">ent_mask</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">modeling</span><span class=\"o\">.</span><span class=\"n\">ErnieConfig</span><span class=\"p\">(</span><span class=\"n\">vocab_size_or_config_json_file</span><span class=\"o\">=</span><span class=\"mi\">32000</span><span class=\"p\">,</span> <span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">768</span><span class=\"p\">,</span>\n    <span class=\"n\">num_hidden_layers</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"mi\">3072</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">modeling</span><span class=\"o\">.</span><span class=\"n\">ErnieModel</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"o\">=</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">all_encoder_layers</span><span class=\"p\">,</span> <span class=\"n\">pooled_output</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">token_type_ids</span><span class=\"p\">,</span> <span class=\"n\">input_mask</span><span class=\"p\">,</span> <span class=\"n\">input_ent</span><span class=\"p\">,</span> <span class=\"n\">ent_mask</span><span class=\"p\">)</span>\n</code></pre></div>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieModel.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieModel.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieModel.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieModel.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    output_all_encoded_layers=True\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"fullname": "canlpy.core.models.ernie.model.ErnieForMaskedLM", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForMaskedLM", "type": "class", "doc": "<p>Ernie model with the masked language modeling head.</p>\n\n<p>This module comprises the Ernie model followed by the masked language modeling head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>masked_lm_labels</code>:</strong>  masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]\nwith indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss\nis only computed for the labels set in [0, ..., vocab_size]</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>masked_lm_labels</code> is <code>None</code>:\n      Outputs the masked language modeling loss.\n  if <code>masked_lm_labels</code> is <code>None</code>:\n      Outputs the masked language modeling logits of shape [batch_size, sequence_length, vocab_size].</p>\n</blockquote>\n\n<p>Example usage:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"c1\"># Already been converted into WordPiece token ids</span>\n<span class=\"n\">input_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"mi\">51</span><span class=\"p\">,</span> <span class=\"mi\">99</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_mask</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">token_type_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_ent</span><span class=\"p\">:</span> <span class=\"n\">shape</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">100</span><span class=\"p\">)</span>\n<span class=\"n\">ent_mask</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">ErnieConfig</span><span class=\"p\">(</span><span class=\"n\">vocab_size_or_config_json_file</span><span class=\"o\">=</span><span class=\"mi\">32000</span><span class=\"p\">,</span> <span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">768</span><span class=\"p\">,</span>\n    <span class=\"n\">num_hidden_layers</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"mi\">3072</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ErnieForMaskedLM</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">masked_lm_logits_scores</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">token_type_ids</span><span class=\"p\">,</span> <span class=\"n\">input_mask</span><span class=\"p\">,</span><span class=\"n\">input_ent</span><span class=\"p\">,</span><span class=\"n\">ent_mask</span><span class=\"p\">)</span>\n</code></pre></div>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForMaskedLM.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForMaskedLM.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    input_ents,\n    ent_mask=None,\n    token_type_ids=None,\n    attention_mask=None,\n    masked_lm_labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"fullname": "canlpy.core.models.ernie.model.ErnieForPreTraining", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForPreTraining", "type": "class", "doc": "<p>Ernie model with pre-training heads.\nThis module comprises the Ernie model followed by the two pre-training heads:\n    - the masked language modeling head, and\n    - the next sentence classification head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: an ErnieConfig class instance with the configuration to build a new model.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>masked_lm_labels</code>:</strong>  masked language modeling labels: torch.LongTensor of shape [batch_size, sequence_length]\nwith indices selected in [-1, 0, ..., vocab_size]. All labels set to -1 are ignored (masked), the loss\nis only computed for the labels set in [0, ..., vocab_size]</li>\n<li><strong><code>next_sentence_label</code>:</strong>  next sentence classification loss: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, 1].\n0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>masked_lm_labels</code> and <code>next_sentence_label</code> are not <code>None</code>:\n      Outputs the total_loss which is the sum of the masked language modeling loss and the next\n      sentence classification loss.\n  if <code>masked_lm_labels</code> or <code>next_sentence_label</code> is <code>None</code>:\n      Outputs a tuple comprising\n      - the masked language modeling logits of shape [batch_size, sequence_length, vocab_size], and\n      - the next sentence classification logits of shape [batch_size, 2].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForPreTraining.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForPreTraining.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForPreTraining.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    masked_lm_labels=None,\n    input_ent=None,\n    ent_mask=None,\n    next_sentence_label=None,\n    candidate=None,\n    ent_labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"fullname": "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNextSentencePrediction", "type": "class", "doc": "<p>Ernie model with next sentence prediction head.\nThis module comprises the Ernie model followed by the next sentence classification head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>next_sentence_label</code>:</strong>  next sentence classification loss: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, 1].\n0 =&gt; next sentence is the continuation, 1 =&gt; next sentence is a random sentence.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>next_sentence_label</code> is not <code>None</code>:\n      Outputs the total_loss which is the sum of the masked language modeling loss and the next\n      sentence classification loss.\n  if <code>next_sentence_label</code> is <code>None</code>:\n      Outputs the next sentence classification logits of shape [batch_size, 2].</p>\n</blockquote>\n\n<p>Example usage:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"c1\"># Already been converted into WordPiece token ids</span>\n<span class=\"n\">input_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">31</span><span class=\"p\">,</span> <span class=\"mi\">51</span><span class=\"p\">,</span> <span class=\"mi\">99</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">input_mask</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n<span class=\"n\">token_type_ids</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">LongTensor</span><span class=\"p\">([[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">]])</span>\n\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"n\">ErnieConfig</span><span class=\"p\">(</span><span class=\"n\">vocab_size_or_config_json_file</span><span class=\"o\">=</span><span class=\"mi\">32000</span><span class=\"p\">,</span> <span class=\"n\">hidden_size</span><span class=\"o\">=</span><span class=\"mi\">768</span><span class=\"p\">,</span>\n    <span class=\"n\">num_hidden_layers</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">num_attention_heads</span><span class=\"o\">=</span><span class=\"mi\">12</span><span class=\"p\">,</span> <span class=\"n\">intermediate_size</span><span class=\"o\">=</span><span class=\"mi\">3072</span><span class=\"p\">)</span>\n\n<span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ErnieForNextSentencePrediction</span><span class=\"p\">(</span><span class=\"n\">config</span><span class=\"p\">)</span>\n<span class=\"n\">seq_relationship_logits</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">token_type_ids</span><span class=\"p\">,</span> <span class=\"n\">input_mask</span><span class=\"p\">)</span>\n</code></pre></div>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNextSentencePrediction.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNextSentencePrediction.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    next_sentence_label=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"fullname": "canlpy.core.models.ernie.model.ErnieForEntityTyping", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForEntityTyping", "type": "class", "doc": "<p>Ernie model with entity typing prediction head.\nThis module comprises the Ernie model followed by the entity typing head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.\n  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForEntityTyping.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForEntityTyping.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"fullname": "canlpy.core.models.ernie.model.ErnieForSTSB", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSTSB", "type": "class", "doc": "<p>Ernie model with STSB prediction head (predict sentence similarity).\nThis module comprises the Ernie model followed by the STSB head.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>config: a ErnieConfig class instance with the configuration to build a new model.\n  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForSTSB.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSTSB.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForSTSB.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSTSB.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"fullname": "canlpy.core.models.ernie.model.ErnieForSequenceClassification", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSequenceClassification", "type": "class", "doc": "<p>Ernie model for classification.\nThis module is composed of the Ernie model with a linear layer on top of\nthe pooled output.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p><code>config</code>: an ErnieConfig class instance with the configuration to build a new model.\n  <code>num_labels</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>:\n      Outputs the CrossEntropy classification loss of the output with the labels.\n  if <code>labels</code> is <code>None</code>:\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSequenceClassification.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_labels=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForSequenceClassification.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNQ": {"fullname": "canlpy.core.models.ernie.model.ErnieForNQ", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNQ", "type": "class", "doc": "<p>Ernie model for NQ.\nThis module is composed of the Ernie model with a linear layer on top of\nthe pooled output.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p><code>config</code>: an ErnieConfig class instance with the configuration to build a new model.\n  <code>num_choices</code>: the number of classes for the classifier. Default = 2.</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong><code>input_ids</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length]\nwith the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n<code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)</li>\n<li><strong><code>token_type_ids</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\ntypes indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\na <code>sentence B</code> token (see BERT paper for more details).</li>\n<li><strong><code>attention_mask</code>:</strong>  an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\ninput sequence length in the current batch. It's the mask that we typically use for attention when\na batch has varying length sentences.</li>\n<li><strong><code>input_ent</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\nwith the entities embeddings</li>\n<li><strong><code>ent_mask</code>:</strong>  a torch.LongTensor of shape [batch_size, sequence_length] with indices\nselected in [0, 1]</li>\n<li><strong><code>choice_mask</code>:</strong> </li>\n<li><strong><code>labels</code>:</strong>  labels for the classification output: torch.LongTensor of shape [batch_size]\nwith indices selected in [0, ..., num_labels].</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>if <code>labels</code> is not <code>None</code>:\n      Outputs the CrossEntropy classification loss of the output with the labels.\n  if <code>labels</code> is <code>None</code>:\n      Outputs the classification logits of shape [batch_size, num_labels].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForNQ.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNQ.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config, num_choices=2)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForNQ.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForNQ.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    choice_mask=None,\n    labels=None\n)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"fullname": "canlpy.core.models.ernie.model.ErnieForQuestionAnswering", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForQuestionAnswering", "type": "class", "doc": "<p>Ernie model for Question Answering (span extraction).\nThis module is composed of the Ernie model with a linear layer on top of\nthe sequence output that computes start_logits and end_logits</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p><code>config</code>: either\n      - a ErnieConfig class instance with the configuration to build a new model</p>\n</blockquote>\n\n<h6 id=\"inputs\">Inputs</h6>\n\n<blockquote>\n  <p><code>input_ids</code>: a torch.LongTensor of shape [batch_size, sequence_length]\n      with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n      <code>extract_features.py</code>, <code>run_classifier.py</code> and <code>run_squad.py</code>)\n  <code>token_type_ids</code>: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n      types indices selected in [0, 1]. Type 0 corresponds to a <code>sentence A</code> and type 1 corresponds to\n      a <code>sentence B</code> token (see BERT paper for more details).\n  <code>attention_mask</code>: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n      selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n      input sequence length in the current batch. It's the mask that we typically use for attention when\n      a batch has varying length sentences.\n  <code>input_ent</code>: a torch.LongTensor of shape [batch_size, sequence_length,embedding_size]\n      with the entities embeddings\n  <code>ent_mask</code>: a torch.LongTensor of shape [batch_size, sequence_length] with indices\n      selected in [0, 1]\n  <code>start_positions</code>: position of the first token for the labeled span: torch.LongTensor of shape [batch_size].\n      Positions are clamped to the length of the sequence and position outside of the sequence are not taken\n      into account for computing the loss.\n  <code>end_positions</code>: position of the last token for the labeled span: torch.LongTensor of shape [batch_size].\n      Positions are clamped to the length of the sequence and position outside of the sequence are not taken\n      into account for computing the loss.</p>\n</blockquote>\n\n<h6 id=\"outputs\">Outputs</h6>\n\n<blockquote>\n  <p>if <code>start_positions</code> and <code>end_positions</code> are not <code>None</code>:\n      Outputs the total_loss which is the sum of the CrossEntropy loss for the start and end token positions.\n  if <code>start_positions</code> or <code>end_positions</code> is <code>None</code>:\n      Outputs a tuple of start_logits, end_logits which are the logits respectively for the start and end\n      position tokens of shape [batch_size, sequence_length].</p>\n</blockquote>\n", "bases": "PreTrainedErnieModel"}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"fullname": "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForQuestionAnswering.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, config)", "funcdef": "def"}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"fullname": "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward", "modulename": "canlpy.core.models.ernie.model", "qualname": "ErnieForQuestionAnswering.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    input_ids,\n    token_type_ids=None,\n    attention_mask=None,\n    input_ent=None,\n    ent_mask=None,\n    start_positions=None,\n    end_positions=None\n)", "funcdef": "def"}, "canlpy.core.models.knowbert": {"fullname": "canlpy.core.models.knowbert", "modulename": "canlpy.core.models.knowbert", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.knowbert_heads": {"fullname": "canlpy.core.models.knowbert.knowbert_heads", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"fullname": "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "qualname": "KnowBertForPreTraining", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"fullname": "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "qualname": "KnowBertForPreTraining.__init__", "type": "function", "doc": "<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>\n", "signature": "(self, knowbert_model)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"fullname": "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward", "modulename": "canlpy.core.models.knowbert.knowbert_heads", "qualname": "KnowBertForPreTraining.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<p>Should be overridden by all subclasses.</p>\n\n<div class=\"pdoc-alert pdoc-alert-note\">\n\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code>Module</code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n\n</div>\n", "signature": "(\n    self,\n    tokens=None,\n    segment_ids=None,\n    candidates=None,\n    lm_label_ids=None,\n    next_sentence_label=None,\n    **kwargs\n)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge": {"fullname": "canlpy.core.models.knowbert.knowledge", "modulename": "canlpy.core.models.knowbert.knowledge", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"fullname": "canlpy.core.models.knowbert.knowledge.EntityEmbedder", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "EntityEmbedder", "type": "class", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"fullname": "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "EntityEmbedder.__init__", "type": "function", "doc": "<p></p>\n", "signature": "()", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"fullname": "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "read_embeddings_from_text_file", "type": "function", "doc": "<p>Read pre-trained word vectors from an eventually compressed text file, possibly contained\ninside an archive with multiple files. The text file is assumed to be utf-8 encoded with\nspace-separated fields: [word] [dim 1] [dim 2] ...</p>\n\n<p>Lines that contain more numerical tokens than <code>embedding_dim</code> raise a warning and are skipped.</p>\n\n<p>The remainder of the docstring is identical to <code>_read_pretrained_embeddings_file</code>.</p>\n", "signature": "(\n    gzip_filename: str,\n    embedding_dim: int,\n    vocab: canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary,\n    namespace: str = 'tokens'\n) -> torch.FloatTensor", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding", "type": "class", "doc": "<p>Combines pretrained fixed embeddings with learned POS embeddings.</p>\n\n<h6 id=\"given-entity-candidate-list\">Given entity candidate list</h6>\n\n<blockquote>\n  <ul>\n  <li>get list of unique entity ids</li>\n  <li>look up</li>\n  <li>concat POS embedding</li>\n  <li>linear project to candidate embedding shape</li>\n  </ul>\n</blockquote>\n", "bases": "torch.nn.modules.module.Module, EntityEmbedder"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.__init__", "type": "function", "doc": "<p>pass pos_emedding_dim = None to skip POS embeddings and all the\n    entity stuff, using this as a pretrained embedding file\n    with feedforward</p>\n", "signature": "(\n    self,\n    embedding_file: str,\n    entity_dim: int,\n    entity_file: str = None,\n    vocab_file: str = None,\n    entity_h5_key: str = 'conve_tucker_infersent_bert',\n    dropout: float = 0.1,\n    pos_embedding_dim: int = 25,\n    include_null_embedding: bool = False\n)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.POS_MAP", "type": "variable", "doc": "<p></p>\n", "default_value": " = {'@@PADDING@@': 0, 'n': 1, 'v': 2, 'a': 3, 'r': 4, 's': 5, '@@MASK@@': 6, '@@NULL@@': 7, '@@UNKNOWN@@': 8}"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.get_output_dim", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.get_null_embedding", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"fullname": "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward", "modulename": "canlpy.core.models.knowbert.knowledge", "qualname": "WordNetAllEmbedding.forward", "type": "function", "doc": "<p>entity_ids = (batch_size, num_candidates, num_entities) array of entity\n    ids</p>\n\n<p>returns (batch_size, num_candidates, num_entities, embed_dim)\n    with entity embeddings</p>\n", "signature": "(self, entity_ids)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics": {"fullname": "canlpy.core.models.knowbert.metrics", "modulename": "canlpy.core.models.knowbert.metrics", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.metrics.Metric": {"fullname": "canlpy.core.models.knowbert.metrics.Metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric", "type": "class", "doc": "<p>A very general abstract class representing a metric which can be\naccumulated.</p>\n"}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.__init__", "type": "function", "doc": "<p></p>\n", "signature": "()", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.get_metric", "type": "function", "doc": "<p>Compute and return the metric. Optionally also call <code>self.reset</code>.</p>\n", "signature": "(self, reset: bool) -> Union[float, Tuple[float, ...], Dict[str, float]]", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self) -> None", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"fullname": "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Metric.unwrap_to_tensors", "type": "function", "doc": "<p>If you actually passed gradient-tracking Tensors to a Metric, there will be\na huge memory leak, because it will prevent garbage collection for the computation\ngraph. This method ensures that you're using tensors directly and that they are on\nthe CPU.</p>\n\n<p>In addition, all tensors are cast to float32 as torch does not\nimplement many operations for HalfTensor on CPU.</p>\n", "signature": "(*tensors: torch.Tensor)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Average": {"fullname": "canlpy.core.models.knowbert.metrics.Average", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average", "type": "class", "doc": "<p>This <code>Metric</code> breaks with the typical <code>Metric</code> API and just stores values that were\ncomputed in some fashion outside of a <code>Metric</code>.  If you have some external code that computes\nthe metric for you, for instance, you can use this to report the average result using our\n<code>Metric</code> API.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.Average.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.Average.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The average of all values that were passed to <code>__call__</code>.</p>\n", "signature": "(self, reset: bool = False) -> float", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.Average.reset": {"fullname": "canlpy.core.models.knowbert.metrics.Average.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "Average.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy", "type": "class", "doc": "<p>Categorical Top-K accuracy. Assumes integer labels, with\neach item to be classified having a single correct class.\nTie break enables equal distribution of scores among the\nclasses with same maximum predicted scores.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, top_k: int = 1, tie_break: bool = False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The accumulated accuracy.</p>\n", "signature": "(self, reset: bool = False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"fullname": "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "CategoricalAccuracy.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage", "type": "class", "doc": "<p>This <code>Metric</code> breaks with the typical <code>Metric</code> API and just stores values that were\ncomputed in some fashion outside of a <code>Metric</code>.  If you have some external code that computes\nthe metric for you, for instance, you can use this to report the average result using our\n<code>Metric</code> API.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The average of all values that were passed to <code>__call__</code>.</p>\n", "signature": "(self, reset: bool = False) -> float", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"fullname": "canlpy.core.models.knowbert.metrics.WeightedAverage.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "WeightedAverage.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage", "type": "class", "doc": "<p>Keep an exponentially weighted moving average.\nalpha is the decay constant. Alpha = 1 means just keep the most recent value.\nalpha = 0.5 will have almost no contribution from 10 time steps ago.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, alpha: float = 0.5)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>The average of all values that were passed to <code>__call__</code>.</p>\n", "signature": "(self, reset: bool = False) -> float", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"fullname": "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "ExponentialMovingAverage.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.F1Metric": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric", "type": "class", "doc": "<p>A generic set based F1 metric.\nTakes two lists of predicted and gold elements and computes F1.\nOnly requirements are that the elements are hashable.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, filter_func=None)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.F1Metric.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "F1Metric.get_metric", "type": "function", "doc": "<h2 id=\"returns\">Returns</h2>\n\n<p>A tuple of the following metrics based on the accumulated count statistics:\nprecision : float\nrecall : float\nf1-measure : float</p>\n", "signature": "(self, reset: bool = False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank", "type": "class", "doc": "<p>A very general abstract class representing a metric which can be\naccumulated.</p>\n", "bases": "Metric"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank.get_metric", "type": "function", "doc": "<p>Compute and return the metric. Optionally also call <code>self.reset</code>.</p>\n", "signature": "(self, reset=False)", "funcdef": "def"}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"fullname": "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset", "modulename": "canlpy.core.models.knowbert.metrics", "qualname": "MeanReciprocalRank.reset", "type": "function", "doc": "<p>Reset any accumulators or internal state.</p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.model": {"fullname": "canlpy.core.models.knowbert.model", "modulename": "canlpy.core.models.knowbert.model", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.models.knowbert.model.KnowBert": {"fullname": "canlpy.core.models.knowbert.model.KnowBert", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert", "type": "class", "doc": "<p>Base class for all neural network modules.</p>\n\n<p>Your models should also subclass this class.</p>\n\n<p>Modules can also contain other Modules, allowing to nest them in\na tree structure. You can assign the submodules as regular attributes::</p>\n\n<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n</code></pre>\n\n<p>Submodules assigned in this way will be registered, and will have their\nparameters converted too when you call <code>to</code>, etc.</p>\n\n<p>:ivar training: Boolean represents whether this module is in training or\n                evaluation mode.\n:vartype training: bool</p>\n", "bases": "torch.nn.modules.module.Module"}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.__init__", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.__init__", "type": "function", "doc": "<p>state_dict_map maps from string name in state_dict to new string name to fit</p>\n", "signature": "(\n    self,\n    soldered_kgs: Dict[str, canlpy.core.components.fusion.knowbert_fusion.soldered_kg.SolderedKG],\n    soldered_layers: Dict[str, int],\n    bert_model_name: str,\n    mode: str = None,\n    state_dict_file: str = None,\n    strict_load_archive: bool = True,\n    remap_segment_embeddings: int = None,\n    state_dict_map: Dict[str, str] = None\n)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.from_pretrained", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.from_pretrained", "type": "function", "doc": "<p></p>\n", "signature": "(cls, str_or_url, strict_load_archive=True)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.load_state_dict", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.load_state_dict", "type": "function", "doc": "<p>Copies parameters and buffers from <code>state_dict</code> into\nthis module and its descendants. If <code>strict</code> is <code>True</code>, then\nthe keys of <code>state_dict</code> must exactly match the keys returned\nby this module's <code>~torch.nn.Module.state_dict</code> function.</p>\n\n<h6 id=\"arguments\">Arguments</h6>\n\n<blockquote>\n  <p>state_dict (dict): a dict containing parameters and\n      persistent buffers.\n  strict (bool, optional): whether to strictly enforce that the keys\n      in <code>state_dict</code> match the keys returned by this module's\n      <code>~torch.nn.Module.state_dict</code> function. Default: <code>True</code></p>\n</blockquote>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p><code>NamedTuple</code> with <code>missing_keys</code> and <code>unexpected_keys</code> fields:\n      * <strong>missing_keys</strong> is a list of str containing the missing keys\n      * <strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p>\n</blockquote>\n", "signature": "(self, state_dict, strict=True)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.unfreeze", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.unfreeze", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"fullname": "canlpy.core.models.knowbert.model.KnowBert.forward", "modulename": "canlpy.core.models.knowbert.model", "qualname": "KnowBert.forward", "type": "function", "doc": "<p>Receives: \ntokens['tokens']: Tensor of tokens indices (used to idx an embedding) =&gt; because a batch contains multiple\nsentences with varying # of tokens, all tokens tensors are padded with zeros \nshape: (batch_size (#sentences), max_seq_len)</p>\n\n<p>segment_ids: Tenso of segments_ids for each token (0 for first segment and 1 for second), can be used for NSP\nshape: (batch_size,max_seq_len)</p>\n\n<p>candidates, for each SolderedKB contains:</p>\n\n<p>candidates['wordnet']['candidate_entity_priors']: hape:(batch_size, max # detected entities, max # KB candidate entities)\n  Correctness probabilities estimated by the entity extractor (sum to 1 (or 0 if padding) on axis 2)\n  Adds 0 padding to axis 1 when there is less detected entities in the sentence than in the max sentence\n  Adds 0 padding to axis 2 when there is less detected KB entities for an entity in the sentence than in the max candidate KB entities entity</p>\n\n<p>candidates['wordnet']['ids']: shape: (batch_size, max # detected entities, max # KB candidate entities)\n  Ids of the KB candidate entities + 0 padding on axis 1 or 2 if necessary</p>\n\n<p>candidates['wordnet']['candidate_spans']: shape: (batch_size, max # detected entities, 2)\n  Spans of which sequence of tokens correspond to an entity in the sentence, eg: [1,2] for Michael Jackson (both bounds are included)\n  Padding with [-1,-1] when no more detected entities</p>\n\n<p>candidates['wordnet']['candidate_segment_ids']: shape: (batch_size, max # detected entities)\n  For each sentence entity, indicate to which segment ids it corresponds to</p>\n\n<p>kwargs:\nlm_label_ids: suppose it is the labels of the masked token\nnext_sentence_label: labels of the next sentence for NSP</p>\n", "signature": "(self, tokens=None, segment_ids=None, candidates=None, **kwargs)", "funcdef": "def"}, "canlpy.core.util": {"fullname": "canlpy.core.util", "modulename": "canlpy.core.util", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.file_utils": {"fullname": "canlpy.core.util.file_utils", "modulename": "canlpy.core.util.file_utils", "type": "module", "doc": "<p>Utilities for working with the local dataset cache.\nThis file is adapted from the AllenNLP library at <a href=\"https://github.com/allenai/allennlp\">https://github.com/allenai/allennlp</a>\nCopyright by the AllenNLP authors.</p>\n"}, "canlpy.core.util.file_utils.url_to_filename": {"fullname": "canlpy.core.util.file_utils.url_to_filename", "modulename": "canlpy.core.util.file_utils", "qualname": "url_to_filename", "type": "function", "doc": "<p>Convert <code>url</code> into a hashed filename in a repeatable way.\nIf <code>etag</code> is specified, append its hash to the url's, delimited\nby a period.</p>\n", "signature": "(url: str, etag: str = None) -> str", "funcdef": "def"}, "canlpy.core.util.file_utils.filename_to_url": {"fullname": "canlpy.core.util.file_utils.filename_to_url", "modulename": "canlpy.core.util.file_utils", "qualname": "filename_to_url", "type": "function", "doc": "<p>Return the url and etag (which may be <code>None</code>) stored for <code>filename</code>.\nRaise <code>FileNotFoundError</code> if <code>filename</code> or its stored metadata do not exist.</p>\n", "signature": "(\n    filename: str,\n    cache_dir: Union[str, pathlib.Path] = None\n) -> Tuple[str, str]", "funcdef": "def"}, "canlpy.core.util.file_utils.cached_path": {"fullname": "canlpy.core.util.file_utils.cached_path", "modulename": "canlpy.core.util.file_utils", "qualname": "cached_path", "type": "function", "doc": "<p>Given something that might be a URL (or might be a local path),\ndetermine which. If it's a URL, download the file and cache it, and\nreturn the path to the cached file. If it's already a local path,\nmake sure the file exists and then return the path.</p>\n", "signature": "(\n    url_or_filename: Union[str, pathlib.Path],\n    cache_dir: Union[str, pathlib.Path] = None\n) -> str", "funcdef": "def"}, "canlpy.core.util.file_utils.split_s3_path": {"fullname": "canlpy.core.util.file_utils.split_s3_path", "modulename": "canlpy.core.util.file_utils", "qualname": "split_s3_path", "type": "function", "doc": "<p>Split a full s3 path into the bucket name and path.</p>\n", "signature": "(url: str) -> Tuple[str, str]", "funcdef": "def"}, "canlpy.core.util.file_utils.s3_request": {"fullname": "canlpy.core.util.file_utils.s3_request", "modulename": "canlpy.core.util.file_utils", "qualname": "s3_request", "type": "function", "doc": "<p>Wrapper function for s3 requests in order to create more helpful error\nmessages.</p>\n", "signature": "(func: Callable)", "funcdef": "def"}, "canlpy.core.util.file_utils.s3_etag": {"fullname": "canlpy.core.util.file_utils.s3_etag", "modulename": "canlpy.core.util.file_utils", "qualname": "s3_etag", "type": "function", "doc": "<p>Check ETag on S3 object.</p>\n", "signature": "(url: str) -> Union[str, NoneType]", "funcdef": "def"}, "canlpy.core.util.file_utils.s3_get": {"fullname": "canlpy.core.util.file_utils.s3_get", "modulename": "canlpy.core.util.file_utils", "qualname": "s3_get", "type": "function", "doc": "<p>Pull a file directly from S3.</p>\n", "signature": "(url: str, temp_file: <class 'IO'>) -> None", "funcdef": "def"}, "canlpy.core.util.file_utils.http_get": {"fullname": "canlpy.core.util.file_utils.http_get", "modulename": "canlpy.core.util.file_utils", "qualname": "http_get", "type": "function", "doc": "<p></p>\n", "signature": "(url: str, temp_file: <class 'IO'>) -> None", "funcdef": "def"}, "canlpy.core.util.file_utils.get_from_cache": {"fullname": "canlpy.core.util.file_utils.get_from_cache", "modulename": "canlpy.core.util.file_utils", "qualname": "get_from_cache", "type": "function", "doc": "<p>Given a URL, look for the corresponding dataset in the local cache.\nIf it's not there, download it. Then return the path to the cached file.</p>\n", "signature": "(url: str, cache_dir: Union[str, pathlib.Path] = None) -> str", "funcdef": "def"}, "canlpy.core.util.file_utils.read_set_from_file": {"fullname": "canlpy.core.util.file_utils.read_set_from_file", "modulename": "canlpy.core.util.file_utils", "qualname": "read_set_from_file", "type": "function", "doc": "<p>Extract a de-duped collection (set) of text from a file.\nExpected file format is one item per line.</p>\n", "signature": "(filename: str) -> Set[str]", "funcdef": "def"}, "canlpy.core.util.file_utils.get_file_extension": {"fullname": "canlpy.core.util.file_utils.get_file_extension", "modulename": "canlpy.core.util.file_utils", "qualname": "get_file_extension", "type": "function", "doc": "<p></p>\n", "signature": "(path: str, dot=True, lower: bool = True)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer": {"fullname": "canlpy.core.util.knowbert_tokenizer", "modulename": "canlpy.core.util.knowbert_tokenizer", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "type": "module", "doc": "<p>A Vocabulary maps strings to integers, allowing for strings to be mapped to an\nout-of-vocabulary token.</p>\n"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "pop_max_vocab_size", "type": "function", "doc": "<p>max_vocab_size is allowed to be either an int or a Dict[str, int] (or nothing).\nBut it could also be a string representing an int (in the case of environment variable\nsubstitution). So we need some complex logic to handle it.</p>\n", "signature": "(params: Dict[str, Any]) -> Union[int, Dict[str, int]]", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "namespace_match", "type": "function", "doc": "<p>Matches a namespace pattern against a namespace string.  For example, <code>*tags</code> matches\n<code>passage_tags</code> and <code>question_tags</code> and <code>tokens</code> matches <code>tokens</code> but not\n<code>stemmed_tokens</code>.</p>\n", "signature": "(pattern: str, namespace: str)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary", "type": "class", "doc": "<p>A Vocabulary maps strings to integers, allowing for strings to be mapped to an\nout-of-vocabulary token.</p>\n\n<p>Vocabularies are fit to a particular dataset, which we use to decide which tokens are\nin-vocabulary.</p>\n\n<p>Vocabularies also allow for several different namespaces, so you can have separate indices for\n'a' as a word, and 'a' as a character, for instance, and so we can use this object to also map\ntag and label strings to indices.  Most of the\nmethods on this class allow you to pass in a namespace; by default we use the 'tokens'\nnamespace, and you can omit the namespace argument everywhere and just use the default.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>counter : <code>Dict[str, Dict[str, int]]</code>, optional (default=<code>None</code>)\n    A collection of counts from which to initialize this vocabulary.  We will examine the\n    counts and, together with the other parameters to this class, use them to decide which\n    words are in-vocabulary.  If this is <code>None</code>, we just won't initialize the vocabulary with\n    anything.\nmin_count : <code>Dict[str, int]</code>, optional (default=None)\n    When initializing the vocab from a counter, you can specify a minimum count, and every\n    token with a count less than this will not be added to the dictionary.  These minimum\n    counts are <code>namespace-specific</code>, so you can specify different minimums for labels versus\n    words tokens, for example.  If a namespace does not have a key in the given dictionary, we\n    will add all seen tokens to that namespace.\nmax_vocab_size : <code>Union[int, Dict[str, int]]</code>, optional (default=<code>None</code>)\n    If you want to cap the number of tokens in your vocabulary, you can do so with this\n    parameter.  If you specify a single integer, every namespace will have its vocabulary fixed\n    to be no larger than this.  If you specify a dictionary, then each namespace in the\n    <code>counter</code> can have a separate maximum vocabulary size.  Any missing key will have a value\n    of <code>None</code>, which means no cap on the vocabulary size.\nnon_padded_namespaces : <code>Iterable[str]</code>, optional\n    By default, we assume you are mapping word / character tokens to integers, and so you want\n    to reserve word indices for padding and out-of-vocabulary tokens.  However, if you are\n    mapping NER or SRL tags, or class labels, to integers, you probably do not want to reserve\n    indices for padding and out-of-vocabulary tokens.  Use this field to specify which\n    namespaces should <code>not</code> have padding and OOV tokens added.</p>\n\n<pre><code>The format of each element of this is either a string, which must match field names\nexactly,  or ``*`` followed by a string, which we match as a suffix against field names.\n\nWe try to make the default here reasonable, so that you don't have to think about this.\nThe default is ``(\"*tags\", \"*labels\")``, so as long as your namespace ends in \"tags\" or\n\"labels\" (which is true by default for all tag and label fields in this code), you don't\nhave to specify anything here.\n</code></pre>\n\n<p>pretrained_files : <code>Dict[str, str]</code>, optional\n    If provided, this map specifies the path to optional pretrained embedding files for each\n    namespace. This can be used to either restrict the vocabulary to only words which appear\n    in this file, or to ensure that any words in this file are included in the vocabulary\n    regardless of their count, depending on the value of <code>only_include_pretrained_words</code>.\n    Words which appear in the pretrained embedding file but not in the data are NOT included\n    in the Vocabulary.\nmin_pretrained_embeddings : <code>Dict[str, int]</code>, optional\n    If provided, specifies for each namespace a minimum number of lines (typically the\n    most common words) to keep from pretrained embedding files, even for words not\n    appearing in the data.\nonly_include_pretrained_words : <code>bool</code>, optional (default=False)\n    This defines the strategy for using any pretrained embedding files which may have been\n    specified in <code>pretrained_files</code>. If False, an inclusive strategy is used: and words\n    which are in the <code>counter</code> and in the pretrained file are added to the <code>Vocabulary</code>,\n    regardless of whether their count exceeds <code>min_count</code> or not. If True, we use an\n    exclusive strategy: words are only included in the Vocabulary if they are in the pretrained\n    embedding file (their count must still be at least <code>min_count</code>).\ntokens_to_add : <code>Dict[str, List[str]]</code>, optional (default=None)\n    If given, this is a list of tokens to add to the vocabulary, keyed by the namespace to add\n    the tokens to.  This is a way to be sure that certain items appear in your vocabulary,\n    regardless of any other vocabulary computation.</p>\n"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    counter: Dict[str, Dict[str, int]] = None,\n    min_count: Dict[str, int] = None,\n    max_vocab_size: Union[int, Dict[str, int]] = None,\n    non_padded_namespaces: Iterable[str] = ('*tags', '*labels'),\n    pretrained_files: Union[Dict[str, str], NoneType] = None,\n    only_include_pretrained_words: bool = False,\n    tokens_to_add: Dict[str, List[str]] = None,\n    min_pretrained_embeddings: Dict[str, int] = None\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.default_implementation", "type": "variable", "doc": "<p></p>\n", "default_value": " = 'default'"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.save_to_files", "type": "function", "doc": "<p>Persist this Vocabulary to files so it can be reloaded later.\nEach namespace corresponds to one file.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>directory : <code>str</code>\n    The directory where we save the serialized vocabulary.</p>\n", "signature": "(self, directory: str) -> None", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.from_files", "type": "function", "doc": "<p>Loads a <code>Vocabulary</code> that was serialized using <code>save_to_files</code>.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>directory : <code>str</code>\n    The directory containing the serialized vocabulary.</p>\n", "signature": "(\n    cls,\n    directory: str\n) -> canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.set_from_file", "type": "function", "doc": "<p>If you already have a vocabulary file for a trained model somewhere, and you really want to\nuse that vocabulary file instead of just setting the vocabulary from a dataset, for\nwhatever reason, you can do that with this method.  You must specify the namespace to use,\nand we assume that you want to use padding and OOV tokens for this.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>filename : <code>str</code>\n    The file containing the vocabulary to load.  It should be formatted as one token per\n    line, with nothing else in the line.  The index we assign to the token is the line\n    number in the file (1-indexed if <code>is_padded</code>, 0-indexed otherwise).  Note that this\n    file should contain the OOV token string!\nis_padded : <code>bool</code>, optional (default=True)\n    Is this vocabulary padded?  For token / word / character vocabularies, this should be\n    <code>True</code>; while for tag or label vocabularies, this should typically be <code>False</code>.  If\n    <code>True</code>, we add a padding token with index 0, and we enforce that the <code>oov_token</code> is\n    present in the file.\noov_token : <code>str</code>, optional (default=DEFAULT_OOV_TOKEN)\n    What token does this vocabulary use to represent out-of-vocabulary characters?  This\n    must show up as a line in the vocabulary file.  When we find it, we replace\n    <code>oov_token</code> with <code>self._oov_token</code>, because we only use one OOV token across\n    namespaces.\nnamespace : <code>str</code>, optional (default=\"tokens\")\n    What namespace should we overwrite with this vocab file?</p>\n", "signature": "(\n    self,\n    filename: str,\n    is_padded: bool = True,\n    oov_token: str = '@@UNKNOWN@@',\n    namespace: str = 'tokens'\n)", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.is_padded", "type": "function", "doc": "<p>Returns whether or not there are padding and OOV tokens added to the given namespace.</p>\n", "signature": "(self, namespace: str) -> bool", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.add_token_to_namespace", "type": "function", "doc": "<p>Adds <code>token</code> to the index, if it is not already present.  Either way, we return the index of\nthe token.</p>\n", "signature": "(self, token: str, namespace: str = 'tokens') -> int", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_index_to_token_vocabulary", "type": "function", "doc": "<p></p>\n", "signature": "(self, namespace: str = 'tokens') -> Dict[int, str]", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_token_to_index_vocabulary", "type": "function", "doc": "<p></p>\n", "signature": "(self, namespace: str = 'tokens') -> Dict[str, int]", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_token_index", "type": "function", "doc": "<p></p>\n", "signature": "(self, token: str, namespace: str = 'tokens') -> int", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_token_from_index", "type": "function", "doc": "<p></p>\n", "signature": "(self, index: int, namespace: str = 'tokens') -> str", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.get_vocab_size", "type": "function", "doc": "<p></p>\n", "signature": "(self, namespace: str = 'tokens') -> int", "funcdef": "def"}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"fullname": "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics", "modulename": "canlpy.core.util.knowbert_tokenizer.vocabulary", "qualname": "Vocabulary.print_statistics", "type": "function", "doc": "<p></p>\n", "signature": "(self) -> None", "funcdef": "def"}, "canlpy.core.util.tokenization": {"fullname": "canlpy.core.util.tokenization", "modulename": "canlpy.core.util.tokenization", "type": "module", "doc": "<p>Tokenization classes.</p>\n"}, "canlpy.core.util.tokenization.load_vocab": {"fullname": "canlpy.core.util.tokenization.load_vocab", "modulename": "canlpy.core.util.tokenization", "qualname": "load_vocab", "type": "function", "doc": "<p>Loads a vocabulary file into a dictionary.</p>\n", "signature": "(vocab_file)", "funcdef": "def"}, "canlpy.core.util.tokenization.whitespace_tokenize": {"fullname": "canlpy.core.util.tokenization.whitespace_tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "whitespace_tokenize", "type": "function", "doc": "<p>Runs basic whitespace cleaning and splitting on a peice of text.</p>\n", "signature": "(text)", "funcdef": "def"}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"fullname": "canlpy.core.util.tokenization.whitespace_tokenize_ent", "modulename": "canlpy.core.util.tokenization", "qualname": "whitespace_tokenize_ent", "type": "function", "doc": "<p></p>\n", "signature": "(text, ents, label=False)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer": {"fullname": "canlpy.core.util.tokenization.BertTokenizer", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer", "type": "class", "doc": "<p>Runs end-to-end tokenization: punctuation splitting + wordpiece</p>\n"}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.__init__", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, vocab_file, do_lower_case=True, max_len=None, label=False)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.tokenize", "type": "function", "doc": "<p></p>\n", "signature": "(self, text, ents)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.convert_tokens_to_ids", "type": "function", "doc": "<p>Converts a sequence of tokens into ids using the vocab.</p>\n", "signature": "(self, tokens)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.convert_ids_to_tokens", "type": "function", "doc": "<p>Converts a sequence of ids in wordpiece tokens using the vocab.</p>\n", "signature": "(self, ids)", "funcdef": "def"}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"fullname": "canlpy.core.util.tokenization.BertTokenizer.from_pretrained", "modulename": "canlpy.core.util.tokenization", "qualname": "BertTokenizer.from_pretrained", "type": "function", "doc": "<p>Instantiate a PreTrainedBertModel from a pre-trained model file.\nDownload and cache the pre-trained model file if needed.</p>\n", "signature": "(cls, pretrained_model_name, cache_dir=None, *inputs, **kwargs)", "funcdef": "def"}, "canlpy.core.util.tokenization.BasicTokenizer": {"fullname": "canlpy.core.util.tokenization.BasicTokenizer", "modulename": "canlpy.core.util.tokenization", "qualname": "BasicTokenizer", "type": "class", "doc": "<p>Runs basic tokenization (punctuation splitting, lower casing, etc.).</p>\n"}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"fullname": "canlpy.core.util.tokenization.BasicTokenizer.__init__", "modulename": "canlpy.core.util.tokenization", "qualname": "BasicTokenizer.__init__", "type": "function", "doc": "<p>Constructs a BasicTokenizer.</p>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>do_lower_case:</strong>  Whether to lower case the input.</li>\n</ul>\n", "signature": "(self, do_lower_case=True, label=False)", "funcdef": "def"}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"fullname": "canlpy.core.util.tokenization.BasicTokenizer.tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "BasicTokenizer.tokenize", "type": "function", "doc": "<p>Tokenizes a piece of text.</p>\n", "signature": "(self, text, ents)", "funcdef": "def"}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"fullname": "canlpy.core.util.tokenization.WordpieceTokenizer", "modulename": "canlpy.core.util.tokenization", "qualname": "WordpieceTokenizer", "type": "class", "doc": "<p>Runs WordPiece tokenization.</p>\n"}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"fullname": "canlpy.core.util.tokenization.WordpieceTokenizer.__init__", "modulename": "canlpy.core.util.tokenization", "qualname": "WordpieceTokenizer.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(self, vocab, unk_token='[UNK]', max_input_chars_per_word=100)", "funcdef": "def"}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"fullname": "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize", "modulename": "canlpy.core.util.tokenization", "qualname": "WordpieceTokenizer.tokenize", "type": "function", "doc": "<p>Tokenizes a piece of text into its word pieces.</p>\n\n<p>This uses a greedy longest-match-first algorithm to perform tokenization\nusing the given vocabulary.</p>\n\n<h6 id=\"for-example\">For example</h6>\n\n<blockquote>\n  <p>input = \"unaffable\"\n  output = [\"un\", \"##aff\", \"##able\"]</p>\n</blockquote>\n\n<h6 id=\"args\">Args</h6>\n\n<ul>\n<li><strong>text:</strong>  A single token or whitespace separated tokens. This should have\nalready been passed through <code>BasicTokenizer</code>.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>A list of wordpiece tokens.</p>\n</blockquote>\n", "signature": "(self, text)", "funcdef": "def"}, "canlpy.core.util.util": {"fullname": "canlpy.core.util.util", "modulename": "canlpy.core.util.util", "type": "module", "doc": "<p></p>\n"}, "canlpy.core.util.util.get_dtype_for_module": {"fullname": "canlpy.core.util.util.get_dtype_for_module", "modulename": "canlpy.core.util.util", "qualname": "get_dtype_for_module", "type": "function", "doc": "<p></p>\n", "signature": "(module)", "funcdef": "def"}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"fullname": "canlpy.core.util.util.extend_attention_mask_for_bert", "modulename": "canlpy.core.util.util", "qualname": "extend_attention_mask_for_bert", "type": "function", "doc": "<p></p>\n", "signature": "(mask, dtype)", "funcdef": "def"}, "canlpy.core.util.util.find_value": {"fullname": "canlpy.core.util.util.find_value", "modulename": "canlpy.core.util.util", "qualname": "find_value", "type": "function", "doc": "<p></p>\n", "signature": "(config, key)", "funcdef": "def"}, "canlpy.helpers": {"fullname": "canlpy.helpers", "modulename": "canlpy.helpers", "type": "module", "doc": "<p></p>\n"}, "canlpy.helpers.cokebert_helpers": {"fullname": "canlpy.helpers.cokebert_helpers", "modulename": "canlpy.helpers.cokebert_helpers", "type": "module", "doc": "<p></p>\n"}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"fullname": "canlpy.helpers.cokebert_helpers.load_k_v_queryR", "modulename": "canlpy.helpers.cokebert_helpers", "qualname": "load_k_v_queryR", "type": "function", "doc": "<p></p>\n", "signature": "(\n    input_ent,\n    ent_to_neighbors,\n    ent_to_relations,\n    ent_to_outORin,\n    embed_ent,\n    r_embed,\n    device='cpu'\n)", "funcdef": "def"}, "canlpy.helpers.tokens": {"fullname": "canlpy.helpers.tokens", "modulename": "canlpy.helpers.tokens", "type": "module", "doc": "<p></p>\n"}, "canlpy.train": {"fullname": "canlpy.train", "modulename": "canlpy.train", "type": "module", "doc": "<p></p>\n"}, "canlpy.train.optimization": {"fullname": "canlpy.train.optimization", "modulename": "canlpy.train.optimization", "type": "module", "doc": "<p></p>\n"}, "canlpy.train.optimization.warmup_cosine": {"fullname": "canlpy.train.optimization.warmup_cosine", "modulename": "canlpy.train.optimization", "qualname": "warmup_cosine", "type": "function", "doc": "<p></p>\n", "signature": "(x, warmup=0.002)", "funcdef": "def"}, "canlpy.train.optimization.warmup_constant": {"fullname": "canlpy.train.optimization.warmup_constant", "modulename": "canlpy.train.optimization", "qualname": "warmup_constant", "type": "function", "doc": "<p></p>\n", "signature": "(x, warmup=0.002)", "funcdef": "def"}, "canlpy.train.optimization.warmup_linear": {"fullname": "canlpy.train.optimization.warmup_linear", "modulename": "canlpy.train.optimization", "qualname": "warmup_linear", "type": "function", "doc": "<p></p>\n", "signature": "(x, warmup=0.002)", "funcdef": "def"}, "canlpy.train.optimization.BertAdam": {"fullname": "canlpy.train.optimization.BertAdam", "modulename": "canlpy.train.optimization", "qualname": "BertAdam", "type": "class", "doc": "<p>Implements BERT version of Adam algorithm with weight decay fix.</p>\n\n<h6 id=\"params\">Params</h6>\n\n<blockquote>\n  <p>lr: learning rate\n  warmup: portion of t_total for the warmup, -1  means no warmup. Default: -1\n  t_total: total number of training steps for the learning\n      rate schedule, -1  means constant learning rate. Default: -1\n  schedule: schedule to use for the warmup (see above). Default: 'warmup_linear'\n  b1: Adams b1. Default: 0.9\n  b2: Adams b2. Default: 0.999\n  e: Adams epsilon. Default: 1e-6\n  weight_decay: Weight decay. Default: 0.01\n  max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0</p>\n</blockquote>\n", "bases": "torch.optim.optimizer.Optimizer"}, "canlpy.train.optimization.BertAdam.__init__": {"fullname": "canlpy.train.optimization.BertAdam.__init__", "modulename": "canlpy.train.optimization", "qualname": "BertAdam.__init__", "type": "function", "doc": "<p></p>\n", "signature": "(\n    self,\n    params,\n    lr=<required parameter>,\n    warmup=-1,\n    t_total=-1,\n    schedule='warmup_linear',\n    b1=0.9,\n    b2=0.999,\n    e=1e-06,\n    weight_decay=0.01,\n    max_grad_norm=1.0\n)", "funcdef": "def"}, "canlpy.train.optimization.BertAdam.get_lr": {"fullname": "canlpy.train.optimization.BertAdam.get_lr", "modulename": "canlpy.train.optimization", "qualname": "BertAdam.get_lr", "type": "function", "doc": "<p></p>\n", "signature": "(self)", "funcdef": "def"}, "canlpy.train.optimization.BertAdam.step": {"fullname": "canlpy.train.optimization.BertAdam.step", "modulename": "canlpy.train.optimization", "qualname": "BertAdam.step", "type": "function", "doc": "<p>Performs a single optimization step.</p>\n\n<h6 id=\"arguments\">Arguments</h6>\n\n<blockquote>\n  <p>closure (callable, optional): A closure that reevaluates the model\n      and returns the loss.</p>\n</blockquote>\n", "signature": "(self, closure=None)", "funcdef": "def"}}, "docInfo": {"canlpy": {"qualname": 0, "fullname": 1, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core": {"qualname": 0, "fullname": 2, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.activation_functions": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.activation_functions.gelu": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 49}, "canlpy.core.components.activation_functions.get_activation_function": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.components.fusion": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.cokebert_fusion": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 147}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 75}, "canlpy.core.components.fusion.ernie_fusion": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 147}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 14, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 75}, "canlpy.core.components.fusion.fusion": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.fusion.fusion.Fusion": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 14}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 75}, "canlpy.core.components.fusion.knowbert_fusion": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.heads": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.components.heads.BertLMPredictionHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.BertOnlyMLMHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.BertOnlyNSPHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 67}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 14}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 67}, "canlpy.core.models": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.bert": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.bert.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.bert.model.MultiHeadAttention": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 133}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 12, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertAttention": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 141}, "canlpy.core.models.bert.model.BertAttention.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertAttention.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertEmbeddings": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 204}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 16, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.DenseSkipLayer": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 124}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertLayer": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 180}, "canlpy.core.models.bert.model.BertLayer.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 19, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertLayer.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.BertPooler": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 80}, "canlpy.core.models.bert.model.BertPooler.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 14}, "canlpy.core.models.bert.model.BertPooler.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.LayerNorm": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 82}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 16}, "canlpy.core.models.bert.model.LayerNorm.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 67}, "canlpy.core.models.bert.model.init_weights": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 45}, "canlpy.core.models.cokebert": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.cokebert.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 28}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 5, "signature": 0, "bases": 0, "doc": 11}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 5, "signature": 0, "bases": 0, "doc": 12}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 4, "signature": 0, "bases": 0, "doc": 13}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 14}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 66, "bases": 0, "doc": 356}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 46}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 23}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 24}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"qualname": 5, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 23}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"qualname": 5, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 23}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 20}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 36}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 13, "bases": 0, "doc": 147}, "canlpy.core.models.cokebert.model.CokeBertModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 14}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 29}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 27, "bases": 0, "doc": 359}, "canlpy.core.models.cokebert.model.DKEncoder": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 15}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 66}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 119}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 18}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 70}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 117}, "canlpy.core.models.cokebert.model.DK_text": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 16}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 70}, "canlpy.core.models.cokebert.model.DK_text.forward": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 71}, "canlpy.core.models.cokebert.model.DK_knowledge": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 16}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 36}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 61}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 28}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 53}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 334}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 27}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 53}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 334}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 30}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 35}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 338}, "canlpy.core.models.ernie": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.ernie.components": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 276}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 25, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 343}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 21, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.components.ErnieEncoder": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 207}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.ernie.model.ErnieConfig": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 56, "bases": 0, "doc": 320}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 15}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 10}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 10}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 20}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 6}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 135}, "canlpy.core.models.ernie.model.ErnieModel": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 875}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 23, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 793}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 21, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 463}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 31, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 651}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 16, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 308}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 309}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 361}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 20, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForNQ": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 370}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 23, "bases": 0, "doc": 67}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 433}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 24, "bases": 0, "doc": 67}, "canlpy.core.models.knowbert": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowbert_heads": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 14}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 19, "bases": 0, "doc": 67}, "canlpy.core.models.knowbert.knowledge": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 2, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"qualname": 5, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 21, "bases": 0, "doc": 79}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 6, "doc": 50}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 39, "bases": 0, "doc": 25}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 29, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 28}, "canlpy.core.models.knowbert.metrics": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.Metric": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 15}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 2, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 15}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 68}, "canlpy.core.models.knowbert.metrics.Average": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 60}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 20}, "canlpy.core.models.knowbert.metrics.Average.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 36}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 60}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 20}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 36}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 20}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.F1Metric": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 28}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 27}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 1, "doc": 15}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 15}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 9}, "canlpy.core.models.knowbert.model": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.model.KnowBert": {"qualname": 1, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 5, "doc": 147}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 47, "bases": 0, "doc": 18}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 10, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 159}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 302}, "canlpy.core.util": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.file_utils": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 29}, "canlpy.core.util.file_utils.url_to_filename": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 32}, "canlpy.core.util.file_utils.filename_to_url": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 12, "bases": 0, "doc": 34}, "canlpy.core.util.file_utils.cached_path": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 15, "bases": 0, "doc": 54}, "canlpy.core.util.file_utils.split_s3_path": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 14}, "canlpy.core.util.file_utils.s3_request": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 16}, "canlpy.core.util.file_utils.s3_etag": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 8}, "canlpy.core.util.file_utils.s3_get": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 9}, "canlpy.core.util.file_utils.http_get": {"qualname": 2, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.file_utils.get_from_cache": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 30}, "canlpy.core.util.file_utils.read_set_from_file": {"qualname": 4, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 22}, "canlpy.core.util.file_utils.get_file_extension": {"qualname": 3, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer": {"qualname": 0, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"qualname": 0, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 21}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 45}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"qualname": 2, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 40}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"qualname": 1, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 821}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 50, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 3, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 39}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 12, "bases": 0, "doc": 34}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 16, "bases": 0, "doc": 271}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 18}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"qualname": 5, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 25}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"qualname": 6, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"qualname": 6, "fullname": 12, "annotation": 0, "default_value": 0, "signature": 8, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"qualname": 5, "fullname": 11, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"qualname": 4, "fullname": 10, "annotation": 0, "default_value": 0, "signature": 7, "bases": 0, "doc": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"qualname": 3, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 5}, "canlpy.core.util.tokenization.load_vocab": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 10}, "canlpy.core.util.tokenization.whitespace_tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 14}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.BertTokenizer": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 11}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 14, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"qualname": 5, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 13}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"qualname": 5, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 14}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 11, "bases": 0, "doc": 22}, "canlpy.core.util.tokenization.BasicTokenizer": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 11}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 9, "bases": 0, "doc": 27}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 8}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"qualname": 1, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 6}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"qualname": 3, "fullname": 7, "annotation": 0, "default_value": 0, "signature": 13, "bases": 0, "doc": 3}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 93}, "canlpy.core.util.util": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.core.util.util.get_dtype_for_module": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"qualname": 5, "fullname": 9, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.core.util.util.find_value": {"qualname": 2, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 4, "bases": 0, "doc": 3}, "canlpy.helpers": {"qualname": 0, "fullname": 2, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.helpers.cokebert_helpers": {"qualname": 0, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"qualname": 4, "fullname": 8, "annotation": 0, "default_value": 0, "signature": 19, "bases": 0, "doc": 3}, "canlpy.helpers.tokens": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.train": {"qualname": 0, "fullname": 2, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.train.optimization": {"qualname": 0, "fullname": 3, "annotation": 0, "default_value": 0, "signature": 0, "bases": 0, "doc": 3}, "canlpy.train.optimization.warmup_cosine": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.train.optimization.warmup_constant": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.train.optimization.warmup_linear": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 6, "bases": 0, "doc": 3}, "canlpy.train.optimization.BertAdam": {"qualname": 1, "fullname": 4, "annotation": 0, "default_value": 0, "signature": 0, "bases": 4, "doc": 110}, "canlpy.train.optimization.BertAdam.__init__": {"qualname": 3, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 33, "bases": 0, "doc": 3}, "canlpy.train.optimization.BertAdam.get_lr": {"qualname": 3, "fullname": 6, "annotation": 0, "default_value": 0, "signature": 3, "bases": 0, "doc": 3}, "canlpy.train.optimization.BertAdam.step": {"qualname": 2, "fullname": 5, "annotation": 0, "default_value": 0, "signature": 5, "bases": 0, "doc": 32}}, "length": 269, "save": true}, "index": {"qualname": {"root": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 56, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "t": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 21}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 1}}}}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}}, "df": 4}}}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}}}}}}, "f": {"1": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 4}}}}}}}, "docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 6}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 3, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 39}}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 5, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 12}}}}, "d": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 9, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 6}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}, "m": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 59}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 4}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}}, "df": 3}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}}, "df": 3}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}}, "df": 3, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}}, "df": 3}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 5}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3}}}}}}}}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 2}}}}}, "t": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}}}, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 1}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}}, "df": 3}}}}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}}, "df": 3}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}}, "df": 3}}}}}}}}, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 4}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}}, "df": 3}}}}}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}}, "df": 1}}}}}, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 11}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}}}}, "o": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 15, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 5, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5}}}, "s": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 5}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}, "s": {"3": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 4}, "docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 2}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 2}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 3, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}}, "df": 3}}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 5}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {"canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 1}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 6}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 2}}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 3}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 3}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.train.optimization.warmup_constant": {"tf": 1}}, "df": 1}}}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 7}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}}, "df": 3}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 1, "d": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 2, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 2}}}}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1}}}}, "j": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 4}}}}, "k": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 3}}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 6, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 4, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 2}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 2}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 7}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 1}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}}, "df": 1}}}}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils.http_get": {"tf": 1}}, "df": 1}}}}, "v": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}}, "df": 3, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 14}}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}}, "fullname": {"root": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 56, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy": {"tf": 1}, "canlpy.core": {"tf": 1}, "canlpy.core.components": {"tf": 1}, "canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models": {"tf": 1}, "canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}, "canlpy.helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}, "canlpy.helpers.tokens": {"tf": 1}, "canlpy.train": {"tf": 1}, "canlpy.train.optimization": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 269}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 1, "d": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core": {"tf": 1}, "canlpy.core.components": {"tf": 1}, "canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models": {"tf": 1}, "canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 255}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components": {"tf": 1}, "canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}}, "df": 47}}}}}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.helpers.cokebert_helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 46, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 7}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}}, "df": 3}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 3}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.train.optimization.warmup_constant": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}}, "df": 4}}}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}}}}}}, "f": {"1": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 4}}}}}}}, "docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.activation_functions": {"tf": 1}, "canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}}, "df": 3}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1.4142135623730951}}, "df": 14}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 3, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 39}}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 15, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 12}}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "t": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 21}}}, "d": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 9, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 6}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}, "m": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 59}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 4}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.ernie_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 52, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}}, "df": 3}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}}, "df": 3}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}}, "df": 3}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}}, "df": 3, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}}, "df": 3}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 5}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3}}}}}}}}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 2}}}}}, "t": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}}}, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 1}}}}, "k": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.knowbert_fusion": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 71, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 13}}}}}}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 23}}}, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers": {"tf": 1}, "canlpy.helpers.cokebert_helpers": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.helpers.tokens": {"tf": 1}}, "df": 4}}}}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils.http_get": {"tf": 1}}, "df": 1}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 26, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}}, "df": 3}}}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}}, "df": 3}}}}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}}, "df": 3}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}}, "df": 3}}}}}}}}, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 4}}}}, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}}, "df": 3}}}}}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 107, "s": {"docs": {"canlpy.core.models": {"tf": 1}, "canlpy.core.models.bert": {"tf": 1}, "canlpy.core.models.bert.model": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie": {"tf": 1}, "canlpy.core.models.ernie.components": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 166}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 1}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}}, "df": 1}}}}}, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 11, "s": {"docs": {"canlpy.core.models.knowbert.metrics": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 30}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train": {"tf": 1}, "canlpy.train.optimization": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 9}}}}, "o": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 15, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 5, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 18}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 16}}}}}}}, "s": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.helpers.tokens": {"tf": 1}}, "df": 3}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 5}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}, "s": {"3": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 4}, "docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 2}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 2}}}, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 3, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}}, "df": 3}}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 5}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {"canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}}, "df": 1}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 6}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 3}}}}}}}}}}}}}}}}}, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}}, "df": 2}}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 3}}}}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 2, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 2}}}}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}}, "df": 1}}}}, "j": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}}, "df": 4}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 4, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 4}}}}}}}}}}}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}}, "df": 1}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 2}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 2}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 7}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 8}}}}}}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}, "f": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}}, "df": 1}}}}}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.util": {"tf": 1.4142135623730951}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}}, "df": 51, "s": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 12}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}, "v": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}}, "df": 3, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1.4142135623730951}}, "df": 17}}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.find_value": {"tf": 1}}, "df": 1}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}}, "annotation": {"root": {"docs": {}, "df": 0}}, "default_value": {"root": {"0": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "1": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "3": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "4": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "5": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "6": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "7": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "8": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1.4142135623730951}}, "df": 5, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}}, "df": 1}}}}}}, "j": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}}, "df": 2}}}}, "p": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}}, "df": 1}}}, "n": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}}, "v": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "a": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1}}, "df": 1}}}}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1}}, "df": 1}}}}}}}}}, "signature": {"root": {"0": {"0": {"2": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "1": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "6": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 2}}, "df": 8}, "1": {"0": {"0": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "2": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 3}, "docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1.7320508075688772}}, "df": 5, "e": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 2}}, "2": {"0": {"0": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "5": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}}, "df": 8}, "3": {"0": {"7": {"2": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "4": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "5": {"1": {"2": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}}, "df": 1}, "7": {"6": {"8": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "9": {"9": {"9": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_request": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_get": {"tf": 2}, "canlpy.core.util.file_utils.http_get": {"tf": 2}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.4142135623730951}, "canlpy.core.util.util.find_value": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}, "canlpy.train.optimization.warmup_cosine": {"tf": 1.4142135623730951}, "canlpy.train.optimization.warmup_constant": {"tf": 1.4142135623730951}, "canlpy.train.optimization.warmup_linear": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 2}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 174, "x": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}}, "df": 6}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 3, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 10, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "o": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}}, "df": 4, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1, "e": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 35, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 2}}}}}}, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}}, "df": 13}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 3}}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 5, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.activation_functions.get_activation_function": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 27, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 3}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}}, "df": 11}}}, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 137}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}}, "df": 2}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 3}}}}}}, "g": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 3}}}}}, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 13}}}, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.7320508075688772}}, "df": 1, "k": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}}}}}, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 15, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 7}}}}}, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 4}}}}}}}, "e": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 2}}, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}}, "v": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 13, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 9, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}}, "df": 8}, "r": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 4, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}}, "df": 5}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 11}}}}}}, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}}, "df": 1}, "o": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 2, "t": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 7}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 6, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 15}}}}}, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 4}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}}, "df": 2}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 3}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}}, "df": 1}}, "r": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}, "q": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}}, "df": 8}, "i": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}}, "df": 11, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}}}}}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 18, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 5}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3}}}}}}}}}, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}}}}, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 2}}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}}, "df": 1}}}}, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 18}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}, "h": {"5": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}}, "df": 22}}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 7}}}}}, "e": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 2.23606797749979}}, "df": 21, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 7}}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}}, "df": 5}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3}}}}}, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 1}}, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.4142135623730951}}, "df": 1, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.7320508075688772}}, "df": 5, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 5}}}}}}}}}, "p": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 10, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 7}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}}, "df": 8, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 3}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 2}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}}, "df": 4}}}}}}}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 27}}}}}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 1}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}}, "df": 2}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 3}, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}, "f": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}}, "df": 4}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}}, "df": 6, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 5}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}}, "df": 1}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}}, "df": 6, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 12}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 2}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "t": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1, "o": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}}, "df": 2, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 18, "s": {"docs": {"canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}}, "df": 13}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}}}}}, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 2}}}, "p": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}}, "df": 17, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}}, "df": 2}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5}}}, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 10}}}, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 2}}}}}}}}, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.util.util.find_value": {"tf": 1}}, "df": 23}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 3}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 2}}}}}}}, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 3}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 5}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 2}}}, "l": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 7}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}}}}, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}, "b": {"1": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 5}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 13}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1}}, "df": 1}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1, "l": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 6}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1}}, "df": 3}}}}}, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1}}, "df": 20, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}}, "df": 3}}}}, "x": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 7}, "p": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.4142135623730951}}, "df": 1}}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}}, "df": 3}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.warmup_cosine": {"tf": 1}, "canlpy.train.optimization.warmup_constant": {"tf": 1}, "canlpy.train.optimization.warmup_linear": {"tf": 1}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1.4142135623730951}}, "df": 4}}}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}}, "df": 7}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 2}, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "v": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}, "r": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 7}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1}}, "df": 1}}}}}}}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}, "z": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.train.optimization.BertAdam.__init__": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 4}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 2}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "k": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1.4142135623730951}}, "df": 1, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.http_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 8}}}}}, "bases": {"root": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}}, "df": 2}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}}, "df": 2}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}}, "df": 2}}}}}}}}}}, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}}, "df": 2}}}}}}, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 27}}}}}, "n": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 26}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 26, "s": {"docs": {"canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 26}}}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 6}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}}, "df": 4}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 9}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}}}}, "doc": {"root": {"0": {"1": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}, "4": {"4": {"7": {"1": {"5": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.7416573867739413}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 2}}, "df": 25}, "1": {"0": {"0": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}}, "df": 2}, "2": {"4": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}, "2": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}}, "df": 3}, "5": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.7416573867739413}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.4641016151377544}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 2.449489742783178}}, "df": 38, "e": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}, "2": {"0": {"2": {"0": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "4": {"8": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {}, "df": 0}, "docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}}, "df": 11}, "4": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}}, "df": 11}, "3": {"0": {"7": {"2": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "1": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "2": {"0": {"0": {"0": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}, "5": {"1": {"2": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 16}, "6": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 3}, "7": {"6": {"8": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {}, "df": 0}, "docs": {}, "df": 0}, "8": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}, "9": {"9": {"9": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}, "docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}, "docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}, "docs": {"canlpy": {"tf": 1.7320508075688772}, "canlpy.core": {"tf": 1.7320508075688772}, "canlpy.core.components": {"tf": 1.7320508075688772}, "canlpy.core.components.activation_functions": {"tf": 1.7320508075688772}, "canlpy.core.components.activation_functions.gelu": {"tf": 3.3166247903554}, "canlpy.core.components.activation_functions.get_activation_function": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 4.795831523312719}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 5.656854249492381}, "canlpy.core.components.fusion.ernie_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 4.795831523312719}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 5.656854249492381}, "canlpy.core.components.fusion.fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 4.795831523312719}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 5.656854249492381}, "canlpy.core.components.fusion.knowbert_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 4.795831523312719}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 4.795831523312719}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 4.795831523312719}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 4.795831523312719}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 4.795831523312719}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 3.872983346207417}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 4.795831523312719}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 3.872983346207417}, "canlpy.core.models": {"tf": 1.7320508075688772}, "canlpy.core.models.bert": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 6}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.transpose_for_scores": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertAttention": {"tf": 6}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 6.48074069840786}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 6.48074069840786}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertLayer": {"tf": 6.164414002968976}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.BertPooler": {"tf": 5.744562646538029}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 6.4031242374328485}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 3.872983346207417}, "canlpy.core.models.bert.model.init_weights": {"tf": 4.358898943540674}, "canlpy.core.models.cokebert": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 10.198039027185569}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 5}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 3.4641016151377544}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 3.4641016151377544}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 4.358898943540674}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 6.48074069840786}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 3.872983346207417}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 8.426149773176359}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 5}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 5.5677643628300215}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 5.385164807134504}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 5.744562646538029}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 5.291502622129181}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 4.58257569495584}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 4}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 4.47213595499958}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 4.898979485566356}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 9.219544457292887}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 4.898979485566356}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 9.219544457292887}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 4.123105625617661}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 9.219544457292887}, "canlpy.core.models.ernie": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 6.4031242374328485}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 7.0710678118654755}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 7.3484692283495345}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 9.539392014169456}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 6.244997998398398}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 20.591260281974}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 20.199009876724155}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 9.797958971132712}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 17.88854381999832}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 8.366600265340756}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 8.366600265340756}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 9.433981132056603}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 9.797958971132712}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 3.872983346207417}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 8.12403840463596}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 3.872983346207417}, "canlpy.core.models.knowbert": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 4.795831523312719}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 3.872983346207417}, "canlpy.core.models.knowbert.knowledge": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.EntityEmbedder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 3.7416573867739413}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 4.58257569495584}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.POS_MAP": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_output_dim": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.get_null_embedding": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 2}, "canlpy.core.models.knowbert.metrics": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 3.3166247903554}, "canlpy.core.models.knowbert.metrics.Average.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 3}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 3.3166247903554}, "canlpy.core.models.knowbert.metrics.WeightedAverage.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 3}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 3}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 4.795831523312719}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 7}, "canlpy.core.models.knowbert.model.KnowBert.unfreeze": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 6}, "canlpy.core.util": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils": {"tf": 2.23606797749979}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 2.6457513110645907}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 3.3166247903554}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_request": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_get": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.http_get": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.get_file_extension": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 8.717797887081348}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.default_implementation": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 5.916079783099616}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_index_to_token_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_to_index_vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_index": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_token_from_index": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.get_vocab_size": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.print_statistics": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.whitespace_tokenize_ent": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.tokenize": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 3.7416573867739413}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.WordpieceTokenizer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 6.164414002968976}, "canlpy.core.util.util": {"tf": 1.7320508075688772}, "canlpy.core.util.util.get_dtype_for_module": {"tf": 1.7320508075688772}, "canlpy.core.util.util.extend_attention_mask_for_bert": {"tf": 1.7320508075688772}, "canlpy.core.util.util.find_value": {"tf": 1.7320508075688772}, "canlpy.helpers": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers": {"tf": 1.7320508075688772}, "canlpy.helpers.cokebert_helpers.load_k_v_queryR": {"tf": 1.7320508075688772}, "canlpy.helpers.tokens": {"tf": 1.7320508075688772}, "canlpy.train": {"tf": 1.7320508075688772}, "canlpy.train.optimization": {"tf": 1.7320508075688772}, "canlpy.train.optimization.warmup_cosine": {"tf": 1.7320508075688772}, "canlpy.train.optimization.warmup_constant": {"tf": 1.7320508075688772}, "canlpy.train.optimization.warmup_linear": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam": {"tf": 3.3166247903554}, "canlpy.train.optimization.BertAdam.__init__": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam.get_lr": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam.step": {"tf": 3.605551275463989}}, "df": 269, "i": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 11, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 3}}}}}, "s": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11}}}}}, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.58257569495584}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 56, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 4}}}}}}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 4, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}}, "df": 29}, "r": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 3}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 4}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}}}}}}}}}}, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 7, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 42}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 8}}}}}}}, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 2}}}}}, "o": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 12}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 47}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 3}}}}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 29}}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 2}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 22}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 4}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}}, "df": 2, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 25, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 5}}}}, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 2}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 40}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}, "g": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}}, "df": 2}}}}}}, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 21}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}, "x": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}, "f": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 33}, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 21, "e": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}}}}, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5}}}, "o": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.6457513110645907}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.605551275463989}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 3.4641016151377544}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.8284271247461903}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 105}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 23, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 2}}}}}}, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 12, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}}, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 39, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 3, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}}}, "w": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}}, "n": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}}, "df": 16, "e": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 31}, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 6}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 3, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 19, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}}, "df": 13}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 3}}}}}, "r": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}, "b": {"docs": {}, "df": 0, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 4}}}}}, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "v": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 3}}}, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 2, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertAttention": {"tf": 3}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 4.123105625617661}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertLayer": {"tf": 3.4641016151377544}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 4.795831523312719}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 4.58257569495584}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 4.123105625617661}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 4.123105625617661}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 4.58257569495584}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 4.69041575982343}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 4.69041575982343}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 4.898979485566356}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 4.242640687119285}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 4}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 4.47213595499958}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 4.47213595499958}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 5.5677643628300215}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3.1622776601683795}, "canlpy.core.util.file_utils": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 2.23606797749979}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 5.830951894845301}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 3.605551275463989}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 2}, "canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 134, "m": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 38}, "i": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 12}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 4}}, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}, "n": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 4}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.358898943540674}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 3}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}}, "df": 67}, "n": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 32}, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 16}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 9}}}}}}, "o": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 5.916079783099616}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 110, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}}, "df": 41}}}, "o": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 31, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}}, "df": 33, "/": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}}, "df": 3}}}}}}}}, "/": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 3}}}}}}}, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}}}}}, "p": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 9}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 4}}}, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 30}, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}}}, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 2}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 14}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}}, "df": 5}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}}, "df": 8}}}}}}}}, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}}}}, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}}, "df": 5}}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}}, "df": 16, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 16}}, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 17}}}}}, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 7, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 2}}}}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1.4142135623730951}}, "df": 13, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}}}, "f": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}}, "df": 1}}}}}, "w": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}, "n": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 6}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 1}}}, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 3}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.1622776601683795}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.4641016151377544}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.cached_path": {"tf": 2}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.795831523312719}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 2}, "canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 98, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}}}}}, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 4}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 7}}}}}}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}}, "df": 2}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}, "n": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 28, "d": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.7416573867739413}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 92}, "y": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 9, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 1}}}}}}}}, "l": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 55, "o": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 13}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 15}}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 7}}}}}, "p": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.7320508075688772}}, "df": 1}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}}}}}}}, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 25, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 12, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 13}}}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}}}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}, "s": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 31, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2.6457513110645907}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 25}}}}}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 46}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 2}}}}}}}, "e": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 15}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 3}}}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 1}}}}, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}}, "df": 2, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}}}}}, "f": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}, "d": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 3}}, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 2}}, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 1}}}}, "b": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 4}}}}}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}}, "df": 2}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}}, "df": 6}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}, "g": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}}}, "x": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2}}, "df": 1}}}, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}, "f": {"1": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 2}, "docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}}, "df": 11, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 34, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 4}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 5, "y": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.605551275463989}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 2}}, "df": 90, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 50}}}}, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 6}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"3": {"2": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}, "docs": {}, "df": 0}, "docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1.7320508075688772}}, "df": 2, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}}, "df": 12}}}}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 19}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}}}, "n": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 3}, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 6}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}}, "df": 2}, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}}, "df": 23, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 4}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 3}}}, "o": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}}}}, "x": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 3}}}, "s": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}}}}}, "s": {"3": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 4}, "docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 21, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}, "q": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 40}}}, "w": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}}, "df": 29}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.8284271247461903}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}}, "df": 29}}}}, "u": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1, "b": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}}}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 4}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}}, "df": 10, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 12, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 2}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}}, "df": 1, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 2.449489742783178}}, "df": 42, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}}, "df": 13}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3}}}}}, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}}, "df": 1}}}, "y": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}}, "d": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}}, "df": 1}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}, "d": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1.4142135623730951}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "v": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}}, "s": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}}, "df": 1}}, "u": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}, "m": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 2.6457513110645907}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 2.6457513110645907}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2.6457513110645907}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2.6457513110645907}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2.6457513110645907}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2.6457513110645907}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2.6457513110645907}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 14}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}}, "df": 20}}}}}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 2, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.605551275463989}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 33, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.4641016151377544}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}}, "df": 15, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 14}}}}}}}, "e": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 15, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}}, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 6, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}}, "df": 1}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 4}, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}}, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}}}}}, "g": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}}, "df": 29}}}}}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1.4142135623730951}}, "df": 2}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}, "g": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 4}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}}}, "z": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.6457513110645907}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 3.1622776601683795}, "canlpy.core.models.bert.model.BertLayer": {"tf": 3}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3.3166247903554}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 4.123105625617661}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.7416573867739413}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.605551275463989}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 37}}, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 1}}}}}}}}}, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}, "w": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5}}}}, "o": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 3, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 3, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 3}}}}}, "w": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}}, "df": 2}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 3}}}}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 1}}, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 2}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 3}}}, "s": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 1}}}}}, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 12, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 5}}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 2.8284271247461903}}, "df": 4, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}}, "df": 5}}}, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}}, "df": 2}}}}}}, "r": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 2}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}}}}}}}, "e": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 1, "f": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 27}, "d": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.3166247903554}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}, "canlpy.train.optimization.BertAdam": {"tf": 2.8284271247461903}}, "df": 12}}}}}, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 14}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2}}}, "v": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}}, "df": 1}, "s": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}}}}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 2}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}}, "df": 9}}}}}}, "o": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 4, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 4}}, "w": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 4, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}}}}}}}, "c": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}, "y": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 12}}}}}}, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}}, "df": 3, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}}, "df": 2, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}}, "df": 2}}}}}}}}}}}}}, "u": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}}, "df": 2}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 4}}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 1, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 1}}}}}}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.reset": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.reset": {"tf": 1}}, "df": 9}, "r": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}}, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 37}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1}}}}}}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 16}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 1}}}}}}}}}, "o": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}}}}, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 17, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 43}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 7, "s": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}}, "df": 2}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 3}}}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}}, "df": 2}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}}, "df": 1}, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 1}}}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}}}}}}}}, "u": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 13, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}, "s": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}}, "df": 4}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 9}}, "e": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 1}}, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3}}, "d": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 2}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 2}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 1}}}}, "x": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 2}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 2}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2}}, "df": 13}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1.4142135623730951}}, "df": 1}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 3, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.7320508075688772}}, "df": 1}}}}}, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 5}, "s": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}}, "df": 19, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}}, "df": 6}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 6}}}}, "x": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3.1622776601683795}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 20, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 6}}}}}, "p": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 2, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}}, "n": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}, "k": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 2.23606797749979}}, "df": 86, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}}, "df": 11}}}}, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 40, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 14}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 4}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 17}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 2}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}}}}, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 2}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 3}}}, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}}, "df": 4}}}, "x": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 2}, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 1, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 2.23606797749979}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 8, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 1}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 3}}, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer.tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.components.activation_functions.gelu": {"tf": 1}}, "df": 1}, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1.4142135623730951}}, "df": 2, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.23606797749979}}, "df": 7, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}}, "df": 5}, "d": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 8}}}}, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 26}}}}}, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 10}}}, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 36, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 7}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 14}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.cached_path": {"tf": 2}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 8}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 1}}}}}, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}}, "df": 3}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 4}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 9}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}}}}, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}}}}}}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}}, "df": 9, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 8}, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 9}}, "y": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 5}}, "y": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}}, "df": 2}}}}}, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}, "d": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}}, "df": 1}}}}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 2}}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}}, "df": 4}}}}}}}, "j": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1.4142135623730951}}, "df": 6, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.3166247903554}}, "df": 10, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13}}}}}}}}}}, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 3}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 2}}}}}}, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 2}}}}}, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "y": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}}, "df": 13, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.to_dict": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 2}}, "df": 2}}}}}}, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.file_utils.s3_get": {"tf": 1}}, "df": 1}}, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 2}}}}}}}}}}}, "b": {"1": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 1}, "2": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 1}, "docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 14, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 12, "d": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}}}}}}}}}}, "t": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 3}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.3166247903554}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.1622776601683795}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}}, "df": 29}}}}, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}}, "df": 67, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 3}}}}}, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 20, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 5}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 3}}}}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 14, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 13}}}}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 30}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}}, "df": 67}, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 5}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 12}}}, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 1}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}}, "df": 5}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}}}}, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.7320508075688772}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.7320508075688772}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 40, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}}, "df": 12}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 15}, "d": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.util.tokenization": {"tf": 1}}, "df": 8}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "s": {"docs": {"canlpy.core.models.bert.model.BertPooler": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 21, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.6457513110645907}}, "df": 2, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}}, "df": 2}}}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 42, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1.4142135623730951}}, "df": 4}, "t": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 5, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 3}}}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}}}}}, "p": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 16, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 15}}}, "s": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 2}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}}, "df": 1}}, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 2}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 1}}}}, "i": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 2}}}}}}}}}, "v": {"1": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11}, "2": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}}, "df": 11}}, "docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 14}}, "s": {"docs": {"canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 2}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 6}}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}}, "df": 2, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 11}}}}}, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}}}}, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_dict": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 23, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 16}}}}}}}}}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 28}}}}}, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank.get_metric": {"tf": 1}}, "df": 2, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 4}, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 4}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 6}}}}, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}}, "df": 5}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}}, "df": 1}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}, "b": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}}}, "/": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 16}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 7}}}}}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}}}, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1.4142135623730951}}, "df": 7, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}}, "df": 5}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}}, "df": 8}}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}}}}}}}}, "d": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 3}}, "u": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric.get_metric": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.8284271247461903}}, "df": 2, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 1}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 1}}}, "l": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}}}, "y": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 1, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}}, "df": 3}}}}}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 4, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}}, "o": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 1}}}}}}, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 14}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 3}}}}, "o": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 6}}}}}}}}}}}, "p": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}}, "df": 1}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}, "t": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.from_pretrained": {"tf": 1}}, "df": 2}}}}, "x": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 3.1622776601683795}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 5}}, "w": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1}}, "df": 14}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.cokebert_fusion.DK_fusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.__init__": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 2.449489742783178}, "canlpy.core.components.fusion.fusion.Fusion.__init__": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertLMPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyMLMHead.__init__": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertPredictionHeadTransform.__init__": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.BertOnlyNSPHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErnieEntPredictionHead.__init__": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 2.449489742783178}, "canlpy.core.components.heads.ErniePreTrainingHeads.__init__": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.__init__": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.__init__": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.__init__": {"tf": 1}, "canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 2.449489742783178}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}}, "df": 43}, "u": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 2}}, "df": 22, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 20}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}}, "o": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 10, "n": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 6, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.449489742783178}}, "df": 12}}, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 1}}}}}}}}}}}, "m": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.4142135623730951}}, "df": 4, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3, "i": {"docs": {}, "df": 0, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.LayerNorm": {"tf": 1}}, "df": 1}}}}}}}}, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 18, "h": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}}}, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CONFIG_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.MAPPING_FILE": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.__init__": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.split_s3_path": {"tf": 1}}, "df": 5, "d": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}}, "df": 1}}}}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.4641016151377544}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}}}}}}}}, "q": {"docs": {"canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}}, "df": 1}, "s": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 1}}}, "y": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "u": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.872983346207417}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}}, "df": 16, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}}, "df": 12}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 14}, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}, "m": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 2.23606797749979}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 2}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1.4142135623730951}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}}, "df": 15}}, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 43, "i": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}, "o": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}}, "df": 1}}}}}}, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 27}, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.is_padded": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1}}, "df": 16}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 27}}, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.605551275463989}}, "df": 17}}, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.whitespace_tokenize": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 2}}}}}}}}, "a": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 1, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}}}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 18, "p": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 7}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2}}, "df": 1}}}, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.3166247903554}}, "df": 1}}, "k": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3.1622776601683795}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 18, "i": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 4, "s": {"docs": {"canlpy.core.models.bert.model.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.WEIGHTS_NAME": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.init_weights": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}}, "df": 7}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}}, "df": 5}}}, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}}}, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 3}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 17}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}, "n": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 4}}}}, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 13, "h": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 1}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}}}}, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}, "e": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}}, "df": 8, "s": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 11}}}, "l": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}}, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1}}}, "i": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 2}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2.23606797749979}, "canlpy.core.models.bert.model.BertPooler": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}}, "df": 20}}}}}, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.__init__": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "u": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, ":": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "/": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}, "e": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 7, "t": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1, "c": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}}, "df": 12}, "a": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.file_utils.url_to_filename": {"tf": 1}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.s3_etag": {"tf": 1}}, "df": 3}}}, "v": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 3, "y": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 27, "w": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "n": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}}}}}}}}}, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 18, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.449489742783178}}, "df": 14}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 3.3166247903554}}, "df": 23}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}}, "df": 1}}}}}, "h": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1.4142135623730951}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1.4142135623730951}}, "df": 3}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 3.4641016151377544}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 20}, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 4}}}}}, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}, "canlpy.core.util.tokenization.BertTokenizer": {"tf": 1.4142135623730951}}, "df": 3, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}, "s": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}}}}, "v": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}}}}}}}, "m": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 1}}, "df": 3}}}}}}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}}, "df": 1, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.23606797749979}}, "df": 26, "s": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.components.fusion.fusion.Fusion.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2.449489742783178}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.forward": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 34}}}}}}}}, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}}, "df": 1}}}}}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.7320508075688772}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 13}}}, "p": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 2}}}}}}, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 14, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}}, "df": 2}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_text_encoder_config": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}}, "df": 1}}}}}}}}, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 11}}}}}}, "m": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 3}}}}}, "f": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}}, "df": 1}}}}}}}}, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 1}}}}}}}}}}}}}}}}}}}}}}}}}}}}, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.file_utils.s3_request": {"tf": 1}}, "df": 1}}}}, "x": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2, "t": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 14, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}}, "df": 2}}}}}}, "a": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 6}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}}}, "p": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}}, "df": 1}}}}}}}}}}, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}}, "df": 1}}}}}}, "i": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.file_utils.filename_to_url": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.util.file_utils.cached_path": {"tf": 1}}, "df": 1}}}}, "c": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "v": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}}, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.add_token_to_namespace": {"tf": 1}}, "df": 4}}}}}, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 1}}}}, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1.4142135623730951}}, "df": 1}}}}}}, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "m": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}}, "g": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}, "v": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}}, "df": 13, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "y": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.components.fusion.cokebert_fusion.DK_fusion": {"tf": 1}, "canlpy.core.components.fusion.ernie_fusion.ErnieFusion": {"tf": 1}, "canlpy.core.components.fusion.fusion.Fusion": {"tf": 1}, "canlpy.core.components.heads.BertLMPredictionHead": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert": {"tf": 1}}, "df": 11}}}}, "y": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 14}}}}, "i": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 1}}}}}}, "l": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 2, "s": {"docs": {"canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage.get_metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage.get_metric": {"tf": 1}}, "df": 5}}}}}, "o": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}}, "df": 12, "u": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 4.47213595499958}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.8284271247461903}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 23}, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1.4142135623730951}}, "df": 2}}}}}}}}}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.cokebert.model": {"tf": 1}}, "df": 1}}}}, "u": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "y": {"docs": {"canlpy.core.models.knowbert.metrics.Metric": {"tf": 1}, "canlpy.core.models.knowbert.metrics.MeanReciprocalRank": {"tf": 1}}, "df": 2}}, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}}, "df": 3, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 9}}}}}}}, "l": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.components.heads.BertLMPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyMLMHead.forward": {"tf": 1}, "canlpy.core.components.heads.BertPredictionHeadTransform.forward": {"tf": 1}, "canlpy.core.components.heads.BertOnlyNSPHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErnieEntPredictionHead.forward": {"tf": 1}, "canlpy.core.components.heads.ErniePreTrainingHeads.forward": {"tf": 1}, "canlpy.core.models.bert.model.MultiHeadAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings.forward": {"tf": 1}, "canlpy.core.models.bert.model.DenseSkipLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer.forward": {"tf": 1}, "canlpy.core.models.bert.model.BertPooler.forward": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering.forward": {"tf": 1}, "canlpy.core.models.knowbert.knowbert_heads.KnowBertForPreTraining.forward": {"tf": 1}}, "df": 26}}}, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.save_to_files": {"tf": 1}}, "df": 1}}}, "y": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 2}, "canlpy.core.models.bert.model.LayerNorm": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 22, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "m": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.LayerNorm.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}}, "df": 3}}}}, "s": {"docs": {"canlpy.core.models.bert.model.BertLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 12}}}}, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}}, "df": 3, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "b": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 5, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.6457513110645907}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2}}, "df": 16}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1.4142135623730951}}, "df": 1}}}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}}, "df": 7}}, "n": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}}}}}}}, "e": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}}, "df": 1, "g": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "h": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 2}, "canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.bert.model.BertPooler": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 3}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.8284271247461903}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 3.3166247903554}}, "df": 28}}}}, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1.7320508075688772}}, "df": 1}}}}}, "k": {"docs": {"canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}}, "df": 1}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.MultiHeadAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertAttention": {"tf": 1}, "canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1.4142135623730951}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 2.23606797749979}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 2.449489742783178}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1.7320508075688772}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 3}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 3.1622776601683795}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2.6457513110645907}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 2.449489742783178}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.6457513110645907}}, "df": 22}}}}}}, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}}}, "a": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 1, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.tokenization.load_vocab": {"tf": 1}}, "df": 4}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}}, "df": 2}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel": {"tf": 1}}, "df": 2}}}}}, "g": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "c": {"docs": {"canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.pop_max_vocab_size": {"tf": 1}}, "df": 14}, "t": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2.23606797749979}}, "df": 9}}}}, "s": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 2.23606797749979}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 2}, "canlpy.train.optimization.BertAdam.step": {"tf": 1}}, "df": 10}}, "c": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}}, "df": 1}}}, "l": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 3}}}, "o": {"docs": {}, "df": 0, "k": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 2}}, "w": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.tokenization.BasicTokenizer": {"tf": 1}, "canlpy.core.util.tokenization.BasicTokenizer.__init__": {"tf": 1.4142135623730951}}, "df": 2}}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.file_utils.read_set_from_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2}}, "df": 2, "a": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.bert.model.DenseSkipLayer": {"tf": 1}, "canlpy.core.models.bert.model.BertLayer": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.init_weights": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 15}}, "s": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}}, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 12, "s": {"docs": {"canlpy.core.models.knowbert.metrics.F1Metric": {"tf": 1}}, "df": 1}, "[": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}, "b": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "y": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}, "m": {"docs": {"canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 2}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1.7320508075688772}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 4}, "r": {"docs": {"canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 1}}, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 2.6457513110645907}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 2.23606797749979}, "canlpy.train.optimization.BertAdam": {"tf": 1}}, "df": 20, "d": {"docs": {"canlpy.core.models.bert.model.BertEmbeddings": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayer": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieLayerMix": {"tf": 1}, "canlpy.core.models.ernie.components.ErnieEncoder": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForPreTraining": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForEntityTyping": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSTSB": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForSequenceClassification": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNQ": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 21}, "s": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}, "a": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 3}}}, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "g": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Metric.unwrap_to_tensors": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.from_files": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_tokens_to_ids": {"tf": 1}, "canlpy.core.util.tokenization.BertTokenizer.convert_ids_to_tokens": {"tf": 1}, "canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 9}}}}, "r": {"docs": {}, "df": 0, "l": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.util.file_utils.url_to_filename": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.filename_to_url": {"tf": 1}, "canlpy.core.util.file_utils.cached_path": {"tf": 1.4142135623730951}, "canlpy.core.util.file_utils.get_from_cache": {"tf": 1}}, "df": 5}}, "t": {"docs": {}, "df": 0, "f": {"docs": {"canlpy.core.models.knowbert.knowledge.read_embeddings_from_text_file": {"tf": 1}}, "df": 1}, "i": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.util.file_utils": {"tf": 1}}, "df": 1}}}}}}}}, "n": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1, "i": {"docs": {}, "df": 0, "q": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}}, "df": 1}}}, "o": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "[": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}}}}, "e": {"docs": {}, "df": 0, "x": {"docs": {}, "df": 0, "p": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 1.7320508075688772}}, "df": 1}}}}}}}}, "a": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "f": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "b": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.util.tokenization.WordpieceTokenizer.tokenize": {"tf": 1}}, "df": 1}}}}}}}}, "p": {"docs": {"canlpy.core.models.knowbert.knowledge.WordNetAllEmbedding": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 2}}, "j": {"docs": {}, "df": 0, "u": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.__init__": {"tf": 1}, "canlpy.core.models.knowbert.metrics.Average": {"tf": 1}, "canlpy.core.models.knowbert.metrics.WeightedAverage": {"tf": 1}, "canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary.set_from_file": {"tf": 1}}, "df": 7}}}, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.load_from_json": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertConfig.to_json_string": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.load_from_json": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieConfig.to_json_string": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1.4142135623730951}, "canlpy.core.models.ernie.model.ErnieModel": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForMaskedLM": {"tf": 1}, "canlpy.core.models.ernie.model.ErnieForNextSentencePrediction": {"tf": 1}}, "df": 9}}}, "a": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "k": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}, "k": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 2}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.knowbert.metrics.CategoricalAccuracy": {"tf": 1}}, "df": 14, "n": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "w": {"docs": {}, "df": 0, "l": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "e": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 2}, "canlpy.core.models.cokebert.model.CokeBertModel.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge": {"tf": 1}, "canlpy.core.models.cokebert.model.DK_knowledge.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_knowledge.forward": {"tf": 1.7320508075688772}, "canlpy.core.models.cokebert.model.CokeBertForSequenceClassification.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForEntityTyping.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.CokeBertForMaskedLM.forward": {"tf": 1}}, "df": 16, "e": {"docs": {}, "df": 0, "n": {"docs": {}, "df": 0, "c": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "d": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.to_knowl_encoder_config": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1}}, "df": 2}}}}}}}}}}}}}}}, "w": {"docs": {}, "df": 0, "a": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "g": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.cokebert.model.PreTrainedCokeBertModel.from_pretrained": {"tf": 1}, "canlpy.core.models.ernie.model.PreTrainedErnieModel.from_pretrained": {"tf": 1}, "canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 3}}}}}, "e": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "p": {"docs": {"canlpy.core.models.knowbert.metrics.ExponentialMovingAverage": {"tf": 1.4142135623730951}, "canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 2}}, "y": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1.4142135623730951}}, "df": 1, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.load_state_dict": {"tf": 3.1622776601683795}}, "df": 1}, "e": {"docs": {}, "df": 0, "d": {"docs": {"canlpy.core.util.knowbert_tokenizer.vocabulary.Vocabulary": {"tf": 1}}, "df": 1}}}}, "b": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 2.23606797749979}}, "df": 1}}, "q": {"docs": {"canlpy.core.models.cokebert.model.CokeBertConfig.__init__": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder.forward": {"tf": 1}, "canlpy.core.models.cokebert.model.DKEncoder_layer.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DKEncoder_layer.forward": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.__init__": {"tf": 1.4142135623730951}, "canlpy.core.models.cokebert.model.DK_text.forward": {"tf": 1.4142135623730951}}, "df": 7, "u": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "s": {"docs": {}, "df": 0, "t": {"docs": {}, "df": 0, "i": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "n": {"docs": {"canlpy.core.models.ernie.model.ErnieForQuestionAnswering": {"tf": 1}, "canlpy.core.util.knowbert_tokenizer.vocabulary.namespace_match": {"tf": 1}}, "df": 2}}}}}}}}, "z": {"docs": {}, "df": 0, "e": {"docs": {}, "df": 0, "r": {"docs": {}, "df": 0, "o": {"docs": {}, "df": 0, "s": {"docs": {"canlpy.core.models.knowbert.model.KnowBert.forward": {"tf": 1}}, "df": 1}}}}}}}}, "pipeline": ["trimmer"], "_isPrebuiltIndex": true};

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();