{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from canlpy.core.models.knowbert  import KnowBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_is_correct(custom_model,test_set):\n",
    "    def custom_equal(a,b):\n",
    "        return torch.allclose(a,b, atol=1e-04)\n",
    "    custom_model.eval()\n",
    "    for test_case in test_set:\n",
    "        with torch.no_grad():\n",
    "            custom_output = custom_model(**test_case[\"input\"])\n",
    "            \n",
    "        expected_output = test_case[\"expected\"]\n",
    "\n",
    "        for key in test_case[\"expected\"].keys():\n",
    "            if(key in ['wiki','wordnet']):\n",
    "                print(f\"{key} entity_attention_probs are equal: {custom_equal(expected_output[key]['entity_attention_probs'],custom_output[key]['entity_attention_probs'])}\")\n",
    "\n",
    "                print(f\"{key} output linking scores are equal: {custom_equal(expected_output[key]['linking_scores'],custom_output[key]['linking_scores'])}\")\n",
    "            else:\n",
    "                if(key=='loss'):\n",
    "                    print(f\"{key} are equal : {expected_output[key]==custom_output[key]}\")\n",
    "                else:\n",
    "                    print(f\"{key} are equal : {custom_equal(expected_output[key],custom_output[key])}\")\n",
    "\n",
    "                    print(f\"{key} are equal : {custom_equal(expected_output[key],custom_output[key])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordnet entity_attention_probs are equal: True\n",
      "wordnet output linking scores are equal: True\n",
      "loss are equal : True\n",
      "pooled_output are equal : True\n",
      "pooled_output are equal : True\n",
      "contextual_embeddings are equal : True\n",
      "contextual_embeddings are equal : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Antoine/Documents/EPFL/MA2/NLP/canlpy/canlpy/core/components/fusion/knowbert_fusion/span_extractor.py:309: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1391.)\n",
      "  masked_vector = vector.masked_fill((1 - mask).byte(), mask_fill_value)\n"
     ]
    }
   ],
   "source": [
    "test_set = torch.load(\"knowbert_wordnet_model_test\")\n",
    "WORDNET_ARCHIVE = \"https://allennlp.s3-us-west-2.amazonaws.com/knowbert/models/knowbert_wordnet_model.tar.gz\"\n",
    "wordnet_model = KnowBert.from_pretrained(WORDNET_ARCHIVE)\n",
    "model_is_correct(wordnet_model,test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity\n",
      "Reading pretrained embeddings from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "470105it [00:52, 8947.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki entity_attention_probs are equal: True\n",
      "wiki output linking scores are equal: True\n",
      "loss are equal : True\n",
      "pooled_output are equal : True\n",
      "pooled_output are equal : True\n",
      "contextual_embeddings are equal : True\n",
      "contextual_embeddings are equal : True\n"
     ]
    }
   ],
   "source": [
    "WIKI_ARCHIVE = \"https://allennlp.s3-us-west-2.amazonaws.com/knowbert/models/knowbert_wiki_model.tar.gz\"\n",
    "wiki_model = KnowBert.from_pretrained(WIKI_ARCHIVE)\n",
    "test_set = torch.load(\"knowbert_wiki_model_test\")\n",
    "model_is_correct(wiki_model,test_set)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dd83c0049ca90416432c7bf31543fa4a43c6d1cbcb766d79372bfcb46406b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
