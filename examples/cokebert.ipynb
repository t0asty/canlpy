{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import tagme\n",
    "from canlpy.helpers.ernie_helpers import load_name_to_QID,load_QID_to_eid,process_sentences\n",
    "from canlpy.helpers.cokebert_helpers import load_k_v_queryR\n",
    "import pickle\n",
    "\n",
    "from canlpy.core.components.tokenization import BertTokenizer\n",
    "from canlpy.core.models.cokebert.model import CokeBertForMaskedLM\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "KNOWLEDGE_DIR = '../canlpy/knowledge/cokebert/kg_embed/'\n",
    "GRAPH_NEIGHBOR_DIR = '../canlpy/knowledge/cokebert/load_data_n/'\n",
    "PRE_TRAINED_DIR = '../canlpy/pretrained_models/cokebert'\n",
    "\n",
    "NAME_TO_QID_FILE = KNOWLEDGE_DIR + 'entity_map.txt'\n",
    "QID_TO_EID_FILE = KNOWLEDGE_DIR + 'entity2id.txt'\n",
    "EID_TO_VEC_FILE = KNOWLEDGE_DIR + 'entity2vec.vec'\n",
    "REL_TO_VEC_FILE = KNOWLEDGE_DIR + 'relation2vec.vec'\n",
    "\n",
    "ENT_AND_NEIGHBOR_FILE = GRAPH_NEIGHBOR_DIR + 'e1_e2_list_2D_Tensor.pkl'\n",
    "ENT_AND_RELATION_FILE = GRAPH_NEIGHBOR_DIR + 'e1_r_list_2D_Tensor.pkl'\n",
    "ENT_AND_INOUT_FILE = GRAPH_NEIGHBOR_DIR + 'e1_outORin_list_2D_Tensor.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = CokeBertForMaskedLM.from_pretrained(PRE_TRAINED_DIR)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ENT_AND_NEIGHBOR_FILE, 'rb') as f:\n",
    "    ent_to_neighbors = pickle.load(f)\n",
    "\n",
    "with open(ENT_AND_RELATION_FILE, 'rb') as f:\n",
    "    ent_to_relations = pickle.load(f)\n",
    "\n",
    "with open(ENT_AND_INOUT_FILE, 'rb') as f:\n",
    "    ent_to_outORin = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-trained model tokenizer (vocabulary)\n",
    "#Special tokenizer for text and entities\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_DIR)\n",
    "\n",
    "#Eg: 'Northern Ireland': 'Q26'\n",
    "name_to_QID = load_name_to_QID(NAME_TO_QID_FILE)\n",
    "#Eg: {'Q11456633': 4525438, 'Q8863973': 1628631}\n",
    "QID_to_eid = load_QID_to_eid(QID_TO_EID_FILE)\n",
    "\n",
    "#eid_to_embeddings = torch.load(EID_TO_VEC_FILE)\n",
    "vecs = []\n",
    "vecs.append([0]*100)\n",
    "with open(EID_TO_VEC_FILE, 'r') as fin:\n",
    "    for line in fin:\n",
    "        vec = line.strip().split('\\t')\n",
    "        vec = [float(x) for x in vec]\n",
    "        vecs.append(vec)\n",
    "embed_ent = torch.FloatTensor(vecs)\n",
    "ent_embed = torch.nn.Embedding.from_pretrained(embed_ent)\n",
    "#Creats a dictionnary of entity index->embeddings\n",
    "\n",
    "vecs = []\n",
    "vecs.append([0]*100) # CLS\n",
    "with open(REL_TO_VEC_FILE, 'r') as fin:\n",
    "#with open(\"kg_embed/relation2vec.del\", 'r') as fin:\n",
    "    for line in fin:\n",
    "        vec = line.strip().split('\\t')\n",
    "        vec = [float(x) for x in vec]\n",
    "        vecs.append(vec)\n",
    "r_embed = torch.FloatTensor(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sentence(text_a,text_b,model,tokenizer,masked_indices):\n",
    "\n",
    "    tokens_tensor,ents_tensor,ent_mask,segments_tensors = process_sentences(text_a,text_b,masked_indices,name_to_QID,QID_to_eid,ent_embed,tokenizer,device=device)\n",
    "\n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        #ents_tensor = ents_tensor+1\n",
    "        k_1, v_1, k_2, v_2 = load_k_v_queryR((ents_tensor + 1).to(torch.long), ent_to_neighbors, ent_to_relations, ent_to_outORin, embed_ent, r_embed, device)\n",
    "        predictions = model(tokens_tensor, ents_tensor, ent_mask, segments_tensors, k_v_s=[(k_1, v_1), (k_2, v_2)])\n",
    "\n",
    "        # confirm we were able to predict 'henson'\n",
    "        for masked_index in masked_indices:\n",
    "            predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "            predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "            print(f\"predicted_token for index {masked_index} is {predicted_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_a = \"Who was Jim Henson ? \"\n",
    "text_b = \"Jim Henson was a puppeteer .\"\n",
    "\n",
    "#tokens_tensor,ents_tensor,ent_mask,segments_tensors = process_sentences(text_a,text_b,masked_indices,name_to_QID,QID_to_eid,tokenizer)\n",
    "#tokens: ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '.', '[SEP]']\n",
    "masked_indices = [8,11,12]#henson, puppet, ##eer\n",
    "eval_sentence(text_a,text_b,model,tokenizer,masked_indices)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
