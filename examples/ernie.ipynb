{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import tagme\n",
    "from canlpy.helpers.ernie_helpers import load_name_to_QID,load_QID_to_eid,process_sentences\n",
    "\n",
    "from canlpy.core.util.tokenization import BertTokenizer\n",
    "from canlpy.core.models.ernie.model import ErnieForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "KNOWLEDGE_DIR = '../canlpy/knowledge/ernie/'\n",
    "PRE_TRAINED_DIR = '../canlpy/pretrained_models/ernie/ernie_base/'\n",
    "\n",
    "NAME_TO_QID_FILE = KNOWLEDGE_DIR+ 'entity_map.txt'\n",
    "QID_TO_EID_FILE = KNOWLEDGE_DIR+ 'entity2id.txt'\n",
    "EID_TO_VEC_FILE = PRE_TRAINED_DIR + 'entity2vec.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model,_ = ErnieForMaskedLM.from_pretrained(PRE_TRAINED_DIR)\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 103, 103, 1012, 102]\n",
      "predicted_token for index 8 is henson\n",
      "predicted_token for index 11 is popular\n",
      "predicted_token for index 12 is actor\n"
     ]
    }
   ],
   "source": [
    "#Suppose to predict hensen for idx 8\n",
    "def eval_sentence(text_a,text_b,model,tokenizer,masked_indices):\n",
    "\n",
    "    tokens_tensor,ents_tensor,ent_mask,segments_tensors = process_sentences(text_a,text_b,masked_indices,name_to_QID,QID_to_eid,eid_to_embeddings,tokenizer,device=device)\n",
    "\n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        predictions = model(tokens_tensor, ents_tensor, ent_mask, segments_tensors)\n",
    "\n",
    "        # confirm we were able to predict 'henson'\n",
    "        for masked_index in masked_indices:\n",
    "            predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "            predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "            print(f\"predicted_token for index {masked_index} is {predicted_token}\")\n",
    "\n",
    "#Load pre-trained model tokenizer (vocabulary)\n",
    "#Special tokenizer for text and entities\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_DIR)\n",
    "\n",
    "#Eg: 'Northern Ireland': 'Q26'\n",
    "name_to_QID = load_name_to_QID(NAME_TO_QID_FILE)\n",
    "#Eg: {'Q11456633': 4525438, 'Q8863973': 1628631}\n",
    "QID_to_eid = load_QID_to_eid(QID_TO_EID_FILE)\n",
    "\n",
    "eid_to_embeddings = torch.load(EID_TO_VEC_FILE)\n",
    "#Creats a dictionnary of entity index->embeddings\n",
    "eid_to_embeddings = Embedding.from_pretrained(eid_to_embeddings)\n",
    "\n",
    "text_a = \"Who was Jim Henson ? \"\n",
    "text_b = \"Jim Henson was a puppeteer .\"\n",
    "\n",
    "#tokens_tensor,ents_tensor,ent_mask,segments_tensors = process_sentences(text_a,text_b,masked_indices,name_to_QID,QID_to_eid,tokenizer)\n",
    "#tokens: ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '.', '[SEP]']\n",
    "masked_indices = [8,11,12]#henson, puppet, ##eer\n",
    "eval_sentence(text_a,text_b,model,tokenizer,masked_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dd83c0049ca90416432c7bf31543fa4a43c6d1cbcb766d79372bfcb46406b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
