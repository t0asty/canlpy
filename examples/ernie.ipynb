{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import tagme\n",
    "from canlpy.helpers.ernie_helpers import load_name_to_QID,load_QID_to_eid,process_sentences\n",
    "\n",
    "from canlpy.core.util.tokenization import BertTokenizer\n",
    "from canlpy.core.models.ernie.model import ErnieForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "KNOWLEDGE_DIR = '../canlpy/knowledge/ernie/'\n",
    "PRE_TRAINED_DIR = '../canlpy/pretrained_models/ernie/ernie_base/'\n",
    "\n",
    "NAME_TO_QID_FILE = KNOWLEDGE_DIR+ 'entity_map.txt'\n",
    "QID_TO_EID_FILE = KNOWLEDGE_DIR+ 'entity2id.txt'\n",
    "EID_TO_VEC_FILE = PRE_TRAINED_DIR + 'entity2vec.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model,_ = ErnieForMaskedLM.from_pretrained(PRE_TRAINED_DIR)\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ErnieModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): ErnieEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dense_intermediate): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (skip_layer_out): DenseSkipLayer(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dense_intermediate): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (skip_layer_out): DenseSkipLayer(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dense_intermediate): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (skip_layer_out): DenseSkipLayer(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dense_intermediate): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (skip_layer_out): DenseSkipLayer(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (dense_intermediate): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (skip_layer_out): DenseSkipLayer(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): ErnieLayerMix(\n",
      "        (attention_tokens): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (fusion): ErnieFusion(\n",
      "          (dense_intermediate_tokens): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_intermediate_ent): Linear(in_features=100, out_features=3072, bias=True)\n",
      "          (skip_layer_tokens): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer_ent): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): ErnieLayer(\n",
      "        (attention_tokens): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (attention_ent): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (key): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (value): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (fusion): ErnieFusion(\n",
      "          (dense_intermediate_tokens): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_intermediate_ent): Linear(in_features=100, out_features=3072, bias=True)\n",
      "          (skip_layer_tokens): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer_ent): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): ErnieLayer(\n",
      "        (attention_tokens): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (attention_ent): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (key): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (value): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (fusion): ErnieFusion(\n",
      "          (dense_intermediate_tokens): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_intermediate_ent): Linear(in_features=100, out_features=3072, bias=True)\n",
      "          (skip_layer_tokens): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer_ent): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): ErnieLayer(\n",
      "        (attention_tokens): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (attention_ent): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (key): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (value): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (fusion): ErnieFusion(\n",
      "          (dense_intermediate_tokens): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_intermediate_ent): Linear(in_features=100, out_features=3072, bias=True)\n",
      "          (skip_layer_tokens): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer_ent): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): ErnieLayer(\n",
      "        (attention_tokens): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (attention_ent): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (key): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (value): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (fusion): ErnieFusion(\n",
      "          (dense_intermediate_tokens): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_intermediate_ent): Linear(in_features=100, out_features=3072, bias=True)\n",
      "          (skip_layer_tokens): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer_ent): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): ErnieLayer(\n",
      "        (attention_tokens): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (attention_ent): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (key): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (value): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (fusion): ErnieFusion(\n",
      "          (dense_intermediate_tokens): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_intermediate_ent): Linear(in_features=100, out_features=3072, bias=True)\n",
      "          (skip_layer_tokens): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer_ent): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): ErnieLayer(\n",
      "        (attention_tokens): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (attention_ent): BertAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (query): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (key): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (value): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=100, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (fusion): ErnieFusion(\n",
      "          (dense_intermediate_tokens): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_intermediate_ent): Linear(in_features=100, out_features=3072, bias=True)\n",
      "          (skip_layer_tokens): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (skip_layer_ent): DenseSkipLayer(\n",
      "            (dense): Linear(in_features=3072, out_features=100, bias=True)\n",
      "            (LayerNorm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n",
      "BertOnlyMLMHead(\n",
      "  (predictions): BertLMPredictionHead(\n",
      "    (transform): BertPredictionHeadTransform(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm()\n",
      "    )\n",
      "    (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for _,module in model.named_children():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose to predict hensen for idx 8\n",
    "def eval_sentence(text_a,text_b,model,tokenizer,masked_indices):\n",
    "\n",
    "    tokens_tensor,ents_tensor,ent_mask,segments_tensors = process_sentences(text_a,text_b,masked_indices,name_to_QID,QID_to_eid,eid_to_embeddings,tokenizer,device=device)\n",
    "\n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        predictions = model(tokens_tensor, ents_tensor, ent_mask, segments_tensors)\n",
    "\n",
    "        # confirm we were able to predict 'henson'\n",
    "        for masked_index in masked_indices:\n",
    "            predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "            predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "            print(f\"predicted_token for index {masked_index} is {predicted_token}\")\n",
    "\n",
    "#Load pre-trained model tokenizer (vocabulary)\n",
    "#Special tokenizer for text and entities\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_DIR)\n",
    "\n",
    "#Eg: 'Northern Ireland': 'Q26'\n",
    "name_to_QID = load_name_to_QID(NAME_TO_QID_FILE)\n",
    "#Eg: {'Q11456633': 4525438, 'Q8863973': 1628631}\n",
    "QID_to_eid = load_QID_to_eid(QID_TO_EID_FILE)\n",
    "\n",
    "eid_to_embeddings = torch.load(EID_TO_VEC_FILE)\n",
    "#Creats a dictionnary of entity index->embeddings\n",
    "eid_to_embeddings = Embedding.from_pretrained(eid_to_embeddings)\n",
    "\n",
    "text_a = \"Who was Jim Henson ? \"\n",
    "text_b = \"Jim Henson was a puppeteer .\"\n",
    "\n",
    "#tokens_tensor,ents_tensor,ent_mask,segments_tensors = process_sentences(text_a,text_b,masked_indices,name_to_QID,QID_to_eid,tokenizer)\n",
    "#tokens: ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '.', '[SEP]']\n",
    "masked_indices = [8,11,12]#henson, puppet, ##eer\n",
    "eval_sentence(text_a,text_b,model,tokenizer,masked_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dd83c0049ca90416432c7bf31543fa4a43c6d1cbcb766d79372bfcb46406b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
